[{"categories":["SPFx"],"contents":"Introduction The disadvantages of typically writing long and detailed blogs is that it constantly raises the bar for the next blog post. Which leads to procrastination. So, I am going to try something different this time. I\u0026rsquo;m going to go back to how I started blogging: short posts that are intended to be a note to myself about something I always forget.\nBecause I am lazy, I don\u0026rsquo;t want to have to look it up every time.\nSo this post is going to be a #NoteToSelf about how to terminate batches quickly in VSCode. It may not be earth-shattering, or unique, and I\u0026rsquo;m sure that you can look it up easily, but I always forget. If you happen to find it useful, that\u0026rsquo;s great. If not, that\u0026rsquo;s fine too.\nThe problem When you run a batch task in VSCode, you often need to terminate it. When building SPFx solutions, this is especially true when you run gulp serve or npm run serve (if using fast-serve. Wait, you are using fast-serve, right?).\nWhen you terminate a batch task in VSCode (by hitting CTRL-C), you get a confirmation message that asks you if you are sure you want to terminate the batch. You need to hit \u0026ldquo;Y\u0026rdquo; to confirm, or hit CTRL-C again to terminate the batch. (Although, if you hit CTRL-C twice, you may end up in an endless loop where it prompts you again and again until you hit \u0026ldquo;Y\u0026rdquo;.)\nThe solution You can configure automatic response in the VS Code terminal with the use of some settings.\nHere\u0026rsquo;s how to do it:\nOpen the settings in VSCode (CTRL-,) or File \u0026gt; Preferences \u0026gt; Settings.\nIn the preferences search bar, search for autoreplies. Select Edit in settings.json.\nIn the settings.json file, add the following lines:\n\u0026#34;terminal.integrated.autoReplies\u0026#34;: { \u0026#34;Terminate batch job (Y/N)\u0026#34;: \u0026#34;Y\\r\u0026#34; } Save the file.\nNext time you get prompted to terminate a batch job, it will automatically respond with \u0026ldquo;Y\u0026rdquo; and terminate the batch.\nYou can add more auto-replies for other prompts as well.\nConclusion That\u0026rsquo;s it. Now you can terminate batches twice as fast in VSCode.\nI told you it was gonna be a quick one!\nI hope this helps?\n","permalink":"http://localhost:1313/posts/terminate-batch-quickly-in-vscode/","tags":["VSCode","Node.js","Gulp","NPM","NoteToSelf"],"title":"Terminate batches quickly in VSCode"},{"categories":null,"contents":"Introduction I use NVS to switch between different versions of Node.js on my development workstation. It is a great tool, and I have been using it for a while now. But recently, I ran into an issue using Teams Toolkit to build a Copilot plugin.\nThe toolkit requires Node.js to be installed on the workstation. But I had not installed any version of Node.js on my workstation. I had only installed NVS. So, I was getting an error when I tried to create a new project using the toolkit, saying that Node.js was not a valid command.\nNVS works great when you launch a terminal from within VSCode, or when you launch an instance of the command prompt / Windows Terminal. When you launch VSCode, however, it does not have the context of the latest version of Node.js you used with NVS. When you launch Teams Toolkit (which needs Node.js), it does not have the context of the latest version of Node.js you used with NVS either.\nThe Fix I had to install Node.js using NVS. I did that by running the following command in the terminal:\nnvs link [version] \u0026hellip;where [version] is the version of Node.js you want to install. For example, I ran the following command to install Node.js version 18.18.0:\nnvs link 18.18.0 This will set up the \u0026lsquo;default\u0026rsquo; version of Node.js to be used by NVS.\nNow, when I launch VSCode, it will have the context of the latest version of Node.js I used with NVS. When I launch Visual Studio Code \u0026ndash; with Teams Toolkit within it \u0026ndash; it will have a default version of Node.js.\nPhoto Credit Image by Eva Michalkova from Pixabay\n","permalink":"http://localhost:1313/posts/using-teams-toolkit-with-nvs/","tags":["VSCode","TeamsToolkit","Node.js","nvs","NoteToSelf"],"title":"Using Teams Toolkit with NVS"},{"categories":["SPFx"],"contents":"Introduction Here the deal: I am lazy. I don\u0026rsquo;t want to have to remember to switch to the right version of Node.js every time I open an SPFx solution in VSCode. I want it to be automatic. I want it to be lazy.\nThis solution works in Windows, but I am sure you can adapt it to other platforms.\nThe problem When you open an SPFx solution in VSCode, you need to make sure you are using the right version of Node.js. If you don\u0026rsquo;t, you will get a nasty error message.\nAnd every version of SPFx potentially requires a different version of Node.js. If you manage multiple SPFx solutions, you may need to switch between different versions of Node.js several times a day.\nSure, you can look up the appropriate version of Node.js for every version of SPFx, and load it when you open a solution (and there is a great resource to do so). But that is a lot of work. And it is boring. And I am lazy.\nAnd even if you are not as lazy as I am, it takes extra time, and potentially leads to errors.\nAnd, technically, you can only have one version of Node.js installed at once. So you need to uninstall the current version, and install the new version.\nThe solution Use a node version manager The solution is to use a node version manager. A node version manager allows you to switch back and forth between versions of Node.js without uninstalling and re-installing.\nThere are several options, but the two most popular ones are nvm, nvs and Volta.\nI use nvs (I\u0026rsquo;ll explain why in a second), but the instructions below should work with the other version managers as well.\nnvs is a cross-platform version manager, and it is easy to install. The best part, however, is that you don\u0026rsquo;t need to have administrator access to your workstation to install it, and you don\u0026rsquo;t need to have administrator access to install new versions of Node.js. This is important if you are working in a corporate environment where you don\u0026rsquo;t have administrator access to your workstation.\nThe only downside is that nvs forgets what version of Node.js you\u0026rsquo;re using every time you open a new command prompt. But that\u0026rsquo;s kinda the point, isn\u0026rsquo;t it?\nBut again, feel free to use whatever version manager you want. I\u0026rsquo;m not judging.\nAssociate a version of Node.js with a solution The next step is to remember which version of Node.js you need for each solution. You can do this by creating a .nvmrc file in the root folder of your solution. The .nvmrc file is a simple text file that contains the version of Node.js you want to use for that solution. Most version managers understand how to use this file.\nTo generate the .nvmrc file, you can use the following command:\nnode -v \u0026gt; .nvmrc This will create a .nvmrc file in the root folder of your solution, containing the version of Node.js you are currently using.\nIt looks a little bit like this:\nv20.6.0 You can also write 20.6.0 without the `v`` letter, it\u0026rsquo;ll will work just fine.\nOnce your .nvmrc file is created, you can use the following command to load the right version of Node.js:\nnvs use For nvm, you\u0026rsquo;d use the following command:\nnvm use It\u0026rsquo;ll magically look up the version of Node.js you need, and load it for you.\nNote to Windows and nvs users if you get an error message saying that your version string is invalid, it may be due to the way that Windows encodes files. Use the following command to fix the file encoding:\n[string]::Join( \u0026#34;`n\u0026#34;, (gc .nvmrc)) | sc .nvmrc Automatically load the right version of Node.js when you open a solution Now that you have a version manager installed, and you have associated a version of Node.js with your solution, you need to make sure that the right version of Node.js is loaded when you open a solution in VSCode.\nTo do this, I prefer to use solution settings in VSCode. Solution settings are stored in a .vscode folder in the root folder of your solution. You can create a settings.json file in that folder, and add the following setting for PowerShell and nvs:\n{ \u0026#34;terminal.integrated.profiles.windows\u0026#34;: { \u0026#34;PowerShell\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;PowerShell\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;terminal-powershell\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;-NoExit\u0026#34;, \u0026#34;-Command\u0026#34;, \u0026#34;nvs use\u0026#34; ] } } } Feel free to update the command to use the version manager of your choice.\nThe .vscode file is usually ignored by GitHub, so you\u0026rsquo;ll have to look for it in the .gitignore file, and remove it if you use GitHub to store your code.\nIf you use nvm, you can use the VSCode extension that automatically loads the right version of Node.js when you open a solution.\nConclusion There you go. Now you can be as lazy as I am, and automatically load the right version of Node.js when you open an SPFx solution in VSCode.\nCould I have use other approaches? Sure. But this one works for me.\nWhat about you? How do you manage multiple versions of Node.js? Let me know in the comments.\nPhoto Credit Photo by G.C. from Pixabay\n","permalink":"http://localhost:1313/posts/associate-node-version-with-spfx-solution/","tags":["VSCode","Node.js","nvm","nvs","NoteToSelf"],"title":"Associate Node.js version with your SPFx solutions"},{"categories":["Life"],"contents":"In October of 2021, I decided to switch from a WordPress-based blog to a Hugo-based site. I mean, how can I not?!\nI made a backup of my site. Set up my new site, and decided that it was a good time to review and update my site\u0026rsquo;s look and feel, and content.\nBut first, I had to prepare for the Microsoft 365 Conference in December, then the one in April.\nOf course, my WordPress subscription expired while I was in Vegas, and my old content wasn\u0026rsquo;t moved. \u0026ldquo;I\u0026rsquo;ll get to it when I get home\u0026rdquo;, I foolishly told myself.\n\"I'll get to it when I get home\"\rA foolish me\rBut, shortly after I got home, I heard the good news that I got the new job of Community Program Manager for Power Pages (which was not yet announced).\nBetween then and my official start date in my new role, I\u0026rsquo;d have to start planning from my old role as a Senior Cloud Solution Architect; I\u0026rsquo;d also be helping (albeit in a non-official capacity) prepare for the launch of the new Microsoft Power Pages Community.\nOh, and somewhere during that whole time I was busy helping with the creation (and the migration) of the Microsoft 365 Platform Community Blog, adding development containers to the [SPFx Web Parts repository], and working on some new Sharing is Caring sessions.\nBut things are finally getting back to normal \u0026ndash; a little.\nTwo weeks ago was my first day in my new role. I had to travel to Seattle (for the first time in over 10 years) so I could meet my new team.\nCame back last week. Tested positive for COVID. Rested \u0026ndash; probably more than I have in many, many years \u0026ndash; and now I\u0026rsquo;m fixing my blog while fighting a fever (the pink elephants are telling me I\u0026rsquo;m doing a fine job, by the way).\nI\u0026rsquo;ll do my best to migrate all my old content \u0026ndash; starting with the most frequently-visited content first \u0026ndash; and keep the original URLs the same.\nBut until then, thank you for being patient.\nAlso, thank you for reaching out to tell me that my blog is down. I knew that people visited my blog (because I saw the traffic stats), but I never quite realized that those \u0026ldquo;visitors\u0026rdquo; on my site stats were from real people in the community.\nAnd I certainly never expected to receive so many messages from people telling me that they always rely on my site for so many things.\nFor something that started as a place to leave notes for myself, I am quite flattered that others find my ramblings useful.\nThank you! As I get back on my feet, so will the content on my blog!\nPhoto Credits Photo by Pierre Bamin on Unsplash\n","permalink":"http://localhost:1313/posts/migrating/","tags":null,"title":"Wait... where did all the content go?!"},{"categories":["Productivity"],"contents":"Introduction If you\u0026rsquo;ve ever tried to give a PowerPoint presentation and switch to your desktop to do a demo, you may have noticed that PowerPoint tends to fight with you to stay in slide show mode.\nSlide show mode shows your presentation in full screen, but it hides your cursor and captures your keyboard and mouse. If you want to get out of it to do your demo, you have to hit Esc, and Alt-Tab to your demo. Then you have to go back to your presentation, restart the slide show (and often restart at the first slide by mistake).\nUgh!\nYou usually end up fighting with Alt-Tab (and potentially reveal to your audience what other applications you\u0026rsquo;ve got running and/or show your private chats to the world \u0026ndash; like I\u0026rsquo;ve done), or end up showing your presentation in PowerPoint without using the slide show (I\u0026rsquo;m looking at you, Microsoft employees!)\nIn today\u0026rsquo;s post, I\u0026rsquo;ll explain how you can use the slide show mode and make it easy to switch back and forth between your demo and your presentation.\nAs a bonus, I\u0026rsquo;ll show you how you can also keep Teams open and monitor the chat window as you present.\nUsing Presenter Mode in PowerPoint First things first: use the slide show mode!!!. When you present to your audience, you\u0026rsquo;re competing for their attention and trying to get them to focus on what you\u0026rsquo;re showing. They\u0026rsquo;re already fighting to stay awake and will probably look at everything on your slides. If you\u0026rsquo;re just showing your slides in PowerPoint without the slide show mode, you\u0026rsquo;re making harder on your audience to focus and stay engaged. They see all the slides in your deck (\u0026ldquo;Oh my god, he\u0026rsquo;s got 37 slides! We\u0026rsquo;ll never get out of here!\u0026rdquo;), all the ribbons and buttons (\u0026ldquo;Ooh, I wander what the Design Ideas button does?!\u0026rdquo;), and you make the content on your slides smaller.\n(Just so we\u0026rsquo;re clear: this is not cool!)\nDon\u0026rsquo;t you want to be respectful to your audience and save them from boredom? They certainly want you to!\nTo launch your PowerPoint presentation in slide show mode, you just need to hit F5 from anywhere in your presentation. It\u0026rsquo;ll start your slides full-screen (unless you use a custom slide show, but that\u0026rsquo;s another story).\nIf you want to start from the current slide you\u0026rsquo;re editing, you can simply hit Shift-F5.\nTo get out of the slide show mode, hit Esc.\nSo far, this is probably obvious to you (except, maybe, if you\u0026rsquo;re a Microsoft employee, who apparently forget about the F5 key as soon as they join Microsoft 😊).\nThe hard part comes next: how to you easily switch between your slide show mode to your demo (without getting out of your slide show)?\nUsing Desktops As it turns out, the solution is built-in into Windows 10: just use desktops.\nTo get to desktops, just hit the Task View from your task bar.\nYou should begin with only one desktop. To create a new one, select + New desktop at the top of the Task View.\nOnce you have created your new desktop, your task view will allow you to switch back and forth between desktops.\nTo switch between desktops quickly, just use Ctrl-Win-→ and Ctrl-Win-← to go to your next or previous desktops.\nNow that you know how to switch between desktops, let\u0026rsquo;s set them up for your presentation.\nSetting up the desktops I like to set up my desktops as follows:\nThe Default desktop is where I\u0026rsquo;ll run PowerPoint from. The Demo desktop is where the code that I\u0026rsquo;ll demo will be running from. NOTE: You can rename the desktops from the task view by clicking on their names and typing a new name\nDuring my presentation, I\u0026rsquo;ll launch PowerPoint is slide show mode on the default desktop; when I\u0026rsquo;m ready to show the demo, I\u0026rsquo;ll switch to my demo desktop without leaving the slide show mode!\nFor example, in this screen capture below, I go from my PowerPoint slide (which says \u0026ldquo;Demo\u0026rdquo;) to the web page containing the web parts I am demoing.\nSometimes I\u0026rsquo;ll add another desktop to pre-load Visual Studio Code, or one for each of my clients where I place all my windows related to a client so I don\u0026rsquo;t have to close all my apps before I start presenting.\nAll you need to do is to send your apps from the task view to another deskop.\nHere\u0026rsquo;s how\nFrom the Windows task bar, start the task view From the task view, right-click on an app you want to move between desktop Select Move to\u0026hellip; and select the name of the desktop where you want the app to appear. In my case, I\u0026rsquo;ll select Demo. That\u0026rsquo;s it!\nKeeping Teams visible on all desktops There is one disadvantage to using desktops: if you use Teams to connect to a meeting and watch the meeting video and/or chat window, and Teams is on your default desktop, it disappears when you switch to another desktop.\nThankfully, David Warner II \u0026ndash; who is the master of presentation tips \u0026ndash; there is a way you can make Teams (or any other apps) appear on all desktops, regardless of which one is currently displayed.\nTo do so, follow these steps:\nForm the task view, right-click on Teams (or the app you want to appear on all desktops) From the context menu, select Show this window on all desktops (or, if you want the window and all the pop-up chat windows and other dialog, select Show windows from this app on all desktops) When you switch desktops, Teams will remain visible!\nConclusion I hope that you\u0026rsquo;ll find slide show mode and desktops useful when doing your presentations.\nDo you use desktops in any other creative ways? Let us know in the comments.\nPhoto Credit Photo by Jeffrey Hamilton on Unsplash\n","permalink":"http://localhost:1313/posts/from-powerpoint-to-demos-easily-with-desktops/","tags":null,"title":"From PowerPoint to Demos Easily With Desktops"},{"categories":["GitHub"],"contents":"Introduction I apologize: when I write blog posts, I like to be very detailed. I tend to be very verbose.\nThis is a summary of my much longer GitHub cheat sheet for PnP contributions, but without all the explanations.\nIf you need help to get started, I suggest you read the full article.\nOtherwise, enter your information below and we’ll automatically generate all the GitHub commands you need to get started on a PnP contribution.\nCustomize this article This article will automatically change the instructions to reflect the parameters you enter below.\nVariable Value Original Repository(Upstream) Your GitHub username Start branch name(default is main) Branch name Step 1: Fork repository In your browser go to the repository where you want to contribute (https://github.com/pnp/sp-dev-fx-webparts). In the upper right corner, select the Fork button\nGitHub will automatically begin the forking process. You get a cute little animation showing that it is \u0026ldquo;copying\u0026rdquo; the repository, and you end up in your own copy of the repository.\nYou’ll know that you’re in a fork because the owner will have changed to you, and it should say \u0026ldquo;forked from …\u0026rdquo;\nStep 2: Clone repository From your computer, launch whatever tool you like to run Git commands. Some people like Git Bash, but I prefer Cmder or the Node.js command prompt.\nMake sure that your command prompt is in the directory where you’ll want to create your local repositories. I like to use c:\\github. You can do so by typing:\ncd \\github\rThe repository you will clone will be created a directory within your current directory. To clone the repository, type the following:\ngit clone https://github.com/[your_github_username]/sp-dev-fx-webparts.git\rIt should create a directory with the same name as your repo, then should download all the files locally to that directory.\nOnce your local repo is created, change to the new directory by typing:\ncd sp-dev-fx-webparts\rTo link your local repo with the original upstream repo, you’ll type the following:\ngit remote add upstream https://github.com/pnp/sp-dev-fx-webparts.git\rBefore you start making changes, you should make sure that you have the latest version from the original upstream repository by typing:\ngit fetch upstream\rStep 3: Create a branch To create your branch, follow these steps:\nUpdate your local repository with the latest changes from the upstream repository by typing the following:\ngit pull upstream main:my-feature\rNow we’ll let your forked origin repo know about the new branch you’ve created by typing:\ngit push origin my-feature\rSwitch to the new branch you’ve created by typing the following:\ngit checkout my-feature\rNow you’re ready to contribute!\nSummary of commands — steps 2-4 Here are all the commands from steps 2-4. You can just copy and paste all the lines below and run them all at once.\ngit clone https://github.com/hugoabernier/sp-dev-fx-webparts.git\rcd sp-dev-fx-webparts\rgit remote add upstream https://github.com/pnp/sp-dev-fx-webparts.git\rgit pull upstream main:my-feature\rStep 4: Contribute Now that you have your own branch, you can make the changes you need. Please make sure you follow the Microsoft Open Source code of conduct.\nIf you aren’t sure about the code of conduct, you can also check out the Code of Conduct FAQ.\nOnce you’re done making your changes, you’ll want to push your contributions.\nStep 5: Push your changes You can do so by following these steps:\nFrom the local branch folder, type:\ngit add .\rCommit your changes by typing:\ngit commit -v -a -m \u0026quot;Initial commit\u0026quot;\rPush your changes to your origin repository, as follows:\ngit push origin my-feature\rSummary of commands — step 5 Here are all the commands from this step . You can just copy and paste all the lines below and run them all at once.\ngit add .\rgit commit -v -a -m \"Initial commit\"\rgit push origin my-feature\rStep 6: Submit a pull request When you’re ready, open your pull request by following these steps:\nUse your browser to go to: .\nYou’ll be prompted to confirm the branches you want to merge, with an arrow going from one branch to another. Make sure that the arrow is pointing from your branch on your forked repo to the branch on the remote repo. If you follow all the steps above, you should also see Able to merge.\nProvide a descriptive title for your pull request. For example, My feature Most PnP repositories have a pull request template. Please be courteous and follow the template instructions. Follow the prompts and answer as much as possible. If there are sections that say \u0026gt; _(DELETE THIS PARAGRAPH AFTER READING)_, delete them. When you have filled the template, click Create pull request. Remember that the people who review — and ultimately approve or reject — your pull request are often volunteers who are most likely bombarded with notifications from GitHub on top of their every-day jobs. Filling the template will make it easier for them to process your pull request faster.\nAfter you’ve completed your pull request, you’ll see that its status is marked as Open\nAll you have to do now is to wait for your pull request to be merged.\nIt can take a few days, sometimes weeks before your pull request is approved. Please be patient; Most reviewers are volunteers and have a day-to-day job.\nWhile you’re waiting, you can start a new contribution!\nStep 7: Repeat If you want to continue making contributions, you simply create a new branch from the original base branch. For example, if you were created the second update to your my-feature, you could call your next branch my-next-feature.\nCustomize this article Enter the name of the next branch you want to create, and we’ll update the instructions for you:\nVariable Value Next branch name To create your next branch, follow these steps:\nType the following:\ngit pull upstream main:my-next-feature\rPush your new branch by typing:\ngit push origin my-next-feature\rFinally, switch to your new branch by calling:\ngit checkout my-next-feature\rOnce your next branch is created, continue contributing as you did before (contribute, push your changes, submit a pull request).\nSummary of commands — step 7 Here are all the commands from this step . You can just copy and paste all the lines below and run them all at once.\ngit pull upstream main:my-next-feature\rgit push origin my-next-feature\rgit checkout my-next-feature\rDeleting your branch Once your pull request has been approved and merged to the main, you can delete your branch. Do not delete your branch before it has been approved — just in case you need to make a change to your pull request before it has been approved.\nTrust me on this one.\nConclusion I hope that this article will make it easier for you to contribute to PnP repositories.\nUpdates July 2, 2022: Updated default branch to main April 26, 2021: Updated to use PnP instead of SharePoint GitHub organization April 21, 2020: Thanks to Daniel Westerdale for pointing out that I had made a mistake in my code. Photo credits Image by Pete Linforth from Pixabay\n","permalink":"http://localhost:1313/posts/summarized-github-cheat-sheet-for-pnp-contributions/","tags":["PnP","GitHub"],"title":"Summarized GitHub cheat sheet for PnP contributions"},{"categories":["Productivity"],"contents":"Introduction Ugh. I was useless today: my internet was down for most of the day and I was powerless.\nI tried to make myself useful by writing blog posts that I have been meaning to write for a long time (it has been a long time, hasn\u0026rsquo;t it?!).\nIf you\u0026rsquo;re like me, you probably have a bazillion accounts on various Microsoft 365 tenants. I have one for each of my clients, sometimes two (one is a regular user, one is an admin user), plus one for each of my developer tenants, my MVP tenant, and one for when I collaborate with the nicest, most hard-working MVP that I know.\nI have already shared how to use Edge profiles to log on to different tenants and even how to add custom images for each profile, but today I\u0026rsquo;ll show you the next step: creating shortcuts to launch an instance of the Edge browser as a different profile.\nIf you use an Elgato Streamdeck, I\u0026rsquo;ll also show you how you can create keys to launch your browser as a different profile from your Streamdeck.\nCreating a shortcut to launch Edge as a different profile For these instructions, I\u0026rsquo;ll assume that you already have more than one profile on Edge. If you don\u0026rsquo;t, please follow my instructions and come back when you\u0026rsquo;re done. I\u0026rsquo;ll be right here.\nI recently moved to a new computer and I haven\u0026rsquo;t migrated all my accounts yet, but I\u0026rsquo;ll the profiles that I already have set up as an example.\nLet\u0026rsquo;s say that I want to create a shortcut to launch the browser to my Warner.Digital tenant. I\u0026rsquo;d use the following steps:\nBefore we start, we need to know the location of the shortcut we want to create. The shortcut we need consists of three components: [path to your Edge executable] [profile flag] [url]. I usually open a file in Notepad to write down my shortcut path. The first part is easy: you want to find where the Edge executable is installed on your computer. It is most likely \u0026quot;c:\\program files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\u0026quot;, but we\u0026rsquo;ll confirm it in the next step. The second part of your shortcut is the profile flag. It usually consists of the following: --profile-directory=\u0026quot;Your profile directory\u0026quot;. To find your profile directory, follow these steps: Launch Edge under the profile you wish to use. I\u0026rsquo;m going to use my Warner Digital one for this example While running as the Edge profile you want, in the address bar, type: edge://version and hit Enter In the page that appears, you should find the path to your Edge installation under Executable path, and the path to your profile, under Profile path. NOTE: You may be tempted to use the value from Command-line, but it always points to the wrong profile path \u0026ndash; at least in the version of Edge that I\u0026rsquo;m currently using.\nYou only need the last part after the last \\ of your Profile path. For example, my profile path is D:\\Users\\hugoa\\AppData\\Local\\Microsoft\\Edge\\User Data\\Profile 4, so I\u0026rsquo;ll use Profile 4 We have what we need for the first two parts of your shortcut! My shortcut to launch my Warner Digital profile would be \u0026quot;C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\u0026quot; --profile-directory=\u0026quot;Profile 4\u0026quot;. Note that if your profile path has any spaces in it, you\u0026rsquo;ll want to use double quotes (\u0026quot;), like I did in mine. If you just want your shortcut to open to a blank tab (or whatever is your default start page for that profile), you don\u0026rsquo;t need to add anything else. However, if you want to launch a particular URL, just add a space, followed by whatever URL you want. For example, to launch SharePoint in the Warner Digital tenant, I\u0026rsquo;d use: \u0026quot;C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\u0026quot; --profile-directory=\u0026quot;Profile 4\u0026quot; https://warnerdidigal.sharepoint.com Once you have your shortcut path ready, you can use whatever approach you want to create the shortcut. If you want to create shortcuts for your Elgato Streamdeck, just use the path as is (see below). To create a new Windows shortcut, use these steps: In Windows, go to the location where you want your shortcut to be created and select New \u0026gt; Shortcut In the Create Shortcut dialog, you\u0026rsquo;ll be prompted to enter the location of the new item. , just past your new shortcut path and select Next Give your new shortcut a name, for example I used Warner Digital and select Finish. That\u0026rsquo;s all you need! You should be able to add the shortcut to your Start Menu, your task bar, or anywhere on your desktop.\nCreating Shortcuts to open Teams (web-based) using different profiles This is so easy, it probably doesn\u0026rsquo;t warrant a section, but I\u0026rsquo;ll say it anyway: you just need to need to make the URL portion of your shortcut https://teams.microsoft.com.\nThat\u0026rsquo;s it.\nSo, to open Teams in my Warner Digital profile, my shortcut would be: \u0026quot;C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\u0026quot; --profile-directory=\u0026quot;Profile 4\u0026quot; https://teans.microsoft.com\nCreating a shortcut to call/chat with someone using Teams on a specific profile Also pretty easy, but I thought I\u0026rsquo;d share. Just make the URL portion of the shortcut https://teams.microsoft.com/l/chat/0/0?users=, followed by the email address of the user (or users) you want to chat with.\nFor example, to chat with David Warner, I\u0026rsquo;d use: \u0026quot;C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\u0026quot; --profile-directory=\u0026quot;Profile 4\u0026quot; https://teams.microsoft.com/l/chat/0/0?users=david.warner@fakeemail.com\nTo chat with David Warner and Luise Freese, I\u0026rsquo;d use: \u0026quot;C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\u0026quot; --profile-directory=\u0026quot;Profile 4\u0026quot; https://teams.microsoft.com/l/chat/0/0?users=david.warner@fakeemail.com,luise.freese@fakeemail.com\nLaunching a regular meeting using a profile Just like the previous tips, this one is pretty straight forward. Copy the URL from the join link of a Teams meeting, and add it as the URL portion of your shortcut.\nFor example, if I wanted to join the bi-weekly SPFx special interest group community call using my regular profile, I\u0026rsquo;d use: \u0026quot;C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\u0026quot; --profile-directory=Default https://aka.ms/spdev-spfx-call-join\nBONUS SECTION: Putting it all together on an Elgato Streamdeck I have a 15-key Elgato Streamdeck and I really enjoy it. I should probably get myself the XL Stream Deck one of these days\u0026hellip;\nOne thing that many people don\u0026rsquo;t know (I myself learned it from David Warner, who is the king of gadgets) is that you can create folder buttons on your Streamdeck. Your folder can contain a different set of buttons \u0026ndash; or even more folders!\nTo create a folder in Stream deck:\nLaunch your Stream Deck application In the right pane, search for folder and select Create folder from the Stream Deck group Drag the Create folder icon to a blank button on your Stream Deck. After you drop the Create folder icon on a button, it will create a new folder for you. While the new button is selected, you can edit the folder\u0026rsquo;s title or icon, if you wish. If you click on the newly created folder, it will open into the new folder where you can add new buttons or more folders. You can also click on the back arrow icon (on the top left button in the folder) to go back one level. Theoretically, you could create an infinite number of folders with buttons\u0026hellip; so the possibilities are endless.\nHere\u0026rsquo;s how I use my Streamdeck. I\u0026rsquo;m sure there are plenty of other ways to set it up, but this is how I like to set mine up:\nAt the root, I have folder for Edge profiles, one for Teams instances, and one for regular Meetings\nIn my Edge folder, I have all my most frequently used profile. The ones I use for my clients and my personal tenants.\nIn my Teams folder, I have all my frequent Teams clients that I use.\nAnd, finally, in my Meetings folder, I have all the join links for all my regular meetings, as well as some frequent chat buttons.\nOf course, I make sure to select fun icons so I can easily identify which button is for what meeting \u0026ndash; complete with a warrior horse animated GIF for the General Microsoft 365 Special Interest Group bi-weekly call, because: Chris Kent.\nYou may wonder: why wouldn\u0026rsquo;t I just create a folder for each client/team I work with and put my Edge, Teams, and meetings buttons in each client folder? Sometimes I work with more clients than I have buttons available, and I still want to have enough room to have my ZoomIt, PowerPoint presentation, light control, and sound control buttons :-(\nConclusion I hope that this will help you making the most of shortcuts with Edge profile.\nDo you use Edge profile in creative ways? Let me know in the comments.\n","permalink":"http://localhost:1313/posts/launching-edge-with-different-profiles-using-shortcuts/","tags":["streamdeck","microsoftedge","windows"],"title":"Launching Edge with different profiles using shortcuts"},{"categories":["Public speaking"],"contents":"Introduction I’m not a great presenter.\nI have been working in IT for over thirty years, during which time I have done many technical demos… and failed many of them.\nHowever, I’m always trying to improve myself. Since I started presenting regularly on the PnP community calls and the demos are posted on YouTube, I reached out to Andrew Benson (who does an amazing job editing and publishing the videos) for his help with a demo checklist that I can use to improve the quality and consistency of my demos.\nI hope that this checklist will help someone else preparing for their technical demos.\nLet’s get one thing straight, though: I’m not sharing this list because I think I’m an awesome presenter (I’m not), but because I hope that it’ll help others who — like me — are on a continued journey to improve their presentation skills.\nIf you have other tips you’d like to share, feel free to use the comments section.\nGetting your environment ready Headset PC fans are noisy. When you use a microphone, the fan sound is often picked up by the microphone.\nUnless you’re a professional broadcaster with a fancy microphone, you should use a headset.\nHeadsets are great because they keep your microphone a constant distance from your mouth.\nIf you use a wireless headset, make sure it is charged before your presentation. Alternatively, use a wired headset so you don’t have to worry about batteries.\n(I use a Jabra Evolve 75, which seems to be adequate for me)\nMicrophones Internal In a pinch, you can use your built-in microphone on your computer, but keep in mind that you’ll sound far away, and your microphone will pick up every sound in the room. When I review old demos I did with my Surface Studio 2’s built-in microphone, I can hear when I move my mouse and my keyboard clacking as I type on it.\nExternal According to Andrew, you should use XLR – vocal/speech microphones. Avoid using USB mics because of the lousy sound quality.\nIf you’re going to buy a microphone, here’s Andrew’s recommendations from low cost to higher end:\nShure SM57/58 ($100) Shure SM7B / ElectroVoice RE20 ($400-$500) AT4050 / Neumann TLM 102 ($600-$800) Neumann U87 ($3,000+) Speakers If you aren’t using a headset, make sure that your speakers aren’t too loud so that you don’t generate echo when you speak.\nVideo camera Internal Your built-in PC camera is probably adequate — just make sure that you elevate your PC so that the audience can get a straight view of you (instead of a view of inside your nostrils).\nExternal 720p or 1080p HD is plenty — no need for 4k. Teams does not conference or stream 4K, so your picture quality will be lowered to 1080p anyway.\nAndrew recommends a 1080p webcam with a built-in tripod so you can position the camera on a stable surface rather than straddling on your unstable laptop screen.\nBackground While they are cool, avoid using background effects. You should strive to appear as real and natural as if you were in the same room. With backgrounds, you often appear like a cut-out. With that being said, my office is also used for storage, so I always have a background on.\nMost importantly, it makes it a lot harder to subtly cut and splice videos when you use background effects.\nScreen resolution If you’re going to be demoing something, your screen resolution is pretty important.\nLet’s put it plainly: it does not matter whether you use 720p or 1080p; the key is to use a 16:9 ratio.\nHere is a list of resolutions that will provide a 16:9 ratio:\nResolution Examples Dimensions Wide XGA (WXGA-H) Minimum, 720p HDTV 1280×720 Full HD (FHD) 1080 HDTV (1080i, 1080p) 1920×1080 Wide Quad HD WQHD Dell UltraSharp U2711, Dell XPS One 27, Apple iMac 2560×1440 Wide QXGA+ (WQXGA+) HP Envy TouchSmart 14, Fujitsu Lifebook UH90/L, Lenovo Yoga 2 Pro 3200×1800 4K Ultra HD 1 (4K UHD-1) 2160p, 4000-lines UHDTV (4K UHD) 3840×2160 8K Ultra HD 2 (8K UHD-2) 4320p, 8000-lines UHDTV (8K UHD) 7680×4320 Please note that if you use a higher resolution, you need to make sure that all font sizes are big enough for everyone in the audience to be able to read your text.\nWhen using a browser, make sure that your app resolution is at 100%.\nWhen presenting in PowerPoint, make sure to use the Presenter mode, which will render your presentation at 100% resolution and use your full screen.\nTo use the presenter mode, hit F5 to start from the first slide, or SHIFT-F5\nTheme Yes, yes, dark theme is cool. But when it comes to presenting — especially if you’re showing code in Visual Studio Code / Visual Studio — use a light theme.\nCreating your demo You have a very short period of time to convey your message. If you’re demoing during one of the PnP community calls, you typically have between 10 to 15 minutes to do your demo.\nCreate your story Try to explain to your audience why they should care about your demo; present the current state, then your \u0026ldquo;improved\u0026rdquo; state so that people can quickly understand what’s in it for them.\nOnce you have introduced yourself (see below), show a demo as quickly as possible. Or, at least, show a teaser that will keep your audience interested.\nResist the urge to talk for 10 minutes about your code without showing your demo or your audience will get bored and fall asleep.\nMake sure that you’re able to answer the audience’s \u0026ldquo;what’s in it for me?\u0026rdquo;\nCreate your companion deck You don’t need to create a huge PowerPoint presentation here; just something that provides your name, title, and contact information.\nYou might need a slide to explain your usage scenario or to show the before/after pictures.\nIf you want to, you can include an architecture diagram — but it is often unnecessary.\nAvoid using transition and animations. They don’t show well on Teams and/or YouTube videos.\nPrepare your code walk-through If you’re going to show code, it’s a good idea to create screen shots of your code in PowerPoint and highlight the important sections.\nI know, you may think that it is cooler to show code directly in Visual Studio Code/Visual Studio, but it invariably results in blurry code as you scroll around and move your mouse around.\nPlus: it forces you to think ahead of time about what code you want to show.\nCreate your resources list You should wrap up your companion deck with a demo summary and reference slides. It’s a good idea to provide a link to your source code.\nTake the time to include links to the articles, blog posts, previous demos that you may refer to during your demo.\nCreate your \u0026ldquo;oh shit\u0026rdquo; deck No matter how simple your demo is, you should always prepare for the eventuality that everything will go wrong.\nDo a dry run of your demo and take screen shots throughout so that if the demo gods are not playing nice, you’ll have something to show.\nIf you’re preparing for a PnP call demo, David Warner II — who does a screenshot summary of every PnP call — will most likely contact you to ask if you have any slides before you’re scheduled to present. Make sure to include your screenshot slides.\nCreate the metadata for your demo If you’re doing a demo for a PnP call, it will be recorded and posted on YouTube. You may want to write a 100-word description for your demo title, description. Make sure to include the tools or technologies you used if that’s what your demo is about.\nPrepare for the Q\u0026amp;A Be ready! People may ask about compatibility, licensing, availability, why you used this approach instead of another one, etc.\nGet permissions If you’re demoing work that you did for a customer, you should obtain a written permission from them before you mention them and/or show their solution. Otherwise, make sure to make to sanitize or otherwise make your demo so that nobody gets in trouble.\nGiving your demo Demo day checklist Cue up your demo and load your presentation Create your virtual desktops (see below) Confirm that you are a presenter (the agenda for PnP calls is usually published in advance on social media) Find out which presentation slot is yours — but be prepared to present sooner Fifteen minutes before the call:\nTurn off notifications (trust me on this one!); if using Windows 10, consider turning on Focus assist\nSet your phone to mute Sign-in to the Teams call. While you do, make sure to test your audio and video. While on the call, check the participants list to make sure that you’re a presenter.\nTest your audio/video before everybody signs in When it is your time to demo:\nTake control of your presentation (hit the Share tray icon) Make sure to present your PowerPoint in presentation mode Close the meeting control box (the one in the lower right corner that shows the meeting video) Confirm that you’re being seen and heard Introduce yourself; don’t mention the time of the day (remember that your demo will be recorded and available on-demand for months to come) Stick to your script (except for the Q\u0026amp;A portion at the end) Don’t prompt for questions; They’re handled through the chat window. If you choose to answer a question from the chat window, make sure to restate the question before giving the answer (the chat window doesn’t show up on recordings) Relinquish control Mute yourself after your demo Answer questions in the chat window. Demo tips Use ZoomIt When you want people to focus on something on the screen, it’s always a good idea to zoom in or highlight the screen in some way.\nLuckily, there’s free tool by Microsoft called ZoomIt which is designed to help during presentations.\nAfter you install ZoomIt, you can use these useful shortcut keys to enable ZoomIt features:\nShortcut key Function Ctrl-1 Begin Zoom-In mode Ctrl-2 Begin drawing (while not zoomed in) ↑ Zoom In ↓ Zoom Out Left-Click Begin drawing (while zoomed in) R, B, Y, G, O, P Change pen color to red, blue, yellow, green, orange, purple Ctrl-↑ Increase pen size Ctrl-↓ Decrease pen size E Erase ESC Stop zoom Tab Draw ellipse (while drawing) SHIFT Draw a straight line (while drawing) CTRL Draw a rectangle (while drawing) SHIFT+CTRL Draw a rectangle (while drawing) T Type (while zoomed in) If you want to see cool demos using ZoomIt, take a look at presentations by David Warner II.\nThere are other cool features you can use (like timers, blanking the screen, etc.). I recommend you take visit the ZoomIt site for more information.\nUsing multiple desktop When you’re in PowerPoint presenter mode, it can be hard to switch to your desktop to show your demo, and switch back. It’s like PowerPoint doesn’t want to stop presenting, or it doesn’t want to back to presenting…\nI like use Windows 10’s Desktop functionality to create multiple desktops. With multiple desktops in Windows, you can assign which \u0026ldquo;desktop\u0026rdquo; you want the application to appear in. While you’re showing a desktop, only the applications from that desktop will show up. When you switch to another desktop, it hides the applications from the previous desktop and shows applications from the current desktop only.\nI usually have a Work desktop (so I can work while waiting for the call), a Demo desktop (where I show the application I’m going to demo), and a Presentation desktop, where I have PowerPoint in presentation mode.\nTo use multiple desktops, follow these steps:\nLaunch PowerPoint and Teams From the taskbar, select Task view \u0026gt; New desktop +. Alternatively, you can use WIN-Ctrl-D In the new desktop, launch the apps you want to use while demoing. Launch your browser and/or Visual Studio Code, for example. Cue your browser to your demo page. When you’re ready to switch between desktops, use Ctrl-WIN-→ and Ctrl-WIN-← to go to the next/previous desktop If you need to see all your desktops (to rename or re-organize them), you can use WIN+Tab. The great thing is when you’re sharing your desktop in Teams, it shows the content your monitor sees — regardless of which desktop shows.\nConclusion I hope that this checklist will help you prepare for your demo.\nIf you’re looking for inspiration, take a look at these demos which follow the format discussed above:\nChris Kent (DMI) https://www.youtube.com/watch?v=v5tGR6Eh_Jo, https://www.youtube.com/watch?v=_-Q_itkE0Uk David Warner (Catapult Systems) \u0026amp; Hugo Bernier https://www.youtube.com/watch?v=D9P6kGECklI Hugo Bernier https://www.youtube.com/watch?v=gWrvC-0HF4A Paolo Pialorsi (PiaSys.com) https://www.youtube.com/watch?v=_8Jkj2NUAEc Niket Jain (Microsoft) https://www.youtube.com/watch?v=oIAJ2_Md8xI Markus Möller (Avanade) https://www.youtube.com/watch?v=h4NXi-p2fEw Wictor Wilén (Avanade) https://www.youtube.com/watch?v=zc9S270c-Dg Sudharsan Kesavanarayanan https://www.youtube.com/watch?v=ndHMdfFscsk I hope this helps?\nPhoto credits Image by Rudy and Peter Skitterians from Pixabay\n","permalink":"http://localhost:1313/posts/my-demo-checklist-for-pnp-calls/","tags":["PnP"],"title":"My Demo Checklist for PnP Calls"},{"categories":["VS Code"],"contents":"Introduction If you’re an SPFx developer who uses Visual Studio Code, you may have noticed that the JSON files that the Yeoman generator creates contain comments to help you understand how to configure your manifest.\nThe only problem is: JSON files aren’t supposed to have comments. And Visual Studio Code likes to remind you of that when it sees comments in a JSON file.\nFor example, when you open the manifest for your brand new SPFx web part, you’ll find these nasty error messages:\nAn example of schema validation errors caused by comments\nI’m one of those people who can’t stand any validation errors or warnings. I know, I know, I’m weird. But it drives me insane!!!\nLuckily, Paul Schaeflein has a solution that he Tweeted this morning:\nTired of the squigglies in the SPFx configuration files? Add this to your Workspace settings (.vscodesettings.json):\n\u0026ldquo;files.associations\u0026rdquo;: {\n\u0026ldquo;*.json\u0026rdquo;: \u0026ldquo;jsonc\u0026rdquo;\n}\n— Paul Schaeflein (@paulschaeflein) August 12, 2020\nIn this super-quick post, I’ll show how to configure your Visual Studio Code to stop showing validation errors for comments in JSON files.\nPaul Schaeflein deserves all the credit for this. I’m just giving you step-by-step instructions.\nConfiguring JSON files to accept comments From Visual Studio Code, follow these steps:\nFrom the menu, go to File | Preferences | Settings In the User preferences tab, expand the Text Editor section and select Files In the Associations setting, select Add Item In the new row, enter the following values: Under Key enter *.json Under Value enter jsonc Select OK to add your entry That’s it! Now you should be able to go to your manifest file and enjoy the squiggle-less JSON with comments!\nAhhh, no more schema validation errors!\nWhat unholy magic is this? Few people know that if you save your .JSON file as a .JSONC file, you won’t get validation errors. That’s because .JSONC stands for \u0026ldquo;JSON with comments\u0026rdquo;.\nHowever, you can’t rename your schema files in an SPFx solution to .JSONC because SPFx expects .JSON files — not .JSONC.\nPaul’s \u0026ldquo;hack\u0026rdquo; simply associates .JSON files with the .JSONC schema. That way, Visual Studio Code treats every .JSON file as a .JSONC — regardless of the extension.\nThank You Thanks Paul Schaeflein for this tip! You may have saved my sanity!\n","permalink":"http://localhost:1313/posts/getting-rid-of-json-validation-errors-on-comments/","tags":null,"title":"Getting rid of JSON validation errors on comments"},{"categories":["Productivity"],"contents":"Introduction With Edge Chromium, you can set up multiple profiles with different credentials, history, cookies, extensions, etc.\nIf, like me, you work with multiple Microsoft 365 tenants, this feature can be a real time saver. I’ve already written about how to configure multiple in a previous post, so I won’t repeat myself here.\nTo keep track of who you’re currently logged on as, Edge displays a profile picture on the upper-right corner.\nYou can configure a different picture for every profile in your browser, but you’re limited to two choices:\nThe profile picture associated to your Microsoft 365 tenant (if you’re signed in with a Microsoft 365 tenant); or One of the cute avatar images that come with Edge\nUnfortunately, there isn’t a choice for custom profile pictures.\nI was collaborating with David Warner II this evening, solving world problems, when we suddenly got distracted with fixing an issue with one of his profiles.\nIn the process of fixing his browser issues, I discovered a way to change my profile images.\nI searched for this and didn’t find anything, and I definitely don’t know if this is a supported feature or not, but I thought I’d share with you how I did it.\nChanging your profile picture Here’s how to do it:\nUsing Edge Chromium, switch to the profile for which you wish to set up a custom profile image. Make sure that it already has an image (if not, click on your profile, select Manage profile settings | … | Edit | Change Picture ) From the address bar, type edge://version From the About version page that shows up, look for Profile path. Copy the path that’s displayed next to it (it should be something like C:\\Users\\hugoa\\AppData\\Local\\Microsoft\\Edge SxS\\User Data\\Profile 1) Launch a file explorer and navigate to that path. (I use [Windows]+[R] to launch the Run… dialog and paste the path). In the list of files that appear, look for one called Edge Profile Picture.png and make a backup copy of it. Find whatever custom image that you’d like to use, resize it to 424×424 pixels, and save it as Edge Profile Picture.png Close your browser and your new profile picture should show up\nConclusion That’s it! I have now configured all my profiles to use the corporate logo of every tenant I have so that I easily tell which profile is currently in use.\nLet me know if you found a better way to do this.\nI hope this helps?\nPhoto credit Image by Andre Mouton from Pixabay\n","permalink":"http://localhost:1313/posts/adding-custom-edge-profile-images/","tags":["Microsoft Edge"],"title":"Adding custom Edge profile images"},{"categories":["Microsoft List"],"contents":"Introduction Over the last few years, Microsoft has done an amazing job at modernizing SharePoint.\nIt used to be that the first question my clients would ask me when I would start a new engagement was \u0026ldquo;How can we make SharePoint not look like SharePoint?\u0026rdquo;.\nNow, most engagements start with \u0026ldquo;How can we make our old SharePoint sites look more like the new SharePoint sites?\u0026rdquo;.\nThat’s a testament to the hard work of folks at Microsoft. They’ve changed how you edit SharePoint pages and sites to make it easier for everyone to quickly design beautiful content.\nBut lists in SharePoint have not changed at the same pace. Sure, they got a slightly updated look and feel (well, some lists, anyway), but they were still not easily approachable for every user.\nWith Microsoft Lists, Microsoft seems to be doing to Lists what the SharePoint team did to pages. They are modernizing them and making them much easier to use for everyone.\nThey’re still lists behind the scenes, but they’re no longer relegated to being hidden in a site somewhere. They’re becoming first-class citizens in Microsoft 365, crossing the boundaries of SharePoint, Groups, and Teams.\nI already covered the lists templates, but in today’s post, I’ll explain how you can easily build rules to to notify someone, and how rules will continue to evolve to do a lot more.\nNOTE: As per my previous post on Microsoft Lists, much of this is speculation based on Microsoft marketing materials, demos, and videos. I’m like one of those people who watch trailers for Marvel Movies frame-by-frame to get as many spoilers as possible, but for Microsoft marketing videos :-). Actual functionality may be different once this feature is fully released.\nCreating a rule Here are the steps to create a rule:\nFrom within you list, go to the Automate menu and select + Create a rule\nFrom the Create a rule pane, select the rule trigger you wish to use\nYou’ll notice that — at this time — the only options are to Notify someone when. The way this panel is done, it looks like they’ll be adding more rules in the future though. Depending on the trigger you select, you’ll get a nice conversational interface with an easy \u0026ldquo;fill-in the blanks\u0026rdquo; sentence that makes it easy to configure your rule. Rules are very simple: they all follow a \u0026ldquo;if/then\u0026rdquo; format. This is when you select A column changes\nThis is when you select A column value changes to something\nA new item is created\nAn item is deleted\nFill the blanks with the values you want\nThe most \u0026ldquo;complicated\u0026rdquo; one seems to be A column value changes to something, which asks you to Choose a column, Choose a condition and a Enter a value. Note that when \u0026ldquo;fill-in-the-blank\u0026rdquo; sections are related, you need to fill the first part before you call fill the next one. For example, you need to Choose a column before you can Choose a condition, and the Choose a condition field needs to be filled before you Enter a value. That’s presumably to (eventually) give different condition choices when you pick different types of columns, I guess.\nEmail fields allow you to enter multiple values and seem to resolve the email address to people, if available. Also, you can refer to other columns on the list item. For example, if you have a column called Speakers, you can select Speakers instead of entering an email there.\nOnce you’ve filled in the blanks, select Create to create the rule. When the rule is created, it will display the Manage Rules pane with your new rule created.\nEditing a rule From the Manage rules pane (Automate | Manage rules ), select the rule you wish to change. In the Edit rule pane, you get the same fill-in-the-blanks fields that you got when you created the rule, but now they contain the values you selected when you created the rule.\nTo delete the rule, select the Delete rule button at the bottom of the pane.\nOtherwise, select Save to update your rule and return to the Manage rules pane. Note that you can also temporarily disable a rule from within the Manage rules pane and selecting the toggle to turn a rule off.\nWhy put rules under Automate? By the looks of it, the Automate menu will eventually become the place for other cool automation features.\nFor example, if you add a date field in your list, you’ll see a Set a reminder option show up (my list has a Date reported field).\nWhen you have an item selected, the list of choices under Automate seems to change as well:\nConclusion The overall look and feel of rules in Microsoft Lists is a very user-friendly interface that seems to be designed to grow. Every aspect, from how the menu is constructed to how the configuration panels are configured are built to continue adding new functionality in the future without adding complexity.\nIn general, I like the new visual feel of Microsoft Lists and the style they’re using for configuring rules, column formatting, etc. I think that every day users will also feel more comfortable exploring the features too.\nI hope that you’ll enjoy Microsoft Lists and rules when they become available. I certainly hope to find out if my frame-by-frame analysis of screenshots, demos, and videos proved to be correct.\nAre rules enabled in your tenant yet? I’d love to know!\n(Sigh) I really need a hobby!\nFor more information A first look at Microsoft Lists Microsoft Lists ","permalink":"http://localhost:1313/posts/working-with-rules-in-microsoft-lists/","tags":null,"title":"Working with rules in Microsoft Lists"},{"categories":["SPFx"],"contents":"Introduction Since SPFx 1.8, we have been able to make web parts aware of what section they reside in on a modern page.\nEach SharePoint site theme has four variants: the main variant, a neutral variant, a soft variant, and a strong variant.\nYou can configure each page section’s background color with one of the four theme’s variants.\nWhen you place a web part on a section with a different background color, the web part has the ability to adapt to that section’s background color.\nMicrosoft has a great article explaining how to add section support to your web parts, but it does not go into great detail explaining the theme variants.\nTheme variants define a lot of different colors, like the background color, body color, button colors, etc.\nEvery time I write a web part that is \u0026ldquo;theme-variant-aware,\u0026rdquo; I find myself looking up which theme colors I should use for each element in my web part.\nIf you dig enough in the SharePoint code (under sp-component-base) you’ll find helpful comments describing how to use each color of a theme variant.\nHoping this will help someone, I extracted the description of each color in theme variants from the comments and created this post.\nKeep in mind that this information may change between versions of SPFx. I’ll do my best to keep it up-to-date between versions.\nAdding support for theme variants Before we explore the various colors that are available at your disposal, let’s discuss how to make your web part aware when a section theme variant changes.\nWhen you create a new web part using the Yeoman generator, your web part does not adapt to theme variants. If you change the background color of the section where you web part resides, it mostly stays the same color, like the sample below:\nTo make it support theme variants, you need to follow these steps (this code is extracted from Microsoft’s article:\nIn your web part’s .manifest.json, add the following (I usually add it above the preconfiguredEntries):\n\u0026ldquo;supportsThemeVariants\u0026rdquo;: true,\nAt the top of your web part’s code (YourWebPartNameWebPart.ts, add the following imports:\nimport { ThemeProvider, ThemeChangedEventArgs, IReadonlyTheme, ISemanticColors } from \u0026#39;@microsoft/sp-component-base\u0026#39;; In your web part class (just below export default class YourWebPartNameWebPart, add these two variables:\nprivate _themeProvider: ThemeProvider; private_themeVariant: IReadonlyTheme | undefined; The _themeProvider variable will store the web part’s instance of the theme provider, which notifies the web part of the currently selected theme. The _themeVariant variable will store the currently selected theme variant.\nAdd an event handler in your web part to react to changing theme variants:\nprivate _handleThemeChangedEvent(args: ThemeChangedEventArgs): void { this._themeVariant = args.theme; this.render(); } In your web part code, add an onInit method to initialize the theme provider, get the initial theme variant, and associate the event handler:\nprotected onInit(): Promise\u0026lt;void\u0026gt; { // Consume the new ThemeProvider service this._themeProvider = this.context.serviceScope.consume(ThemeProvider.serviceKey); // If it exists, get the theme variant this._themeVariant = this._themeProvider.tryGetTheme(); // Register a handler to be notified if the theme variant changes this._themeProvider.themeChangedEvent.add(this, this._handleThemeChangedEvent); return super.onInit(); } In your web part’s render method, you’ll need to add code to pass the theme variant to your component:\npublic render(): void { const element: React.ReactElement\u0026lt;IYourWebPartNameProps \u0026gt; = React.createElement( YourWebPartName, { themeVariant: this._themeVariant, // whatever other props you want to pass } ); ReactDom.render(element, this.domElement); } In your web part’s component’s props (IYourWebPartNameProps), add a prop for the theme variant:\nimport { IReadonlyTheme } from \u0026#39;@microsoft/sp-component-base\u0026#39;; export interface IYourWebPartNameProps { themeVariant: IReadonlyTheme | undefined; } Finally, in your web part’s component’s tsx file, you can use the themeVariant prop to retrieve variant colors:\npublic render(): React.ReactElement\u0026lt;IYouWebPartNameProps\u0026gt; { const { semanticColors }: IReadonlyTheme = this.props.themeVariant; return ( \u0026lt;div style={{backgroundColor: semanticColors.bodyBackground, color: semanticColors.bodyText}}\u0026gt; \u0026lt;span className={ styles.title }\u0026gt;Welcome to SharePoint!\u0026lt;/span\u0026gt; \u0026lt;p className={ styles.subTitle }\u0026gt;This web part is theme variant aware.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ); } Once your rebuild your web part (gulp build) and add your web part to a page (remember: if you changed the manifest since you added the web part to a page, you need to re-add the web part), your web part will now be aware of section background colors:\nYou’ll notice that we use the bodyBackground and bodyText colors from the themeVariant. But theme variants define a lot more colors.\nTheme variant colors In a theme variant, you can find the palette colors (e.g.: themeDark, themePrimary, themeSecondary, etc.) and the semantic colors.\nYour first instinct might be to try to use the palette colors, but that would require you to know exactly which color is applied to what element. For example, do you know which palette color is used for a button’s background color when a user mouses over it?\nMe neither.\nThe semantic colors, however, describe how you would use each palette color semantically. For example, it tells you that the background color of a hover button should be buttonBackgroundHovered.\nHere is the full list of semantic colors available within a theme variant. The list is extracted from Microsoft’s code.\nBase colors Color Description bodyBackground The default color for backgrounds. bodyStandoutBackground The standout color for highlighted content backgrounds. For highlighted content when there is no emphasis, use the neutral variant instead. This should be a shade darker than bodyBackground in light themes, and a shade lighter in inverted themes. bodyFrameBackground The color for chrome adjacent to an area with bodyBackground. This can be used to provide visual separation of zones when using stronger colors, when using a divider line is not desired. In most themes, this should match the color of bodyBackground. bodyFrameDivider Used as the border between a zone with bodyFrameBackground and a zone with bodyBackground. If bodyBackground and bodyFrameBackground are different, this should be the same color as bodyFrameBackground in order to visually disappear. bodyDivider Divider lines; e.g. lines that separate sections in a menu, an \u0026lt;HR\u0026gt; element. disabledBackground The color of the outline around focused controls that don’t already have a border; e.g. menu items variantBorder The color of the border that provides contrast between an element, such as a card, and an emphasized background. variantBorderHovered Hover color of border that provides contrast between an element, such as a card, and an emphasized background. defaultStateBackground Background color for default/empty state graphical elements; e.g. default icons, empty section that needs user to fill in content, placeholder graphics, empty seats, etc. errorBackground The background for errors, if necessary, or highlighting the section of the page where the error is present. blockingBackground Background for blocking issues, which is more severe than a warning, but not as bad as an error. warningBackground Background for warning messages. warningHighlight Foreground color for warning highlights successBackground Background for success inputBorder The border of a large input control in its resting, state; e.g. the box of a dropdown. smallInputBorder The border of a small input control in its resting unchecked state; e.g. the box of an unchecked checkbox. inputBorderHovered The border color of a large hovered input control, such as textbox. inputBackground The background color of an input, e.g. textbox background. inputBackgroundChecked The background of a checked control; e.g. checked radio button’s dot, checked toggle’s background. inputBackgroundCheckedHovered The background of a checked and hovered control; e.g. checked checkbox’s background color on hover. inputForegroundChecked The foreground of a checked control; e.g. checked checkbox’s checkmark color, checked toggle’s thumb color, radio button’s background color around the dot. inputFocusBorderAlt The alternate focus border color for elements that already have a border; e.g. text field borders on focus. buttonBackground Background of a standard button buttonBackgroundChecked Background of a checked standard button; e.g. bold/italicize/underline text button in toolbar buttonBackgroundHovered Background of a hovered standard button buttonBackgroundCheckedHovered Background of a checked and hovered standard button; e.g. bold/italicize/underline text button in toolbar buttonBackgroundDisabled Background of a disabled standard button buttonBackgroundPressed Background of a pressed standard button; i.e. currently being clicked by mouse buttonBorder Border of a standard button buttonBorderDisabled Border of a disabled standard button primaryButtonBackground Background of a primary button primaryButtonBackgroundHovered Background of a hovered primary button primaryButtonBackgroundPressed Background of a pressed primary button; i.e. currently being clicked by mouse primaryButtonBackgroundDisabled Background of a disabled primary button primaryButtonBorder Border of a primary button accentButtonBackground Background of an accent button (kicker) menuBackground The background of a menu. menuDivider The divider between menu items. menuIcon The default colors of icons in menus. menuHeader The headers in menus that denote title of a section. menuItemBackgroundHovered The background of a hovered menu item. menuItemBackgroundPressed The background of a pressed menu item. menuItemText The text color of a menu item. menuItemTextHovered The text color of a hovered menu item. listBackground The background color for the entire list. listText The default text color for list item titles and text in column fields. listItemBackgroundHovered The background color of a hovered list item. listItemBackgroundChecked The background color of a checked list item. listItemBackgroundCheckedHovered The background color of a checked and hovered list item. listHeaderBackgroundHovered The background color for a hovered list header. listHeaderBackgroundPressed The background color for a pressed list header. Text colors Color Description bodyText The default color for text. bodyTextChecked Checked text color, e.g. selected menu item text. bodySubtext De-emphasized text; e.g. metadata, captions, placeholder text. actionLink Neutral colored links and links for action buttons. actionLinkHovered Hover state for neutral colored links and links for action buttons. link The color of a link. linkHovered The color of a hovered link. Also used when the link is active. disabledText The default color for disabled text on top of disabledBackground; e.g. text in a disabled text field, disabled button text. disabledBodyText The default color for disabled text on the default background (bodyBackground). disabledSubtext Disabled de-emphasized text, for use on disabledBackground disabledBodySubtext Disabled de-emphasized text, for use on the default background (bodyBackground). errorText The default color of error text, used on bodyBackground. warningText The color of text on errorBackground, warningBackground, blockingBackground, or successBackground. inputText The color of input text. inputTextHovered The color of input text on hover. inputPlaceholderText The color of placeholder text. buttonText Color of text in a standard button buttonTextHovered Color of text in a hovered standard button buttonTextChecked Color of text in a checked standard button buttonTextCheckedHovered Color of text in a checked and hovered standard button buttonTextPressed Color of text in a pressed standard button; i.e. currently being clicked by mouse buttonTextDisabled Color of text in a disabled standard button primaryButtonText Color of text in a primary button primaryButtonTextHovered Color of text in a hovered primary button primaryButtonTextPressed Color of text in a pressed primary button; i.e. currently being clicked by mouse primaryButtonTextDisabled Color of text in a disabled primary button accentButtonText Color of text for accent button (kicker) listText The default text color for list item titles and text in column fields. Conclusion Like chameleons, SPFx web parts can change colors to adapt to changing environments and blend in.\nWith a few lines of code and some knowledge of which semantic colors you can use, you can built awesome web parts that will look good no matter what theme (or theme variant) your site uses.\nI hope this helps?\nPhoto Credits Photo by Pierre Bamin on Unsplash\n","permalink":"http://localhost:1313/posts/adding-support-for-theme-variants-in-spfx-web-parts/","tags":null,"title":"Adding support for theme variants in SPFx web parts"},{"categories":["Microsoft List"],"contents":"Introduction As Microsoft Lists starts rolling out to Microsoft 365, I find that more and more people seem to get confused about Microsoft Lists vs SharePoint, or complaining about how they’ll have to \u0026ldquo;learn a new product … again!\u0026rdquo;.\nTo help alleviate concerns, I thought it would be a great opportunity to introduce you to the upcoming list templates that will be available when it shows up on your tenant.\nI’m not using a secret preview of Lists or anything like that; I have cobbled the information from public Microsoft materials. As such, the actual details described in this post may change when Lists roll out completely.\nLists Home When it becomes available on your tenant, you’ll find a new Lists icon in your suite bar (a.k.a. \u0026ldquo;The Waffle\u0026rdquo;). This is where you’ll find your recent lists, your favorite lists, and where you’ll be able to create lists easily.\nYou can create a new list by selecting + Create new list at the top of the screen and selecting to create from a Blank list, From Excel, From an Existing List or pick from the existing Templates.\nNote that you’ll also be able to create a list from SharePoint (under Site Content | New | List) and from Microsoft Teams.\nI’ll cover the templates at your disposal (since everything else hasn’t changed much)\nAs of now, the templates that are available are (may be subject to change):\nIssue Tracker New hire checklist Event itinerary Business trip approvals Team evaluations Asset tracker Project planning Social media calendar Let’s cover each one in greater details\nIssue Tracker The issue tracker makes it easy to manage issues, track statuses, priorities, and notify your team when things happen.\nYou can imagine adding this list to every project site\nColumns Column\nType\nComments\nTitle\nSingle line of text\nRequired\nModified\nDate and Time\nCreated\nDate and Time\nIssue description\nMultiple lines of text\nDescribe the issue\nPriority\nChoice\nThe priority of this issue.\nChoices include:\n– Critical\n– High\n– Normal\n– Low\nStatus\nChoice\nStatus of the issue\nChoices include:\n– New (Default)\n– Blocked\n– In progress\n– Completed\n– Duplicate\n– By design\n– Won’t fix\nPerson or group the issue is assigned to\nPerson or Group\nDate reported\nDate and Time\nThe date the issue was reported\nDays old\nCalculated\nNumber of days since date reported\nIssue source\nHyperlink or Picture\nWhere was the issue logged (ticket, customer support call, etc.)\nImages\nThumbnail\nAny photos or images of the issue\nIssue logged by\nPerson or Group\nCreated By\nPerson or Group\nModified By\nPerson or Group\nAssociated files\nAttachments\nAny other files associated with the issue\nViews The issue tracker list includes the following views:\nAll Items Issues grouped by person assigned to Issues grouped by priority Issues grouped by status Employee Onboarding One of those lists that every organization should have, the onboarding list helps you manage new employees as they start on their first day at your company.\nIt looks like this would be a generic list you would show on an Employee orientation site. The same items would appear for every employee, although you could use this list to create new workflow tasks for new employees.\nColumns Column\nType\nComments\nTitle\nSingle line of text\nRequired\nModified\nDate and Time\nCreated\nDate and Time\nDescription\nMultiple lines of text\nComplete by\nChoice\nThe due date by when work should be completed.\nChoices include:\nBefore joining\nFirst day\nWeek 1\nAfter 30 days\nAfter 60 days\nAfter 90 days\nComplete?\nYes/No\nMark as yes if work is completed\nCompleted On\nDate and Time\nDate on which work was completed\nMentor\nPerson or Group\nPoint of contact to help with the work item\nRelevant link\nHyperlink or Picture\nHelpful link to support the work\nRelevant files\nAttachments\nHelpful files to support the work\nCreated By\nPerson or Group\nModified By\nPerson or Group\nViews All Items Group work by completed by date Group work by completion status Work to be completed\nEvent Itinerary A great way to plan events.\nSo this is how Microsoft plans all these awesome events?!\nColumns Column\nType\nComments\nTitle\nSingle line of text\nRequired\nModified\nDate and Time\nCreated\nDate and Time\nSession code\nSingle line of text\nSession type\nChoice\nDescribes what kid of a session this is\nChoices include:\n– Meal\n– Keynote\n– Breakout\n– Workshop\n– Panel\n– Talk\n– Networking\nDescription\nMultiple lines of text\nSpeaker(s)\nPerson or Group\nStart date and time\nDate and Time\nEnd Date and Time\nDate and Time\nDuration\nCalculated\nCapacity\nNumber\nLocation\nChoice\nNotes\nMultiple lines of text\nCreated By\nPerson or Group\nModified By\nPerson or Group\nAttachments\nAttachments\nViews All Items Event itinerary – grid view Event itinerary – list view Grouped by session type Asset Manager An great way to keep track of all your stuff, and whether they are checked-in and returned (and when).\nNOTE TO SELF: Must create an asset manager list to keep track of all the stuff I lent to my neighbors.\nColumns Column\nType\nComments\nAsset Tag\nSingle line of text\nRequired\nModified\nDate and Time\nCreated\nDate and Time\nDevice Photo\nThumbnail\nImage of the asset\nStatus\nChoice\nStatus of the asset\nOne of:\n– Available\n– Reserved\n– In use\n– In repair\n– Retired\nManufacturer\nChoice\nManufacturer of the asset. Intended to be replaced with your own list of manufacturers.\nModel\nSingle line of text\nModel/make of the device\nAsset type\nChoice\nType of asset:\n– Smartphone\n– Laptop\n– Tablet\n– Printer\n– Accessory\nColor\nChoice\nChoice of:\n– Space gray\n– White\n– Black\n– Silver\n– Dark blue\n– Pink\n– Red\nSerial number\nSingle line of text\nSerial number associated with the asset\nPurchase date\nDate and Time\nWhen the asset was purchased\nPurchase price\nCurrency\nThe purchase price of the asset\nOrder #\nSingle line of text\nOrder or invoice number for the purchase\nCurrent owner\nPerson or Group\nPerson currently using the asset\nPrevious owner\nPerson or Group\nPerson who last used the asset\nDue date\nDate and Time\nWhen the asset will be returned by the current owner\nCondition notes\nMultiple lines of text\nNotes about the current condition of the asset\nCreated By\nPerson or Group\nModified By\nPerson or Group\nAttachments\nAttachments\nViews All Items Grouped By asset type Grouped By manufacturer Purchase information All available assets Asset gallery Recruitment Tracker Keep track of your recruitment pipeline within your company or team and keep track of the candidates, their potential position, hiring process, recruiter, etc.\nSeems to be designed to make it easy to adapt to your own business process. I hope that one day I’ll show up on one of those lists at Microsoft 😉\nColumn\nType\nComments\nCandidate Name\nSingle line of text\nRequired\nModified\nDate and Time\nCreated\nDate and Time\nPosition\nChoice\nPosition the candidate is applying for. Contains sample positions that you’ll want to change to suit your needs.\nProgress\nChoice\nWhere the candidate is in the hiring process\nChoice of:\n– New application\n– Active\n– On hold\n– Top pick\n– Offer sent\nRecruiter\nPerson or Group\nPerson who will manage candidate scheduling\nApplication date\nDate and Time\nDate the application was submitted\nPhone screen date\nDate and Time\nDate on which candidate will be phone-screened\nPhone screener\nPerson or Group\nPerson who will screen candidate by phone\nInterview date\nDate and Time\nDate of the interview\nInterviewer(s)\nPerson or Group\nPerson or team who will interview the candidate\nNotes\nMultiple lines of text\nNotes about the candidate\nLinkedIn profile\nHyperlink or Picture\nURL pointing to the candidate’s LinkedIn profile\nCreated By\nPerson or Group\nModified By\nPerson or Group\nResume or CV\nAttachments\nAttach candidate’s resume or CV here, if available\nViews All Items All Items in Grid Group by role Group by application status All new and active applicants Travel requests This list template doesn’t have a description. Probably because no one is traveling right now.\nNot only is this list useful for tracking travel requests, but you could also use it to track who’s currently away (in case of emergencies, etc.)\nColumns Column\nType\nComments\nTrip Title\nSingle line of text\nRequired\nModified\nDate and Time\nCreated\nDate and Time\nReason for travel\nMultiple lines of text\nProvide a reason for this travel request. (Possible reason: to get there?)\nRequester\nPerson or Group\nPerson who is going on this trip\nDestination\nLocation\nProvide the trip destination\nTravel start date\nDate and Time\nDate when the travel starts\nTravel end date\nDate and Time\nDate when the travel ends\nTravel duration (days)\nCalculated\nAirline\nChoice\nName of the airline you will be flying with\nChoice of:Alaska Air\nSouthwest\nBritish Airways\nEmirates\nJapan Airlines\nEstimated airfare\nCurrency\nEstimated cost of airline tickets\nHotel\nLocation\nWhich hotel will you be staying at\nEstimated hotel cost\nCurrency\nEstimate hotel costs and description (not including the $50 can of peanuts)\nApproved?\nYes/No\nIs this travel request approved\nCreated By\nPerson or Group\nModified By\nPerson or Group\nAttachments\nAttachments\nViews All Items Grouped by approval status Work progress tracker Track priorities and progress as you work towards delivering products and services.\nColumns Column\nType\nComments\nWork item\nSingle line of text\nModified\nDate and Time\nCreated\nDate and Time\nDescription\nMultiple lines of text\nWork to be done\nCategory\nChoice\nType of work\nChoice of:\n– Planning\n– Design\n– Engineering\n– Marketing\n– Research\nProgress\nChoice\nChoice of :\n– Not started\n– In progress\n– Completed\n– Blocked\n– Behind\nPriority\nChoice\nChoice of:\n– Critical\n– High\n– Medium\n– Low\nStart date\nDate and Time\nDate on which work was started\nDue date\nDate and Time\nDue date by when work should be completed\nAssigned to\nPerson or Group\nPerson or group the work is assigned to\nNotes\nMultiple lines of text\nAdditional notes\nCreated By\nPerson or Group\nAttachments\nAttachments\nModified By\nPerson or Group\nViews All Items Grouped by approval status Content scheduler Plan, schedule, and manage your content with this template. Filter down to just the items that are due soon, or get notifications when authors check in their drafts.\nImagine using this when creating a blog post series with multiple guest authors, but you could also use this for issuing RFPs, responding to proposals, etc.\nColumns Column\nType\nComments\nContent title\nSingle line of text\nRequired\nModified\nDate and Time\nCreated\nDate and Time\nDescription\nMultiple lines of text\nDescribe the content in a few words\nStatus\nChoice\nChoice of:\n– Planned\n– Assigned\n– Draft needs approval\n– Ready to publish\n– Published\nDraft due by\nDate and Time\nDate when the draft is due\nPublish by\nDate and Time\nDate when content should be published\nContent type\nChoice\nType of content being created –not SharePoint content-type\nChoice of:\n– Help article\n– Blog post\n– Video\n– Social media post\nContent image\nThumbnail\nImage used in the content\nPublished link\nHyperlink or Picture\nLink once the content is published\nAuthor\nPerson or Group\nModified By\nPerson or Group\nContent files\nAttachments\nAdditional files, such as the text and additional images if more than one is used.\nConclusion As you can see, Microsoft Lists are going to be useful, but they’re also going to be very familiar because they’re really your good old SharePoint lists, but made available outside of SharePoint.\nI hope this helps?\nFor More Information Visit: https://aka.ms/microsoftlists Updates July 28, 2020: Minutes after posting this blog, people started reporting that Microsoft Lists is showing up on their tenants. Very exciting! ","permalink":"http://localhost:1313/posts/getting-to-know-microsoft-lists/","tags":null,"title":"Getting to know Microsoft Lists"},{"categories":["SPFx"],"contents":"Introduction I was recently working on a custom meganav SPFx solution for a client who reported that one of the links in the navigation would always produce the following error:\nNotFoundError: Failed to execute 'removeChild' on 'Node': The node to be removed is not a child of this node.\rin t in div in div in t in CustomizedPageLayoutScrollRegion in div in article in t in t in o in t in t in t in t in t in section in div in div in t in Styledt in t in o in t in t in t\rI immediately assumed that one of the many application extensions on the page were causing the issue.\nSince the target of that link was a modern page, I assumed that there was something different on that page that would cause the issue.\nBut after removing all custom extensions on the site collection where that page resided, removing all custom web parts, and even starting with a blank modern page, I still got the error.\nI eventually solved the issue, but it was a frustrating process.\nIn this post, I’ll explain how I solved the issue.\nI hope it will save you from having to search like I did.\ndata-interception=\u0026ldquo;off\u0026rdquo; When you navigate between SharePoint modern pages, there is usually a lot of stuff that is repeated on each page; stuff like navigation, suite bar, headers, footers, etc.\nIn fact, for most pages, the only thing that changes is the content area. It does not make sense for SharePoint to re-load everything on the page — that’s just a waste of valuable bandwidth.\nSo SharePoint uses a page router to efficiently refresh only the parts of the page that change when you navigate between pages.\nIn most cases, that’s a good thing.\nExcept when you try to do navigate between pages from a custom SPFx solution. Especially if you open your links to a new browser tab or a new browser window.\nThe page router will cause SharePoint to ignore target attributes on your hyperlinks and produce weird errors like the one I got.\nAnd the problem is: your error may be completely different from mine, making it practically impossible to find a solution to this problem.\nAs it turns out, there is an article about this on the SharePoint development documentation.\nAll you need to do is to add data-interception='off' to your anchor tag to tell SharePoint not to intercept your page navigation and to bypass the page router.\nSo, instead of this:\n\u0026lt;a href=\u0026quot;https://yoursite.sharepoint.com/sites/hr/SitePages/benefits.aspx\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;Benefits\u0026lt;/a\u0026gt;\rUse this:\n\u0026lt;a href=\u0026quot;https://yoursite.sharepoint.com/sites/hr/SitePages/benefits.aspx\u0026quot; target=\u0026quot;_blank\u0026quot; data-interception='off'\u0026gt;Benefits\u0026lt;/a\u0026gt;\rOf course, once you figure out to use data-interception, you’ll find that the amazing Julie Turner, Elio Struyf, and Corey Roth all blogged about this before.\nConclusion In summary: SharePoint ignores your anchor tags’ target attributes because it uses a page router to make things more efficient, which causes the issue. Adding data-interception='off' will tell SharePoint not to mess with how to navigate to your pages.\nI have never experienced this issue because I always convince my clients not to open hyperlinks in new tabs, unless the links point to non-web documents — in which case you should use new tabs. Read this article if you want to know why.\nI have learned over the years that ultimately, it is up to the client to decide what they want to do… even if it is the wrong thing to do. My job is to give them the relevant information they need to make an educated decision — even if I don’t agree with their decision.\nI also learned that any time I have a problem, I should always check Julie Turner’s blog first because she often has the answers I’m looking for.\nI hope this helps?\nPhoto Credit Photo by Agence Olloweb on Unsplash\n","permalink":"http://localhost:1313/posts/data-interception/","tags":["SPFx","Data interception","Mystery solved"],"title":"Solving the “Failed to execute ‘removeChild’ on ‘Node'” error on modern SharePoint pages"},{"categories":["SPFx"],"contents":"Introduction Dear blog, how I’ve missed you! How long has it been? I know, I know, I’ve been insanely busy, I wasn’t ignoring you, I swear.\nAs you know, I like to use this blog as a series of \u0026ldquo;Note to self\u0026rdquo; notes so that I can find the things I tend to look for more often than I’d like.\nToday’s post is another \u0026ldquo;Note to self\u0026rdquo;. It isn’t intended to be the best way or the only way to do this, it is my way.\nIf, like me, you use the PnP Yeoman Generator to create your SPFx projects, you have the ability to turn on Stylelint when generating your projects.\nStylelint is a tool that reports bad code (or smelly code) in your CSS (and SCSS) files. It helps enforcing consistent code and prevents you from making errors in your style sheets.\nHowever, I use a few super-useful switches in my SCSS that always produce an error when running stylelint.\nThey’re perfectly valid pseudo-classes, but stylelint likes to warn you about them — probably because you shouldn’t abuse them.\nIn today’s post, I’ll show you how I use these pseudo-classes, and how I configure stylelint in my projects to stop these errors.\nNOTE: I simplified some explanations to keep this article short(ish). If you know the inner workings of how SCSS, CSS, CSS Modules, and Stylelint works, you’ll have to forgive my creative license. But then again, if you know how these things work, this article is probably not for you 🙂\nWhy bother? I can’t tell you how many SPFx projects I’ve opened run gulp build on and was bombarded with errors and warning… and when I reached to the developers who created the project, they said \u0026ldquo;Oh, I just ignore all that!\u0026rdquo;.\nThe warnings (and errors) are there to tell you that something is wrong (or potentially wrong) with your project; if you ignore them, you might let an issue slip by unnoticed.\nUsing linting in your projects helps you become a better developer, and it helps keep your code clean and consistent — so that if someone else has to maintain your code, they can get comfortable with your code pretty quickly (presuming that they’re also using linting tools).\nIn my opinion, it is every developer’s job to constantly improve the quality of their code and to improve themselves. I’m not smart enough to know all the best practices, so I rely on linting tools to help me become better.\nDon’t ignore warnings. Fix them, or — once you’ve decided to accept the warning — change your project settings so that you can get a clean — warning free — build.\nThe :global switch I’ve already written about the :global pseudo-class before, so I’ll keep it short.\nWhen you use .scss files for your style sheets in a SPFx project, the SASS pre-processor creates unique names for all your CSS classes. It does this to ensure that the CSS from your components does not interfere with the CSS from other components. This is also know as local scope.\nBut sometimes you need to define CSS class names that can’t change. For example, if you’re embedding a third-party component and you need to override their style sheet. That’s when you want your CSS classes to be global scoped.\nAnd that’s exactly what :global is does.\nFor example, if I wanted to style a .ms-DocumentCard element inside my component, I’d use:\n:global(.ms-DocumentCard) { border: 2px solid red; } Be careful though: :global changes apply globally. If you use :global(.ms-DocumentCard) in your style sheet, it will affect every single .ms-DocumentCard on the entire page.\nTo override styles within your web part, use something like this:\n.yourWebPart { :global(.ms-DocumentCard) { border: 2px solid red; } } To define a whole area of your .scss that you don’t want to be renamed, use a :global block, like this:\n:global { .ms-DocumentCard { border: 2px solid red; .ms-DocumentCard--compact { .ms-DocumentCardPreview { -ms-flex-negative: 0; flex-shrink: 0; width: 144px; } } .ms-DocumentCardPreview-icon img { width: 32px; height: 32px; } } .ms-DocumentCard:not(.ms-DocumentCard--compact) { ... } } The only problem is: stylelint will yell at you at build time:\nUnexpected unknown pseudo-class selector \u0026quot;:global\u0026quot; selector-pseudo-class-no-unknown\rThat’s because the :global is not a valid pseudo-class in CSS, it is a CSS module switch.\nAs far as stylelint is concerned, :global has no business in CSS… and it’s probably a good thing: you should be careful when using the :global switch because you could completely mess up every page your web part is on if you’re not careful.\nIf you promise to be careful, though, here’s how you can tell stylelint that you’re ok with using the :global switch in your .scss and that you promise to use it for good, not evil:\nIn the root of your project, find the .stylelintrc file and open it. The .stylelintrc is where you can configure the stylelint rules.\nPRO TIP: If you’re using Visual Studio Code, it most likely doesn’t know that your .stylelintrc file is a .json file. Just go in the lower-right corner of VS Code, click on Plain text:\nIn the list of files types that pop-up at the top, select JSON with comments\nFind the \u0026quot;rules\u0026quot; node, and insert the following JSON at the bottom — making sure to add a comma (,) at the end of the previous rule:\n\u0026#34;selector-pseudo-class-no-unknown\u0026#34;: [ true, { \u0026#34;ignorePseudoClasses\u0026#34;: [ \u0026#34;global\u0026#34; ] } ], Save the file and rebuild. Your .stylelintrc file should look something like this:\n{ \u0026#34;extends\u0026#34;: \u0026#34;stylelint-config-standard\u0026#34;, \u0026#34;plugins\u0026#34;: [ \u0026#34;stylelint-scss\u0026#34; ], \u0026#34;rules\u0026#34;: { \u0026#34;at-rule-no-unknown\u0026#34;: null, \u0026#34;scss/at-rule-no-unknown\u0026#34;: true, \u0026#34;selector-pseudo-class-no-unknown\u0026#34;: [ true, { \u0026#34;ignorePseudoClasses\u0026#34;: [ \u0026#34;global\u0026#34; ] } ], } } The :export pseudo-selector Call me old-fashioned, but I like to keep my styles completely separate from the presentation layer and the business/data layers.\nFor this reason, I always try to avoid store any colors, fonts, or dimensions in my .tsx files, and stick them in my .scss files.\nBut sometimes I need to access some values from my .scss in my code. For example, if I need to dynamically change colors of elements, or if I need to know the dimensions of an element.\nIn this case, I would define the values in my .scss (because that’s where styles belong!), and use :export to make them available to my code:\n:export { backgroundColor1: rgba(75,192,192,0.4); borderColor1: rgba(75,192,192,1); pointBorderColor1: rgba(75,192,192,1); pointBackgroundColor1: rgba(75,192,192,1);; pointHoverBackgroundColor1: rgba(75,192,192,1); pointHoverBorderColor1: rgba(220,220,220,1); } And:\n:export { centerPadding: 50px; } And then, in my code, import the styles like I normally would:\nimport styles from \u0026#39;./LineChartDemo.module.scss\u0026#39;; And call the exported values as needed in my code:\nlet color: string = styles.backgroundColor1; But you’ll soon find out that stylelint does not like the :export pseudo-selector. Again, that’s because as far as stylelint is concerned, anything that starts with : is a pseudo-class.\nTo solve this, simply add the following rule in your .stylelintrc:\n\u0026#34;selector-pseudo-class-no-unknown\u0026#34;: [ true, { \u0026#34;ignorePseudoClasses\u0026#34;: [ \u0026#34;export\u0026#34; ] } ], How to figure out what rules to put in? When stylelint gives you an error, it usually tells you what rule was broken.\nFor example:\nUnexpected unknown pseudo-class selector \u0026quot;:export\u0026quot; selector-pseudo-class-no-unknown\r…tells you that selector-pseudo-class-no-unknown is the rule that causes this error.\nGo to the stylelint user guide and find the rule that is causing the issue. Then look for the optional secondary options section to see if there are any configuration settings that allow you to override the settings.\nIn the case of selector-pseudo-class-n-unknown, it says that you can pass an array of class names to the ignorePseudoClasses setting, as follows:\nignorePseudoClasses: [\u0026#34;/regex/\u0026#34;, \u0026#34;string\u0026#34;] So, all you need to do is to pass the values you want to ignore (in our case export and global) in a string array:\n\u0026#34;selector-pseudo-class-no-unknown\u0026#34;: [ true, { \u0026#34;ignorePseudoClasses\u0026#34;: [ export\u0026#34;, global\u0026#34; ] } ], } Conclusion I hope that using CSS module switches and stylelint configurations in your projects will help keep your projects clean and warning free.\nUpdates June 16th 2020: Thanks to Stefan Bauer for pointing out I was incorrectly describing :global and :export as pseudo-classes, when they are really CSS module switches. That explains why I can never find any information about them when I google them. Photo Credits Image by Ich bin dann mal raus hier. from Pixabay\n","permalink":"http://localhost:1313/posts/spfx-scss-pseudo-classes-and-stylelint/","tags":null,"title":"SPFx Projects, SCSS, Pseudo-classes, and Stylelint"},{"categories":["SPFx"],"contents":"Introduction Displaying the version number in your web part can make it easy to quickly identify areas in your SharePoint tenant(s) where you have not updated your web part solution.\nIf you’re ever trie to handle a helpdesk call with a site owner who was experiencing problems with a web part you wrote, and you could have sworn you fixed the issue the user is describing — only to find out that they have an older version of your web part — you’ll know what I’m talking about.\nOn the March 26th SharePoint Framework Community Call, Bo George demoed a very cool Q\u0026amp;A solution for SharePoint written in SPFx. During his demo, he demonstrated that he added the web part version in the property pane.\nUnfortunately, Bo didn’t get to share his code, but it is something that I also like to do in my production web parts.\nIn this article, I’ll share my approach for showing the solution version in your web part.\nI’m sure Bo’s code is much cooler than mine, but this is the method I use.\nWhere is the version number stored? NodeJS projects have a version number which is stored in your project’s package.json. It follows the semantic versioning guidelines, which consists of a major, minor, and patch version.\nSharePoint solutions, however, use a different versioning scheme, which consists of a major, minor, patch, and a revision number.\nStefan Bauer does a great job at explaining the differences between the two types of versioning.\nThe SharePoint solution version that SharePoint displays when you show Details about a web part is stored in src\\package-solution.json in your project. This is an example of the version format that SharePoint uses:\nSyncing the NodeJS package version with the solution version I like to keep the NodeJS version in sync with the SharePoint solution. But I really dislike copying the version numbers manually.\nI may have mentioned once or twice that I’m the world’s laziest developer — if I can avoid to do anything more than once, I try to avoid it.\nFortunately Stefan also has a great solution to automatically synchronize the NodeJs package version to your SharePoint package solution version every time you build the solution.\nIf you use the PnP SPFx Yeoman generator, there is already a gulp task that will execute every time you run npm version.\nIf you use the regular SPFx Yeoman generator — not the PnP one — you can achieve the same thing by adding a custom gulp task written by Stefan.\nYou can do the same thing by following these steps:\nIn your SPFx solution, edit your gulpfile.js\nFind the following line:\nbuild.initialize(require(\u0026#39;gulp\u0026#39;)); Insert the following code before the line you found in step 2.\n// This section is inspired by Stefan Bauer\u0026#39;s article at https://n8d.at/how-to-version-new-sharepoint-framework-projects/ // Stefan rocks! let syncVersionsSubtask = build.subTask(\u0026#39;version-sync\u0026#39;, function (gulp, buildOptions, done) { this.log(\u0026#39;Synching versions\u0026#39;); // import gulp utilits to write error messages const gutil = require(\u0026#39;gulp-util\u0026#39;); // import file system utilities form nodeJS const fs = require(\u0026#39;fs\u0026#39;); // read package.json var pkgConfig = require(\u0026#39;./package.json\u0026#39;); // read configuration of web part solution file var pkgSolution = require(\u0026#39;./config/package-solution.json\u0026#39;); // log old version this.log(\u0026#39;package-solution.json version:\\t\u0026#39; + pkgSolution.solution.version); // Generate new MS compliant version number var newVersionNumber = pkgConfig.version.split(\u0026#39;-\u0026#39;)[0] + \u0026#39;.0\u0026#39;; if (pkgSolution.solution.version !== newVersionNumber) { // assign newly generated version number to web part version pkgSolution.solution.version = newVersionNumber; // log new version this.log(\u0026#39;New package-solution.json version:\\t\u0026#39; + pkgSolution.solution.version); // write changed package-solution file fs.writeFile(\u0026#39;./config/package-solution.json\u0026#39;, JSON.stringify(pkgSolution, null, 4), function (err, result) { if (err) this.log(\u0026#39;error\u0026#39;, err); }); } else { this.log(\u0026#39;package-solution.json version is up-to-date\u0026#39;); } done(); }); let syncVersionTask = build.task(\u0026#39;version-sync\u0026#39;, syncVersionsSubtask); build.rig.addPreBuildTask(syncVersionTask); ``` That’s it. Now, next time you run a gulp build, the Stefan’s gulp task will make sure both versions are in sync.\nChanging the version number To change the package version of your solution, you can simply edit the package.json version.\nBut npm has a command to easily change your package version. You can call any of the following commands from your SPFx solution folder:\nnpm version major\rnpm version minor\rnpm version patch\r…to change the major, minor, and patch version — respectively — in your package.json.\nWhen to change major, minor, and patch version I often see two extremes: either developers leave their solution versions at 1.0.0 no matter how many times they change their code, or they semi-randonmly change the version number every time they change their code.\nLuckily, semantic versioning (or semver) provide guidelines on how to change your package versions.\nYou should pretty much always start at version 1.0.0, and increase the major, minor, and patch versions depending on the types of changes you made.\nThe following table shows when you should call which npm version command, depending on the types of changes you’re making to your solution:\nType of change Stage Versioning rule Example version NPM command First release New solution Start with 1.0.0 1.0.0 npm version major Backward compatible bug fixes Patch release Increment the third digit 1.0.1 npm version patch Backward compatible new features Minor release Increment the middle digit and reset last digit to zero 1.1.0 npm version minor Changes that break backward compatibility Major release Increment the first digit and reset middle and last digits to zero 2.0.0 npm version major Using the manifest version Probably the easiest way to display the version number is to use the version property of the web part’s manifest which is available in the web part’s context, for example:\nconst version: string = `Version: ${this.context.manifest.version}`; Unfortunately, the version number that comes from the manifest is a 3-digit version (major.minor.patch), whereas the version number in your SharePoint solution is a 4-digit version.\nNow, that’s perfectly fine if you don’t use the 4th digit (the revision) in your SharePoint solution version numbers, or if — like me — you sync your package.json version with the package-solution.json. You can simply add an extra .0 at the end of the version from this.context.manifest.version.\nIf you want to get the 4-digit version number, however, it gets a little more complicated…\nImporting the version number using a static import To get the 4-digit version from your SharePoint solution, you’ll need to import the version number that’s found in the package-solution.json in your code.\nYour first instinct might be to simply add an import statement to your code and point to your project’s config/package-solution.json, like this:\n// Static import import * as packageSolution from \u0026#39;../../../config/package-solution.json\u0026#39;; But — depending on the version of TypeScript you’re using –you’ll likely get a nasty error:\nError - [tsc] src/webparts/versionDisplay/VersionDisplayWebPart.ts(21,34): error TS2732: Cannot find module '../../../config/package-solution.json'. Consider using '--resolveJsonModule' to import module with '.json' extension\rYou could add \u0026quot;resolveJsonModule\u0026quot;: true to your solution’s tsconfig.json, but I have found that it doesn’t consistently work — depending on which version of TypeScript you’re using.\nInstead, I use the following steps:\nIn your project’s src folder, add a file called typings.d.ts\nPaste the following code to your newly created file:\ndeclare module \u0026#34;*.json\u0026#34; { const value: any; export default value; } In your code add a static import to your package-solution.json (you may have to adjust the path to the file depending on where in your code you’re adding your import)\n// Static import import * as packageSolution from \u0026#39;../../../config/package-solution.json\u0026#39;; When you want to display the version number, use the following code:\n(\u0026lt;any\u0026gt;packageSolution).solution.version Importing the version using require You can also use a require statement, by following these steps:\nIn your code, where you want to insert the version number, insert this code:\n// Import package version const packageSolution: any = require(\u0026#34;../../../config/package-solution.json\u0026#34;); (Again, the path to your `package-solution.json` may vary depending on where you’re adding the code) When ready to show the version number, you can simply use:\npackageSolution.solution.version Displaying the version number in the property pane To display the version number, I like to use the PropertyPaneWebPartInformation control from the @pnp/spfx-property-controls library.\nTo do so, follow these steps:\nImport the @pnp/spfx-property-controls-library package in your solution by entering the following command in your command-line:\nnpm install @pnp/spfx-property-controls --save --save-exact\rAdd the following import to your web part class:\n// Used to display version information\rimport { PropertyPaneWebPartInformation } from '@pnp/spfx-property-controls/lib/PropertyPaneWebPartInformation';\rIn your web part’s getPropertyPaneConfiguration method, add the following code inside the groups array:\n{ groupName: \u0026#34;About\u0026#34;, groupFields: [ PropertyPaneWebPartInformation({ description: \u0026#34;Version: \u0026#34; + (\u0026lt;any\u0026gt;packageSolution).solution.version, key: \u0026#39;webPartInfoId\u0026#39; }) ] } The full code for my getPropertyPaneConfiguration looks as follows:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: \u0026#34;This web part displays the current version of the solution\u0026#34; }, groups: [ { groupName: \u0026#34;About\u0026#34;, groupFields: [ PropertyPaneWebPartInformation({ description: \u0026#34;Version: \u0026#34; + (\u0026lt;any\u0026gt;packageSolution).solution.version, key: \u0026#39;webPartInfoId\u0026#39; }), ] } ] } ] }; } Note that I didn’t localize the code for simplicity, but please use localized resources instead of hard-coded text.\nWhen you’re done, your web part’s property pane should display the current version number:\nConclusion I know it was a very long explanation for such a simple concept, but our goal was to make sure that we never have to copy the version number of your web part manually.\nWe also learned how to properly version solutions along the way.\nThanks to Bo George for the inspiration to write this article, and Stefan Bauer for writing a custom gulp task that I use in every one of production SPFx solutions.\nYou can find the code for this solution in my GitHub repo.\nI hope this helps?\nUpdate April 1, 2020: After joking with Stefan Bauer that this should be a standard feature in the PnP SPFx Yeoman generator, he pointed out that it is already a feature. Of course, because: Stefan. I updated my article accordingly. April 1, 2020: Ohmygod ohmygod ohmygod! Julie Turner read my blog and reached out to me to point out that I should tell people how to use the this.context.manifest.version before importing the package-solution.json. She’s absolutely right, plus I’m such a big fan of her work. I’ve updated my article accordingly. March 31, 2020: John Sanders suggested that it might be a good idea to add a link to launch the web part maintenance mode, and I really like it. You just need to append ?maintenancemode=true to the page URL to turn the page into maintenance mode. Great idea! Photo credits Photo by Nick Hillier on Unsplash\n","permalink":"http://localhost:1313/posts/display-the-solution-version-in-your-web-part/","tags":null,"title":"Display the solution version in your web part"},{"categories":["Power Platform"],"contents":"Introduction Power Automate allows you to create automated workflows that help you streamline your business processes on focus on what really matters.\nYou can do this by combining building blocks known as \u0026ldquo;connectors\u0026rdquo;.\nThere are several hundred connectors to pick and choose from: you can send emails, connect to databases, call custom APIs, connect to Dynamics, SharePoint, Planner, etc.\nIn fact, there are so many connectors at your disposal that you may never have noticed one connector that allows you to generate Word documents by inserting dynamic data into Word templates.\nIn today’s post, I’ll explain how to use the Word connector in Power Automate to generate some documents. It’ll be useful any time that you have a business process that needs to send a letter, generate a contract, or produce any sorts of documentation that needs to be printed and/or signed.\nPrepare your template The first thing you need is a Word template.\nFor this article, I’ll use a standard Word template, but you can follow my instructions with your own template.\nLet’s get started by using the following steps:\nFrom within Word, select File \u0026gt; New\nFrom the list of templates that are available, search for the template you’d like. For this sample, I’m using Blue curve letterhead because I’m too lazy to write my own template.\nIt will give you a preview of the template. Just click Create to create a new document from that template. If you prefer, you can use a new blank document and copy and paste your existing template. I’m not picky.\nTo insert content dynamically inside your template, you’ll need to create some Content controls. Content controls allow you to define areas within a Word document that you want to make editable. The Blue curve letterhead template already has content controls, but we’ll define some custom ones as well. To insert content controls, you need to use the Developer tab. If you already see the developer tab, skip to step 8.\n. If you don’t see the Developer tab, right-click on a blank area of your Word ribbon, and select Customize the Ribbon…\nIn the Customize the Ribbon and keyboard shortcuts dialog, find the Developer tab on the right side of the dialog (under Customize the Ribbon) and check it, the select OK.\nLet’s insert a custom content control in our template. For this example, we’ll pretend that we want to specify a case number in our letter. From your Word document, find the line between the [Recipient Name], [Street Address, City, ST ZIP Code] and Dear Recipient and insert a new line, then type Case Number:.\nPosition your cursor to the right of Case Number: and, from the Developer tab, select Plain text control.\nYou should see a new content control appear where your cursor was:\nTo change the prompt text for your Case Number placeholder, select Design Mode from the Developer tab\nWord will highlight the content controls in your document. Replace Click or tap here to enter text with [Case Number]. You can also control the text format if you wish to do so.\nIf you’re up to it, replace the placeholder text in the other content controls in your template. 13. To get out of the Design Mode, click it again in the ribbon. The placeholders should hide again. Select the [Case Number] content control and select Properties from the Developer tab. In the Content Control Properties dialog, change the Title to Case Number then click OK.\nRepeat setting the content control properties for all the content controls or they won’t appear as dynamic fields to populate in Power Automate. When your template is ready, you’ll need to save it as a Template (dotx), and you’ll need to save it where Power Automate can find it. I like to store my templates in a SharePoint document library that I’ve pre-created (called Templates — I know, super original). To do so, use the Word File then Save As menu, then select your desired SharePoint site and document library then click Save.\nI named mine Case Letter Template, if you’d like to know.\nOnce your document is saved as a template on a SharePoint site, we’re ready to create the workflow in Power Automate.\nPrepare your Flow Let’s create a Flow in Power Automate.\nIn a real-life scenario, you’d probably want a change in your systems to trigger a document generation — a new record in Dynamics 365, a record change in Common Data Services, or a new record in SharePoint for example.\nHowever, to keep this example simple, I’ll use a simple manual trigger that we can call at any time.\nTo do so, follow these steps:\nGo to https://make.powerapps.com/ In the left navigation, selec Flows From the + New menu, select Instant — from blank. Again, you can choose the best trigger for your own specific needs.\nFrom the Build an instant flow dialog, specify a name (e.g.: Generate Case Letter) and select Manually trigger a flow under Choose how to trigger this flow, then click Create.\nIn your new flow, select + New step.\nIn the Choose an action box, type Word and select Word Online (Business)\nFrom the list of actions that appear, select Populate a Microsoft Word template\nIn the new Populate a Microsoft Word Template action, select the SharePoint site (or Group) where you saved your document, the Document Library where you stored the template, and pick the template from the file picker.\nIf you can’t find the document you’ve saved, make sure it isn’t still open in Word and try changing the site or the Document Library. When you pick the proper template, the action dialog will change to display the various content controls. Note that it displays a dynamic value for each content placeholder you created.\nIn a real production system, you’d probably want to retrieve your template data from your existing systems — like Dynamics 365, Common Data Services, or a database. for this article, we’ll just prompt for it when we launch the workflow. To do so, select the Manually trigger a workflow box to expand it\nFrom the Manually trigger a workflow box, select + Add an input and select Text when prompted to Choose the type of user input\nIn the new Input field that is created, type Address. Repeat adding new inputs for Recipient Name, Case Number, Sender Name and Sender Title\nNote that I’m trying to keep this sample as simple as possible. In real life, I’d probably want to pick the name of the sender from the current context, and I’d get the title from the user’s properties. I’d probably also use a separate field for address 1, city, state, zip. Now go back to the Populate a Microsoft Word template and, for each placeholder, insert the matching dynamic values from the trigger inputs.\nWe’re almost done! In our next step, we’ll store the newly generated document in a SharePoint library.\nSaving the generated document The Populate a Microsoft Word template action generates the document, but it doesn’t do anything with it. It’s up to you to save it somewhere, convert it to PDF, or email it.\nFor our sample, we’ll use the SharePoint Create file action by following these steps:\nBelow the Populate a Microsoft Word template action, select + New step In the Choose an action dialog, type SharePoint and select Create file from the list of possible actions.\nIn the newly created action called Create file, select the Site Address where you want to store the document, and the Folder path for the document library where the newly generated documents will go. For the File Name, use the Case Number dynamic value from the trigger. For the File Content, use the Microsoft Word Document from the Populate a Microsoft Word Template action.\nThat’s it! Now we just need to test the Flow by selecting Save and Test. When prompted to enter values, go ahead and enter some text values and click Run flow\nOnce the flow is finished running, you’ll find a document with a matching case number in your destination library. It should look like this:\nBut what about conditional sections? That’s really all there is to it… but a common question I get is \u0026ldquo;How do I change content of the template based on some conditional values?\u0026rdquo;.\nThe easiest answer is: just use more than one template and create conditional logic in your flow to populate the appropriate template based on whatever rules you want.\nHelp, my content controls don’t show up in the Populate a Microsoft Word Template If you find that your content controls don’t show up after you save your template, I have found that adding a Title to the property control seems to help.\nIf that doesn’t work, make sure you used a Plain text content control and try removing the formatting.\nIf the template doesn’t seem to refresh, try saving your flow, leaving the flow, then editing it again. It will reload the template and should refresh the list of content controls.\nConclusion As you may have noticed, it probably takes longer to create a proper Word template than it does to dynamically populate a document in Power Automate.\nI encourage you to explore the capabilities of the Word Online (Business) connector.\nI hope this helps?\nPhoto Credits Photo by Patrick Fore on Unsplash\n","permalink":"http://localhost:1313/posts/generate-word-documents-from-a-template-using-power-automate/","tags":null,"title":"Generate Word documents from a template using Power Automate"},{"categories":["Power Platform"],"contents":"Introduction When using cloud-based services like Office 365 and the Power Platform, it can be challenging to integrate with your on-premises resources. All of a sudden, your on-premises databases, APIs, file shares, and even your existing on-premises SharePoint infrastructure become impossible to reach. At least, not without making some giant holes in your firewall.\nAt our recent Toronto Citizen Developer User Group meeting, my good friend Luis Duran demonstrated how to use the on-premises data gateway to access a custom web API running on his workstation from Power Automate.\nHe had rehearsed the demo earlier that day from our offices. Still, he had changed many environmental variables by moving his demo to our meetup venue. Luis ran a web API from his workstation, over a different network (the guest wifi at the Microsoft office), using a new IP address.\nLet’s say that if his demo didn’t work, no one would have blamed him. Heck, I tried to run a web API project using a static IP address on my workstation earlier in the day, and I had issues getting it to work.\nBut the demo worked!\n\"Any sufficiently advanced technology is indistinguishable from magic.\"\rArthur C. Clarke\rAs Arthur C. Clarke once said: \u0026ldquo;Any sufficiently advanced technology is indistinguishable from magic.\u0026rdquo;. In today’s blog post, I’ll explain how to use the on-premises data gateway to access your local resources from the Power Platform.\nMaybe I can prove that the Data Gateway isn’t magic?\nWhat is the On-Premises Data Gateway You have services in the cloud, like Power BI, Power Apps, Power Automated, Azure Analysis Services, or Azure Logic Apps.\nYour data is not in the cloud. It sits on your company’s network behind firewalls.\nThe on-premises data gateway works as a sort of bridge that lets your cloud-based services work with your on-premises data.\nBut it does so securely without requiring you to punch any holes in your firewalls.\nAnd it is fast!\nHow does it work? Do you use some chat app at work? Maybe you use Microsoft Teams or Twitter?\nWhen someone sends you a chat, they’re not connecting directly to your workstation over some obscure port.\nWhen your friend sends you a chat message, they send it to a gateway service that is usually in the cloud.\nThe gateway service then tells your app that you received a new chat message and displays it for you.\nThe chat gateway knows how to reach you because when you signed-in with your chat app, the app contacted the gateway and said, \u0026ldquo;If you need to send me notifications, let me know! I’m right here\u0026rdquo;.\nIt often uses the standard SSL ports (443) to keep prying eyes from intercepting your chat messages from the app to the gateway.\nThe on-premises gateway mostly works the same way. Except that instead of a chat app you install on your workstation, it is a Windows service you install anywhere on your network (e.g., your workstation or a server).\nInstead of chat messages, it receives requests to retrieve data from available resources on that same network. It can also receive requests to update data.\nWhen it launches, your on-premises gateway lets the cloud-based gateway service that it is ready. \u0026ldquo;Hey, let me know if you need any data. I’ll be here!\u0026rdquo;.\nWhen your Power App, Power Automate, or any of the other services needs data, it sends an encrypted request with credentials to the cloud gateway service.\nThe gateway service then sends that encrypted request to your on-premises gateway.\nAnd your on-premises gateway decrypts the request, extracts the credentials, and connects to your data source with those credentials. It sends the query to the data source and, when it gets a response, sends the encrypted results back through the gateway service, which sends it to cloud service that requested the data in the first place.\nMicrosoft has a pretty diagram that explains the concept. I encourage you to read more about how it works on their site:\nImage: Microsoft\nWhat are the requirements? The good news is: you don’t need to punch any holes in your firewalls or anything like that.\nHowever, you shouldn’t install the gateway on any rinky-dink computer. You need at least a 64-bit version of Windows 8 or Windows Server 2012 R2.\nThe machine should always be on and always connected to the Internet. Please don’t install it on a laptop that goes to sleep or puts the network adapter to sleep to save power.\nMicrosoft recommends an 8-core CPU with at least 8 GB of memory and a solid-state drive (SSD).\nTry using a physical network connection over a wireless network.\nThe person installing the gateway on the device must also be the administrator of the gateway. You’ll need to have enough privileges on the computer you’ll be using to be able to install the application.\nYou can only install one type of gateway per computer (yeah, there are more than one types of gateway — we’ll explain later)\nIf you’re planning on using Windows credentials in your data sources, your gateway should go on a domain-joined machine.\nAnd please don’t install the gateway on a domain controller.\nHow do I install a gateway? At the risk of repeating myself: you’ll want to install gateways on computers that are always on and connected to the Internet.\nThe steps below are the same installation steps provided by Microsoft; you should check their instructions to see if they have updated.\nDownload the gateway. You can also download the gateway from any cloud service that supports gateways. For example, in Power Apps, you can go to Data \u0026gt; Gateways \u0026gt; + New gateway.\nLaunch the installer and select Next.\nWhen it prompts you to choose the type of gateway you need, select On-premises data gateway (recommended) and select Next. Like I said earlier, there is another version of the gateway called the \u0026ldquo;personal mode,\u0026rdquo; but it is intended to be used by you and with Power BI only.\nYou may or may not get a warning saying that the gateway should be installed on a computer that is always on. You can just select Next. It’ll prompt you for an installation path and to accept the terms of use. Pretend to read the terms of use and privacy statement, select the checkbox then select Install.\nYou’ll need to enter the Email address to use with this gateway. Use the Office 365 email address who will become the administrator for this gateway, then select Sign in. You’ll probably be prompted to sign-in.\nIf all goes well, it’ll say that you’re signed in. It will ask you if you want to register a new gateway or migrate, restore, or takeover another gateway. Since you’re here, I’ll assume you want to select Register a new gateway on this computer and select Next.\nIt will ask you to enter a New on-premises data gateway name. Make sure to use a unique name that will make it easy to distinguish it from others (i.e., not Gateway). You’ll also be asked for a Recovery key — that’s an 8-character or longer secret you’ll use if you ever need to recover a gateway. You can make up whatever recovery key you want, but make sure you store it somewhere safe! If you were adding a gateway to an existing cluster, this is where you would specify to join the cluster. Feel free to read Microsoft’s instructions to add to an existing cluster if you want. Select Configure.\nIf all goes well, you’ll get a message saying the gateway is online and ready to be used. Yay! Select Close. Since the gateway works with Power Apps, Power Automate, Power BI, and Azure, it’ll show you all which services it connects to. Usually, the Azure service is not connected by default, but you can select Create a gateway in Azure if you want.\nIf all goes well, you should find your gateway in the Power Platform site. For example, in Power Apps, you would go to Data \u0026gt; Gateways in your default environment.\nYou’re done! Now you’re ready to use the on-premises data gateway!\nTo use an on-premises data gateway with a standard connector To use your gateway, just create a connection for one of the gateway-enabled connectors.\nRight now, it works with the following connectors:\nApache Impala DB2 File System Http with Azure AD Informix MySQL Oracle Database PostgreSQL SharePoint SQL Server Teradata To use SQL Server For example, to create a connection in Power Apps, follow these steps:\nLog-in to Power Apps From the left navigation, select Data then Connections Select + New connection\nSelect a connector from the list. For this example, we’ll select SQL Server\nA dialog that is specific to the type of connector will pop-up. Note that, depending on the connector, the option to connect to a gateway may only appear based on what configuration you choose. For example, SQL Server does not let you use a gateway when your Authentication Type is Azure AD Integrated. It makes sense since that option is for cloud-based SQL Server connections.\nTo use a gateway connection, you’ll need to select either SQL Server Authentication or Windows Authentication\nIf you scroll to the bottom of the configuration dialog, you should see an option to Choose a gateway\nIf you didn’t install your gateway yet, you could install it from the link below the Choose a gateway then hit the Refresh icon to show your newly installed gateway. Fill the configuration information (SQL server name, SQL database name, and credentials), then select your gateway and select Create. To use SharePoint Some other connectors may prompt you to select at the start of your connection. For example, if you create a SharePoint connection, the first thing you’ll see is this option:\nAnd if you select Connect using an on-premises data gateway, you’ll get prompted to enter more details:\nIf you scroll to the bottom of the configuration dialog, it’ll prompt you to select a gateway:\nTo use the File System When some connectors only work with on-premises data, you’ll have to select a gateway right away. For example, when creating a connection to your on-premises File System, you’ll get the following dialog:\nAnd if you fill all the configuration details, the last option is to select a gateway:\nUsing a gateway with a custom connector You can also use an on-premises data gateway with custom connectors.\nFor example, let’s say you have an API that is only available within your on-premises network, but you want to call it from within Power Apps or Power Automate. You would follow these steps:\nLog-in to Power Apps From the left navigation, select Data then Custom Connectors Select + New custom connector and pick how you want to define the custom connector. This article is already super-long, so I’ll spare you the details here, but leave a comment if you want more information about how to create a custom connector.\nEventually, you’ll get to the General information step. This is where you select Connect via an on-premises data gateway\nFinish the custom connector steps. You’ll be prompted to select a gateway only when you create a connection with your new custom connector.\nHow to use a gateway connection? Your gateway connections will appear in your list of connections, just like cloud-based connections. You can use them as any other regular connections within your apps.\nIt may not always be obvious that you can connect to an on-premises resource. For example, let’s say you want to create a new Flow with Power Automate that launches when a new file is created on your on-premises SharePoint server. You would follow these steps:\nMake sure to create your gateway first! From within https://make.powerapps.com, select Flows then + New \u0026gt; + Automated — from blank\nIn the dialog that pops up, you would name your Flow and select When a new item is created under SharePoint, and select Create\nYour new Flow will prompt you to select enter a URL to your SharePoint site Site address and select a List Name.\nThis is where it gets tricky: if you enter the URL of your on-premises SharePoint site, Flow may simply tell you ‘Site Address’ is required and ignore the URL you entered.\nThat’s most likely because the default connection for SharePoint actions is for your SharePoint Online instance. You can change your action’s connection by using the … and select your on-premises connection from under My connections\nYou can tell which one is your on-premises connection because its default name will be the name of the user you specified when you created the connection. Once you change your connection, you should be able to enter the URL to your on-premises SharePoint site, and it should work. Note that you can also have multiple SharePoint actions in your Flow, and each one can use a different connection. It could come in handy if you wanted to move files from SharePoint on-premises to your SharePoint online instance, for example.\nHow about support for environments? The Power Platform allows you to define environments to separate your production data from your sandbox, dev, and test data.\nUnfortunately, as of this writing, the on-premises data gateways only work with the default environment on your tenant.\nIf you need to create a Power App or a Flow that use the gateway, they must also be in the default environment.\nIt means that your apps and Flows must also be in the same region as your default environment.\nIt is a serious limitation, and the Power Platform team is aware of this.\nThey’re super busy adding new features all the time, so you can’t blame them if it hasn’t been a priority for them.\nI’m sure that one day they’ll get around to adding support for non-default environments, but until then, feel free to provide them with feedback.\nConclusion They may seem magical, but on-premises data gateways allow you to access your on-premises data from the cloud in a secure way, and it is very fast and easy to use.\nYou should definitely consider establishing some form of governance before you use on-premises data gateways, but that’s a topic for another day.\nI hope this helps?\nThanks Thanks to Luis Duran for doing all the hard work for our user group presentation. I simply recapped what he said in this post.\nPhoto Credit Image by Pexels from Pixabay\n","permalink":"http://localhost:1313/posts/accessing-your-on-prem-data-using-on-prem-data-gateway/","tags":null,"title":"Accessing Your On-Premises Data Using the On-Premises Data Gateway"},{"categories":["Microsoft 365"],"contents":"Introduction I was installing the latest version (2.7) of the Office 365 CLI — if you haven’t tried it yet, you definitely should — and I started thinking \u0026ldquo;Hmm, I wonder if I could do a quick contribution for this?\u0026rdquo;.\nI absolutely love the Office 365 CLI and I think the team has done an amazing job with it. I even made a tiny contribution a while ago, but never got around to doing more.\nKeep in mind that I have to study for two certification exams that I have scheduled over the next two days, I have to review my materials for Office 365 Saturday Redmond 2020, I have to prepare for the upcoming Toronto Citizen Developer User Group meeting, I have a web part that I need to finish with the help of David Warner II, and I need to finish adding Graph integration to my PnP Calendar Control…\n… but other than that, I have some spare time. I took a look at the list of Office 365 CLI issues to look for inspiration and found a request for a new command called get ID of the current tenant.\nWait a minute, I know how to get the tenant ID! I use this trick all the time. And it doesn’t require any code or any tools to be installed.\nSo I thought I should at least share my trick for finding the tenant ID, and if I’m a good boy and do all my work today maybe I’ll treat myself and do a contribution to the Office 365 CLI.\nGetting the Tenant ID I found this trick over 3 years ago in a Stack Overflow discussion and, but it took a little playing around to get it working.\nTo get your tenant id, follow these steps:\nStart with your original tenant name. It should be in the form of [yourtenant].onmicrosoft.com. Do not use your custom domain name, use your original tenant name. If in doubt, use whatever comes before .sharepoint.com on your SharePoint Online site.\nBrowse to https://login.microsoftonline.com/[yourtenant].onmicrosoft.com/.well-known/openid-configuration. Note that you have to replace [yourtenant] with the tenant name you obtained in step 1. Make sure to keep the onmicrosoft.com bit too. This URL is not authenticated, so you should be able to get to it from anywhere without logging in, so you can use something list Postman if you want, but a regular browser will do.\nYou’ll get some JSON back. Don’t worry, you don’t need to speak JSONese, just look for whatever URL comes after \u0026quot;token_endpoint\u0026quot;: . It should start with \u0026quot;[https://login.microsoftonline.com/](https://login.microsoftonline.com/).\nYour tenant ID is the alphanumeric value immediately after \u0026quot;[https://login.microsoftonline.com/](https://login.microsoftonline.com/) and before /oauth2/token\u0026quot;,. For example, if you get this first line:\n\u0026quot;token_endpoint\u0026quot;: \u0026quot;https://login.microsoftonline.com/ef32e188-30ce-4f80-8956-d95598788bdc/oauth2/token\u0026quot;,\ryour tenant ID will be ef32e188-30ce-4f80-8956-d95598788bdc\nThat’s it!\nConclusion I know, I know, some of you will say \u0026ldquo;You can just go to the Azure Admin center and get the directory ID\u0026rdquo; as per Official Microsoft documentation, but it assumes that you have access to the Azure Admin center.\nThe way described in this post works regardless of your permissions, and does not need any tools to be installed on your computer, or any code.\nI hope this helps?\nPhoto Credit Image by Pexels from Pixabay\nUpdates March 2, 2020: Laurent Sittler has an article which shows about 17 different ways to retrieve the tenant ID. Very cool!\nMarch 2, 2020: Joseph Velliah has also written an article about this topic. Thanks Joseph!\nMarch 2, 2020: João Ferreira kindly pointed out that he has a great article showing two more approaches to get your tenant ID.\nMarch 1, 2020: Thanks to Kevin McDonnell for reminding me that ShareGate has a web-based tool available at www.whatismytenantid.com.\nMarch 1, 2020: If you want to use PowerShell to find your tenant ID, Pen Warner wrote in with this cool PowerShell script:\n$tenantID = (Invoke-WebRequest https://login.windows.net/\u0026lt;TENANT_NAME\u0026gt;.onmicrosoft.com/.well-known/openid-configuration|ConvertFrom-Json).token_endpoint.Split('/')[3]\r","permalink":"http://localhost:1313/posts/find-your-sharepoint-online-tenant-id/","tags":null,"title":"Find Your SharePoint Online Tenant ID without tools or code"},{"categories":["Power Platform"],"contents":"Introduction When it comes to the type of work I do, I guess I have a niche.\nI work on challenging business process management projects with a lot of Dynamics, SharePoint, and workflows. Nowadays, I use Power Automate, but when I started, workflows were not so easy to build.\nThe majority of the projects I worked on had already failed at least once or twice before I join them.\nBy the time I join a project, the team is usually willing to try anything if it means it’ll help them succeed.\nInvariably, when I start digging into the requirements, there is always an over-complicated workflow that must handle every possible scenario known to man.\nThat’s when I tell them the story of how Ohio State University designed the walkways for its campus.\nThe Oval The Ohio State University, founded in 1870, has an incredible 11-acre courtyard that many students and locals believe is the heart of the campus.\nLocals call it \u0026ldquo;The Oval.\u0026rdquo; It is a network of pathways and landscaping and sculptures surrounded by buildings. It is a beautifully inspiring place to hang out, relax, and study.\nThe Oval wasn’t always the way it is today. It began as a place where livestock grazed near the library and the university hall.\nIn 1911, as the story goes, Joseph N. Bradford became the University’s architect.\nHis design for the campus landscaping was a very rigid geometric pattern of walks within the Oval. He wanted a very symmetrical design that would require changing the bordering streets to make the Oval more rectangular.\nUnfortunately (or fortunately for my story), project delays and cost overruns meant that there was no money left to implement Bradford’s full design.\nThe landscaping crew went to Bradford to ask for his revised plans for the campus landscaping.\nIn response, Bradford had the crew join him in a hot-air balloon that rose above the campus.\nFrom such a high viewpoint, they could see the paths that the students had made walking back and forth between the buildings.\nWhere people walked most frequently, the grass had visible indentations. As this was in the winter, the snow made the pathways even more distinctive.\nThe pathways were far from symmetrical. Instead, they showed the most efficient routes between buildings — something that was in itself beautiful and had an organic quality to it.\n\u0026ldquo;There’s your landscaping design! Follow these pathways!\u0026rdquo; said Bradford. He took a selfie of himself and the grounds below and dropped the mike. \u0026ldquo;Bradford, OUT!!!\u0026rdquo;\nOk, that might not be exactly how it happened, but you get the gist of it.\nDesire Paths and workflows A desire path is a path that is formed when people (or animals) choose to walk between points A and B. It often represents the most direct or most convenient way between the source and destination.\nUrban planners often observe drastic differences between their designs and the real-life use of their designs.\nWith modern tools such as Power Automate, it can be very easy to design workflows.\nMaybe too easy sometimes.\nThe first instinct is to design super-complicated workflows that will handle every single possible scenario — regardless of how probable the scenario is.\nSometimes, the best thing to do is to design the bare minimum workflow possible, and then step back and observe how people use the workflows.\nWhere are there exceptions?\nWhere are the delays?\nWhere do people make mistakes?\nDo you find that the workflows start and stop in mid-flow because there is missing information that should have been captured?\nInstead of trying to automate everything from the start, try to handle the most common scenarios. Then try to fix where things break most often, or where the most costly mistakes happen.\nInstead of doing one giant revision of a workflow that will take you and your team months and months of work to implement, try to do multiple smaller iterations and continue to add value to your end-users and customers.\nYou may find that you’ll get 80% of the scenarios done with 20% of the effort.\nIn other words, let your users show you their desire paths and implement the workflows your organization truly needs to solve business problems — not what you thought you needed.\nConclusion The Ohio State University campus story is a story I like to use to illustrate how it is better to design a simpler workflow and observe how people use your new system instead of over-complicating your process.\nI largely made up the details of the story. If anyone has a more accurate depiction of the story, please let me know.\nSources I inspired my definition from Jussia Hola’s great article on Desire Paths. I strongly recommend you read it. The Oval is a great article about the history behind the design of the campus. I largely inspired my narrative from that. Any inaccuracies are mine alone. ","permalink":"http://localhost:1313/posts/simplify-workflows-with-desired-paths/","tags":null,"title":"Simplify workflows with desired paths"},{"categories":["Life"],"contents":"\"As we work to create light for others, we naturally light our own way.\" Mary Anne Radmacher\rI work crazy hours. To top it off, I commute a total of 3 hours every day.\nWhen I get home from work, I’m usually exhausted.\nOne of my guilty pleasures is to play a video game with my kids. When they were younger, we’d play one of the many Lego games on Xbox. Now, we tend to play Halo or Call of Duty.\nRegardless of the age difference between my kids and me, the little buggers are worthy adversaries.\nThey might even be better than me– but don’t tell them I said that.\nI love that in the video game world, we’re able to play as equals. We’re sometimes teammates, partners, and sometimes enemies. We celebrate each other’s victories and tease each other’s failures.\nIn a household with three people diagnosed with an autism spectrum disorder, breaking barriers of communication and making emotional connections can sometimes be hard. Video games are one of the ways that we can connect.\nWhen I ponder about how lucky that we can share a moment like this over video games, it saddens me to think that there are people with physical disabilities who don’t have the opportunity to connect with their loved ones over a video game.\nBut things are changing, thanks to my friend Bryce Johnson and his team.\nWhat they did may seem very simple at first, and you may think that it only affects people with disabilities. Still, I believe that their achievements have much more significant ramifications.\nThe Xbox Adaptive Controller The Xbox Adaptive Controller is a funky-looking gaming input experience that allows people with limited mobility play video games by featuring large programmable buttons and providing the ability to add external devices such as switches, buttons, and joysticks.\nTo be clear, the Xbox Adaptive Controller (XAC) isn’t just for people with disabilities — Bryce is the Inclusive Lead for Microsoft Devices, and the last thing he and his team would want to do is design something that excludes other people from using it.\nThe XAC’s unique design, however, allows people with disabilities to play video games — just like everyone else.\nThere was a time where creating devices with accessibility in mind would be an after-thought for most companies because it would have such a \u0026ldquo;niche\u0026rdquo; market, or because it would increase the cost of production.\nBut with the XAC, Microsoft is sending a clear message: everyone matters. And everyone should be able to play equally.\nThe XAC isn’t just some rare device that only a few people can buy at an exorbitant price either; it is available in the Microsoft Store for a little more than a regular controller (and less than the Xbox Elite Wireless Controller.\nThe controller has gotten so much press coverage since its release (and won so many cool awards) that other large corporations are following suit.\nLogitech, for example, released its Adaptive Gaming Kit which gives users more options with customizable controls for the Xbox Adaptive Controller.\nYou read that right: instead of competing with Microsoft and releasing their own controller, they built controls that works with the XAC to add more capabilities! Something possible because the XAC is not only inclusive for people, but technologies; It works with standard connection types such as 3.5 mm jacks and USB 2.0 devices.\nAnd Logitech isn’t the only company doing this: PDP Gaming, QuadStick. AbleNet, and RAM Mounts are among the visionaries who work together to help empower XAC users.\nInclusivity is cool I have known Bryce Johnson for probably close to 20 years now (that’s right, I met him when I was eight!). He would come up with crazy user interface designs for SharePoint, and I would implement them.\nI would always love it when I would implement his designs, and people would say, \u0026ldquo;Wow, this looks good… there’s no way that’s SharePoint!\u0026rdquo;. It was especially rewarding to hear it from Microsoft employees!\nBack then, Bryce already had an eye for user experience design and inclusivity. Before it was ever cool to care about this stuff, Bryce designed everything with accessibility in mind.\nWe didn’t get to stay in touch when he went to Microsoft, but I was always delighted to read his updates on LinkedIn.\nIn May of 2018, when he started posting about the Xbox Adaptive Controller, I was really proud to be able to tell people that I knew him. I’m still proud!\nBryce will hate that I’m writing this article all about him, and I’m sure that he’ll remind me that he was only part of the team that made the XAC happen, but I know Bryce, and I know the kind of person he is. If the other members of his team are like him, they genuinely care about inclusive design and accessibility.\nI’m also thrilled to know that Microsoft is serious about inclusivity across their devices and that with Bryce as the Inclusive Lead of Microsoft Devices, the Xbox Adaptive Controller is probably the first of many cool products designed with heart and soul.\nI’m sure that the applications of the XAC will reach beyond gaming, and that we’ll see more devices change how people communicate and work together.\nConclusion You may not think that an Xbox controller would be such a big deal, but for someone with a disability who gets to play video games with their family and friends for the first time, I assure you that it can be life-changing.\nTo be able to play online and be treated as an equal by other players for the first time in someone’s life must be an amazing feeling.\nIf one of my children were disabled, I can’t imagine how it would be to be able to play video games with them for the first time thanks to the hard-work of the many team members at Microsoft who contributed to the XAC.\nDesigning with accessibility in mind makes a difference because it gives everyone the same opportunities.\nYou may not design hardware devices –like Bryce and the team– but if you maintain content in SharePoint, build applications in Power Apps, or create custom SPFx web parts, you can still make a positive impact with your users.\nIn my next posts for the SharePoint Framework Design Principles series, we’ll discuss accessibility design principles for SPFx solutions.\nIn the meantime, Bryce, I’m proud of the work you’re doing at Microsoft. You inspire me!\n","permalink":"http://localhost:1313/posts/leveling-the-playing-field-with-accessibility/","tags":null,"title":"Leveling the playing field with accessibility"},{"categories":["SPFx"],"contents":" NOTE: This matrix can also be found in the SharePoint Framework Developer documentation where I hope that the community will continue to help me maintain it.\nIntroduction A while ago, I was looking for an official list of which version of SPFx is compatible with each SharePoint version, but I couldn’t find what I wanted.\nI kinda forgot about it until today, when someone reached out to me and asked me if I had a SPFX/SharePoint compatibility matrix handy.\nAs I turns out, I had created such a matrix when I wrote my SPFX timeline.\nSo, as I am the world’s laziest developer, I figured it would be very little effort to put such a matrix together by leveraging work I had already done.\nThe list in this post is not an official list; it is based on my interpretation of the SPFx release notes. If you find an error in it, please let me know and I’ll fix it.\nSPFx Version Compatibility SharePoint Version Supported SPFx version Notes SharePoint Online All versions SharePoint Server 2019 v1.4.1 or lower SharePoint Server 2016 v1.1 Requires Feature Pack 2 SPFx Development Environment Compatibility PRO TIP: If you need to download a previous of Node.js, use the previous releases page from their download section. You can also use links in the table below to download the versions of Node.js directly.\nSPFx Node.js NPM TypeScript React 1.18 v16, v18 v5, v6, v7, v8, v9 v4.5, v4.7 v17.0.1 1.17.4 v16.13+ v5, v6, v7, v8 v4.5 v17.0.1 1.17.3 v16.13+ v5, v6, v7, v8 v4.5 v17.0.1 1.17.2 v16.13+ v5, v6, v7, v8 v4.5 v17.0.1 1.17.1 v16.13+ v5, v6, v7, v8 v4.5 v17.0.1 1.17.0 v16.13+ v5, v6, v7, v8 v4.5 v17.0.1 1.16.1 v16.13+ v5, v6, v7, v8 v4.5 v17.0.1 1.16.0 v16.13+ v5, v6, v7, v8 v4.5 v17.0.1 1.15.2 v12, v14, v16 v5, v6, v7, v8 v4.5 v16.13.1 1.15 v12, v14, v16 v5, v6, v7, v8 v4.5 v16.13.1 1.14 v14, v12 v5, v6 v3.9 v16.13.1 1.13.1 v14, v12 v5, v6 v3.9 v16.13.1 1.13.0 v14, v12 v5, v6 v3.9 v16.13.1 1.12.1 v14, v12, v10 v5, v6 v3.7 v16.9.0 1.12.0 v12, v10 v5, v6 v3.7 v16.9.0 1.11.0 v10 v5, v6 v3.3 v16.8.5 1.10.0 v10, v8 v5, v6 v3.3 v16.8.5 1.9.1 v10, v8 v5, v6 v2.9 v16.8.5 1.8.2 v8, v10 v5, v6 v2.9 v16.7.0 1.8.1 v8 v5, v6 v2.7, v2.9, v3.x v16.7.0 1.8.0 v8 v5, v6 v2.7, v2.9, v3.x v16.7.0 1.7.1 v8 v5, v6 v2.4 v16.3.2 1.7.0 v8 v5, v6 v2.4 v16.3.2 1.6.0 v6, v8 v3 (w/ Node.js 6.x), v5 (w/ Node.js 8.x) v2.4 15 1.5.1 v6, v8 v3 (w/ Node.js 6.x),v5 (w/ Node.js 8.x) v2.4 v15 1.5.0 v6, v8 v3 (w/ Node.js 6.x), v5 (w/ Node.js 8.x) v2.4 v15 1.4.1 v6, v8 v3, v4 v2.4 v15 1.4.0 v6 v3, v4 v2.4 v15 1.3.0 v6 v3, v4 v2.4 v15 1.1.0 v6 v3, v4 v2.4 v15 1.0.0 v6 v3 v2.4 v15 Conclusion If I made any mistakes in the list above, please do not hesitate to write in the comments. I’ll gladly update my matrix.\nI still think that there should be an official compatibility list something in the SharePoint Documentation.\nMaybe I should just submit a PR to the SP Dev Docs repo and hope the community will help me keep my compatibility matrix accurate?\nThanks Thanks to David Warner II for the inspiration for this post and for helping fix my mistakes While doing my research for this post, I found Andrew Connell has also written a handy article. Updates September 14, 2023: SPFx 1.18 is here! (I know, I\u0026rsquo;m a little late) June 27, 2022: SPFx 1.15 and updated my blog. Feb 19th, 2022: SPFx 1.14 is here! June 25, 2021: Totally forgot about SPFx 1.12.1 March 15, 2021: Added SPFx 1.12 October 5, 2020: Added links to download versions of Node.js directly. September 11, 2020: Thanks to Don Kirkham for suggesting that we add the link to Node.js previous versions page. March 20, 2020: Moved this article to the SharePoint Framework Developer documentation where I hope that the community will continue to help me maintain it. January 12, 2020: I love it when people take the time to write in comments to help me keep content up-to-date! Thank you Ronald Borman for the many corrections to my matrix. Keep ’em coming! January 2, 2020: Thanks to David Warner II for pointing out that Andrew Connell has an awesome article on how to use NVM as a better Node package manager. It is a great solution if you need to run multiple versions of Node.js on the same environment. ","permalink":"http://localhost:1313/posts/spfx-compatibility-matrix/","tags":["React","SPFx"],"title":"SPFx Compatibility Matrix"},{"categories":["SharePoint"],"contents":"Introduction I’ve covered this before, but I’ll repeat myself: moving to SharePoint Online isn’t just about moving your documents.\nYou also need to move your users.\nNot physically, of course. But you need to help your users transition to the new platform, and it should be as painless as possible for them.\nYou should spend some time preparing your users for the upcoming changes, educating them and answering their questions. Because, for most users, change is a scary thing.\nBut even if you spend countless hours educating your users and holding their hands through the migration process, they may still have bookmarks to content that you moved from your on-premises SharePoint server to SharePoint Online. They may have shortcuts and favorites?\nSome of the documents that you migrated may have links to your old on-premises SharePoint installation. Are you going to update every single document that contain hyperlinks to the old SharePoint site?\nAnd how can you whether your users are still trying to go to old on-prem SharePoint links that are no longer there?\nIn today’s post, we’ll bring an old feature back from the dead to help make your migration to SharePoint Online a lot easier for you and your users.\nIt only works in situations where you keep your old SharePoint on-premises (2013, 2016, and 2019) server up and running while you migrate the content from it to your SharePoint Online instance.\nBest of all, you won’t need to install any Dlls, Sandbox solutions, or Add-ons on your servers.\nThe original sharepointsmart404 Back in 2009 a brilliant person by the name of Josh Carlisle created a cool solution called sharepointsmart404. It enhanced the out-of-the-box SharePoint \u0026ldquo;Page Not Found\u0026rdquo; error (also known as a 404 error) to provide support for vanity URLs.\nA vanity URL, in case you’re wondering, is a unique URL branded for marketing purposes. Instead of using long and ugly URLs, you can use shorter, easier to remember URLs.\nWith smart 404, when people looked for a page or document that was no longer there, SharePoint would redirect them to the new location of that page/document as long as it found a matching vanity URL.\nNOTE: If you are the author of the original sharepointsmart404, or know the original author, I would like to link to their profile and give them credit. Please contact me, and I’ll make sure to update this post.\nHere is how the feature worked:\nWhen someone asks for a SharePoint URL which does not exist, SharePoint redirects to the 404 error page The feature intercepts the 404 error and looks for the requested URL against a list of vanity URLs. Each vanity URL entry consists of a requestURL (the URL that caused the page not found error), and a redirectURL (the URL where users should be redirected). If there is a matching vanity URL, redirect users to the redirectURL and don’t display the \u0026ldquo;Page Not Found\u0026rdquo; message If there isn’t a matching vanity URL, display the \u0026ldquo;Page Not Found\u0026rdquo; message This is the process there is a matching vanity URL:\nSyntax error in graphmermaid version 8.8.4\rThis is the process when there are no matching vanity URLs:\nSyntax error in graphmermaid version 8.8.4\rUnfortunately, the original smart 404 is no longer maintained and does not work on SharePoint 2013 or newer.\nBut the idea was brilliant. So much so that nearly 10 years later, I haven’t forgotten about it.\nBringing Smart 404 back from the dead I set out to re-create the smart 404 to help anyone who wants to migrate from SharePoint 2013, 2016, or 2019 to SharePoint Online.\nThe original version used an ASP.NET HttpModule to intercept the request and required deploying DLLs to the server; I wanted to re-create it without using any custom DLLs, Add-ins, or anything of the sort.\nTo make the solution easier to deploy on any version of SharePoint 2013 or later, I’ll provide the steps to create the required lists and deploy the feature using out-of-the-box features of SharePoint. The instructions should work for 2013, 2016, or 2019, but I was only able to test it in 2013 and 2019. Let me know if you find any issues.\nYou can also download the web part and list templates from my repo if you’d like.\nLeveraging PageNotFoundError.aspx Since SharePoint 2013, all 404 errors result in SharePoint displaying the PageNotFoundError.aspx, located in the Pages library of the root SharePoint site.\nWhen SharePoint redirects a request to the PageNotFoundError.aspx page, it adds a query string parameter called requestUrl, which contains the request URL (and caused a 404 error).\nSo if you requested a page called WheresMyStuff on your sharepoint.contoso.com server which resulted in a 404 error, SharePoint would redirect you to:\nhttps://sharepoint.consoso.com/Pages/PageNotFoundError.aspx?requestUrl=https://sharepoint.contoso.com/WheresMyStuff\rBut here is the secret: the PageNotFoundError.aspx is a standard SharePoint web part page!\nAnd our Smart 404 is just a regular good ol’ web part on that page!\nThe new Smart 404 solution There are three elements to the Smart 404 solution:\nThe VanityURLs list: A list which maps a redirectUrl for each requestUrl. The RedirectLog list: A list which records when the Smart 404 Web Part displays, the requested URL , who requested it, and what the outcome was. The Smart 404 Web Part: A Content Editor Web Part that points to an HTML page with Javascript, which redirects the user or displays a \u0026ldquo;Page Not Found\u0026rdquo; message. Let’s explore each component in details.\nThe Smart 404 Web Part The Smart 404 Web Part uses the Content Editor Web Part to embed some HTML in the PageNotFoundError.aspx page.\nThe HTML has some JavaScript which performs the following steps:\nWhen the page loads, it looks to see if there is a requestUrl parameter in the query string. If there is a requestUrl, it looks for a matching entry in the SmartRedirects list. If it finds a matching requestURL, it redirects the user to the matching redirectURL on SharePoint Online. It also creates an entry in the RedirectLogs list so that we can keep track of where we’re redirecting users. If it does not find a matching requestURL, it displays the \u0026ldquo;Page Not Found\u0026rdquo; error message (or, optionally, it redirects to the SharePoint Online search page). It also creates a record in the RedirectLogs list to record any potentially missing vanity URLs. The updated sequence diagram looks as follows:\nSyntax error in graphmermaid version 8.8.4\rWhen looking for a match, the Smart 404 uses the following logic:\nSyntax error in graphmermaid version 8.8.4\rThe VanityURLs List The VanityURLs list is a very simple list. It contains the following fields:\nTitle: A friendly title for your redirect. Not used by the web part, but helps make your list of Vanity URLs manageable. RequestURL: A text field containing the original URL of a resource. RedirectURL: The URL where you wish to redirect users when there is a matching RequestURL RedirectType: A choice field describing what type of redirect to use. The valid choices are either Exact Match, Begins With or Regular Expression RegExp: The regular expression to be used for Regular Expression matches Order: The priority for this vanity URL when more than one vanity URL matches the current URL The RedirectLog List The RedirectLog list contains the following fields:\nTitle: A simple text description of the outcome. RequestURL: The URL that was requested. Referrer: The HTTP Referrer (in case we were directed from somewhere else) RedirectedTo: The URL where we sent the user. Outcome:: Keeps track of whether users were redirected due to an exact match, a partial match, or if they were redirected to the search page because there weren’t any matching Vanity URLs. The list also contains the standard Created, CreatedBy, Modified, ModifiedBy fields, which are used to record who and when the redirection occurred.\nOnce you deploy the Smart 404 Web Part, you can monitor the logs and look for the following patterns:\nLarge numbers of No Match outcomes: Means that users are still trying to go to your old on-premises SharePoint server without a matching RedirectURL. You should consider finding where the content matching the RequestURL was relocated and create a new SmartRedirects item to redirect them to the right place. Many entries to the same RequestURL from multiple users: This means that somewhere out there, there is an old shortcut pointing to the on-premises SharePoint server that hasn’t been updated. It could be an existing system, a link in a document, etc. Look at the Referrer to see if they came from the same place. Many entries from the same user: This means that someone is being stubborn and has not updated their shortcuts to point to the new SharePoint Online tenant. They may simply need your help with updating their records. A decline in the frequency of records/no more records: This means that fewer people are trying to go to the old on-premises SharePoint server and that you should consider retiring your server without impacting your users. To deploy the Smart 404 solution As promised earlier, the Smart 404 solution does not require deploying any DLLs or add-ins to your servers. You simply need to create the required lists, add the Content Editor Web Part to your PageNotFoundError.aspx page, and start adding some entries in your SmartRedirects list.\nThe detailed instructions, along with the code for the Smart 404 Web Part, can be found on my Smart 404 repository, but he’s the summary:\nMake changes to the Smart404.html page as necessary to meet your own needs. For example, you can change the look and feel of the \u0026ldquo;Page Not Found\u0026rdquo; content template, or the \u0026ldquo;Your File Has Moved\u0026rdquo; template. Upload the modified Smart404.html page to your root site’s Site Assets folder Create the VanityURLs and RedirectLog lists (manually or using the list templates from the repo) Add a content viewer web part that points to your /SiteAssets/Smart404.html page to your PageNotFoundError.aspx Conclusion The process of migrating your SharePoint content from on-premises to SharePoint Online can take a while. During that time, your users may have shortcuts that point them to the old SharePoint instance.\nThe Smart 404 is a simple solution you can deploy on your on-premises SharePoint server that will replace the standard \u0026ldquo;Page Not Found\u0026rdquo; behavior of your SharePoint on-premises server to redirect users to the SharePoint Online equivalent of the content they were looking for.\nThanks Thanks to Gary Rong for helping build the code, and Rodney Hayden for being a test subject volunteer participant, Credit goes to Josh Carlisle for the original sharepointsmart404. Updates December 16, 2019: Gary Rong added logic to handle Regular Expressions and helped identify issues with the code in Internet Explorer, because — apparently — people still use IE?!?!. ","permalink":"http://localhost:1313/posts/move-your-users-to-sharepoint-online-with-smart404/","tags":null,"title":"Redirect your users to SharePoint Online with Smart 404"},{"categories":["Productivity"],"contents":"Introduction Until today, I assumed everyone knew about this.\nI was speaking to a co-worker –someone I respect and always assumed he knows way more than I do– when he talked about how frustrated he was with having to log-in and out of Office 365 when working on multiple tenants, or when working as more than one user.\n\u0026ldquo;Don’t you have user profiles in Edge Chromium or Chrome?\u0026rdquo; I asked.\n\u0026ldquo;No… what’s that?\u0026rdquo;\nSo I used Microsoft Teams to demo him how to leverage user profiles in Edge Chromium (which solved the issues he was complaining about).\nI often choose not to blog about things because I assume that they’re just too obvious and that someone is going to call me out for writing about something that everybody knows.\nBut I figured that if he didn’t know about browser user profiles, maybe there’s someone else out there who can benefit from learning about this.\nIf you already know about browser user profiles, this article isn’t for you.\nBut if you haven’t heard about them, you’re in for a treat!\nWhat are profiles User profiles have been available in Chrome for a little while now, but they recently started appearing in Microsoft new Edge Chromium browser.\nThey allow you to create different sets of browser favorites, history, passwords, and various other settings.\nFor example, you may want to keep your personal settings separate from your work settings.\nWhen you switch between your browser user profiles, all those profile settings change.\nYou can log-in to Office 365 as one user, open a whole bunch of tabs, then switch to another user profile to log-in as another Office 365 user and open another whole new set of tabs.\nWhen you switch back and forth, your browser remembers who you’re logged in as, what tabs you had open, and everything else — like cookies, history, etc.\nIn the following animation, you can see how switching between profiles shows two different Office 365 tenants and browser tabs.\nYou can even open multiple browser windows with a different user profile in each window!\nCreating user profiles in Edge Chromium To create a new user profile on the Chromium version of Microsoft Edge, follow these steps:\nOpen Microsoft Edge Chromium From the upper-right corner, tap the elipsis (the three dots) and select Settings\nFrom the Settings navigation list, select Profiles.\nFrom the Your profile tab, select + Add profile\nOn the Add profile dialog, select Add\nEdge will open a new browser window prompting you to sign-in. Select Sign in to sync data.\nLog-in using your first set of Office 365 credentials by selecting existing credentials or by selecting Work or school account.\nOnce logged in, if you get prompted to Use your account everywhere on your device, uncheck Allow my organization to manage my device and select This app only instead of the Yes button.\nOnce you complete the steps, the new profile will open as a whole different process.\nRepeat the steps above to create additional profiles.\nHow to customize your profile When you create a new profile, the profile usually gets a default name — something like Profile 2.\nIf you have a lot of profiles, it may be easier to rename them so that you can tell them apart.\nTo do so, follow these steps:\nFrom Edge Chromium, tap the profile icon in the upper-right corner then select Manage profile settings\nFrom the Your profile window, select the ellipsis then Edit\nIn the Edit profile dialog, change the name of the profile to whatever you’d like, then select Update Setting your new tab experience Did you know that, in Edge Chromium, you can show your latest Office 365 files when you open a new browser tab?\nIt’s easy!\nAll you have to do is follow these steps:\nFrom a new browser tab, select the settings icon in the upper-right corner\nSelect Office 365 You’ll probably get prompted to log-in. Once you do, the you’ll get your Office 365 start page. Conclusion The concept of user profiles in your browser isn’t new, but it is new to Edge Chromium. It allows you to work as multiple users across multiple browser windows without having to use the Private mode.\nIf you use Chrome, I encourage you to find instructions to create new profiles. If you use Edge Chromium, I hope you’ll find the above steps useful!\n","permalink":"http://localhost:1313/posts/working-as-multiple-office-365-users-using-user-profiles-in-edge-chromium/","tags":null,"title":"Working as multiple Office 365 users using user profiles in Edge Chromium"},{"categories":["Community"],"contents":"Introduction Making your first contribution to the SharePoint PnP community can be scary!\nDavid Warner II felt the same way before his first contribution.\nThat’s why his new Sharing is Caring initiative is designed to help everyone with their first contribution, or anyone who has already contributed but want to do more in the PnP community.\nHis goal is to make it less scary for everyone.\nAnd it can be plenty scary!\nYou are not alone I remember my first contribution to the SharePoint PnP community.\nI was terrified!\nI’ve been working with SharePoint since before it was called SharePoint. Heck, I’ve known SharePoint longer than I’ve known my wife!\nBut still, the first time I contributed to an issue in GitHub, I was convinced that I would be discovered as a fraud.\nInevitably, someone was going to find out I had made a mistake and ridicule me.\nI wasn’t well versed in GitHub. I was concerned that my code would irrevokably destroy the SharePoint repository –including every backup — and ruin it for everyone.\nI’d have to legally change my name, move somewhere far away, and go back to cooking professionally.\nEvery time I found a code or documentation issue, I would assume that someone much smarter than I would see the same problem and that they would fix it.\n\u0026ldquo;It isn’t my place,\u0026rdquo; I would tell myself.\n\u0026ldquo;They probably already know about this…\u0026rdquo; was my mantra. It was the thing I repeated to myself every time I considered contributing to the community until the urge to fix an issue would go away.\nAnd I’m not a timid person! I’m very strong-willed, stubborn, and opinionated. I’m blunt and direct (hey, if you wanted someone who’ll tell you what you want to hear, you should have hired someone else!).\nBut the idea of contributing to the PnP community felt like what Superman must feel when he’s near Kryptonite.\nUntil one day –when I probably had a momentary lapse in judgment– I submitted my first contribution and waited for the world to explode.\nWhen I got my first email telling me that my pull request was merged, I realized that I had been worrying for absolutely no reason. In fact, the reviewer who had accepted my pull request was very kind and grateful!\nIt gave me the courage to contribute a little more often.\nWith every new contribution, I grew more and more comfortable with GitHub, repos, and discussions, but I still felt nervous every time.\nOne day, when I was preparing to speak at a SharePoint Saturday, I started chatting with other speakers and talking about how nervous I was when contributing to the PnP community.\nOne after the other, they all admitted that they all felt the same way their first time.\nI couldn’t believe it!\nThose were people whose blogs I read, podcasts I listened to, and videos that I watched! They were the people whose presentations I attended at every conference I went to!\nAnd they all said that they were scared at first!!!\nJust like me!\nAnd, if you’re reading this, probably just like you too!\nYou too can contribute It doesn’t matter whether you have found an error in documentation, have a code sample to share, or want to participate in an open-source initiative, you have a voice!\nAnd it deserves to be heard, no matter how scared you may be!\nThat’s why David Warner created the Sharing Is Caring initiative.\nSharing Is Caring Sharing Is Caring is an official PnP GitHub repository that is intended to be a safe \u0026ldquo;sandbox\u0026rdquo; for those who want to learn to contribute and/or become more familiar with the PnP GitHub repos.\nIt is something that David, with the help of Vesa Juvonen, put together to help grow the PnP community and encourage contributions from new (and experienced) contributors.\nEvery month, David hosts live hands-on workshops where he’ll walk you through step-by-step instructions to contribute to a PnP repository.\nThe workshops are conducted over Microsoft Teams, and you are encouraged to use your camera and microphone to create a fun and relaxed atmosphere.\nDuring the sessions –hosted at different times of the day to accommodate people from all around the globe– you’ll get to use your own space in a GitHub repository. You can follow along, as David demonstrates how to make a contribution.\nThe first workshop shows you how you can fix a simple spelling mistake in the documentation. Future sessions will include things like creating list formatting samples, contributing to a PnP open-source initiative or creating your own SPFx web part or list extension code sample.\nBy the end of the session, you’ve made an official contribution (you’ll even get recognized on the monthly PnP calls!). More importantly, you realize that contributing isn’t as scary as it sounds and that it is very difficult to mess up. Github isn’t going to blow up after all!\nI had the privilege to help David host the very first Sharing Is Caring sessions last week. I watched as he patiently explained to 15 new PnP contributors on how to create their first pull requests.\nIt was great to meet people whose names I had seen countless times on the PnP calls and to interact with them. Because the sessions had few attendees, we got to chat (and we didn’t have to ask people to \u0026ldquo;Please please please mute yourself\u0026rdquo;) and joke a little.\nAs I was watched on the call, I remembered how nerve-wrecking my first contribution was, and how relieved I was when I realized that many others experienced that same thing. I didn’t do much, but I took a moment to tell the attendees that I had been where they were, and that contributing to the community can be very rewarding.\nI couldn’t help but feel that I was witnessing something important, because the Pnp community became 15-people stronger.\nThat’s 15 new people who are also passionate about SharePoint and Office 365 and who want to help others by sharing their knowledge.\nIf you’d like to contribute to the PnP community, but need a little help getting through your first contribution, fill the attendee registration form, and David will send you an invitation to his upcoming sessions.\nAnd I’ll be there to help!\nConclusion I’m constantly amazed at how generous people in the PnP community are. David will hate my saying this, but it is pretty amazing that he’s willing to spend his time to help other people learn to contribute.\nThe attendees are incredibly generous, because they spend the time out of their day to learn a skill that will help them donate more of their time to help others!.\nFinally, it also says a lot that both Microsoft and Vesa understand the importance of growing a strong community and that they are willing to let people like David (and I) host such sessions and officially recognize the attendees’ contributions.\nI hope to see many of you on upcoming calls, and I can’t wait to meet you all!\nPhoto Credits Image by Wokandapix from Pixabay\n","permalink":"http://localhost:1313/posts/sharing-is-scaring/","tags":null,"title":"The Sharing is Caring Initiative"},{"categories":["SPFx"],"contents":"Introduction Scott Hanselman is someone that I admire, both as a Developer and as a Human Being. I never miss a chance to attend his presentations. I’m not smart enough to understand everything he talks about all the time, but he’s always entertaining to watch.\nEveryone once in a while, he creates an ultimate list of developer and power tools which always has one or two new tools I didn’t know about. Any serious developer should look at his list as a great starting point to configure their workstation.\nWhen SPFx first came out, I had never touched Node.js, React, or TypeScript. Visual Studio Code was (in my mind) just a free/lightweight version of Visual Studio — why would anyone use VS Code over the full-on Visual Studio?!\nAnd don’t get me started about GitHub!\nI had a steep learning curve ahead of me. And I had a whole new set of development tools to install on my workstation. It took me a while to figure out what I needed to install to be efficient at creating SPFx solution.\nI’m in the process of updating my Windows 10 workstation and, as I was writing down the list of things to re-install, I thought I’d share my list. This list is specifically for people who want to write SPFx solutions on Windows. It isn’t as comprehensive as Scott’s list, but I hope that it will help anyone getting started with SPFx development.\nI also work with .NET, Azure, VR and AR, and Dynamics 365, so I have other tools on my workstation, but I wanted to focus on SPFx development.\nIf you develop SPFx solutions and see that I forgot anything here, I would love to hear from you!\nNOTE: I’m a bit of a minimalist when it comes to installing stuff on my workstation. I hate installing things that will automatically start when I launch windows (that’s why I never install anything from Adobe anymore). You’ll rarely find anything in this article that will completely change how your operating system works or takes over your machine… and if you do, it is because I feel that the trade-off is worth it.\nMandatory Node.JS Find the .MSI file in the list that suits your workstation (x86 or x64). As tempting as it may be to download the latest version, don’t. The only version that is officially supported for SPFx development is 10.x.\nGulp Gulp is a tool that helps automate building your solutions. Once NodeJS is installed, install Gulp by launching the Node.js command prompt and type the following:\nnpm install -g gulp\rYeoman Yeoman is a tool that scaffolds solutions. Think of it as the Visual Studio new project wizard, if the new project wizard was command-line driven, open-sourced, and contained a bazillion project types. To install it, use your Node.js command prompt and type:\nnpm install -g yo\rSharePoint Framework Yeoman Generator Now that Yeoman is installed, you need to add what is essentially your \u0026ldquo;SPFx Project Wizard\u0026rdquo;. To do so, use your Node.js command prompt and type:\nnpm install -g @microsoft/generator-sharepoint\rRecommended Visual Studio Code When I first started writing SPFx solutions, I refused to use Visual Studio Code (real developers use Visual Studio, right?). Unfortunately, Visual Studio messed up my SPFx solutions more than once and I quickly learned to appreciate Visual Studio Code. Visual Studio no longer messes with your SPFx solutions, but I still use VS Code for all-things-SharePoint.\nGit for Windows Even if your company uses Azure DevOps or TFS for source control, you should install Git to make your life easier when downloading SPFx code samples.\nCmder for Windows If you’ve ever wondered what that cool command-line they use on the SharePoint Development Community calls, you have found it! Follow my instructions if you need help installing it. Fira Code Font This font will add the cool visualization to the Cmder command prompt. You should also configure it as your default Visual Studio Code font Cmder Powerline When paired with the Fira Code font (above), it will add that cool command-prompt to Cmder.\nPostman Test your APIs using this awesome tool. It can even intercept calls and replay them. I use this tool all the time when I’m trying to understand how SharePoint does something.\nFiddler Use Fiddler to capture your workstation’s network traffic and diagnose issues. For example, if you want to know how the Microsoft Teams app retrieves your list of groups, use Fiddler to capture what calls it makes.\nCLI for Microsoft 365 CLI A command-line interface that lets you do tons of stuff in Microsoft 365 and SPFx solutions. To install, use your Node.js command prompt and type the following:\nnpm i -g @pnp/cli-microsoft365\rPnP PowerShell An awesome library of PowerShell commands that allows you to perform complex provisioning and artifact management actions towards SharePoint. Uses a combination of CSOM and REST behind the scenes, and works against both SharePoint Online as SharePoint On-Premises.\nSharePoint Online Management Shell Use it to create SharePoint Online sites and add users, you can quickly and repeatedly perform tasks much faster than you can in the Office 356 admin center. You can also perform tasks that are not possible to perform in the Office 356 admin center.\nPnP Yeoman Generator If you find yourself always adding the PnP developer controls, PnP Property Controls, PnPJs, unit testing, etc. to your SPFx solutions, you should probably try the PnP Yeoman Generator. It is built on top of the SPFx Yeoman generator, so you’re not missing out on anything the SPFx generator will give you, but it automatically adds many other useful features — like unit testing, code linting, bundle optimization. To install it, use your Node.js command prompt and type:\nnpm install -g @pnp/generator-spfx\rVisual Studio Code Extensions GitHub Pull Requests Allows you to review and manage GitHub pull requests in Visual Studio Code. Paste JSON as Code Convert JSON object to typescript interfaces as you paste into Visual Studio Code. What, you thought I typed all those classes? Rencore Deploy SPFx Package Easily deploy a SharePoint Framework solution package to SharePoint Online directly from Visual Studio Code.\nRencore SPFx Script Check Using the Rencore Script Check Visual Studio Code extension you can easily reference external libraries in SharePoint Framework projects the right way. Additionally, you can ensure, that the CDN they are using is well performing.\nRencore Tenant-Wide SPFx Extension Deployment Easily add tenant-wide deployment information for your SPFx extension directly from Visual Studio Code.\nSPFx Debug Configuration This Visual Studio Code extension can be used to add the required configuration for debugging your SharePoint Framework.\nSPFx Essentials This is an extension pack that contains useful extension for SharePoint Framework projects. Most of the extensions I listed here are already included in Elio’s awesome list.\nSPFx Localization This extension for Visual Studio Code makes it easier to work with locale resource files in SharePoint Framework projects. The extension has the ability to export all locale labels to a CSV file to make translations easier to process. With this extension, you have absolutely no excuse to hard-code your text in English within your solutions. SPFx Snippet I never realized how much I use this extension until I tried to write spfx-rcc for a web part on a machine that didn’t have the extension installed. Take it from the World’s Laziest Developer, you need this extension. SPFx Task Runner This extension allows you to easily run SharePoint Framework tasks with a couple of mouse clicks. At the moment you can for example list all the available gulp tasks in your project, start the local development server and create debug or release solution packages or pick a task to run from the list of available tasks. SP Formatter Sergei strikes again with a great extension that works with the SP Formatter browser extension to make it easy to use syntax highlighting on list formatting.\nSharePoint Typed Item Sergei’s awesome extension generates interfaces based on list and content type fields. Also check out Sergei’s SPFx Rest Client Prettier — Code Formatter This extension format your JavaScript / TypeScript / CSS using Prettier.\nSPGo for Visual Studio Code SPGo allows you to develop SharePoint web solutions from your local PC using Visual Studio Code. It pulls down remote folders from SharePoint to your local workspace and automatically publishes files when you save. It is one of those \u0026ldquo;where has this been all my (SharePoint) life?!\u0026rdquo; extensions.\nDocs Authoring Pack If you maintain any kind of Markdown documentation, or if you contribute to Microsoft Docs (you should!), you should install this extension pack that will make your life much easier. Thanks to Paul Bullock for pointing this one out.\nCodeTour CodeTour is an awesome Visual Studio Code extension, which allows you to record and playback guided code walkthroughs. I’ve been using it to add tours to all my new web part projects and adding new tours to my old SPFx samples in the Samples repo. Nice to have Zoomit Be a considerate presenter! If you do presentations and show your code, you should consider installing this tool. Those people in the back of the room (who sat in the back so that they can exit quickly if they find you boring) may not exit so fast if they can actually see what you’re doing.\nPaint.NET A great image editing tool that’s fully featured and free. I use it to edit icons and other assets.\nInkscape A powerful SVG editing tool. I use it to create SVG icons. If only I could get SVG icons to work consistently in SPFx, it’d be great.\nSnagIt Probably the golden standard for screen capture tools. I stubbornly used the Windows Snipping Tool for the longest time until I reluctantly installed SnagIt and I don’t think I’ll use anything but SnagIt from now on. If you write any kind of documentation, help guides, or blogs, this is a must.\nCamtasia Like SnagIt, I used to avoid it because I was too cheap to pay for the license… but if you do any kind of video editing, give this one a try. It is fantastic. (Why do I have to be so stubborn?!)\nScreenToGif Do everyone a favor and show an animated GIF of what your SPFx solutions can do in the README.MD file. It saves them having to install your solution to see what it does. This tool is a screen, webcam and sketchboard recorder with an integrated editor that makes it super-easy to create animated GIFs. Available as a Microsoft Store App or a WPF install. Browser Extensions Note that these extensions can be used in Chrome or in Edge Chromium. (I use Edge Chromium, personally).\nSP Editor A Google Chrome Extension for creating and updating files (js, css), injecting files to sites, modifying web/list property bag values (add, edit, remove, index) and creating webhook subscriptions, edit/add/remove web parts from publishing pages and run sp-pnp-js typescript snippets in SP2013, SP2016 and SharePoint Online from Chrome Developer Tools. This tool will help you create amazing SharePoint applications fast from your browser from any computer which runs Chrome!\nReact Developer Tools Allows you to inspect the React component hierarchies in the Chrome Developer Tools. You get a new tab called React in your Chrome DevTools which shows you the root React components that were rendered on the page, as well as the subcomponents that they ended up rendering. It is great when trying to understand how the SharePoint team built a component.\nScreen Reader for Google Chrome Test your web parts for accessibility by giving you the same experience your users will get when they use a screen reader.\nAXE No, not the body spray. Use this tool to check for accessibility for WCAG 2.0 and Section 508 accessibility. If you aren’t testing for accessibility, you’re possibly making it difficult for 10 to 20% of your users.\nRefined GitHub If you use GitHub regularly, but get a little annoyed with some missing features, this extension is for you. It adds tons of cool features including my favorites: remove changes to individual files in a commit/pull request and download a folder. SP Formatter Not so much a developer-focused extension, but a very useful one nevertheless. SP Formatter adds JSON syntax highlighting, live preview, and autocompletion to SharePoint list formatting. Websites PnP Home Can’t keep up with all the new things that the Microsoft 365 PnP community members are doing? You can find everything in one convenient place. SharePoint Look Book Get inspired with cool looking SharePoint sites. SharePoint Design Guidance Learn how to create great looking SharePoint solutions. Fluent UI See what components are at your disposal when building awesome Microsoft 365 solutions.\nPnP/PnPJS PnPjs is a collection of fluent libraries for consuming SharePoint, Graph, and Microsoft 365 REST APIs in a type-safe way. You can use it within SharePoint Framework, Nodejs, or any JavaScript project. This an open source initiative and we encourage contributions and constructive feedback from the community.\nReusable property pane controls for the SharePoint Framework solutions This repository provides developers with a set of reusable property pane controls that can be used in their SharePoint Framework (SPFx) solutions. Reusable React controls for your SharePoint Framework solutions Provides developers with a set of reusable React controls that can be used in SharePoint Framework (SPFx) solutions. The project provides controls for building web parts and extensions. You should really try the ChartControl 🙂 Microsoft 365 \u0026amp; SharePoint Community – PnP (YouTube) YouTube channel with SharePoint Dev Weekly videos, SharePoint Framework Tutorials and Training videos, SharePoint Framework and Extensions Tutorials, Getting Started videos, PnP Webcasts, etc. If you no like read, you watch these good.\nBase64 Image Encoder Use this site to encode your web part icons to base 64. You can also use my interactive post to do all the work for you. EzGif.com If you don’t want to install ScreenToGif but want to create animated GIFs to help people see what your web part will look like without having to install it, I recommend using this web site. Create a video of your web part in action, then use EZ GIF’s Video to animated GIF converter to create your GIF. Add the GIF to your README.MD file and people will see how cool your web part really is! GitHub Repos Microsoft Fluent UI When I want to learn how to create awesome React components, I take my inspiration from Microsoft Fluent UI.\nSP Dev FX WebParts Almost every SPFx project I create starts from one of the many samples available on this awesome repo.\nPnP Property Controls Back when most of us were still learning React and SPFx, they were already creating re-usable controls for SPFx. Take some time to read their code for inspiration.\nPnP Developer Controls From the brilliant minds that brought you the PnP Property Controls. Read the code to learn tons!\nSharePoint Starter Kit Look at some of the best solutions used to build the perfect demo environments.\nConclusion This article listed the various tools I use when building SPFx solutions on a Windows 10 workstation. As I stated previously, I’m kind of a minimalist when it comes to installing stuff on my machine. I’m sure that there are many other tools that I should install, but I haven’t found a need for it yet. What other tools do you install on your workstation? Let me know in the comments.\nUpdate Feb 4, 2021: Added SP Formatter VS Code Extension. Mind.blown. September 7, 2020: Added Enhanced GitHub. July 9, 2020: Refreshed links and added CodeTour, SP Formatter and the PnP Landing Page. April 27, 2020: Added Docs Authoring Pack. December 06, 2019: Updated version of Node.js to 10.x. October 10, 2019: I added SPGo after attending Beau Cameron and David Warner II‘s great SharePoint Saturday New England session about SPFx Development Tips from the trenches. Watching those two present together reminded me that there is always room to learn more. July 2, 2019: Thanks to Denis Molodtsov for suggesting ScreenToGif instead of using EzGif. It makes it so much easier to capture an animated GIF of your web part in action! April 4, 2019: Added SharePoint Developer Community – PnP YouTube channel March 28, 2019: Added [Sergei Sergeev’s] cool SPFx Typed Item extension, which he demoed in the March 28th SharePoint Dev Ecosystem call. Watch out for those Kung-fu Gophers. March 25, 2019: Thanks to Thomas Lamb for suggesting Prettier — Code Formatter. March 20, 2019: Thanks to Sam Culver for pointing out that Fira Code makes a great font in Visual Studio. March 16, 2019: Added Paint.NET and Inkscape as graphical tools. March 14, 2019: Thanks to Miguel Isidoro for pointing out that I had the wrong link to the Rencore SPFx Script Check. Credits Header image by Rudy and Peter Skitterians from Pixabay\n","permalink":"http://localhost:1313/posts/ultimate-developer-tool-list-for-spfx/","tags":["React","SPFx"],"title":"Ultimate Developer Tool List for SPFx"},{"categories":["SPFx"],"contents":"Introduction According to Microsoft documentation, you can use a base64-encoded image for your web part icons. However, base64-encoded SVG images — as is shown in the documentation — don’t work as expected. And by the looks of it, this hasn’t worked for a while.\nSince the SPFx team has been working tirelessly to deliver more than 15 releases of SPFx since its general availability, I’m sure we can forgive them for letting something so minor fall through the cracks.\nHowever, I really don’t like how icons that were converted from PNG look slightly blurry. (I tend to obsess about little things like that sometimes).\nAs I was writing another post for my SharePoint Framework Design series, I decided to get to the bottom of the issue.\nAs it turns out, it was pretty easy to solve.\nTL;DR This is an interactive post: we’ll convert your SVG so that you can use it as an SPFx web part icon.\nIf you don’t care about the explanation, you can go straight to the solution\nThe Challenge My challenge was that I wanted to use SVG images in my web part’s manifest, but I didn’t want to have a separate SVG asset. I wanted to define a base64-encoded SVG file, as is demonstrated in the SharePoint documentation.\nI knew it didn’t work (believe me, I’ve tried), so I wanted a solution that would not rely on any unsupported hacks.\nSince I don’t have access to change the SharePoint code, I needed a solution that would work without requiring any changes from SharePoint.\nHow SPFx web part icons work According to the Microsoft documentation, for your SPFx web part icon you can use either an Office UI Fabric icon, an external icon image, or a base64-encoded image.\nTo change your icon to an Office UI Fabric icon, you simply open your web part’s [YourWebPartName].manifest.json and change the \u0026quot;officeFabricIconFontName\u0026quot; node to the name of the icon you want from the UI Fabric site.\nThe default icon is Page. If you wanted to change your icon to the Sunny icon, you would simply change the following line:\n\u0026#34;officeFabricIconFontName\u0026#34;: \u0026#34;Page\u0026#34;, To this:\n\u0026#34;officeFabricIconFontName\u0026#34;: \u0026#34;Sunny\u0026#34;, Note that you have to re-build the web part (run gulp build) and reload your workbench (press [F5] on your keyboard) before you’ll see the new icon. Trust me, I wasted a lot of time trying to figure out why my new icons weren’t showing up.\nIf you want to set the icon to an external image, you’ll want to find the URL of a publicly-accessible image and change your web part’s manifest \u0026quot;officeFabricIconFontName\u0026quot; attribute from the following:\n\u0026#34;officeFabricIconFontName\u0026#34;: \u0026#34;Page\u0026#34;, For a \u0026quot;iconImageUrl\u0026quot; image URL, as follows:\n\u0026#34;iconImageUrl\u0026#34;: \u0026#34;https://assets.contoso.com/weather.png\u0026#34;, You can also use a CDN, or use your SharePoint CDN to store your images.\nIf you don’t want to use an external image, you’ll want to use a base64-encoded image.\nTo do so, you’ll have to first convert your image using a tool like this web site. Once you have your base64-encoded image, you’ll change your web part’s manifest from this:\n\u0026#34;officeFabricIconFontName\u0026#34;: \u0026#34;Page\u0026#34;, To this:\n\u0026#34;iconImageUrl\u0026#34;: \u0026#34;data:...\u0026#34;, And you would put the entire base64-encoded string as the web part’s URL. Because you see, the base64-encoded string is actually a valid URL.\nIt is just a special kind of URL, called a data URI.\nAbout data URI Base64-encoded images, whether they are SVG or PNG, JPG, or GIF, rely on data URI. Data URI allow you to embed a resource in a URI which would normally result in a separate HTTP request.\nMost data URI consists of the data type of the item (e.g.: image/png), followed by a semicolon, and the data of that file.\nThe cool thing about data URI is that — on most modern browsers — you can pretty much use them anywhere you would normally use a link to a resource.\nFor example, to show the above image of Parker in HTML, you would embed an img element and point the src attribute to the URL of the image, as follows:\n\u0026lt;img src=\u0026#34;https://avatars0.githubusercontent.com/u/31443929?s=200\u0026amp;v=4\u0026#34; /\u0026gt; Using a data URI, you could also do this:\n\u0026lt;img src=\u0026#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAYAAACtWK6eAABpUUlEQVR4nOxdBVgU2xc/S3d3d0iDtKgI2N3d+tBnd+uzu7D924mJGIgoIAooKiGIIp1KLsvS+f/mbrAxu+xiofL75JvZmTt3Ztd75vQ5Qi0tLdCJTnQCHwK/+gE60YmOjE4C6... Which produces this image:\nThe first version of this image had a URL pointing to the original source of the image, while the second one contained the actual image!\nTo generate the super-long gibberish, I used this online base64-encoder and uploaded a copy of Parker’s avatar, then copied that super-long string it generated into the src attribute of my img tag.\nYou have to base64-encode the image because you’re trying to embed a binary file inside of HTML.\nExcept that SVG files are not binaries…\nUsing data URI without base64-encoding SVG files are simply text markup files, like HTML.\nDuring my research, I found an article entitled Probably don’t base64 SVG which explains that when you base64-encode an image…\n\u0026ldquo;It takes 4 characters per 3 bytes of data, plus potentially a bit of padding at the end.\u0026rdquo;\nEssentially, base64-encoding SVG takes more room than the original file! Files are essentially 133% bigger!\nFortunately, you can actually use your UTF-8 encoded SVG file inside a data URI as follows:\n\u0026lt;img src=\u0026#34;data:image/svg+xml; ... \u0026#34;\u0026gt; Now, you need to make sure that you don’t embed unsupported characters inside your src attribute. For example, if your SVG has a single quote (') and your src attribute uses single-quotes to define it, you’ll want to escape the '.\nFortunately, Taylor Hunt wrote a great article explaining how to encode SVGs in data URI while optimizing them to help you with that.\nTaylor’s awesome article inspired someone to write a codepen to encode SVGs.\nI forked Jakob-e’s codepen to make my own which makes it easy to encode SVGs to work as a data URI icon for a web part’s manifest.\nUsing a data URI SVG as your icon To use your custom SVG as an icon, take the following steps:\nDesign an icon so that it fits within a square, ideally 64×64, or at least 32×32.\nMake sure that your icon \u0026lt;svg\u0026gt; element sets the width and height attributes — otherwise, your icon will be cropped and/or will not appear centered. To do so, simply change your SVG opening tag from:\n\u0026lt;svg\u0026gt; To this:\n\u0026lt;svg height=\u0026#34;64\u0026#34; width=\u0026#34;64\u0026#34;\u0026gt; Consider optimizing your SVG by using SVGOMG or a similar tool.\nPaste your SVG in the box below to encode your SVG\nCustomize this article Variable Value Original SVG In your web part’s [YourWebPartName].manifest.json, change the following line:\n\u0026#34;officeFabricIconFontName\u0026#34;: \u0026#34;Page\u0026#34;, To this:\nPaste your SVG above to generate this code\rCopy to clipboard\nPaste your SVG above to generate this code\nCopy to clipboard\nDon’t forget the extra , at the end of the line.\nRebuild your web part by running gulp build\nRefresh your workbench\nYour new SVG icon should appear!\nConclusion You still can’t use base64-encoded icons as your web part icon — at that’s probably a good thing, because base64-encoded SVG files are bigger! — but you can use a data URI image instead.\nThis article shows you how to convert your SVG so that it will produce beautiful web part icons.\nRegardless of whether Microsoft ever fixes the issue with SVG icons for web parts, you should still consider optimizing your SVG before using it in your solutions.\nI hope this helps?\nUpdates September 1, 2019: This approach will also work for application extension. Sources Probably don’t base64 SVG, https://css-tricks.com/probably-dont-base64-svg/ Optimizing SVGs in data URIs, https://codepen.io/tigt/post/optimizing-svgs-in-data-uris Configure web part icon, Microsoft Documentation, https://docs.microsoft.com/sharepoint/dev/spfx/web-parts/basics/configure-web-part-icon Codepen to encode SVGs, https://codepen.io/jakob-e/pen/doMoML ","permalink":"http://localhost:1313/posts/fixing-base64-svg-icons-in-spfx/","tags":null,"title":"Fixing base64 SVG icons in SPFx"},{"categories":["SPFx"],"contents":"Introduction Microsoft has an awesome web site called SharePoint Design. It provides design guidance on beautiful and fast sites, pages, and web parts with SharePoint in Office 365.\nHowever, it does not tell you how to create those beautiful web parts.\nThis blog series is intended as a companion to the SharePoint Design site. It provides code samples and detailed how-to information for every design topic.\nIt should help you create web parts that look exactly like the ones on the SharePoint Design site.\nSo far, we have discussed the following topics:\nWeb Part Titles and Descriptions Property Panes, Part I Property Panes, Part II Property Panes, Part III Layout Patterns, Part I: The Grid layout Layout Patterns, Part II: The Filmstrip layout Layout Patterns, Part III: The Carousel layout In today’s post, we’ll continue our discussion about the web part layout patterns and discuss the compact layout.\nWhat is the Compact layout? According to the SharePoint Design site:\nThe compact layout is designed to show content in a smaller format and works the best in a one-third column. This layout can support a small image or icon and a few rows of text for a title, description, and/or metadata.\nHowever, it seems that the compact layout is not only used in 1/3 columns. The SharePoint look book and the SharePoint Online Provisioning Service both make use of the compact layout with the Quick Links web part.\nWhen to use the compact layout Use the compact layout when the items in your web part have very little information. A title and an icon or a small thumbnail is pretty much all you’ll be able to fit it.\nHow is it made? The compact layout is simply a Grid layout, but where the individual items use a compact document card layout instead of the full document card.\nTo create your own, you would use an Office UI Fabric List control and render each item inside the list with a DocumentCard control where the type of the DocumentCard control would be set to DocumentCardType.compact.\nOr, you can simply use the component I built to make my life easier.\nHow to create a web part with the compact layout Note: The source code for this sample can be found in the WebPartLayouts sample on my repo.\nCreate your own web part solution. For this sample, we’ll assume that your web part is called CompactWebPart and that the component which renders the content of the web part is called Compact.\nCopy the content of the src\\components\\compactLayout from my sample code to your own solution. You may need to create a components and compactLayout folder under src to do so.\nIn your web part, load the items you wish to display. For this example, we’ll set them in your web part’s state and hard-code them in your web part’s constructor, but feel free to load any data you want to use. We’ll want to have at least a title attribute and a thumbnail attribute, but — as you’ll see later — you can really display any information you want when you render each item.\nconstructor(props: ICompactProps) { super(props); // Sample data generated at https://mockaroo.com/ this.state = { items: [{ thumbnail: \u0026#34;https://robohash.org/nostrumquiiure.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Aerified\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/minimafugitenim.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Viva\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/nihilbeataeculpa.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Overhold\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/essequiquo.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Latlux\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/inipsumtotam.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Biodex\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/utmodiet.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Bitchip\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/undeenimvel.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Rank\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/pariaturoditdolore.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Opela\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/nullaullamincidunt.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Rank\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/accusantiumnonvoluptatibus.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Bitchip\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/culpaeossapiente.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Sonsing\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/harumnihilvelit.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Duobam\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/quianesciuntet.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Prodder\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/aliquidipsamrem.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Keylex\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/dignissimoseosaccusamus.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Span\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/exomnisexcepturi.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Stringtough\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/occaecatimolestiaererum.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Prodder\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/consequaturinquis.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Alpha\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/sapienteofficiisest.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Job\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/similiquesuntiusto.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Cookley\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/sitnequequi.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Stronghold\u0026#34; }] }; } In your web part’s component, add an import for the compactLayout. You’ll also need an import for the UI Fabric DocumentCard component:\n// Used to render document cards import { DocumentCard, DocumentCardPreview, DocumentCardDetails, DocumentCardTitle, IDocumentCardPreviewProps, DocumentCardType } from \u0026#39;office-ui-fabric-react/lib/DocumentCard\u0026#39;; import { ImageFit } from \u0026#39;office-ui-fabric-react/lib/Image\u0026#39;; import CompactLayout from \u0026#39;../../../components/compactLayout/CompactLayout\u0026#39;; Add a _onRenderGridItem method:\nprivate _onRenderGridItem = (item: any, _index: number): JSX.Element =\u0026gt; { const previewProps: IDocumentCardPreviewProps = { previewImages: [ { previewImageSrc: item.thumbnail, imageFit: ImageFit.centerCover, height: 48, width: 48 } ] }; return \u0026lt;div data-is-focusable={true} data-is-focus-item={true} role=\u0026#34;listitem\u0026#34; aria-label={item.title} \u0026gt; \u0026lt;DocumentCard type={DocumentCardType.compact} onClick={(ev: React.SyntheticEvent\u0026lt;HTMLElement\u0026gt;) =\u0026gt; alert(ev)} \u0026gt; \u0026lt;DocumentCardPreview {...previewProps} /\u0026gt; \u0026lt;DocumentCardDetails\u0026gt; \u0026lt;DocumentCardTitle title={item.title} shouldTruncate={true} /\u0026gt; \u0026lt;/DocumentCardDetails\u0026gt; \u0026lt;/DocumentCard\u0026gt; \u0026lt;/div\u0026gt;; } } Update your component’s render method to render the compact layout as follows:\npublic render(): React.ReactElement\u0026lt;ICompactProps\u0026gt; { return ( \u0026lt;div className={styles.compact}\u0026gt; \u0026lt;CompactLayout items={this.state.items} onRenderGridItem={(item: any, index: number) =\u0026gt; this._onRenderGridItem(item, index)} /\u0026gt; \u0026lt;/div\u0026gt; ); } That’s really all there is to it! You web part will render something like this:\nThe great thing is that it is entirely up to you how you want to render each item. I chose to use the DocumentCard control, but you can replace any part of your _onRenderGridItem method to suit your needs.\nFor example, if you wanted to render a date instead of an thumbnail, you could use something like the DateBox component that I wrote for the React Calendar Feed sample.\nAdding pagination When I first built the React Calendar Feed sample, the Events web part showed little Previous and Next buttons at the bottom of the web part when displaying in the compact mode.\nIt seems that the pagination has since been removed from the standard web part design. Nevertheless, I have included a sample control to show how you can add pagination to your compact web part.\nUse it at your discretion.\nTo add pagination to your web part, follow these steps:\nCopy the content of the src\\components\\paging from my sample code to your own solution. You may need to create a paging folder under src\\components to do so.\nAdd a variable to store the current page number in your component’s state, as follows:\nexport interface ICompactState { items: any[]; currentPage: number; } In your component’s constructor, set the current page to 1, as follows:\nconstructor(props: ICompactProps) { super(props); // Sample data generated at https://mockaroo.com/ this.state = { currentPage: 1, items: [{ thumbnail: \u0026#34;https://robohash.org/nostrumquiiure.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Aerified\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/minimafugitenim.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Viva\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/nihilbeataeculpa.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Overhold\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/essequiquo.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Latlux\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/inipsumtotam.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Biodex\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/utmodiet.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Bitchip\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/undeenimvel.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Rank\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/pariaturoditdolore.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Opela\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/nullaullamincidunt.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Rank\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/accusantiumnonvoluptatibus.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Bitchip\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/culpaeossapiente.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Sonsing\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/harumnihilvelit.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Duobam\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/quianesciuntet.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Prodder\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/aliquidipsamrem.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Keylex\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/dignissimoseosaccusamus.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Span\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/exomnisexcepturi.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Stringtough\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/occaecatimolestiaererum.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Prodder\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/consequaturinquis.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Alpha\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/sapienteofficiisest.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Job\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/similiquesuntiusto.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Cookley\u0026#34; }, { thumbnail: \u0026#34;https://robohash.org/sitnequequi.png?size=48x48\u0026amp;set=set1\u0026#34;, title: \u0026#34;Stronghold\u0026#34; }] }; } Add an import for the paging component at the top of your file:\nimport { Paging } from \u0026#39;../../../components/paging\u0026#39;; Change your render method to get a subset of items to show, as follows:\npublic render(): React.ReactElement\u0026lt;ICompactProps\u0026gt; { let pagedItems: any[] = this.state.items; const totalItems: number = pagedItems.length; let showPages: boolean = false; const maxEvents: number = 5; // Use any page size you want const { currentPage } = this.state; if (true \u0026amp;\u0026amp; totalItems \u0026gt; 0 \u0026amp;\u0026amp; totalItems \u0026gt; maxEvents) { // calculate the page size const pageStartAt: number = maxEvents * (currentPage - 1); const pageEndAt: number = (maxEvents * currentPage); pagedItems = pagedItems.slice(pageStartAt, pageEndAt); showPages = true; } return ( \u0026lt;div className={styles.compact}\u0026gt; \u0026lt;CompactLayout items={pagedItems} onRenderGridItem={(item: any, index: number) =\u0026gt; this._onRenderGridItem(item, index)} /\u0026gt; {showPages \u0026amp;\u0026amp; \u0026lt;Paging showPageNumber={true} currentPage={currentPage} itemsCountPerPage={maxEvents} totalItems={totalItems} onPageUpdate={this._onPageUpdate} nextButtonLabel={strings.NextLabel} previousButtonLabel={strings.PreviousLabel} /\u0026gt; } \u0026lt;/div\u0026gt; ); } Finally, add a method to store the current page number in your state every time the page changes, as follows:\nprivate _onPageUpdate = (pageNumber: number): void =\u0026gt; { this.setState({ currentPage: pageNumber }); } Test your web part. You should now get a next and previous buttons at bottom of your web part.\nConclusion The compact layout is simply a grid control which renders compact document cards.\nIn our next post, we’ll discuss the list layout!\n","permalink":"http://localhost:1313/posts/sharepoint-framework-design-series-layout-patterns-part-iv/","tags":null,"title":"SharePoint Framework Design Series: Layout Patterns — Part IV"},{"categories":["GitHub"],"contents":"Introduction In August of 2019, I wrote a post called My GitHub cheat sheet for PnP contributions — an interactive cheat sheet which explains the GitHub commands that I use when I start a contribution. The post is interactive: you just tell it your GitHub username and what repository you want to contribute to, and it customizes the instructions for you.\nNOTE: I have since updated the interactive cheat sheet to a Summary Cheat Sheet with all the same interactive steps, but without all the lengthy explanation.\nI also wrote another post talking about how impressed I am with David Warner II’s offer to help anyone with their first contribution. I have since joined the Sharing is Caring initiative and proudly co-host all the session with David Warner\nAfter briefly chatting with David I realized that the biggest hurdle for people is that they just don’t know where to get started. In my post, I recommend that you read the contribution guidelines for every repo, but I found that they are often hard to find in each repository.\nI also say that most repositories want you to start from the dev branch, but as the Chris Kent pointed out in the August 22nd PnP community call, some repositories prefer you use the master (or, more and more commonly, the main) branch.\nSo, with David’s help, we compiled a list of the most common PnP repositories to help you get started. We only show the repositories that provide contribution guidelines.\nThe list contains the following:\nRepo: Name of the repository What is it?: Description of the repository Getting started: Links to the most likely resource if you want to get started contributing to that repository Branch: The branch you should target when submitting your pull requests NOTE: The information in each of the repositories can change and that you should always refer to the repository for the latest information.\nPopular repositories Repo What is it? Getting started Branch Adaptive Card Extension SamplesPnP/sp-dev-fx-aces Viva Connection Adaptive Card Extensions (ACEs) sample repositoryhttps://aka.ms/viva/connections/extensibility Contributing main Community BlogPnP/Blog Blogs for pnp.github.io/blog Contributing main CLI for Microsoft 365PnP/CLI-Microsoft365 Manage Microsoft 365 and SharePoint Framework projects on any platformhttps://aka.ms/o365cliNOTE: This repository prefers \u0026ldquo;one commit per pull request\u0026rdquo; Contribution guidelines main Microsoft 365 Community Docs MicrosoftDocs/microsoft-365-community Microsoft 365 community contributed documentationhttps://docs.microsoft.com/microsoft-365/community Adding content main Microsoft Graph .NET Client LibraryMicrosoftGraph/Microsoft-SDK-DotNet Microsoft Graph Client Library for .NET!https://graph.microsoft.com/ Contributing to the Microsoft Graph .Net Client Library dev Microsoft Graph .NET Core Client LibraryMicrosoftGraph/Microsoft-SDK-DotNet-Core The core Microsoft Graph client library for .Net. (Microsoft.Graph.Core)https://graph.microsoft.com/ Contributing to the Microsoft Graph .Net Client Library dev Microsoft Graph documentationMicrosoftGraph/Microsoft-Graph-Docs Documentation for the Microsoft Graph REST API, which feeds the Microsoft Graph Developer Portal.https://docs.microsoft.com/graph Contribute to Microsoft Graph documentation main Microsoft Graph JavaScript Client LibraryMicrosoftGraph/Microsoft-SDK-JavaScript The Microsoft Graph JavaScript client library is a lightweight wrapper around the Microsoft Graph API that can be used server-side and in the browser.https://graph.microsoft.com/ Contributing dev Microsoft Graph Library for PHPMicrosoftGraph/Microsoft-SDK-PHP Microsoft Graph Library for PHPhttps://docs.microsoft.com/graph/toolkit/overview Contributing to the Microsoft Graph PHP SDK Documentation changes, use main Otherwise, use dev Microsoft Graph PowerShell SDKMicrosoftGraph/Microsoft-SDK-PowerShell The Microsoft Graph PowerShell SDK is a collection of PowerShell modules that contain commands for calling Microsoft Graph service. Contributing dev Microsoft Graph SDK for JavaMicrosoftGraph/Microsoft-SDK-Java Get started with the Microsoft Graph SDK for Java by integrating the Microsoft Graph API into your Java application!https://developer.microsoft.com/graph Contributing to the Microsoft Graph SDK for Java dev Microsoft Teams Development Community SamplesPnP/teams-dev-samples Contains community samples that demonstrate different usage patterns for developing on Microsoft Teams as a platform. Samples are generally not production-ready, but are intended to show developers specific patterns and use cases for use in complete applications.http://aka.ms/teams-dev-samples Contribution guidance main Modernization Tools and SolutionsPnP/sp-dev-modernization All modernization tooling and guidancehttp://aka.ms/sppnp-modernize The modernization repository dev PnP FrameworkPnP/PnPFramework PnP Framework is a .Net Standard library targeting Microsoft 365 containing the PnP Provisioning engine and a ton of other useful extensions dev PnP Modern SearchMicrosoft-Search/PnP-Modern-Search Home of PnP Modern Search solutions, helping you move from classic to modern SharePoint and beyond develop PnP PowerShellPnP/PnP-PowerShell SharePoint PnP PowerShell CmdLetshttps://aka.ms/sppnp-powershell Contribution guidance dev PnP Starter KitPnP/sp-starter-kit Modern SharePoint Starter Kit – End-to-end showcase solution to get started with modern experiences. dev PnPJsPnP/PnPjs SharePoint Patterns and Practices Reusable Client-side Librarieshttps://pnp.github.io/pnpjs Contribution guide Version 3Version 2Version 1 Power Apps SamplesPnP/powerapps-samples Power Apps samples and design patterns provided by the PnP team and the community.http://aka.ms/powerplatform-samples Contribution guidelines main Power Automate SamplesPnP/powerautomate-samples Power Automate samples and design patterns provided by the PnP team and the community.http://aka.ms/powerautomate-samples Contribution guidelines main Power Fx SamplesPnP/powerfx-samples Power Fx Samples – Contains samples for Power Fx low-code programming language.Contribution guidelines main Power Virtual Agents SamplesPnP/powerva-samples Power Virtual Agents samples and design patterns provided by the PnP team and the community.http://aka.ms/powerva-samples Contribution guidelines main SharePoint Developer DocumentationSharePoint/sp-dev-docs SharePoint Developer Documentationhttps://docs.microsoft.com/en-us/sharepoint/dev/ Contribute to SharePoint developer documentation main SharePoint Framework Client-Side Web Part Samples \u0026amp; Tutorial MaterialsPnP/sp-dev-fx-webparts Code samples and developer content targeted towards SharePoint Framework client-side web parts. Maintained by the nicest guy 😁.http://aka.ms/spfx-webparts Contribution guidelines main SharePoint Framework Extensions Samples \u0026amp; Tutorial MaterialsPnP/sp-dev-fx-extensions Code samples and developer content targeted towards SharePoint Framework client-side extensions — maintained by yours truly.https://aka.ms/spfx-extensions Contribution guidance main SharePoint Framework Library Component Samples \u0026amp; Tutorial MaterialsPnP/sp-dev-fx-library-components Samples that demonstrate different usage patterns for the SharePoint Framework library component.Contribution guidance Create from: masterSubmit to: dev SharePoint Framework React ControlsPnP/sp-dev-fx-controls-react Reusable React controls for SPFx solutionshttps://pnp.github.io/sp-dev-fx-controls-react/ – Contribution guidelines– Submitting a PR dev SharePoint Framework React Property ControlsPnP/sp-dev-fx-property-controls Reusable SPFx property pane controls – Open source initiativehttps://pnp.github.io/sp-dev-fx-controls-react/ Project guides dev SharePoint List Formatting SamplesPnP/sp-dev-list-formatting SharePoint List Formatting Sampleshttps://pnp.github.io/sp-dev-list-formatting/ Contribution guidelines master Conclusion Let’s keep this list up to date! If you find that we forgot a repository, or that something is wrong, let us know in the comments of via Twitter and we’ll get it updated!\nThanks to David Warner II with putting together this list, and for always making yourself available to help people in this community.\nThis list wouldn’t be possible without the hard work of all of those who contributed (and continue to contribute) to the above repositories. Thank you for your contributions!\nPhoto credit Image by StockSnap from Pixabay\nUpdates July 6, 2022: Added Community Blog, ACE Samples May 24, 2021: Added Power Apps, Power Automate, and Power Virtual Agents Samples and updated contribution guidelines for SPFx Web Parts and SPFx Extensions April 24, 2021: Added Power Fx Samples and updated contribution guidelines for SPFx Web Parts and SPFx Extensions October 18, 2020: There was so much interest around the Microsoft Graph Toolkit repo that I also added the Microsoft Graph repos. Thanks Jeremy Thake for giving me a list of repos. October 15, 2020: Microsoft Graph Toolkit accepts contributions now! Woo hoo! October 13, 2020: Thanks to Nanddeep Nachan for pointing out I had forgotten to list the PnP/Teams-dev-samples! October 12, 2020: The Office 365 CLI is now called the CLI for Microsoft 365. Added Microsoft365DSC as per Dean Gross‘s suggestion. July 27, 2020: Updated repos within PnP organization. April 03, 2020: Yes, both the SPFx extensions and web parts samples repositories now ask you to submit to the master branch. This article was updated accordingly. March 03, 2020: This repository is getting a lot of traffic these days, so I figured I’d update it and add the super-useful microsoft-365-community repo November 22, 2019: I’m incredibly proud to be part of the Sharing is Caring initiative, where we walk people through the process of contributing to open-source repositories and show people how to create their first pull request! If you haven’t done so yet, sign up. September 25, 2019: David Warner II has launched a new initiative to help anyone who wants to create their first PnP contribution. It is called Sharing Is Caring and you can register to attend a live online hands-on session where he walks you through step-by-step instructions to create your first pull request. August 25, 2019: Thanks to Bert Jansen for providing us with details for the SharePoint/sp-dev-modernization repository. August 23, 2019: Erwin van Hunen Tweeted to remind us about SharePoint/PnP-Sites-Core. It is so foundational to other components, I don’t know how we missed it. Urgh! I hate to disappoint someone I hold in such high regard! Sorry! August 23, 2019: Waldek Mastykarz rightly pointed out that we forgot the PnPjs repository. ","permalink":"http://localhost:1313/posts/popular-pnp-repositories-and-how-to-get-started/","tags":["PnP","GitHub"],"title":"Popular PnP repositories and how to get started contributing"},{"categories":["Power Automate"],"contents":"Introduction In my previous post I showed how you can use Flow to trigger a scheduled flow and retrieve an iCal feed over HTTP.\nI also spent a bit of time explaining how to parse the text returned from the iCal feed into individual events and extract the information required to be able to import and synchronize the events in a SharePoint list. I mostly covered at a high-level and didn’t give you detailed steps — which is a good thing, because the article was already pretty long!\nIn today’s post, we’ll set up a SharePoint list and walk you through how to implement the flow, step-by-step.\nLet’s get going!\nSetting up a SharePoint list To synchronize an iCal feed to SharePoint, we need two things:\nA feed A SharePoint list And we’ll need a flow to combine the two.\nFor the feed, I’ll use one of CalendarLabs.com‘s iCal feeds. Being Canadian, I’ll use the Canadian Holidays feed, but feel free to use the US Holidays or any other that suits you. (Make sure that you get the URL from the Download button). I have to admit that I only learned about CalendarLabs.com when I was researching this post, but I’ll definitely be recommending it to everyone!\nThere are all sorts of useful iCal feeds out there. For example, if your company uses People HR to for your HR software, you can get an iCal feed of employee vacations directly from People HR and synchronize with a list called Staff Calendar.\nLet’s assume you have found an iCal feed you want to sync and you tested it to make sure it returns something.\nFor the SharePoint list, we’ll create one. Since the iCal feed I’m using is a list of Statutory Holidays, I’ll call my new list Statutory Holidays (I know, right? How do I come up with this stuff?!)\nTo create the list, follow these steps:\nFrom a SharePoint site of your choice, go to Settings then Site contents From the Site contents page, select + New and pick App. We use App instead of List because we want to create an events list, not a regular list. From the Site contents \u0026gt; Your Apps page, pick Calendar From the Adding calendar dialog, in the Name field, enter Statutory Holidays (or whichever name you picked for your event list, I’m flexible!) then select Create. Your list should automatically get created. Now we need to add one more field called UID to keep track of the unique identifiers for each event. The UIDs are provided by the iCal feed.\nTo add the column, follow these steps:\nFrom the list you just created, go to List settings In the Settings page, in the Columns section, select Create column. In the Settings \u0026gt; Create column page, type UID for the Column name. Un-check Add to default view, but leave everything else. We just want a simple text column to store the unique identifier, no need to get fancy. Select Ok to create the column. If you want, you can remove the columns that you won’t use, but for the sake of brevity, I’ll leave the existing fields as it. To set up the Flow Yesterday, I briefly touched how I build the flow to extract the data. Today, we’ll do it step-by-step, starting with these steps:\nLog-in to https://flow.microsoft.com From the left navigation, select + Create From the Start from blank section, select Scheduled flow In the Build a scheduled flow dialog, pick a Flow name — something like Sync Statutory Holidays from iCal Feed Under Run this flow, pick a Starting time that suits you, and select how often you want to repeat the flow. I picked 1 day under Repeat every. Select Create.\nTo retrieve the iCal feed Once your flow is created, follow these steps:\nSelect the + New step from the flow editor and type HTTP in the Choose an action window From the list of Actions, select HTTP Rename the new action you added to Get events from iCal In the HTTP action’s details, set the Method to GET, and put your iCal feed’s URL in the URI field. Leave everything else as is.\nTry your flow by using the Test button in the upper right corner. Your Get events from iCal should return events. If it doesn’t, check the URL.\nTo get the list of events Select the + New step and type Initialize in the Choose an action window.\nFrom the list of Actions, select Initialize variable\nRename your new action to Get list of events\nIn the initialize action’s details, set the Name to Events, the Type to Array and the Value to:\nsplit(replace(body(\u0026#39;Get_events_from_iCal\u0026#39;), \u0026#39;\\\\n\u0026#39;, \u0026#39;\u0026#39;), \u0026#39;BEGIN:VEVENT\u0026#39;) This will split the iCal feed into an array of events where BEGIN:VEVENT can be found.\nTo filter array elements that aren’t events Select the + New step and type Filter in the Choose an action window\nFrom the list of Actions, select Filter array\nRename the new action to Remove rows that are not events\nIn the From field, select the Events variable using the Dynamic content\nBelow the From field, select Edit in advanced mode and type:\n@not(startsWith(item(), \u0026#39;BEGIN\u0026#39;)) This will keep only array items that don’t start with BEGIN, thus removing all the iCal header information and leaving you with only events.\nTo create a loop to process all events Select the + New step button and type apply to each in the Choose an action window. From the list of Actions, select Apply to each Rename your action Loop through every event In the Select an output from previous steps field, select the Body of Remove rows that are not events in the Dynamic content picker. This will create a loop for every event in the array.\nTo split every event into lines Within the Loop through every event loop, select Add an action\nIn the Choose an action window, type compose\nFrom the list of Actions, select Compose\nRename your new action Get all lines in event\nIn the Input field, you’ll want to use:\nsplit(item(), json(\u0026#39;{\u0026#34;NL\u0026#34;:\u0026#34;\\n\u0026#34;}\u0026#39;)?[\u0026#39;NL\u0026#39;]) Now, all we need to do is extract the data from every relevant line\nTo get the Start Date Still within the loop, select Add an action and type Filter in the Choose an action window\nFrom the list of Actions, select Filter\nRename the new action Find DTSTART\nIn the Inputs field’s Expression tab, type:\n@startsWith(item(), \u0026#39;DTSTART\u0026#39;) Add another action using Add an action and type Compose\nFrom the list of actions, select Compose\nRename the action to Get DTSTART\nIn the Inputs field, type the following expression:\nreplace(first(body(\u0026#39;Find_DTSTART\u0026#39;)), \u0026#39;DTSTART;VALUE=DATE:\u0026#39;, \u0026#39;\u0026#39;) To get the End Date Repeat the same steps as above except that you should call the Filter action Find DTEND and use the following expression:\n@startsWith(item(), \u0026#39;DTEND;VALUE=\u0026#39;) And in the Compose action, call it Get DTEND and use the following expression\nreplace(first(body(\u0026#39;Find_DTEND\u0026#39;)), \u0026#39;DTEND;VALUE=DATE:\u0026#39;, \u0026#39;\u0026#39;) To get the Summary You guessed it, repeat same as above, but name the Filter action Find SUMMARY and use the following expression:\n@startsWith(item(), \u0026#39;SUMMARY:\u0026#39;) And set your Compose action to Get SUMMARY and use this expression:\nreplace(first(body(\u0026#39;Find_SUMMARY\u0026#39;)), \u0026#39;SUMMARY:\u0026#39;, \u0026#39;\u0026#39;) To get the Unique Identifier One last time! Repeat same as above, but name the Filter action Find UID and use the following expression:\n@startsWith(item(), \u0026#39;UID:\u0026#39;) And set your Compose action to Get UID and use this expression:\nreplace(first(body(\u0026#39;Find_UID\u0026#39;)), \u0026#39;UID:\u0026#39;, \u0026#39;\u0026#39;) Now you have all the properties we need. You should test your flow to make sure everything works.\nNote that if your iCal feed has different fields that you need, you may need to adjust your actions above. For example, some feeds will return DATE-TIME and DATE events, so you may want to add a little condition up there to deal with such events. To keep things simple, we won’t do that here.\nTo verify if the event is already in SharePoint Still within the loop, select Add an action and type SharePoint in the Choose an action window From the list of Actions, select Get items In the Site Address field, type your site’s URL From the List Name pick Statutory Holidays. Under Filter Query type UID eq ' then select the Output from Get UID in the Dynamic content window. Add ' to close the filter query Under Top Count, enter 1. We only care if there is already an event with a matching UID, so returning only 1 will do for us. If you test your flow now, every Get Items action should return the following:\n{\r[]\r} Because there are no events to retrieve. Let’s fix that.\nTo create a list item if there are no matches found Still within the loop, select Add an action and type Condition in the Choose an action window\nFrom the list of Actions, select Condition\nRename the condition Any existing events found\nIn the expression below type:\nlength(body(\u0026#39;Get_items\u0026#39;)?[\u0026#39;value\u0026#39;]) Select by is greater than in the next field\nIn the next field, type 0\nThis will cause the condition to go to If yes when there is an existing event, and If no if there isn’t an existing event. We’ll only worry about If no for now, but you could always update the existing item in the If yes side if you wanted to. Just no today, ok?\nIn the If no site, select Add an action\nIn the Choose an action field, type Create item\nIn the Actions list, select Create item from SharePoint\nIn the Create item dialog, type your Site Address and pick Statutory Holidays from the List Name\nIn the Title field, bind to the Output from Get SUMMARY\nWe’ll skip the Start Time and End Time for now. In the UID field, set it to the Output of the Get UID action.\nFor the Start Time, we’ll need to do some surgery because SharePoint expects the value to be formatted as yyyy-MM-ddThh:mm:ss. To do this, we’ll use substring() to extract the year, month, and day from the event’s date but using the following expression:\nconcat(substring(outputs(\u0026#39;Get_DTSTART\u0026#39;),0,4),\u0026#39;-\u0026#39;,substring(outputs(\u0026#39;Get_DTSTART\u0026#39;),4,2),\u0026#39;-\u0026#39;,substring(body(\u0026#39;Get_DTSTART\u0026#39;),6,2),\u0026#39;T00:00:00-00:00\u0026#39;) Which essentially combines the first 4 characters of the Start Date with a -, followed by the next 2 characters of Start Date, followed by another -, and the last two characters of Start Date, followed by T00:00:00 to set the time to midnight. If your iCal returns DATE-TIME values, you’ll also want to parse the time element instead of setting it to 00:00:00.\nThe last part -00:00 is for the timezone. If you find that your events are coming in at the wrong time, you can adjust the time zone accordingly (e.g.: +01:00 or -01:00).\nRepeat the same formula for End Time, except that you should use GET_DTEND instead of GET_DTSTART.\nTest your workflow, and you should have a whole bunch of new events! Then try again, and you should not get more events until the iCal feed adds a new event.\nConclusion (Sigh of relief!) That was a long post!\nThis post showed you how to get an iCal feed in Flow and import events from that feed into a SharePoint list.\nYou can use a similar approach for other types of feeds.\nThere are a few more opportunities to improve the resiliency of this flow, and to deal with all-day events that span over two days when they should really last one day… but that’ll have to be for another post.\nI hope this helped?\nPhoto credit Image by Free-Photos from Pixabay\n","permalink":"http://localhost:1313/posts/using-flow-to-synchronize-an-ical-feed-to-a-sharepoint-event-list-part-ii/","tags":["iCal","Power Automate"],"title":"Using Flow to synchronize an iCal feed to a SharePoint event list — Part II"},{"categories":["Power Automate"],"contents":"Introduction Let’s say you have public iCal feed and you want to access the events from within SharePoint Online.\nYou could use the sample web part I created many months ago which allows you to display external event feeds from RSS, WordPress, Exchange, SharePoint and iCal. You’d get something that looks like it exists in SharePoint.\nBut what if you wanted to use the events from that iCal feed within SharePoint as a lookup for another list. Or what if that iCal feed contained statutory holidays and you wanted to skip scheduled Flows on those days?\nIn such situations, you need to actually import the data into SharePoint so that you can use it. My web part sample won’t do!\nToday, we’ll explain how to use Flow to import events daily from an iCal feed into a SharePoint list.\nThe idea for this post came from an issue that Tejas kindly submitted. Thanks for the inspiration!\nThe problem with repetitive tasks At first, I was very tempted to tweak my React Calendar Feed web part sample to display events and automatically add events to a SharePoint event list. After all, I was already parsing the iCal feeds in my code, so couldn’t I just add the events that were not already in the list?\nThe problem with this idea is that it would require someone with sufficient permissions to add events to that event list to load that web part once a day — or at least regularly enough to make sure the iCal events and the list were in sync.\nBad idea.\nAny time you require someone to do a manual step regularly to keep a system going is not sustainable. It’s like that countdown timer in the TV show Lost that required someone to enter a sequence of numbers or the world would end.\nThe countdown clock from Lost — I don’t need that kind of responsibility!\nIt’s what we called on a project I worked on \u0026ldquo;Death by a thousand cuts\u0026rdquo;. It may not seem like a big deal to ask someone to do something every x days to keep a system going, but those little temporary solutions you take on eventually accumulate to a point where you need a person whose job is just to do those little things. It isn’t a job that’s very fulfilling for anyone.\nMight as well use Homer Simpson’s \u0026ldquo;stupid bird\u0026rdquo; to push a button every once in a while.\nHomer’s stupid bird\nSo, the lazy approach wouldn’t work for me this time.\nWhat could I use? A timer job on a server? Nah, I want a server-less solution.\nHow about a scheduled Azure web job? No, I want a no-code solution. Or at least low-code.\nIf only there was a way to schedule workflows to run regularly that wouldn’t require any code…\nScheduled flows to the rescue Thankfully, Microsoft Flow allows you to create scheduled flows. We already discussed using schedule flows in a previous post, so I know with certainty that it will work.\nI configured my flow to run every day. That’s probably an overkill depending on how often your iCal feed gets updated, so feel free to adjust accordingly:\nNow here’s the problem: Flow does not have a way to parse iCal feeds. I looked everywhere for a ready-to-use \u0026ldquo;import iCal\u0026rdquo; connector, but couldn’t find any. As it turns out, I’m not the only one who wants this.\nNote to Microsoft: if you accept open source contributions for connectors, let me know and I’ll gladly submit an iCal connector.\nBut iCal feeds are really just text files with a very specific structure. Could we not just use the Flow HTTP connector and retrieve the feed as a simple string of text and parse it?\nNote: Unfortunately, HTTP is a Premium connector in Flow… but you get so much more with Flow Premium that it is worth it! Trust me!\nThis is how I configured my HTTP connector to retrieve my iCal feed:\nParsing the results to get a list of events I configured an HTTP connector to do an HTTP GET with a public iCal feed. I used CalendarLabs.com‘s Canadian Holidays sample, but they have many other great sample calendar feeds.\nAnd it worked. The response wasn’t pretty, but it worked!\nHere is an example of what I got. The full list is a lot longer, but you get the idea.\nBEGIN:VCALENDAR\rPRODID:fd29_Array_canada_country_holidays@calendarlabs.com\rVERSION:2.0\rCALSCALE:GREGORIAN\rMETHOD:PUBLISH\rX-WR-CALNAME:Canada Holidays\rX-WR-TIMEZONE:America/New_York\rBEGIN:VEVENT\rDTSTART;VALUE=DATE:20180101\rDTEND;VALUE=DATE:20180102\rDTSTAMP:20111213T124028Z\rUID:5c60f18d0973d@calendarlabs.com\rCREATED:20111213T123901Z\rDESCRIPTION:Visit https://calendarlabs.com/holidays/us/new-years-day.php to know more about New Year\u0026#39;s Day. Like us on Facebook: http://fb.com/calendarlabs to get updates.\rLAST-MODIFIED:20111213T123901Z\rLOCATION:Canada\rSEQUENCE:0\rSTATUS:CONFIRMED\rSUMMARY:New Year\u0026#39;s Day\rTRANSP:TRANSPARENT\rEND:VEVENT\rBEGIN:VEVENT\rDTSTART;VALUE=DATE:20180212\rDTEND;VALUE=DATE:20180213\rDTSTAMP:20111213T124028Z\rUID:5c60f18d09784@calendarlabs.com\rCREATED:20111213T123901Z\rDESCRIPTION:Visit https://calendarlabs.com/holidays/canada/family-day.php to know more about Family Day (BC). Like us on Facebook: http://fb.com/calendarlabs to get updates.\rLAST-MODIFIED:20111213T123901Z\rLOCATION:Canada\rSEQUENCE:0\rSTATUS:CONFIRMED\rSUMMARY:Family Day (BC)\rTRANSP:TRANSPARENT\rEND:VEVENT As you can see, iCal feeds use lines as a delimiter for each field. Every new event start with BEGIN:VEVENT on a new line.\nSo I used the Initialize variable to create an array variable which would contain every event in the feed. I called the variable Events.\nFor the initial value of the variable, I used the split() function, and I specified that it should create a new array element every time it found a BEGIN:VEVENT.\nSome iCal feeds that I tested also had extra newline characters, so I took the opportunity to remove those while I was parsing the feed, by using the replace() function to replace all \\\\n with nothing ('') as follows:\nsplit(replace(body(\u0026#39;Get_events_from_iCal\u0026#39;), \u0026#39;\\\\n\u0026#39;, \u0026#39;\u0026#39;), \u0026#39;BEGIN:VEVENT\u0026#39;) The problem is that the split() function just blindly creates array elements wherever it finds the delimiter you specify. It doesn’t care what comes before or after the delimiter.\nFor example, my sample feed contains 8 lines before the first event, meaning that this text:\nBEGIN:VCALENDAR\rPRODID:fd29_Array_canada_country_holidays@calendarlabs.com\rVERSION:2.0\rCALSCALE:GREGORIAN\rMETHOD:PUBLISH\rX-WR-CALNAME:Canada Holidays\rX-WR-TIMEZONE:America/New_York\rBEGIN:VEVENT\rDTSTART;VALUE=DATE:20180101\rDTEND;VALUE=DATE:20180102\rDTSTAMP:20111213T124028Z\rUID:5c60f18d0973d@calendarlabs.com\rCREATED:20111213T123901Z\rDESCRIPTION:Visit https://calendarlabs.com/holidays/us/new-years-day.php to know more about New Year\u0026#39;s Day. Like us on Facebook: http://fb.com/calendarlabs to get updates.\rLAST-MODIFIED:20111213T123901Z\rLOCATION:Canada\rSEQUENCE:0\rSTATUS:CONFIRMED\rSUMMARY:New Year\u0026#39;s Day\rTRANSP:TRANSPARENT\rEND:VEVENT\rBEGIN:VEVENT\rDTSTART;VALUE=DATE:20180212\rDTEND;VALUE=DATE:20180213\rDTSTAMP:20111213T124028Z\rUID:5c60f18d09784@calendarlabs.com\rCREATED:20111213T123901Z\rDESCRIPTION:Visit https://calendarlabs.com/holidays/canada/family-day.php to know more about Family Day (BC). Like us on Facebook: http://fb.com/calendarlabs to get updates.\rLAST-MODIFIED:20111213T123901Z\rLOCATION:Canada\rSEQUENCE:0\rSTATUS:CONFIRMED\rSUMMARY:Family Day (BC)\rTRANSP:TRANSPARENT\rEND:VEVENT When the text is split where BEGIN:VEVENT is found, I get the following array:\n[ \u0026#34;BEGIN:VCALENDAR\\nPRODID:fd29_Array_canada_country_holidays@calendarlabs.com\\nVERSION:2.0\\nCALSCALE:GREGORIAN\\nMETHOD:PUBLISH\\nX-WR-CALNAME:Canada Holidays\\nX-WR-TIMEZONE:America/New_York\\n\u0026#34;,\r\u0026#34;\\nDTSTART;VALUE=DATE:20180101\\nDTEND;VALUE=DATE:20180102\\nDTSTAMP:20111213T124028Z\\nUID:5c60f18d0973d@calendarlabs.com\\nCREATED:20111213T123901Z\\nDESCRIPTION:Visit https://calendarlabs.com/holidays/us/new-years-day.php to know more about New Year\u0026#39;s Day. \\n Like us on Facebook: http://fb.com/calendarlabs to get updates.\\nLAST-MODIFIED:20111213T123901Z\\nLOCATION:Canada\\nSEQUENCE:0\\nSTATUS:CONFIRMED\\nSUMMARY:New Year\u0026#39;s Day\\nTRANSP:TRANSPARENT\\nEND:VEVENT\\n\u0026#34;,\r\u0026#34;\\nDTSTART;VALUE=DATE:20180212\\nDTEND;VALUE=DATE:20180213\\nDTSTAMP:20111213T124028Z\\nUID:5c60f18d09784@calendarlabs.com\\nCREATED:20111213T123901Z\\nDESCRIPTION:Visit https://calendarlabs.com/holidays/canada/family-day.php to know more about Family Day (BC). \\n Like us on Facebook: http://fb.com/calendarlabs to get updates.\\nLAST-MODIFIED:20111213T123901Z\\nLOCATION:Canada\\nSEQUENCE:0\\nSTATUS:CONFIRMED\\nSUMMARY:Family Day (BC)\\nTRANSP:TRANSPARENT\\nEND:VEVENT\\n\u0026#34;,\r...\r] Notice that the first array element is different than the others. It contains information about the calendar feed, which we don’t care about for our needs.\nTo remove anything that isn’t an event, I simply used the Filter action and kept only array elements that do not start with BEGIN:\n(I could have filtered for events that start with DTSTART, but I didn’t want to have to deal with the funny \\n character at the start of every element)\nThis is the array the filter action returned:\n[\r\u0026#34;\\nDTSTART;VALUE=DATE:20180101\\nDTEND;VALUE=DATE:20180102\\nDTSTAMP:20111213T124028Z\\nUID:5c60f18d0973d@calendarlabs.com\\nCREATED:20111213T123901Z\\nDESCRIPTION:Visit https://calendarlabs.com/holidays/us/new-years-day.php to know more about New Year\u0026#39;s Day. \\n Like us on Facebook: http://fb.com/calendarlabs to get updates.\\nLAST-MODIFIED:20111213T123901Z\\nLOCATION:Canada\\nSEQUENCE:0\\nSTATUS:CONFIRMED\\nSUMMARY:New Year\u0026#39;s Day\\nTRANSP:TRANSPARENT\\nEND:VEVENT\\n\u0026#34;,\r\u0026#34;\\nDTSTART;VALUE=DATE:20180212\\nDTEND;VALUE=DATE:20180213\\nDTSTAMP:20111213T124028Z\\nUID:5c60f18d09784@calendarlabs.com\\nCREATED:20111213T123901Z\\nDESCRIPTION:Visit https://calendarlabs.com/holidays/canada/family-day.php to know more about Family Day (BC). \\n Like us on Facebook: http://fb.com/calendarlabs to get updates.\\nLAST-MODIFIED:20111213T123901Z\\nLOCATION:Canada\\nSEQUENCE:0\\nSTATUS:CONFIRMED\\nSUMMARY:Family Day (BC)\\nTRANSP:TRANSPARENT\\nEND:VEVENT\\n\u0026#34;,\r\u0026#34;\\nDTSTART;VALUE=DATE:20180214\\nDTEND;VALUE=DATE:20180215\\nDTSTAMP:20111213T124028Z\\nUID:5c60f18d097c3@calendarlabs.com\\nCREATED:20111213T123901Z\\nDESCRIPTION:Visit https://calendarlabs.com/holidays/us/valentines-day.php to know more about Valentine\u0026#39;s Day. \\n Like us on Facebook: http://fb.com/calendarlabs to get updates.\\nLAST-MODIFIED:20111213T123901Z\\nLOCATION:Canada\\nSEQUENCE:0\\nSTATUS:CONFIRMED\\nSUMMARY:Valentine\u0026#39;s Day\\nTRANSP:TRANSPARENT\\nEND:VEVENT\\n\u0026#34;,\r...\r] Now all I needed to do was to loop through every event and parse the values…\nProcessing each event So far, I have a scheduled flow which retrieves an iCal feed, splits the text into an array of events, and filters out things that aren’t events.\nTo process every item in the array of events, I just used the Apply for each action:\nWhen it asked me what I wanted to loop through, I specified the Body of the filter action from before.\nNow that I have the flow looping through every event, I need to split the event into individual lines, using the split() function, like before.\nExcept that this time, instead of storing the array of lines in a variable, I use the Compose action to temporarily build my array.\nThe only problem is, I found it very difficult to write a split() function to divide by the newline character. Luckily, someone who is way smarter than I am (tre4B) came up with a solution.\ntre4B’s solution is to temporarily define a JSON object which defines the newline character as a JSON element, and use that JSON element, as follows:\njson(\u0026#39;{\u0026#34;NL\u0026#34;:\u0026#34;\\n\u0026#34;}\u0026#39;)?[\u0026#39;NL\u0026#39;] I must admit, it’s almost like voodoo to me, but it works.\nSo, to split every event into individual lines, I used:\njson(\u0026#39;{\u0026#34;NL\u0026#34;:\u0026#34;\\n\u0026#34;}\u0026#39;)?[\u0026#39;NL\u0026#39;] If your feed uses both a newline and a carriage return, you would use this instead:\nsplit(item(), json(\u0026#39;{\u0026#34;NL\u0026#34;:\u0026#34;\\r\\n\u0026#34;}\u0026#39;)?[\u0026#39;NL\u0026#39;]) Now, every event returns an array of lines that look like this:\n[\r\u0026#34;\u0026#34;,\r\u0026#34;DTSTART;VALUE=DATE:20180101\u0026#34;,\r\u0026#34;DTEND;VALUE=DATE:20180102\u0026#34;,\r\u0026#34;DTSTAMP:20111213T124028Z\u0026#34;,\r\u0026#34;UID:5c60f18d0973d@calendarlabs.com\u0026#34;,\r\u0026#34;CREATED:20111213T123901Z\u0026#34;,\r\u0026#34;DESCRIPTION:Visit https://calendarlabs.com/holidays/us/new-years-day.php to know more about New Year\u0026#39;s Day. \u0026#34;,\r\u0026#34; Like us on Facebook: http://fb.com/calendarlabs to get updates.\u0026#34;,\r\u0026#34;LAST-MODIFIED:20111213T123901Z\u0026#34;,\r\u0026#34;LOCATION:Canada\u0026#34;,\r\u0026#34;SEQUENCE:0\u0026#34;,\r\u0026#34;STATUS:CONFIRMED\u0026#34;,\r\u0026#34;SUMMARY:New Year\u0026#39;s Day\u0026#34;,\r\u0026#34;TRANSP:TRANSPARENT\u0026#34;,\r\u0026#34;END:VEVENT\u0026#34;,\r\u0026#34;\u0026#34;\r] Once I have every line as an array element, I can just use the same filter() technique I used before to find each line for the Start Date, End Date, Summary and anything else I need.\nFor example, to find the Start Date, I find the line which starts with DTSTART:\nAnd to get the date value, I use the replace() function to remove everything before the date, which looks like this:\nreplace(first(body(\u0026#39;Find_DTSTART\u0026#39;)), \u0026#39;DTSTART;VALUE=DATE:\u0026#39;, \u0026#39;\u0026#39;) All that’s left is a string that represents the date. I won’t bother converting the string to a date because SharePoint will expect a very specific date format later anyway.\nI just repeat the same thing with DTEND for the End Date and SUMMARY for the event title.\nAlso, I’ll retrieve every event’s UID which is a unique identifier that I’ll be able to use later to verify if the event has already been created in SharePoint.\nOnce completed, my event parsing looks like this:\nIt looks like it’s a lot of work, but thanks to Flow’s new clipboard functionality, it was able to copy and paste the Find DTSTART and Get DTSTART actions for the DTEND, SUMMARY and UID.\nEasy!\nTo be continued Sorry if this post was long (and probably boring). We had a lot of stuff to cover, and we’re not finished yet!\nSo far, we have created a scheduled workflow which reads an iCal feed and parses each event to retrieve their individual attributes.\nI should point out that my approach isn’t the only way to do this, I’m sure. This is the way I did it. For example, instead of using replace(), I could have used the substring() function to extract the parts of the strings I wanted, but I prefer replace() because it makes it easier to read what the function is doing. Feel free to use whichever approach you like.\nTomorrow, we’ll use the same technique we used before to see if every event exists in a SharePoint list. If it doesn’t, we’ll create it.\nI’ll also share the step by step instructions tomorrow.\nI hope you’ll come back tomorrow for the second part!\nPhoto credit Image by Karolina Grabowska from Pixabay\n","permalink":"http://localhost:1313/posts/using-flow-to-synchronize-an-ical-feed-to-a-sharepoint-event-list-part-i/","tags":["iCal","Power Automate"],"title":"Using Flow to synchronize an iCal feed to a SharePoint event list — Part I"},{"categories":["SharePoint"],"contents":"Introduction I use mind maps to understand things. I do this a lot. They’re a great way to summarize things in a simple picture.\nMy goal is to take major SharePoint/Office 365 announcements, videos, and other relevant pieces of information which may require too much time for busy people to read and watch, and to boil it down to the essential.\nThis one highlights what’s new in August 2019 with SharePoint pages and news authoring.\nJust click on the mind map to see a larger image.\nConclusion Let me know if this was useful for you. Also, if I missed something, let me know.\nSources https://www.microsoft.com/microsoft-365/roadmap?filters=\u0026amp;searchterms=53194 https://www.microsoft.com/microsoft-365/roadmap?filters=\u0026amp;searchterms=53221 https://www.microsoft.com/microsoft-365/roadmap?filters=\u0026amp;searchterms=53228 https://www.microsoft.com/microsoft-365/roadmap?filters=\u0026amp;searchterms=53222 https://www.microsoft.com/microsoft-365/roadmap?filters=\u0026amp;searchterms=53195 https://www.microsoft.com/microsoft-365/roadmap?filters=\u0026amp;searchterms=53198 https://www.microsoft.com/microsoft-365/roadmap?filters=\u0026amp;searchterms=53192 https://techcommunity.microsoft.com/t5/Microsoft-SharePoint-Blog/August-2019-Updates-to-SharePoint-page-and-news-authoring/ba-p/801482 ","permalink":"http://localhost:1313/posts/august-2019-updates-to-sharepoint-pages-and-news-authoring-updates-for-busy-people/","tags":["MindMap","Updates for Busy People"],"title":"August 2019 Updates to SharePoint pages and news authoring — updates for busy people"},{"categories":["ASP.Net"],"contents":"Introduction If you’ve ever used Visual Studio’s Web Deploy feature to deploy using a file share, you may have experienced issues where some files cannot be overwritten because they are in use. You may not already know this: ASP.NET Core has a built-in mechanism to take applications offline and display a message. This article describes how you can use Visual Studio’s Web Deploy feature to automatically take your web application offline while you deploy a new version, and restore it back online when deployment is complete using (pretty much) all out-of-the-box features of Visual Studio and ASP.NET Core.\nUsing Web Deploy If you haven’t used it yet, the Web Deploy feature in Visual Studio pretty much does exactly what its name implies: it deploys a web application.\nNOTE: It has been around for a while, and the “code” I’ll use in this article may work with earlier versions of Visual Studio, but I used Visual Studio 2017 to write this article.\nTo use Web Deploy: 1. From the Solution Explorer within Visual Studio, right-click on your web application project. 2. From the context-menu, select Publish…\n3. From the Pick a Publish Target dialog, pick Folder\n4. In the Choose a folder field, enter the path to your web application folder. For example, I’ll use: \\whousesfilesharesanymore\\websites\\demowebapp\nSelect the drop-down option next to the Publish button and select Create Profile. 6. Visual Studio will create a profile called FolderProfile and open the Publish page for you. 7. Use the chevron next to the Actions link and select Rename Profile\n8. Rename the profile to whatever you like. In this example, we’ll pretend that I’m deploying to my QA server, so I’ll use QAServer as the name. 9. If you wish, you can set up more options by clicking on Configure… . For the purpose of this demo, I’ll just click on Publish to launch the Web Deploy feature. Assuming everything went well, your web application gets deployed to your web server without any issues. Except if you try to re-deploy your web application to a web server that has active sessions; then it says that it can’t overwrite some files because they are in use. Fortunately, that’s why ASP.NET Core has app_offline.htm.\nUsing app_offline.htm Since 2012, we have been able to take web applications offline when deploying them. The mechanism is simple: ASP.NET looks for a file called app_offline.htm in the web application’s root folder. If it sees such a file, it automatically starts redirecting all connections to the app_offline.htm page and shuts down all connections that may hold a lock on your files.\nNOTE: The app_offline.htm should be in the root of your web application folder, not the wwwroot.\nIf you put HTML in you app_offline.htm page, the message will be displayed to your visitors as long as the app_offline.htm page is in the web application folder.\nFortunately, your pubxml (most likely) has a tag just for tag:\nIf you’re lucky, you might even see the app_offline.htm temporarily before your custom target removes the file and the page automatically refreshes itself to show the application online!\nhttp://yoururlgoeshere\nConclusion Honestly, you probably wouldn’t have to do this if you deployed your web app to Azure, use IIS deployment, or use CI/CD to automatically deploy after a successful build but if your client/employer is still using file shares to deploy web applications, this article should help you. I hope this helps someone! Let me know in the comments. Here is a sample app_offline.htm that I use:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; h1 { font-size: 36px; margin: 0; font-family: Open Sans,sans-serif; color: #3b4151; } body { font-family: Open Sans,sans-serif; color: #3b4151; } \u0026lt;/style\u0026gt; \u0026lt;META HTTP-EQUIV=\u0026#34;refresh\u0026#34; CONTENT=\u0026#34;5; URL=/\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;This application is currently under maintenance\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Please try again in a few minutes.\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Nothing special, except that on line 19, I add a META HTTP-EQUIP=”refresh” tag to refresh the page every 5 seconds. That way, the page reloads automatically when the site goes back online. If you want to restore the application online again, go to your web application’s folder and remove (or rename) the app_offline.htm.\nDebugging with app_offline.htm There’s just one problem: if you add a app_offline.htm file in your Visual Studio project, you won’t be able to debug it, because ASP.NET will do what it is supposed to do and report the application as offline. Visual Studio will report that the web request failed with a status code 503, Service Unavailable. Fortunately, ASP.NET is very literal about what file it looks for. If you just rename the file _app_offline.htm or app_online.htm or offliney_mcofflineface.htm, ASP.NET will ignore it — anything but app_offline.htm. So now all you need to do is to keep _app_offline.htm in your Visual Studio project and rename it to app_offline.htm before you deploy it. Fortunately, there’s a way to do this automatically using Web Deploy!\nAutomatically renaming _app_offline.htm when deploying using Web Deploy Lucky for us, Visual Studio’s web deploy profiles follow the MSBuild syntax and can be customized easily. You can find your web deploy profile in Visual Studio’s Solution Explorer under your web project’s properties \u0026gt; PublishProfiles folder.\nIf you open the file by double-clicking on it, you should see something that looks like this:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;!-- This file is used by the publish/package process of your Web project. You can customize the behavior of this process by editing this MSBuild file. In order to learn more about this please visit https://go.microsoft.com/fwlink/?LinkID=208121. --\u0026gt; \u0026lt;Project ToolsVersion=\u0026#34;4.0\u0026#34; xmlns=\u0026#34;http://schemas.microsoft.com/developer/msbuild/2003\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;WebPublishMethod\u0026gt;FileSystem\u0026lt;/WebPublishMethod\u0026gt; \u0026lt;PublishProvider\u0026gt;FileSystem\u0026lt;/PublishProvider\u0026gt; \u0026lt;LastUsedBuildConfiguration\u0026gt;Release\u0026lt;/LastUsedBuildConfiguration\u0026gt; \u0026lt;LastUsedPlatform\u0026gt;Any CPU\u0026lt;/LastUsedPlatform\u0026gt; \u0026lt;SiteUrlToLaunchAfterPublish /\u0026gt; \u0026lt;LaunchSiteAfterPublish\u0026gt;True\u0026lt;/LaunchSiteAfterPublish\u0026gt; \u0026lt;ExcludeApp_Data\u0026gt;False\u0026lt;/ExcludeApp_Data\u0026gt; \u0026lt;ProjectGuid\u0026gt;3a09d6fb-7f5f-4dd8-b712-3e495c6c4936\u0026lt;/ProjectGuid\u0026gt; \u0026lt;publishUrl\u0026gt;\\\\whousesfilesharesanymore\\websites\\demowebapp\u0026lt;/publishUrl\u0026gt; \u0026lt;DeleteExistingFiles\u0026gt;False\u0026lt;/DeleteExistingFiles\u0026gt; \u0026lt;TargetFramework\u0026gt;netcoreapp2.1\u0026lt;/TargetFramework\u0026gt; \u0026lt;SelfContained\u0026gt;false\u0026lt;/SelfContained\u0026gt; \u0026lt;_IsPortable\u0026gt;true\u0026lt;/_IsPortable\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;/Project\u0026gt; That’s something we can work with! MSBuild allows you to add custom actions (or targets) that can be triggered via events. For example, to create a new custom target called TakeOffline and display a message saying “Taking application offline” you would insert the following element in your pubxml file, just before the closing Project tag:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;!-- This file is used by the publish/package process of your Web project. You can customize the behavior of this process by editing this MSBuild file. In order to learn more about this please visit https://go.microsoft.com/fwlink/?LinkID=208121. --\u0026gt; \u0026lt;Project ToolsVersion=\u0026#34;4.0\u0026#34; xmlns=\u0026#34;http://schemas.microsoft.com/developer/msbuild/2003\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;WebPublishMethod\u0026gt;FileSystem\u0026lt;/WebPublishMethod\u0026gt; \u0026lt;PublishProvider\u0026gt;FileSystem\u0026lt;/PublishProvider\u0026gt; \u0026lt;LastUsedBuildConfiguration\u0026gt;Release\u0026lt;/LastUsedBuildConfiguration\u0026gt; \u0026lt;LastUsedPlatform\u0026gt;Any CPU\u0026lt;/LastUsedPlatform\u0026gt; \u0026lt;SiteUrlToLaunchAfterPublish /\u0026gt; \u0026lt;LaunchSiteAfterPublish\u0026gt;True\u0026lt;/LaunchSiteAfterPublish\u0026gt; \u0026lt;ExcludeApp_Data\u0026gt;False\u0026lt;/ExcludeApp_Data\u0026gt; \u0026lt;ProjectGuid\u0026gt;3a09d6fb-7f5f-4dd8-b712-3e495c6c4936\u0026lt;/ProjectGuid\u0026gt; \u0026lt;publishUrl\u0026gt;\\\\whousesfilesharesanymore\\websites\\demowebapp\u0026lt;/publishUrl\u0026gt; \u0026lt;DeleteExistingFiles\u0026gt;False\u0026lt;/DeleteExistingFiles\u0026gt; \u0026lt;TargetFramework\u0026gt;netcoreapp2.1\u0026lt;/TargetFramework\u0026gt; \u0026lt;SelfContained\u0026gt;false\u0026lt;/SelfContained\u0026gt; \u0026lt;_IsPortable\u0026gt;true\u0026lt;/_IsPortable\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;!-- BEGIN: Add this --\u0026gt; \u0026lt;Target Name=\u0026#34;TakeOffline\u0026#34; AfterTargets=\u0026#34;BeforePublish\u0026#34; \u0026gt; \u0026lt;Message Text=\u0026#34;Taking application offline\u0026#34; Importance=\u0026#34;high\u0026#34; /\u0026gt; \u0026lt;/Target\u0026gt; \u0026lt;!-- END: Add this --\u0026gt; \u0026lt;/Project\u0026gt; In the code above, the Importance is set to high to make the message appear in Visual Studio’s output window during the web publish. The custom target we created is set to be triggered after the BeforePublish event. To make the custom target rename the file, you can simply add a Copy command that copies the file called _app_offline.htm (located in your web project’s root folder) and rename it to app_offline.htm in the $(publishUrl) folder (your destination folder).\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;!-- This file is used by the publish/package process of your Web project. You can customize the behavior of this process by editing this MSBuild file. In order to learn more about this please visit https://go.microsoft.com/fwlink/?LinkID=208121. --\u0026gt; \u0026lt;Project ToolsVersion=\u0026#34;4.0\u0026#34; xmlns=\u0026#34;http://schemas.microsoft.com/developer/msbuild/2003\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;WebPublishMethod\u0026gt;FileSystem\u0026lt;/WebPublishMethod\u0026gt; \u0026lt;PublishProvider\u0026gt;FileSystem\u0026lt;/PublishProvider\u0026gt; \u0026lt;LastUsedBuildConfiguration\u0026gt;Release\u0026lt;/LastUsedBuildConfiguration\u0026gt; \u0026lt;LastUsedPlatform\u0026gt;Any CPU\u0026lt;/LastUsedPlatform\u0026gt; \u0026lt;SiteUrlToLaunchAfterPublish /\u0026gt; \u0026lt;LaunchSiteAfterPublish\u0026gt;True\u0026lt;/LaunchSiteAfterPublish\u0026gt; \u0026lt;ExcludeApp_Data\u0026gt;False\u0026lt;/ExcludeApp_Data\u0026gt; \u0026lt;ProjectGuid\u0026gt;3a09d6fb-7f5f-4dd8-b712-3e495c6c4936\u0026lt;/ProjectGuid\u0026gt; \u0026lt;publishUrl\u0026gt;\\\\whousesfilesharesanymore\\websites\\demowebapp\u0026lt;/publishUrl\u0026gt; \u0026lt;DeleteExistingFiles\u0026gt;False\u0026lt;/DeleteExistingFiles\u0026gt; \u0026lt;TargetFramework\u0026gt;netcoreapp2.1\u0026lt;/TargetFramework\u0026gt; \u0026lt;SelfContained\u0026gt;false\u0026lt;/SelfContained\u0026gt; \u0026lt;_IsPortable\u0026gt;true\u0026lt;/_IsPortable\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;Target Name=\u0026#34;TakeOffline\u0026#34; AfterTargets=\u0026#34;BeforePublish\u0026#34; \u0026gt; \u0026lt;Message Text=\u0026#34;Taking application offline\u0026#34; Importance=\u0026#34;high\u0026#34; /\u0026gt; \u0026lt;!-- BEGIN: Add this --\u0026gt; \u0026lt;Copy SourceFiles=\u0026#34;_app_offline.htm\u0026#34; DestinationFiles=\u0026#34;$(publishUrl)\\app_offline.htm\u0026#34; /\u0026gt; \u0026lt;!-- END: Add this --\u0026gt; \u0026lt;/Target\u0026gt; \u0026lt;/Project\u0026gt; Save your pubxml file and publish your web app by right-clicking your web application’s project in Visual Studio’s Solution Explorer then select Publish… and click the Publish button. Great! Now your web application goes offline, displays a custom message to tell your users not to panic, and gets automatically deployed… …but it doesn’t come back online when done… because ASP.NET still see an app_offline.htm file in your web application’s folder! Let’s fix that!\nAutomatically removing app_offline.htm after deployment is complete using Web Deploy We can simply add another custom action, this one triggered by AfterPublish which deletes the file:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;!-- This file is used by the publish/package process of your Web project. You can customize the behavior of this process by editing this MSBuild file. In order to learn more about this please visit https://go.microsoft.com/fwlink/?LinkID=208121. --\u0026gt; \u0026lt;Project ToolsVersion=\u0026#34;4.0\u0026#34; xmlns=\u0026#34;http://schemas.microsoft.com/developer/msbuild/2003\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;WebPublishMethod\u0026gt;FileSystem\u0026lt;/WebPublishMethod\u0026gt; \u0026lt;PublishProvider\u0026gt;FileSystem\u0026lt;/PublishProvider\u0026gt; \u0026lt;LastUsedBuildConfiguration\u0026gt;Release\u0026lt;/LastUsedBuildConfiguration\u0026gt; \u0026lt;LastUsedPlatform\u0026gt;Any CPU\u0026lt;/LastUsedPlatform\u0026gt; \u0026lt;SiteUrlToLaunchAfterPublish /\u0026gt; \u0026lt;LaunchSiteAfterPublish\u0026gt;True\u0026lt;/LaunchSiteAfterPublish\u0026gt; \u0026lt;ExcludeApp_Data\u0026gt;False\u0026lt;/ExcludeApp_Data\u0026gt; \u0026lt;ProjectGuid\u0026gt;3a09d6fb-7f5f-4dd8-b712-3e495c6c4936\u0026lt;/ProjectGuid\u0026gt; \u0026lt;publishUrl\u0026gt;\\\\whousesfilesharesanymore\\websites\\demowebapp\u0026lt;/publishUrl\u0026gt; \u0026lt;DeleteExistingFiles\u0026gt;False\u0026lt;/DeleteExistingFiles\u0026gt; \u0026lt;TargetFramework\u0026gt;netcoreapp2.1\u0026lt;/TargetFramework\u0026gt; \u0026lt;SelfContained\u0026gt;false\u0026lt;/SelfContained\u0026gt; \u0026lt;_IsPortable\u0026gt;true\u0026lt;/_IsPortable\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;Target Name=\u0026#34;TakeOffline\u0026#34; AfterTargets=\u0026#34;BeforePublish\u0026#34; \u0026gt; \u0026lt;Message Text=\u0026#34;Taking application offline\u0026#34; Importance=\u0026#34;high\u0026#34; /\u0026gt; \u0026lt;Copy SourceFiles=\u0026#34;_app_offline.htm\u0026#34; DestinationFiles=\u0026#34;$(publishUrl)\\app_offline.htm\u0026#34; /\u0026gt; \u0026lt;/Target\u0026gt; \u0026lt;!-- BEGIN: Add this --\u0026gt; \u0026lt;Target Name=\u0026#34;RestoreOnline\u0026#34; AfterTargets=\u0026#34;AfterPublish\u0026#34; \u0026gt; \u0026lt;Message Text=\u0026#34;Restoring application online\u0026#34; Importance=\u0026#34;high\u0026#34; /\u0026gt; \u0026lt;Delete Files=\u0026#34;$(publishUrl)\\app_offline.htm\u0026#34; /\u0026gt; \u0026lt;/Target\u0026gt; \u0026lt;!-- END: Add this --\u0026gt; \u0026lt;/Project\u0026gt; Just insert the above code before the Project close tag in your pubxml, save and re-deploy. This time the message will automatically go away once the project has been published.\nBonus Feature: Launch the site automatically after deployment In case I haven’t said it before: I’m the world’s laziest developer. Case in point: I hate navigating to the web application’s web site when web deployment is complete. Fortunately, your pubxml (most likely) has a tag just for tag:\n\u0026lt;SiteUrlToLaunchAfterPublish /\u0026gt; If you’re lucky, you might even see the app_offline.htm temporarily before your custom target removes the file and the page automatically refreshes itself to show the application online!\n\u0026lt;SiteUrlToLaunchAfterPublish\u0026gt;\u0026lt;http://yoururlgoeshere\u0026gt;\u0026lt;SiteUrlToLaunchAfterPublish/\u0026gt; Conclusion Honestly, you probably wouldn’t have to do this if you deployed your web app to Azure, use IIS deployment, or use CI/CD to automatically deploy after a successful build but if your client/employer is still using file shares to deploy web applications, this article should help you. I hope this helps someone! Let me know in the comments.\n","permalink":"http://localhost:1313/posts/automatically-make-your-asp-net-web-application-offline-while-deploying-using-web-deploy-in-visual-studio-2017/","tags":["Visual Studio"],"title":"August 2019 Updates to SharePoint pages and news authoring — updates for busy people"},{"categories":["SharePoint"],"contents":"Introduction Sometimes, you just want to create a link to someone’s Delve profile in SharePoint Online.\nThanks to an article from The Baretta, we know how to formulate the link.\nHowever, since I started doing interactive blog posts, I thought I’d create one which automatically generates the URL for you.\nTo create a link to a Delve profile To create a link to someone’s Delve profile:\nTake your tenant name, and add -my.sharepoint.com/PersonImmersive.aspx?accountname=i%3A0%23%2Ef%7Cmembership%7C to the end of it. Append the person’s email address at the end of what you got in step 1. Generate a link now Enter the your tenant name (the part before .sharepoint.com and without https://) and the email address of the person for whom you want to create a profile below, and the URL will automatically be created for you. Click Copy to clipboard to send it to your clipboard.\nDon’t worry, we don’t store any information you enter.\nVariable Value SharePoint Online tenant name User’s email address Your URL:\nhttps://mytenant-my.sharepoint.com/PersonImmersive.aspx?accountname=i%3A0%23%2Ef%7Cmembership%7Csomeuser@mytenant.com\rCopy to clipboard\nConclusion That’s all there is to it. I really just wanted to create another interactive blog post, because they are fun to create!\nThanks to The Baretta for posting this information in the first place.\n","permalink":"http://localhost:1313/posts/create-a-link-to-a-delve-profile/","tags":["Interactive","Delve"],"title":"Create a Link to a Delve Profile"},{"categories":["PnP"],"contents":"Introduction I have to admit, I still consider myself a GitHub newbie.\nMost of my clients use TFS or Azure DevOps and my previous experiences with GitHub were unpleasant.\nBut since I started contributing to the Office 365 Developer Community, I had no choice but to become familiar with GitHub.\nThe majority of the repositories under https://github.com/PnP have contribution guidelines, but they assume that you have a basic understanding of GitHub — or at least, a better understanding of GitHub than I had when I started contributing.\nBecause I still hesitate with GitHub commands once in a while, I use a cheat sheet when I start a new PnP contribution. I copy and paste the GitHub commands from the cheat sheet and substitute placeholders with the values I want. It is really an amalgamation of GitHub commands from the various contributing guideline documents I have found useful into (I hope) a coherent set of instructions. I try to use the GitHub browser interface wherever I can, and GitHub commands where it is easier.\nI have written this post to answer all the questions I had when I started. It is really a note for myself, but I hope it can be useful for someone else who wants to get started. While this article is written specifically for PnP contributions, they also apply to most open source contributions on GitHub.\nI am not a GitHub expert. There may be better ways to do what is described in this post, but these are the instructions that have worked well for me in the past. If you have any suggestions on how to improve the instructions, please submit a comment below. I’ll even buy you a coffee when you’re in town!\nThis article focuses on the GitHub commands. If you need help with your first contribution, David Warner II has kindly volunteered to help anyone with their first PnP contribution. He’s a true main on the topic.\nNote I’m trying something new today: interactive, personalized instructions for you. Yes, you!\nInstead of putting placeholders in the instructions (like [your_repo_name]) that you have to change as you follow the instructions, the placeholders are connected to a form at the top of each section.\nWhen you change the values of the placeholders, the instructions in this post change automatically!\nTo get customized instructions, just replace the placeholder values with your own values.\nDon’t worry, we don’t save any values you entered.\nLet me know if you like this in the comments below. If you do, I may do more interactive posts in the future. It’s kinda fun!\nOverview If you know me, you know that I love processes.\nThe process consists of the following steps:\nFork repository Clone repository Create a branch Contribute Push changes Submit pull request Repeat (go back to Create branch) Step 1: Fork repository Before you can contribute to a repository, you need to Fork it. Forking a repository creates a copy of it from the original owner’s account to your own.\nOnce you have created your own fork, you can freely change the code in your own copy of the repository without worrying about affecting the original repository, or upstream repository. However, GitHub remembers what the upstream repository is, which will make it easy for you to submit your contributions when you’re done but also to synchronize changes that have been made to the upstream repository since you forked it.\nForking only happens within GitHub; it doesn’t affect the code on your machine (that is, until you clone it, but that’ll happen later).\nHow to fork a repository In your browser go to http://github.com and find the repository you want to contribute to. For example, the sp-dev-fx-webparts is where you would submit SharePoint web part samples. In the upper right corner, select the Fork button\nIf you haven’t already logged in to GitHub, you’ll be prompted to do so. If you haven’t already created a GitHub account, you’ll be able to create one. If you have already logged in, it will automatically begin the forking process. You get a cute little animation showing that it is \u0026ldquo;copying\u0026rdquo; the repository, and you end up in your own copy of the repository.\nYou’ll know that you’re in a fork because the owner will have changed to you, and it should say \u0026ldquo;forked from …\u0026rdquo;\nThe repository name should now be [your_github_username]/[repo_name], for example, if you forked pnp/sp-dev-fx-webparts and your username is hugoabernier, your forked repository will be called hugoabernier/sp-dev-fx-webparts.\nCustomize this article Take a second to enter the original repository URL and your GitHub username below, and the rest of this post will automatically change to match what you should see:\nVariable Value Original Repository (Upstream) Your GitHub username You have created your own fork! This is what is called an origin repository. I know, I know, the terms are confusing, but here is a table that may help break down the differences:\nCharacteristics Upstream Origin What is it The original repository Your forked instance of a repository Where is it https://github.com/pnp/sp-dev-fx-webparts https://github.com/[your_github_username]/sp-dev-fx-webparts Who owns it pnp (Not you!) [your_github_username] (You) What changes should you make Create issues, submit a pull request Whatever you want What is the impact of your changes Affects the original repository Affects only your fork Who can see your changes Everyone Everyone who looks at your repository, unless you made it private Once you have forked a repository, clicking on Fork again will do nothing; It simply redirects you to your own fork.\nStep 2: Clone repository Once you created your origin repository, it is time to clone it. Cloning a repository creates a copy of your fork to your local machine, so you can work on it.\nThe cloned repository, which will reside on your local hard-drive, will become your local repository; The repository that is on GitHub will be what’s called your remote repository.\nYou can make any changes to the local files on your hard-drive, it will only affect your local repository. It won’t affect your remote repository (until later, when we push the changes).\nTo clone your repository From your computer, launch whatever tool you like to run Git commands. Some people like Git Bash, but I prefer Cmder or the Node.js command prompt.\nMake sure that your command prompt is in the directory where you’ll want to create your local repositories. I like to use c:\\github. You can do so by typing:\ncd \\github or, if using Git Bash:\ncd /c/github The repository you will clone will be created a directory within your current directory. To clone the repository, just type git clone followed by the URL of the repository you forked in the previous section. Note that the URL should end with .git:\ngit clone https://github.com/[your_github_username]/sp-dev-fx-webparts.git\rIt should create a directory with the same name as your repo, then should download all the files locally to that directory. It doesn’t take very long, but it really depends on your internet connection. This is what it should look like:\nOnce your local repo is created, change to the directory that was just created by typing cd followed by the repo name and [Enter]:\ncd sp-dev-fx-webparts\rTo link your local repo with the original upstream repo, you’ll type git remote add upstream followed by the original upstream repo URL, as follows:\ngit remote add upstream https://github.com/pnp/sp-dev-fx-webparts.git\rLinking to the upstream repo will make your life easier later when you want to make more contributions.\nBefore you start making changes, you should make sure that you have the latest version from the original upstream repository. Of course, since you just forked the repo, you should already up to date, but if make more contributions later, you’ll want to make sure you’re always making your new contributions against the latest code. To do so, simply type the following:\ngit fetch upstream Now you’ll have a local repository with a remote that is connected to the upstream repo that we can create a branch from.\nStep 3: Create a branch In GitHub, repositories usually have multiple branches. In GitHub, a branch is a way to keep track of change by grouping them into a feature set. The main branch is usually the default branch, where all approved code usually ends up. You normally shouldn’t make changes to the main branch directly, that’s what pull requests are for.\nWhen you want to make changes in a repo, you should create your own branch to help keep track of the changes you’re making. For example, if you want to add a new feature to a repo, you would create a branch called my-feature. Meanwhile, someone else may create their own branch called my-cooler-feature, which may later become the basis for someone else’s most-coolest-feature branch.\nEventually, when those branches are submitted via a pull request (assuming they get approved), they’ll end up being merged back to the main branch.\nMost PnP repositories usually have a main branch, which is meant to be your starting point for your changes.\nTake a moment to look in your repo for any contribution guidelines to make make sure that the starting branch is the main branch.\nTo help you, David Warner II and I have compiled a list of popular PnP repositories that will tell you which branch you should use.\nOnce you have confirmed what branch you should start from, you should create own branch from the starting branch, and give it a name that will describe what you’ll be doing in that branch. For example my-feature, or hugo-patch-1. Try to avoid spaces and funny characters.\nEnter your own variables Enter the name of the branch you want to create, and we’ll update the instructions for you:\nVariable Value Start branch name (default is main) Branch name To create your branch To create your branch, follow these steps:\nTo create a branch, we’ll start by calling git pull upstream, which will update your local repository with the latest changes from the upstream repository. We’ll also specify which branch to start from, and what to call the new branch by typing the following:\ngit pull upstream main:my-feature\rNow we’ll let your forked origin repo know about the new branch you’ve created by typing git push origin followed by your new branch name, as follows:\ngit push origin my-feature\rFinally, we’ll switch to the new branch you’ve created by calling git checkout, followed by your new branch name. Type the following:\ngit checkout my-feature\rIf you’re using Cmder, you should see that your prompt has changed to indicate that you’re now in your new branch:\nNote: If you need instructions to configure Cmder to display your repo and branch, read my earlier post\nNow you’re reading to contribute!\nStep 4: Contribute Now that you have your own branch, you can make the changes you need. Please make sure you follow the Microsoft Open Source code of conduct.\nIf you aren’t sure about the code of conduct, you can also check out the Code of Conduct FAQ.\nOnce you’re done making your changes, you’ll want to push your contributions.\nStep 5: Push your changes As you make changes to files in your local branch, your changes will be tracked locally. Changing the files in your local folder does not affect the local repository until you commit your changes.\nOnce you have committed your changes to the local repository, you can push your changes to your remote repository (the one on GitHub.com).\nYou can do so by following these steps:\nFrom the local branch folder, type:\ngit add . Commit your changes by typing git commit -v -a -m followed by a comment indicating what your changes were. For example, if you wanted to say \u0026ldquo;Initial commit\u0026rdquo;, you would type the following:\ngit commit -v -a -m \u0026#34;Initial commit\u0026#34; Now your changes are committed with a comment. Time to submit a pull request!\nStep 6: Submit a pull request In GitHub, a pull request is really simply a request for someone else to review the work that you’ve done and merge your changes in. When you create a pull request, you need to select two branches on GitHub, the branch that you’ve made your changes on, and the branch where you would want to merge your changes into.\nTo do so, follow these steps:\nPush your changes to your origin repository (the forked repository you created), you’ll want to type git push origin followed by your branch name, as follows:\ngit push origin my-feature\rOnce done, use your browser to your forked repository (https://github.com/[your_github_username]/sp-dev-fx-webparts), you should see that your changes have already been reflected to GitHub.\nFrom your forked repository, click on Pull requests in the navigation, then click on New pull request. Optionally, you can visit https://github.com/hugoabernier/sp-dev-fx-webparts/pull/new/my-feature.\nYou’ll be prompted to confirm the branches you want to merge, with an arrow going from one branch tco another. Make sure that the arrow is pointing from your branch on your forked repo to the branch on the remote repo. If you follow all the steps above, you should also see Able to merge.\nProvide a descriptive title for your pull request. For example, New coolest feature\nMost PnP repositories have a pull request template. Please be courteous and follow the instructions in the template. Follow the prompts and answer as much as possible. If there are sections that say \u0026gt; _(DELETE THIS PARAGRAPH AFTER READING)_, delete them.\nWhen you have filled the template, click Create pull request.\nAfter you’ve completed your pull request, you’ll see that its status is marked as Open\nAll you have to do now is to wait for your pull request to be merged with the main branch.\nIt can take a few days, sometimes weeks before your pull request is approved. Please be patient; Most reviewers are volunteers and have a day-to-day job.\nWhile you’re waiting, you can start a new contribution!\nStep 7: Repeat If you want to continue making contributions, you simply create a new branch from the original base branch. For example, if you were created the second update to your my-feature, you could call your next branch my-new-feature.\nEnter your own variable Enter the name of the next branch you want to create, and we’ll update the instructions for you:\nVariable Value Next branch name To create your next branch, follow these steps:\nCalling git pull upstream with your next branch name by typing the following:\ngit pull upstream main:my-new-feature\rPush your new branch by typing git push origin followed by your next branch name, as follows:\ngit push origin my-new-feature\rFinally, switch to your new branch by calling git checkout, followed by your next branch name. Type the following:\ngit checkout my-new-feature\rOnce your next branch is created, continue contributing as you did before (contribute, push your changes, submit a pull request).\nDeleting your branch Once your pull request has been approved and merged to the main, you can delete your branch. Do not delete your branch before it has been approved — just in case you need to make a change to your pull request before it has been approved.\nTrust me on this one.\nConclusion I know, this was a long post. However, I hope that it will be useful for someone who wants to get started with making contributions to the PnP community.\nFor more information There are many other resources available out there. Here are some that you should definitely check out:\nNo code contributions: See how you can provide “No Code” contributions to the Microsoft 365 PnP (Patterns and Practices) Community using just your browser — with video!. Community Demo – Getting started on using GitHub to contribute to SharePoint dev community: Andrew Connell walks you through how to get started. Maybe you didn’t need to read this entire post after all? Keep Your Forked Git Repo Updated with Changes from The Original Upstream Repo: Andrew Connell explains what happens when the upstream repo has changes that occur between the time when you first forked it and when you submitted the pull request, and how to avoid such issues. Updates April 26, 2021: Updated information to use PnP instead of SharePoint GitHub organization August 23, 2019: Added For more information section, because there are many great references out there that people should know about. Also, added link to the latest list of popular PnP repositories Photo credits Branch image by GitHub.\nNote image by Pexels from Pixabay\n","permalink":"http://localhost:1313/posts/my-github-cheat-sheet-for-pnp-contributions-an-interactive-cheat-sheet/","tags":["Sharing is caring","Interactive","GitHub"],"title":"Interactive Post: My GitHub cheat sheet for PnP contributions"},{"categories":["PnP"],"contents":"Introduction Do you find a spelling mistake in the SharePoint Documentation but you don’t know how to fix it?\nDo you have a cool SPFx web part or extension sample that you think other SharePoint developers would appreciate?\nDo you want to add to the PnP reusable controls, PnP property controls, or write your own command for the PnP Powershell or CLI for Microsoft 365?\nBut you never got around to it because you just didn’t know where to start?\nAt the 2019 SharePoint Conference, the always entertaining Vesa Juvonen presented a session about how to start contributing to the PnP community. (I can’t find the actual session title or a video of it, but if anyone has a link to it, please let me know).\nThe whole point of the session was very clear: the SharePoint Development community (or PnP) is open for everyone to contribute.\nHowever, it can be very overwhelming to get started.\nLuckily, the community is here to help!\nTogether, as a community, we can achieve much more than alone.\nIt is scary for everyone I’m sure if you asked any of the existing PnP contributors, they’ll tell you the same thing: the first contribution is always scary.\nWhy is it scary? Gene Zelazny who taught me everything about public speaking says that being nervous about speaking in public is a good thing: it means that you respect for the audience.\nI think that being scared of making your first contribution to the PnP community is a good thing; it means that you respect the members of the community and you don’t want to introduce something that will break a solution, introduce bugs, or lower the quality bar.\nThat’s a good thing!\nIt doesn’t matter how much (or how little) experience you have with SharePoint. Newbies feel that maybe they have nothing new to add, or that it isn’t their place to contribute, while more senior developers probably experience impostor syndrome.\nIf you’re worried that you’ll make a mistake and make a fool of yourself, don’t be. I’ve written many love letters about the PnP community (here and here), but the fact is: the PnP community is filled with awesome people who will help you. If you make a mistake, they may either fix your mistake for you, or reject your submission, make suggestions to fix it, and kindly encourage you to re-submit.\nDavid Warner II is one of those amazing PnP contributors who goes even further: he’ll help everyone with their first contribution!\nHe recently tweeted this:\nIf you want to contribute \u0026amp; add your name to the contributors’ list, but not sure how I’m offering my time to help! DM me and I will personally walk you thru your 1st contribution in docs! #SharePoint #SPFx #SPC19 #OfficeDev\n— David Warner II via Twitter\nIf you don’t know who David Warner II, he’s a prolific Microsoft Office Development MVP who is deeply focused on developing \u0026amp; branding — two of my favorite topics.\nDuring the day, David is a Managing Consultant at Catapult Systems, but after dark (or whatever spare time he has), he turns into a masked PnP contributor who has contributed to pretty much every PnP repo there is.\nSomewhere in between, he also finds the time to write summaries for every PnP community call, complete with screenshots and links.\nCome on, how could you not trust this guy?!\nI have reached out to David before to seek his advice, and he could not have been more friendly or patient.\nSo, if you’re still afraid to contribute but you want to do so, reach out to him via Twitter.\nPaying it forward The PnP community is so awesome that I feel it is also my responsibility to pay it forward and help.\nI’m not a GitHub expert and I still get confused with pull, pushes, branches, commits and pull requests, so I’m not the right person to help you with making your first contribution to GitHub.\nHowever, I’m pretty comfortable with SPFx web parts and extensions; If you have an idea for an SPFx web part that you’d like to build and you don’t know where to start, reach out to me and I’ll help you start your project and build it — as long as you promise to share it with the rest of the community as your first contribution.\nIf the solution doesn’t work, you can even blame me 🙂\nConclusion The Microsoft 365 PnP community is an awesome community that encourages sharing. It welcomes and celebrates newcomers just like you and me.\nIt can be overwhelming to get started, but the always awesome David Warner II has offered to help anyone get started with a new contribution.\nTogether, as a community, we can achieve much more than alone.\nWelcome to the PnP community. I look forward to your first contribution!\nPhoto Credit Photo credit by Esi Grünhagen from Pixabay\n","permalink":"http://localhost:1313/posts/take-your-first-step-and-contribute-to-m365-dev-pnp/","tags":["Sharing is caring"],"title":"Take your first step and contribute to Microsoft 365 PnP"},{"categories":["SharePoint"],"contents":"Introduction The SharePoint Design is a beautiful web site that provides design guidance on beautiful and fast sites, pages, and web parts with SharePoint in Office 365.\nUnfortunately, the SharePoint Design site does not tell you how to create the beautiful web parts they show you.\nThis series is intended as a companion to the SharePoint Design site, providing you with code samples and detailed how-to information for every design topic. It should help you create web parts that look exactly like the ones on the SharePoint Design site.\nIn our last post we discussed the filmstrip layout.\nIn today’s post, we’ll continue our discussion about the web part layout patterns and discuss the carousel layout.\nWhat is the carousel The carousel is a standard web part layout that presents your web part content, showing items one at a time.\nThe carousel is best suited when you want to showcase the content instead of the metadata about the content. For example, if you want to show a large preview of your documents or a large picture.\nBy default, the carousel will expand your images to fit the whole width of your web part and maintain the aspect ratio of your images, with a minimal amount of metadata below the image (for example, the file name and location). It also shows how many items there are in the carousel and which \u0026ldquo;slide\u0026rdquo; you’re currently viewing.\nAs your cursor approaches the carousel, two buttons appear, providing the users with the options to go to the next and/or the previous slide. The buttons are positioned halfway down the carousel, one button on each side of the image.\nOn touch-enabled devices, such as phones and tablets, users can also swipe left of right to indicate whether they like the image to move to the next/previous slide.\nAfter the user has viewed all images, the carousel restarts with the first images, potentially keeping your users entertained for hours and hours.\nThe problem with carousels If you mention carousels to most designers, they’ll often groan and sigh heavily. That’s because the carousel quickly became a trend that everybody wanted on their web sites without really understanding the impact on their users.\nIf you ask me, there were worse trends out there (like when suddenly everyone decided that you needed to enter your email address and then confirm your email, presumably to fool someone who was trying to enter a fake email address to give your the right email address the second time…? )\nI already discussed the issues with carousels when I covered the filmstrip, but here is a brief summary:\nTheir design and frequent movement make people think that they are an ad, causing banner blindness. Moving elements can hurt accessibility, especially for users with motor skill issues People with cognitive difficulties can have difficulty reading all the text before the carousel moves to the next slide Because they see only one slide at a time, users often miss content The SharePoint carousel: the kinder, gentler carousel Fortunately, the SharePoint carousel is better designed and less evil.\nFor one, it does not automatically scroll. It puts users in control of the navigation.\nIt also supports keyboard navigation and gestures, making it slightly easier for those with accessibility requirements to use the carousel.\nIt is designed to keep the amount of information on each slide simple (instead of overloading users with too much information)\nHow to use a carousel properly Here are some tips for a better carousel design (backed by science!!!!):\nKeep your slides to fewer than 5: It can be frustrating to swipe through too many items in a carousel. Also your users may not be able to keep a mental list of more than 5 items and may not recognize when they’re seeing the same items over and over again. Keeping your items to fewer than 5 the number helps users discovering content, and makes it easy for them to find content again later. Show how many items there are and which slide is currently displayed: It helps users understand that there are more items and helps them feel \u0026ldquo;in control\u0026rdquo;. Try to show items that are related: Because users only get to see one item at a time, stick to items that are related so that users can easily predict what the other items (the ones they can’t see) are. And probably the most important: make each slide a giant button. It’s Fitts’s law!\nFitts’s law In 1954 — long before there were carousels and web sites — Paul Morris Fitts was researching the human motor system. I’ll spare you the boring math, but what he found is this:\nThe greater the distance between your starting point and your target, the harder it is to hit a target The smaller the target is, the harder it is to hit The faster you move from your starting point to your target, the harder it is to hit. Nowadays, Fitts’s law is used in user experience and user interface design. It is the reason why the menu on your Mac computer is located at the top of the screen without a top border (essentially making the menu a button of infinite size), and why Windows 8 tried to use the edges of your screen for the start menu, the share menu, and the context menus.\nFor example, here is how the distance between two buttons affect how easy it is to hit the target:\nAnd here is how size affects how easy it is to hit a target:\nThe reason why the SharePoint Framework web part layouts (the grid, the filmstrip, the carousel and the compact layout) mostly use large rectangular targets is not just because it looks cool, it is also because it makes it easier for users to hit the targets, regardless of where they started from on the page.\nThat’s why you need to make sure that your entire carousel slide is a giant button that will lead to whatever item you’re currently displaying.\nUnfortunately, I still think that the next and previous buttons (and the little dots on the filmstrip layout) are a little too small, but since the layout controls support keyboard, and touch gestures, I’ll stop complaining now.\nFor more information about Fitts’s law, check out this cool interactive visualization\nHow carousel control is implemented As is the case with the filmstrip control, the out-of-the-box carousel layout uses Ken Wheeler’s Slick slider — not just to provide the previous/next functionality, but to control how each slide is resized to fit within the viewable area.\nThe control I created for this sample aims to mimic the exact functionality of the out-of-the-box SharePoint carousel layout. It also uses the Slick slider. (Hey, if it’s good enough for the SharePoint team, it’s good enough for me). It the one I wrote for the React Calendar Feed sample in June 2018.\nHowever, it is worth noting that Piotr Siatka recently submitted a carousel control to the Reusable React controls for SharePoint Framework solutions and I can’t wait for it to become available in an upcoming version of the PnP controls. He actually built it without any third-party libraries and it looks really cool. I encourage you to check out his awesome work.\nPiotr’s carousel control, coming soon to a PnP library near you\nWhen it will become available, Piotr’s control will give you the ability to control most aspects of carousel appearance and behavior.\nMy carousel layout control is designed to make it easy to create a web part with that mimics the carousel layout. It doesn’t give you control over how the arrows look, where they are located, or anything else that deviates from the carousel layout standard.\nFeel free to use whichever control is most suitable for you.\nTo create a carousel layout web part To create your own web part using the carousel layout, follow these steps:\nCopy the folder src/components/carouselLayout from my sample code to your own web part project.\nIn your src\\webparts\\[YourWebPartName]\\components\\[YourWebPartName].tsx, add an import for the CarouselLayout and the CarouselSlide controls.\nimport { CarouselLayout, ICarouselItem } from \u0026#39;../../../components/carouselLayout\u0026#39;; In your web part’s component, retrieve the items you wish to display and store them where you can retrieve them later. For example, it your web part’s state. For this example, I’ll store sample items in the constructor:\nconstructor(props: ICarouselProps) { super(props); this.state = { items: [{ imageSrc: \u0026#34;https://lorempixel.com/744/418/technics/1/\u0026#34;, title: \u0026#34;Adventures in SPFx\u0026#34;, location: \u0026#34;SharePoint\u0026#34;, }, { imageSrc: \u0026#34;https://lorempixel.com/744/418/technics/2\u0026#34;, title: \u0026#34;The Wild, Untold Story of SharePoint!\u0026#34;, location: \u0026#34;SharePoint\u0026#34;, }, { imageSrc: \u0026#34;https://lorempixel.com/744/418/technics/4\u0026#34;, title: \u0026#34;Not Your Grandpa\u0026#39;s SharePoint\u0026#34;, location: \u0026#34;SharePoint\u0026#34;, }, { thumbnail: \u0026#34;https://lorempixel.com/744/418/technics/5/\u0026#34;, title: \u0026#34;Get with the Flow\u0026#34;, location: \u0026#34;Flow\u0026#34;, }] }; } This is pretty much the same thing we’ve done in all web part layouts samples so far, except that this time the items we pass must follow the ISlideItem interface and provide a title, a imageSrc, and a location (that’s all the carousel has room to display).\nIn the onRender method, add a CarouselLayout object and pass it the items you wish to display. You’ll also need to provide a pagingTemplate string, which is template to control how you want to render the \u0026ldquo;1 of 5\u0026rdquo; items label. In your pagingTemplate, use a 0 for the current item placeholder, and 1 for the number of items placeholder.\npublic render(): React.ReactElement\u0026lt;ICarouselProps\u0026gt; { return ( \u0026lt;div className={styles.carousel} \u0026gt; \u0026lt;CarouselLayout pagingTemplate={\u0026#39;{0} of {1}\u0026#39;} ariaLabel={\u0026#39;Use right and left arrow keys to navigate between images in the carousel. Use up and down arrow keys to access the edit and remove buttons for any image.\u0026#39;} items={this.state.items} onSlideClick={(currentSlide) =\u0026gt; { alert(`You clicked on slide ${currentSlide+1}`); }} \u0026gt; \u0026lt;/CarouselLayout\u0026gt; \u0026lt;/div\u0026gt; ); } You should also provide an ariaLabel for accessibility’s sake, and you must pass an event handler to handle when a user clicks on a slide.\nIf all goes well, you’ll render the following carousel:\nConclusion I’m not crazy about the fact that the carousel layout control I used in this sample isn’t as flexible as the previous controls, but that’s because all we can display is an image, a title and a location.\nOn the other hand, it makes it pretty easy to implement your own carousel layout web part.\nThe code for this sample can be found in my WebPartLayouts solution on my repo.\nWe’re almost done with the layouts! Next stop: the compact layout.\nUntil then, let me know if you have any questions, comments, or concerns!\n","permalink":"http://localhost:1313/posts/sharepoint-framework-design-series-layout-patterns-part-iii/","tags":["SPFx"],"title":"SharePoint Framework Design Series: Layout Patterns — Part III"},{"categories":["SharePoint"],"contents":"Introduction When migrating content from a network file share to SharePoint Online (or SharePoint on premises), remember SharePoint’s URL length limitations.\nThis article discusses the current limitation with URL lengths in SharePoint. It discusses how this limitation manifests itself, and how it can impact you during your SharePoint migration.\nA matter of legacy In SharePoint, the limit for a document’s URL is 400 characters long. We’ll discuss this in greater length (see what I did there?) later, but for now, let’s discuss how we get long path names.\nTo begin with, nobody in their right mind ever says \u0026ldquo;I think I’ll name my file SuperInsaneLongFileNameThatIDontEverWantToTypeAgainBecauseItIsTooLong.docx\u0026rdquo;.\nThat’d be just annoying.\nInstead, people get long path names because of the legacy infrastructure dictated by file shares.\nYou see, on a network file share, users don’t get the luxury of using metadata or versioning. As a result, users tend to get creative and create folder structures as a substitute to convey metadata.\nWe’ve used this example before. Imagine that your users store case files on a network file share. They want to group case files by status, so they case folders for each status under the Cases folder:\n\\Cases\r\\Open\r\\Closed\r\\Pending review They also want to group cases by year, so they create a folder for every year in each Cases \u0026gt; Status folder:\n\\Cases\r\\Open\r\\2017\r\\2018\r\\2019\r\\Closed\r\\2017\r\\2018\r\\2019\r\\Pending review\r\\2017\r\\2018\r\\2019 Each case is placed in the folder matching the year it was received, within the folder for the case status.\nNow imagine that, in the process of managing a case, your staff receive electronic evidence, via USB sticks, removable drives, or email attachments — or whatever way. To keep these files together, users start creating folders. Of course, they want to keep track of when they received the files, so they put the files in a folder called John Smith files received Jan 21, 2019\nAlso, because our users want to keep incoming documents (stuff they received during the case management process) from outgoing documents (letters and documents they send out through the case management process), they create separate folders, aptly named Incoming documents and Outgoing documents.\nFor example, let’s pretend we have an open case, numbered CA-12345678, from 2019. The folder structure would look like this:\n\\Cases\r\\Open\r\\2017\r\\2018\r\\2019\r\\CA-12345678\r\\Incoming documents\r\\John Smith files received Jan 21, 2019\r\\Photo evidence 1.png\r\\Letter from complainant.pdf\r\\...\r\\Closed\r\\2017\r\\2018\r\\2019\r\\Pending review\r\\2017\r\\2018\r\\2019 Of course, they also want to keep track of outgoing documents they work on, so they name the files accordingly:\n\\Cases\r\\Open\r\\2017\r\\2018\r\\2019\r\\CA-12345678\r\\Incoming documents\r\\John Smith files received Jan 21, 2019\r\\Photo evidence 1.png\r\\Letter from complainant.pdf\r\\...\r\\Outgoing documents\r\\Case Summary\r\\Case review v1 Feb 21.docx\r\\Case review v2 Feb 25.docx\r\\Case review v3 Feb 27.docx\r\\Case interviews\r\\Interview with John Smith Jan 23, 2019 raw.mp4\r\\Interview with John Smith Jan 23, 2019 transcript v1.docx\r\\Interview with John Smith Jan 23, 2019 transcript final.docx\r\\Interview with John Smith Jan 23, 2019 transcript final final.docx\r\\Closed\r\\2017\r\\2018\r\\2019\r\\Pending review\r\\2017\r\\2018\r\\2019 And so on.\nUsers don’t do this to be annoying. They do this because they need a way to manage their information with the tools they have. Without metadata at their disposal, they use long file and folder names.\nAs long as they keep their file paths shorter than 255 characters, most Windows applications will be able to handle opening and saving files from the file share. This isn’t a limitation of UNC paths, it is a limitation within the apps that try to open and save files (for example, your PDF reader). Depending on the version of Windows you use, and assuming you use applications from this century, you can probably get away with longer file paths.\nTypically, organizations will map file shares to a drive to make it easier for users. So, instead of having a path that starts with:\n\\\\servername\\networksharename They’ll have a single letter pointing to the file share. For example, S:\\. It helps keep the file paths shorter, thus preventing any issues.\nEveryone is happy.\nUntil they try moving the files to SharePoint.\nSharePoint URL Length Limitations Prior to May 2017, the maximum URL length for a file stored in SharePoint was 255 characters.\nSince then, Microsoft kindly increased the maximum path size to 400 characters.\nWhen I say 400 characters, I really mean 400 unicode units. If you use International characters with multibyte values, you actually get less that 400 characters.\n\u0026ldquo;So what? Our file names are less than 400 characters\u0026rdquo;, you may ask.\nYou see, the URL is for the entire URL of the file, including:\nhttps:\\\\yourtenant.sharepoint.com/sites/yoursitename/yourdocumentlibraryname/yourfolderpath/subfolderpath/Filename.extension/?parameters\nFor example, let’s say your tenant is called Contoso, your site called Case Management, and your document library called Shared documents. On your file share, that file path that started with:\nS:\\ …when migrated to SharePoint, will become:\nhttps://contoso.sharepoint.com/sites/case%20management/shared%20documents/ That’s a whopping extra 71 characters added to your file names. Those file paths that didn’t cause any issues on a network file share can suddenly be too long once migrated to SharePoint.\nHow long URLs manifest themselves No issues when uploading documents Here is the problem: you may be able to migrate your documents to SharePoint — even if they have long file names that exceed the maximum path length.\nErrors opening documents online However, when you try to open the file, you get an error. For example, here is what happens when I try to open a document with Word online:\nErrors opening documents using desktop applications What’s worse, if your users are on an older version of Windows, or if they use a Mac, they may experience issues with file paths around the 255 character length!\nAlso, if they try to Sync the files to OneDrive for Business, and they try to open documents using older desktop applications, they may get an error indicating that the \u0026ldquo;file could not be opened\u0026rdquo; or the ever-mysterious \u0026ldquo;an error has occurred\u0026rdquo;.\n\u0026ldquo;Some files work, some files don’t\u0026rdquo; Users may experience an issue when only a few documents (or folders) won’t open, but other files open without problems.\nThis usually happens with file names that have different lengths. Shorter file names open without issues because the full paths are less than 400 characters. Longer file names don’t open because the file names are longer than 400 characters.\nTo regular users, it seems like a random issue.\nBut you and I know better, don’t we?!\nHow to solve the URL length issue You migrated your file share to SharePoint without getting any errors while uploading the documents.\nEverything looks good.\nThen a user tries to open a document with a URL that exceeds the limit. And they get an error. Of course, this always happens with someone very high up in your company, usually minutes before a very important event.\nMove files to a shorter URL The easiest way to solve this problem: use SharePoint’s Move functionality within a document library to move the file to a shorter URL.\nFor example, if the file is 5 folders deep in a document library, try moving the file to the root of that document library.\nIt may shorten the URL with enough precious characters to allow you to open the file.\nThen have the talk (you know, the one about why you should use shorter folder names and file names) with your users.\nErrors with custom code If you use custom code to connect to SharePoint using REST, you may also run into issues when the full URL for the REST call exceeds the limit.\nOne way to solve this problem is to use GetFileById and pass the unique file id instead of trying to use the file name:\nhttps://yourtenant.sharepoint.com/sites/yoursitename/_api/web/GetFileById('fileid')\nHow to test URL length limits When I tested the maximum URL length for this article I manually created super-long file names.\nFortunately, you don’t have to do that. Thanks to Rene Modery, you can use a script to create long file paths. It uses the SharePoint PnP cmdlets to connect to SharePoint and create long paths for you.\nConclusion When planning a SharePoint migration, pay attention to long path names. You may be able to migrate the documents without issues, but your users will run into issues opening documents.\nIf your users work with older desktop applications, older versions of Windows, or Macs, you may want to stick to a maximum URL length of fewer than 255 characters.\nIf your users have the latest version of Windows and Office, you can safely plan for maximum server-relative URL lengths (i.e.: the URL without the https://[yourtenant].sharepoint.com) of 400 characters.\nOf course, after your content is migrated, help your users understand why they shouldn’t use silly long file and folder names anymore and show them how to use metadata.\nI hope this will save you some headaches in the future.\nUpdate Contrary to Microsoft’s own article, it appears the 400 character limit no longer counts the https://[yourtenant].sharepoint.com/ or the parameters (e.g.: ?web=1) in the URL length. The limit of 400 characters applies to the server-relative file path.\nWhen a URL contains special characters, like space, %, #, etc., the characters get URL-encoded. For example, space will be encoded as %20. When verifying if your file URL to shorter than 400 characters, SharePoint uses the un-encoded URL (i.e.: special characters count as 1 character).\nFor more information Increased Path Length for Files in SharePoint Online and OneDrive, Rene Modery New MAXPATH limits in SharePoint and OneDrive, Bill Baer (Microsoft). ","permalink":"http://localhost:1313/posts/sharepoint-migration-mind-the-url-length/","tags":["Migration"],"title":"SharePoint Migration: Mind the URL Length"},{"categories":["SharePoint"],"contents":" Note: There are a lot of screenshots in this post. Here’s why: there is nothing that I dislike more than having to download/install something to find out exactly what’s inside. Yes, there are a lot of screenshots, but you’ll know exactly what to expect if you decide to download my PowerPoint template.\nIntroduction As the self-proclaimed World’s Laziest Developer, I always look for shortcuts and ways to avoid doing work.\nWhen I start a SharePoint project where I have to design an Information Architecture, I like to use low fidelity wireframes instead of spending countless hours creating SharePoint sites.\nI’m not a designer or a user experience specialist, but I’ll take the time to do paper napkin drawings, whiteboard drawings, and any other available tools to help work through how my sites are going to be structured and laid out.\nI’ll even use tools like Balsamiq, UXPin, Adobe XD, and Visio, but I like to spend as little time as possible building my low-fidelity wireframes. Also, I find that few people have experience with those tools (even though they are awesome).\nI do it because it is faster convey to my stakeholders what I’m planning on doing and getting feedback with a minimum effort. And I’m all about minimum efforts.\nSince PowerPoint now has sketchy shapes, I decided to create a PowerPoint template that contains a sketchy design for SharePoint pages and a few of the commonly used web parts.\nMy template is not intended to replace the SharePoint Toolkit, but it requires Adobe XD and most client workstations I use do not have Adobe XD. If you can use Adobe XD and the SharePoint Toolkit, do so. If you can’t feel free to use my PowerPoint template.\nIf you want to use it, you can download it and use it as you wish.\nNote: This template will only work in the desktop version of PowerPoint. And it may require the Office Insider version of PowerPoint.\nA few rules, though:\nIf you add more page designs and web parts that you think other people would enjoy, share it with me and I’ll add it to the template Don’t go selling this template Share it with others (#SharingIsCaring) The components Here are the elements you can use for now:\nThe Communication Site master There is also a read-only version of the communication site if you want to show what the experience looks like for visitors:\nGuided layouts If you choose a slide master, you can pick a layout to help you place your web parts on the page.\n1 column guide\n2 column guide\n3 column guide\nSimply place your web parts so that they fit within the gray area. Once you’re done moving the web parts, select the No guide version, which hides all the guides.\nHero web part (I had a lot of fun drawing the placeholder pictures. Very therapeutic.)\nNews web part Events web part Documents web part People web part Generic grid layout web part If you want to write your web part with the grid layout and would like to mock them up in your wireframes, you can use the Generic Grid Layout Web Part. It comes in 1/3 column, 2/3 columns, and full-width variations.\nGeneric Grid Layout Web Part — Full width\nGeneric Grid Layout Web Part — 2/3 columns\nGeneric Grid Layout Web Part — 1/3 column\nGeneric filmstrip layout web part If you want to write your web part with the filmstrip layout and would like to mock them up in your wireframes, you can use the Generic Filmstrip Layout Web Part. It comes in 1/3 column, 2/3 columns, and full-width variations.\nGeneric Filmstrip Layout Web Part — Full width\nGeneric Filmstrip Layout Web Part — 2/3 columns\nGeneric Filmstrip Layout Web Part — 1/3 column\nGeneric carousel layout web part If you want to design a custom web part that uses the carousel layout, use this template. Like the other generic web parts, it comes in 3 flavors: Full-Width, 2/3 columns and 1/3 column.\nGeneric Carousel Web Part — Full Width\nGeneric Carousel Web Part — 2/3 columns\nGeneric Carousel Web Part — 1/3 column\nGeneric list layout web part I couldn’t do the other generic layouts and omit the list layout! This one is also available in Full Width, 2/3 columns and 1/3 column.\nGeneric List Web Part — Full Width\nGeneric List Web Part — 2/3 columns\nGeneric List Web Part — 1/3 column\nColor palettes Although many believe that low-fidelity wireframes should use grayscale and contrast instead of colors, sometimes I like to include colors. It really depends on my mood (and the audience).\nWhether you’re in the \u0026ldquo;no-colors\u0026rdquo; camp or in the \u0026ldquo;with colors\u0026rdquo; camp, every slide includes the SharePoint color palettes on the right of the page — outside of the viewable area.\nWhen you’re editing your pages, you can pick the Eyedropper tool to pick the colors you need from the palette.\nDon’t worry: because they are outside of the viewable area, the color palettes won’t show up while you’re presenting or when you print.\nIf you need to find out more about what each color is, there is a section at the end of the PowerPoint template that explains the SharePoint colors.\nOther stuff There is also some token lorem ipsum placeholder text in case you need it, but I try to avoid it.\nAlso, there are sticky notes to help annotate your wireframes.\nWhat else would you like to see? Let me know in the comments.\nUsing the template Here are simple tips to use the template:\nThe template uses an 11\u0026quot;x17\u0026quot; page template. It may seem big, but it prevents you from having to deal with 4pt fonts. Don’t worry, it presents well on a screen, and prints great posters for your team project room walls.\nIt uses the new sketchy line styles. It may not work in the web version of PowerPoint or if you don’t have the Office Insider edition of PowerPoint. Let me know if you need a non-sketchy version and I’ll try to oblige. If you get an error opening it in the web browser, try opening it on your desktop\nIf you get this message, it is most likely because I used sketchy lines\nTo emphasize on the \u0026ldquo;work in progress\u0026rdquo; look, I used the Segoe Print font because I found that it was available on most workstations that I use. If you don’t have this font, feel free to use any font you like. Ink Draft and Segoe Marker work well too. Just resist the urge to use Comic sans !\nFor now, every slide uses the communication site layout (and the read-only variation). I’ll add the team site layout if I get requests to do so\nThe title of the slide is the site title\nEvery site element is grouped to make it easier to move them around. Feel free to un-group them and edit them as you need\nI used some theme colors, but feel free to make the designs monochromatic if you want\nIf you need to edit the navigation, feel free to copy the navigation elements (called Site Navigation ) from the master slide and paste the customized navigation on your slide. It already has a white background to hide the navigation from the master slide\nTo edit site navigation To edit the site navigation, follow these steps:\nFrom your PowerPoint slide, go to View then select Slide Master in the Master Views group\nPowerPoint should automatically take you to the master slide called Communication site. Select the site navigation by clicking on the site icon and click Copy.\nFrom the Slide Master menu, select Close Master View to go back to your slide\nPaste the navigation on top of the existing navigation. The white background behind the site navigation you just copied should hide the existing one from the master slide. Edit the navigation and site icon as you wish To create your own wireframe Although I have a sample wireframe in my template, you can create your own using these simple steps:\nIn PowerPoint, insert a new slide in your presentation by going to New Slide and select the layout you want\nYou can pick from the Communication Site — Edit Mode to show what an author would see, or Communication Site — Read-only Mode to show what a visitor would see. Try to start with one of the guides. You can choose from 1 column guide, 2 column guide or 3 column guide. From the Web Part Templates section, find the web parts you want from the other slides in the PowerPoint template, copy them and paste them onto your new slide. Make sure to place the web parts within the gray areas on the guides. Edit the web part elements (like web part title and content). It may help to ungroup them first. Once you’re done placing your web parts, go to Layout and pick the No guide version of whatever master you chose. It will remove the background guides, but will not affect where you placed your web parts.\nTips when preparing low fidelity wireframes As Page Laubheimer from the Nielsen Norman Group puts it:\nSharing low fidelity user-interface prototypes with stakeholders is a great way to transfer knowledge and get buy-in early.\nTell your audience that this is work in progress. It may be obvious to you, but I have had clients get upset that their site was going to look \u0026ldquo;all wobbly\u0026rdquo; (and others who asked if the site was going to only be \u0026ldquo;in French\u0026rdquo; because I used lorem ipsum). Explain that you used this style of wireframe to help focus on the content and structure, not the look.\nExplain to your audience that this is a great opportunity to share knowledge: for them to transfer their knowledge to you by getting their feedback early.\nDon’t worry about the look and feel, worry about the content/structure and function. Resist the urge to put lorem ipsum and try to put some text that is as real as you can make it for now.\nAnother way to use these wireframes is to print them and get your audience to mark them with their notes. You’d be amazed by what information you can get from watching people circle, underline, and annotate paper wireframes.\nConclusion My PowerPoint template is available for you to use.\nI’ll continue adding web parts and designs. If you need anything else added to it, let me know in the comments.\nMaybe I’ll create a higher-fidelity version of these if people like them. I’d also love to create a version that you can print out and cut so that you can layout page designs on paper.\nLet me know what you think?\nUpdates August 5, 2019: Thank you Vesa Juvonen for pointing out the broken link. Moved files to GitHub repo to make it easier for those of you who wish to contribute. August 3, 2019: Added more web parts (List, carousel, filmstrip) and explanation why I have so many damned screenshots. Also added introduction how to use the guides and section explaining color palettes. August 2, 2019: Added more web parts (generic grid 1/3, 2/3, and full width) and guide layouts ","permalink":"http://localhost:1313/posts/sharepoint-wireframes-in-powerpoint/","tags":["PowerPoint"],"title":"Would you like to create low-fidelity SharePoint wireframes in PowerPoint?"},{"categories":["SharePoint"],"contents":"Introduction The SharePoint Design is a beautiful web site that provides design guidance on beautiful and fast sites, pages, and web parts with SharePoint in Office 365.\nUnfortunately, the SharePoint Design site does not tell you how to create the beautiful web parts they show you.\nThis series is intended as a companion to the SharePoint Design site, providing you with code samples and detailed how-to information for every design topic. It should help you create web parts that look exactly like the ones on the SharePoint Design site.\nIn our last post we discussed layout patterns and showed how to create a Grid Layout web part.\nIn today’s post, we’ll continue our discussion about the web part layout patterns.\nThe Filmstrip layout Like the grid layout, the filmstrip displays cards to display content. You can use any other rectangular content though. For example, you can use images of kittens, or event cards (as I did with my Calendar Feed web part).\nCalendar feed web part switches between filmstrip and compact mode\nHowever, unlike the grid layout, the filmstrip displays items on a single row. As the screen resizes, the filmstrip layout resizes the items to keep the same number of items displayed at once. If there are more items than can be shown at once, the filmstrip will change to a carousel and break items into \u0026ldquo;pages\u0026rdquo;.\nThe filmstrip layout resizes items as the page resizes\nIf you’re a web designer, the word carousel may make you shudder. In fact, if you search online, you’ll find over fifty-four million search results explaining why carousels are bad.\nBanner blindness You see, most people have issues with the giant photo carousels on web sites. For most users, the giant photos trigger our banner blindness because we automatically assume it is an advertisement, and we ignore it.\nSince the carousel in the filmstrip layout does not show a giant image, but a series of smaller images (usually a preview of documents), this isn’t something we have to worry about (although we’ll have to have another conversation when we discuss the Carousel layout).\nMobile issues Another issue is that giant carousels are notoriously bad on mobile devices.\nOne of the issues with carousels on mobile devices is that because of limited screen real-estate, it shows only one item at a time. This forces users to use sequential access: to view items in the order that is dictated by the control, not by the user’s choice.\nResearch shows that — with sequential access — users will stop looking at items after the third or fourth item in a carousel.\nAnother issue with carousels that people have is with discoverability. If someone is in a hurry and they quickly glance at a typical carousel, they may not know that there are more items to see. Most carousels will use a teeny tiny little dot (which are often a bad design choice) to indicate that there are more items.\nFortunately, the mobile version of the filmstrip control uses bigger dots that are as big as the main text with a lot of color contrast to help.\nMobile filmstrip. This isn’t so bad?\nIf you plan on using the filmstrip layout, follow these guidelines:\nLimit your items to less than 5: Otherwise, people may not see the other items. Prioritize your items: Keep in mind that, depending on the screen size, some users may only see one item at a time. Make sure that you place the most important items first. Make sure items are related: Because people may not see all items in your filmstrip, make sure that the items you show on the filmstrip are related so that users can predict/easily guess what items are hidden. In other words, don’t put apples and oranges on the filmstrip. Accessibility For me, the biggest concern about most carousels has to do with accessibility.\nYou see, most evil carousels break a lot of accessibility guidelines:\nThe dots at the bottom are often too small to see and/or click The dots often have a poor color contrast The slides often change automatically, without giving users a chance to read the content or slow it down The left/right arrows often rely on the use of a mouse, with no keyboard alternatives Left/right arrows often have poor color contrasts Carousels often do not provide alternative text Luckily for us, the SharePoint filmstrip (and the carousel layout) doesn’t have many of the typical carousel accessibility issues:\nThe slides do not change automatically Users can navigate through the slides using the ← and → keys on their keyboard and use TAB to cycle through the slides. The left/right navigation arrows use a high contrast so that users with color blindness and/or various forms of visual impairment can see them\nThe left/right navigation arrows aren’t too small (but they could be bigger) The filmstrip provides alternative text for the entire filmstrip (e.g.: \u0026ldquo;Highlighted content web part, showing Most recent Documents., Use right and left arrow keys to navigate between cards in the film strip.\u0026rdquo;), as well as alternative text for every item in the filmstrip. The bullets at the bottom of the filmstrip are still pretty small, but they have high contrast (21:1 on the theme I tested) exceeding the minimum required contrast (4.5:1) It still isn’t perfect, but it isn’t as bad as most carousel controls out there.\nHow the filmstrip layout is implemented Behind the scenes, the out-of-the-box SharePoint filmstrip and carousel layouts use Ken Wheeler’s awesome Slick carousel.\nThe slick carousel as a filmstrip\nThey simply made it more \u0026ldquo;Fabric UI\u0026rdquo; and fixed some accessibility issues.\nUnlike the grid layout, which calculates the optimal card size as you resize the page, the filmstrip layout uses breakpoints to use pre-determined settings depending on the dimensions of the filmstrip control.\nHow to use the filmstrip layout Unfortunately — as was the case with the grid layout — there aren’t any ready-to-use controls to create a filmstrip layout web part.\nI had to create my own filmstrip layout when I created the Calendar Feed web part for the SharePoint/sp-dev-fx-webparts repo.\nCustom filmstrip control in the calendar web part\nAnd since I’m the world’s laziest developer and I hate to write things more than once, I had created the filmstrip component as a re-usable component. (Ok, I had called it CarouselContainer back then, but it was really a filmstrip layout control).\nFor the rest of this post, we’ll use my filmstrip layout control. If you don’t like the one I created, feel free to use your own.\nAs we did for the grid layout, I’ll show you how to insert a copy of my control into your own web parts — that way, you can customize it to suit your own needs.\n(Don’t worry, I’ll show you how to move the controls into a component library in a later post, so you won’t have to always copy and paste my code into your solutions)\nTo create your own filmstrip layout web part, follow these steps:\nCreate a web part solution with the Yeoman generator. For this sample, I’ll call my web part filmstrip\nCopy the src\\components\\filmstripLayout folder from my project to yours\nIn your project’s terminal, install the slick-carousel and react-slick dependencies by using the following command:\nnpm i slick-carousel react-slick In your web part’s component, located at src\\webparts\\[YourWebPartName]\\components\\[YourWebPartName].tsx, add an import for the filmstripLayout control:\nimport { FilmstripLayout } from \u0026#39;../../../components/filmstripLayout\u0026#39;; In your code, load the items you wish to display. You can load an array of any items you wish, but for my sample, I used items with thumbnail, title, name, profileImageSrc, location, and activity props because I want to use the DocumentCard control to render my list items. For my sample, I initialized the state with a static list of items in my component’s constructor:\nconstructor(props: IFilmstripProps) { super(props); this.state = { items: [{ thumbnail: \u0026#34;https://lorempixel.com/400/200/technics/1/\u0026#34;, title: \u0026#34;Adventures in SPFx\u0026#34;, name: \u0026#34;Perry Losselyong\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/blanditiisadlabore.png?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;SharePoint\u0026#34;, activity: \u0026#34;3/13/2019\u0026#34; }, { thumbnail: \u0026#34;https://lorempixel.com/400/200/technics/2\u0026#34;, title: \u0026#34;The Wild, Untold Story of SharePoint!\u0026#34;, name: \u0026#34;Ebonee Gallyhaock\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/delectusetcorporis.bmp?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;SharePoint\u0026#34;, activity: \u0026#34;6/29/2019\u0026#34; }, { thumbnail: \u0026#34;https://lorempixel.com/400/200/technics/3\u0026#34;, title: \u0026#34;Low Code Solutions: PowerApps\u0026#34;, name: \u0026#34;Seward Keith\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/asperioresautquasi.jpg?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;PowerApps\u0026#34;, activity: \u0026#34;12/31/2018\u0026#34; }, { thumbnail: \u0026#34;https://lorempixel.com/400/200/technics/4\u0026#34;, title: \u0026#34;Not Your Grandpa\u0026#39;s SharePoint\u0026#34;, name: \u0026#34;Sharona Selkirk\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/velnammolestiae.png?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;SharePoint\u0026#34;, activity: \u0026#34;11/20/2018\u0026#34; }, { thumbnail: \u0026#34;https://lorempixel.com/400/200/technics/5/\u0026#34;, title: \u0026#34;Get with the Flow\u0026#34;, name: \u0026#34;Boyce Batstone\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/nulladistinctiomollitia.jpg?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;Flow\u0026#34;, activity: \u0026#34;5/26/2019\u0026#34; }] }; } In your render method, add a filmstripLayout component. You should set the ariaLabel prop, but it is optional.\npublic render(): React.ReactElement\u0026lt;IFilmstripProps\u0026gt; { return ( \u0026lt;div className={styles.filmstrip}\u0026gt; \u0026lt;FilmstripLayout ariaLabel={\u0026#34;Sample filmstrip layout web part, showing sample items., Use right and left arrow keys to navigate between cards in the film strip.\u0026#34;} \u0026gt; \u0026lt;/FilmstripLayout\u0026gt; \u0026lt;/div\u0026gt; ); } To render elements within your filmstrip layout, you simply add rectangular elements as children of the FilmstripLayout component. In my sample, I’ll use a DocumentCard to render each item. To do so, you’ll need to add the following imports:\n// Used to render document cards import { DocumentCard, DocumentCardActivity, DocumentCardPreview, DocumentCardDetails, DocumentCardTitle, IDocumentCardPreviewProps, DocumentCardLocation, DocumentCardType } from \u0026#39;office-ui-fabric-react/lib/DocumentCard\u0026#39;; import { ImageFit } from \u0026#39;office-ui-fabric-react/lib/Image\u0026#39;; Then, loop through your items and render a DocumentCard in your render method:\npublic render(): React.ReactElement\u0026lt;IFilmstripProps\u0026gt; { return ( \u0026lt;div className={styles.filmstrip}\u0026gt; \u0026lt;FilmstripLayout ariaLabel={\u0026#34;Sample filmstrip layout web part, showing sample items., Use right and left arrow keys to navigate between cards in the film strip.\u0026#34;} \u0026gt; {this.state.items.map((item: any, _index: number) =\u0026gt; { const previewProps: IDocumentCardPreviewProps = { previewImages: [ { previewImageSrc: item.thumbnail, imageFit: ImageFit.cover, height: 130 } ] }; return \u0026lt;div className={styles.documentTile} data-is-focusable={true} role=\u0026#34;listitem\u0026#34; aria-label={item.title} \u0026gt; \u0026lt;DocumentCard type={DocumentCardType.normal} onClick={(ev: React.SyntheticEvent\u0026lt;HTMLElement\u0026gt;) =\u0026gt; alert(\u0026#34;You clicked on an item\u0026#34;)} \u0026gt; \u0026lt;DocumentCardPreview {...previewProps} /\u0026gt; \u0026lt;DocumentCardLocation location={item.location} /\u0026gt; \u0026lt;DocumentCardDetails\u0026gt; \u0026lt;DocumentCardTitle title={item.title} shouldTruncate={true} /\u0026gt; \u0026lt;DocumentCardActivity activity={item.activity} people={[{ name: item.name, profileImageSrc: item.profileImageSrc }]} /\u0026gt; \u0026lt;/DocumentCardDetails\u0026gt; \u0026lt;/DocumentCard\u0026gt; \u0026lt;/div\u0026gt;; })} \u0026lt;/FilmstripLayout\u0026gt; \u0026lt;/div\u0026gt; ); } If I didn’t forget anything, you should see a web part that looks like this:\nConclusion The filmstrip layout is a great way to show more items than available screen, but keep in mind that there are accessibility/usability issues with it.\nIf you want to build a filmstrip layout web part, you can use my code sample to get started.\nIn our next post, we’ll continue exploring the web part layout design patterns.\nPhoto Credits Many of the web part images came from Microsoft’s Layout patterns page Slick carousel screenshot from https://kenwheeler.github.io/slick/ ","permalink":"http://localhost:1313/posts/sharepoint-framework-design-series-layout-patterns-part-ii/","tags":["SPFx"],"title":"SharePoint Framework Design Series: Layout Patterns — Part II"},{"categories":["SharePoint"],"contents":"Introduction Sometimes, when working on a SPFx project, I just want to define a CSS class in my .scss file but I don’t want the SASS pre-processor to append random strings to my class names.\nFor example, let’s say I wanted to customize the DocumentCard elements within my SPFx web part to add a border. If I write my SCSS like this:\n.myWebPart .ms-DocumentCard { border: 2px solid red; } It won’t work.\nThat’s because when building my solution, the SASS pre-processor will append random strings to my class names. So, my .myWebPart and .ms-DocumentCard CSS classes might become .myWebPart-223 and .ms-DocumentCard-242.\nThe problem is, I don’t want my CSS classes to change from .ms-DocumentCard to .ms-DocumentCard-242 because the .ms-DocumentCard CSS class comes from another component (in this case, Microsoft’s Fabric UI DocumentCard).\nLuckily, there’s a way around it. Every time I need to remember how to do it though, I find myself having to re-open old projects.\nUsing the :global pseudo selector To prevent the SASS pre-processor from appending random strings to my CSS class name, just use the :global pseudo selector.\nFor example:\n:global(.ms-DocumentCard) { border: 2px solid red; } You should be careful, though: global CSS changes apply, well, globally. This means that if you use global(.ms-DocumentCard) in your CSS, every single element with a CSS class of .ms-DocumentCard on the entire page will be affected — not just the ones in your web part.\nIf you want to override styles within your web part, use a CSS selector that is a bit more restrictive; something like this:\n.yourWebPart { :global(.ms-DocumentCard) { border: 2px solid red; } } If you need to define a whole bunch of CSS classes that you don’t want to be renamed, you can define a global block, as follows:\n:global { .ms-DocumentCard { border: 2px solid red; .ms-DocumentCard--compact { .ms-DocumentCardPreview { -ms-flex-negative: 0; flex-shrink: 0; width: 144px; } } .ms-DocumentCardPreview-icon img { width: 32px; height: 32px; } } .ms-DocumentCard:not(.ms-DocumentCard--compact) { ... } } More information When you create a SPFx solution, the Yeoman generator creates a [YourWebPartName].module.scss file automatically for you.\nYou may have asked yourself why the file isn’t just called [YourWebPartName].scss instead of [YourWebPartName].module.scss. Well, as it turns out, the .module part of the file name is what instructs the pre-processor to make every CSS class names unique.\nIf you changed your .scss file to [YourWebPartName].scss, the pre-processor would stop renaming the CSS class names, but you’d risk getting more issues; instead of being scoped to your web part, the CSS classes would be globally applied to the page.\nInstead, it is better to continue using [YourWebPartName].module.scss and use the :global pseudo selector.\nBy the way, if you want to define a local CSS class name within a global block, simply use the :local pseudo selector. It works exactly the opposite of the :global pseudo selector.\nFor example:\n:global { .ms-DocumentCard { border: 2px solid red; :local(.myDocument) { border: 2px solid green; } } } Conclusion SCSS rocks, but sometimes it can be annoying how the CSS class names are automatically renamed to make them unique.\nTo prevent renaming a class name, use :global() or :global { } in your SCSS.\nWhatever you do, resist the urge to make all your CSS classes global.\nI hope it helps?\nPhoto Credit Image by Christoph Meinersmann from Pixabay\n","permalink":"http://localhost:1313/posts/prevent-scss-from-changing-your-css-class-names/","tags":["SPFx"],"title":"Prevent SCSS from changing your CSS class names"},{"categories":["SharePoint"],"contents":"Introduction The SharePoint Design is a beautiful web site that provides design guidance on beautiful and fast sites, pages, and web parts with SharePoint in Office 365.\nUnfortunately, the SharePoint Design site does not tell you how to create the beautiful web parts they show you.\nThis series is intended as a companion to the SharePoint Design site, providing you with code samples and detailed how-to information for every design topic. It should help you create web parts that look exactly like the ones on the SharePoint Design site.\nIn today’s post, we’ll begin discussing the web part layout patterns.\nSharePoint web part layouts If you look at the various web parts that are available out-of-the-box on SharePoint, you’ll find that there are many different layouts for web parts.\nIn fact, there are 5 commonly-used layouts:\nGrid Filmstrip List Carousel Compact 5 common web part layouts\nEach layout is best suited for different uses.\nHow to decide which layout to use When planning your web part design, you can pick the best layout by considering the following criteria:\nHow \u0026ldquo;visual\u0026rdquo; is the content: does the content consist of a picture or a document preview (more visual), or is it mostly text (less visual)? How much metadata to display: Do you need to simply provide a title, author, date and maybe a category (like most out-of-the-box web parts do) or do you need to provide more metadata? Number of items to display: Do you want to display only a few items, or do you need to display many items at once. To help the decision process, I use the following matrix which places the standard layouts against a grid of how visual and how much metadata you wish to display. The size of each circle helps to compare how many items you want to display — the bigger the circle, the more items you can show.\nYou should also consider how much space you’ll have on a page and the size of the page.\n\u0026ldquo;But I don’t have control over the content and size of the page!\u0026rdquo;\n…I can already hear some of you say. You’re absolutely right! That’s why you should consider giving your authors a few layout options so that they can pick the layout that is best suited for their page designs.\nLuckily, you don’t have to write multiple versions of the same code to offer multiple layouts; Most of the layouts re-use the same/similar components.\nFor example:\nThe Grid layout and the Filmstrip layout are essentially the same, except that the Grid wraps content over multiple rows, where the Filmstrip keeps items on a single row. The Filmstrip turns into a Carousel when there are more items to show that what can be displayed on a single screen. The Grid turns into a Compact layout when the screen is too small The easiest way to demonstrate this is probably with code!\nGrid layout The grid layout presents content in rectangular areas in rows and columns from left to right and top to bottom. The grid layout will attempt to fit as many columns as possible and resize the grid items, or individual content elements within the grid, to fit the entire width of the grid.\nWhen the grid resizes, it re-flows the grid items by keeping the same number of columns but making each column narrower. When the columns become too narrow, the grid will remove one column and resize the remaining columns to fit within the grid.\nWhen there is only room for 1 column within the grid (e.g.: when viewed on a mobile device or if the web part is located in a one-third column), the grid layout will change to a compact layout.\nThe grid layout re-flows content in rows and columns\nCreating a grid layout web part Unfortunately, there isn’t a readily-usable grid layout component that you can use in your web parts. The Office UI Fabric GitHub repo has a component called TileList which gives you a grid layout, but it is still in the experiments package which contains \u0026ldquo;not production-ready components and should never be used in [production code]\u0026rdquo;. I’m not sure if Microsoft ever plans on moving the TileList component to the main Office UI Fabric component, but if they do, I’ll update this article and code sample accordingly.\nInstead, I created a GridList component that uses the Office UI Fabric List component and made a few modifications to make it look like a grid layout. I used the code from the List of 5000 grid items sample on the UI Fabric web site as the base for my code.\nYou can find the code in the src/components/GridList folder from my repository.\nThe control reacts the same way as the out-of-the-box grid layout. It even handles compact layouts:\nUsing the GridList component in your web part Here’s how to call the GridList component in your web part:\nIf you haven’t done so already, copy the content of the src/components/GridList folder from the sample code to your own project’s src/components/GridList. In your src/webparts/[YourWebPartName]/components/[[YourWebPartName].tsx, retrieve the items you wish to display. To simplify this sample, I used a hard-coded list of items. I am too lazy (and unimaginative) to come up with my own sample data, so I used Mockaroo.com to generate a JSON structure that contains the items I wanted. I saved the items to my component’s state in the constructor, as follows: export default class GridLayout extends React.Component\u0026lt;IGridLayoutProps, IGridLayoutState\u0026gt; { constructor(props: IGridLayoutProps) { super(props); this.state = { items: [{ thumbnail: \u0026#34;https://pixabay.com/get/57e9dd474952a414f1dc8460825668204022dfe05555754d742e7bd6/hot-air-balloons-1984308_640.jpg\u0026#34;, title: \u0026#34;Adventures in SPFx\u0026#34;, name: \u0026#34;Perry Losselyong\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/blanditiisadlabore.png?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;SharePoint\u0026#34;, activity: \u0026#34;3/13/2019\u0026#34; }, { thumbnail: \u0026#34;https://pixabay.com/get/55e8d5474a52ad14f1dc8460825668204022dfe05555754d742d79d0/autumn-3804001_640.jpg\u0026#34;, title: \u0026#34;The Wild, Untold Story of SharePoint!\u0026#34;, name: \u0026#34;Ebonee Gallyhaock\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/delectusetcorporis.bmp?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;SharePoint\u0026#34;, activity: \u0026#34;6/29/2019\u0026#34; }, { thumbnail: \u0026#34;https://pixabay.com/get/57e8dd454c50ac14f1dc8460825668204022dfe05555754d742c72d7/log-cabin-1886620_640.jpg\u0026#34;, title: \u0026#34;Low Code Solutions: PowerApps\u0026#34;, name: \u0026#34;Seward Keith\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/asperioresautquasi.jpg?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;PowerApps\u0026#34;, activity: \u0026#34;12/31/2018\u0026#34; }, { thumbnail: \u0026#34;https://pixabay.com/get/55e3d445495aa514f1dc8460825668204022dfe05555754d742b7dd5/portrait-3316389_640.jpg\u0026#34;, title: \u0026#34;Not Your Grandpa\u0026#39;s SharePoint\u0026#34;, name: \u0026#34;Sharona Selkirk\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/velnammolestiae.png?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;SharePoint\u0026#34;, activity: \u0026#34;11/20/2018\u0026#34; }, { thumbnail: \u0026#34;https://pixabay.com/get/57e6dd474352ae14f1dc8460825668204022dfe05555754d742a7ed1/faucet-1684902_640.jpg\u0026#34;, title: \u0026#34;Get with the Flow\u0026#34;, name: \u0026#34;Boyce Batstone\u0026#34;, profileImageSrc: \u0026#34;https://robohash.org/nulladistinctiomollitia.jpg?size=50x50\u0026amp;set=set1\u0026#34;, location: \u0026#34;Flow\u0026#34;, activity: \u0026#34;5/26/2019\u0026#34; }] }; } Define your component’s props and state interfaces so that you have what you need to retrieve and store the items you wish to display (my props in this sample does not require anything so I left it empty): export interface IGridLayoutProps { // Add your own props here } export interface IGridLayoutState { items: IGridItem[]; } Define an interface to hold the properties for the items you wish to display. For my sample, I used the following interface: export interface IGridItem { thumbnail: string; title: string; name: string; profileImageSrc: string; location: string; activity: string; } In your src/webparts/[YourWebPartName]/components/[[YourWebPartName].tsx, onRender method, insert a GridList element, as follows: public render(): React.ReactElement\u0026lt;IGridLayoutProps\u0026gt; { return ( \u0026lt;div className={styles.gridLayout}\u0026gt; \u0026lt;GridList items={this.state.items} onRenderGridItem={(item: any, finalSize: ISize, isCompact: boolean) =\u0026gt; this.onRenderGridItem(item, finalSize, isCompact)} /\u0026gt; \u0026lt;/div\u0026gt; ); } Make sure to add an import for the GridList at the top of your file: import { GridList } from \u0026#39;../../../components/gridList\u0026#39;; Note that your GridList element uses a method called onRenderGridItem which isn’t defined yet. We’ll do this next.\nUsing the DocumentCard component to render grid items Typically, grids use cards to showcase content, but you can also use any rectangular content you wish to use.\nIn our sample code, we’ll use Fabric UI DocumentCard components to render our content.\nOur DocumentCard elements will contain two sub-elements:\nDocumentCardPreview: which will contain a preview image of the item DocumentCardDetails: which will contain further details The DocumentCardDetails itself contains more elements:\nDocumentCardTitle: The title of the element DocumentCardLocation: The \u0026ldquo;location\u0026rdquo; of the element. Often used to indicate an item’s category or sub-title. DocumentCardActivity: Used to indicate the item’s latest activities, such as date last modified and last modified by The DocumentCardActivity defines the following props:\nactivity: Describes the activity that has taken place, such as \u0026ldquo;Created Feb 23, 2020\u0026rdquo;. people: One or more people who are involved in this activity. Each person consists of the following two props: name: The person’s name you wish to display profileImageSrc: The URL for the person’s profile picture. You can define more properties, but that’s what I used for this sample. If you want to see the full list of properties, look at the IDocumentCardActivityPerson interface, and the IDocumentCardActivityProps interface on the Fabric UI documentation.\nWhen the GridList wants to render a grid item, it will call your onRenderGridItem handler with three parameters:\nitem: The item it wants to render finalSize: Size of the item to render isCompact: Returns true if the grid is rendering in a compact mode. If you return a DocumentCard element within every grid item, you’ll do something like this:\nprivate onRenderGridItem = (item: any, finalSize: ISize, isCompact: boolean): JSX.Element =\u0026gt; { const previewProps: IDocumentCardPreviewProps = { previewImages: [ { previewImageSrc: item.thumbnail, imageFit: ImageFit.cover, height: 130 } ] }; return \u0026lt;div className={styles.documentTile} data-is-focusable={true} role=\u0026#34;listitem\u0026#34; aria-label={item.title} \u0026gt; \u0026lt;DocumentCard onClick={(ev: React.SyntheticEvent\u0026lt;HTMLElement\u0026gt;) =\u0026gt; alert(ev)} \u0026gt; \u0026lt;DocumentCardPreview {...previewProps} /\u0026gt; \u0026lt;DocumentCardLocation location={item.location} /\u0026gt; \u0026lt;DocumentCardDetails\u0026gt; \u0026lt;DocumentCardTitle title={item.title} shouldTruncate={true} /\u0026gt; \u0026lt;DocumentCardActivity activity={item.activity} people={[{ name: item.name, profileImageSrc: item.profileImageSrc }]} /\u0026gt; \u0026lt;/DocumentCardDetails\u0026gt; \u0026lt;/DocumentCard\u0026gt; \u0026lt;/div\u0026gt;; } Make sure to add the following imports otherwise, your code will be sad:\n// Used to render document cards import { DocumentCard, DocumentCardActivity, DocumentCardPreview, DocumentCardDetails, DocumentCardTitle, IDocumentCardPreviewProps, DocumentCardLocation, DocumentCardType } from \u0026#39;office-ui-fabric-react/lib/DocumentCard\u0026#39;; import { ImageFit } from \u0026#39;office-ui-fabric-react/lib/Image\u0026#39;; Note that in my code, I simply display an alert when someone clicks on a grid item. In your real code, you’ll want to replace onClick={(ev: React.SyntheticEvent\u0026lt;HTMLElement\u0026gt;) =\u0026gt; alert(ev)} with your own onClick handler.\nNotice that, in our previous code, we don’t really use the isCompact parameter. It is passed to tell us whether we should render the grid using a compact layout or not.\nLuckily, the DocumentCard component has a built-in compact layout that you can use by simply passing type={DocumentCardType.compact} if the DocumentCard should be compact. The default type for the DocumentCard is DocumentCardType.normal.\nTo handle the compact rendering, I’ll simply change the DocumentCard‘s type depending on whether we’re rendering in compact mode or not:\n\u0026lt;DocumentCard type={isCompact ? DocumentCardType.compact : DocumentCardType.normal} onClick={(ev: React.SyntheticEvent\u0026lt;HTMLElement\u0026gt;) =\u0026gt; alert(ev)} \u0026gt; Finally, the out-of-the-box grid layouts tend to remove unnecessary information when rendering in compact mode (otherwise, there would just be too much stuff). The DocumentCardLocation is often omitted in compact mode. To mimic this behavior, I only render the DocumentCardLocation if the layout isn’t compact, using the following code:\n{!isCompact \u0026amp;\u0026amp; \u0026lt;DocumentCardLocation location={item.location} /\u0026gt;} Which makes the final code for your onRenderGridItem as follows:\nprivate onRenderGridItem = (item: any, finalSize: ISize, isCompact: boolean): JSX.Element =\u0026gt; { const previewProps: IDocumentCardPreviewProps = { previewImages: [ { previewImageSrc: item.thumbnail, imageFit: ImageFit.cover, height: 130 } ] }; return \u0026lt;div className={styles.documentTile} data-is-focusable={true} role=\u0026#34;listitem\u0026#34; aria-label={item.title} \u0026gt; \u0026lt;DocumentCard type={isCompact ? DocumentCardType.compact : DocumentCardType.normal} onClick={(ev: React.SyntheticEvent\u0026lt;HTMLElement\u0026gt;) =\u0026gt; alert(ev)} \u0026gt; \u0026lt;DocumentCardPreview {...previewProps} /\u0026gt; {!isCompact \u0026amp;\u0026amp; \u0026lt;DocumentCardLocation location={item.location} /\u0026gt;} \u0026lt;DocumentCardDetails\u0026gt; \u0026lt;DocumentCardTitle title={item.title} shouldTruncate={true} /\u0026gt; \u0026lt;DocumentCardActivity activity={item.activity} people={[{ name: item.name, profileImageSrc: item.profileImageSrc }]} /\u0026gt; \u0026lt;/DocumentCardDetails\u0026gt; \u0026lt;/DocumentCard\u0026gt; \u0026lt;/div\u0026gt;; } If all goes well, you get something like this:\nPutting the finishing touches If you replace the sample data from above with real data, your web part should be barely distinguishable from the out-of-the-box web parts.\nFor example: in the screen shot below, the top web part is the out-of-the-box Highlighted content web part, while the bottom one is my own, using (almost) the exact same code as show in this post.\nThe only differences are:\nMy web part needs a title (that’s easy to fix, just follow the instructions in my previous post) In my onRenderGridItem, I added an iconSrc parameter to my previewProps to point to the document’s icon, as follows: const previewProps: IDocumentCardPreviewProps = { previewImages: [ { previewImageSrc: item.thumbnail, imageFit: ImageFit.cover, height: 130, iconSrc: item.iconSrc } ] }; And, of course, I used an API call to retrieve the latest documents instead of returning hard-coded data.\nConclusion There are many standardized web part layouts you can chose from. We discussed how to use the Grid layout in today’s post. The code for today’s post can be found in my GitHub repo.\nIn our next posts, we’ll continue to discuss the standard web part layouts.\nI hope this helps?\nUpdate July 29, 2019: Thanks everyone for the kind comments. I have submitted my grid layout control to the @pnp/spfx-controls-react library. Hopefully, the will find it as useful as you did! Photo credits Many web part photos came from the SharePoint web part layouts documentation from Microsoft. Hot air ballons image by skeeze from Pixabay Forest image by Johannes Plenio from Pixabay Log Cabin image by David Mark from Pixabay Grandpa image by sarablatter from Pixabay Faucet image by Katja Just from Pixabay ","permalink":"http://localhost:1313/posts/sharepoint-framework-design-series-layout-patterns-i/","tags":["SPFx"],"title":"SharePoint Framework Design Series: Layout Patterns — Part I"},{"categories":["SharePoint"],"contents":"Here is a timeline which highlights the SPFx Yeoman generator’s history since it first became available.\nThis is not official documentation. Any errors are mine and mine alone. If I have made any mistakes, please leave a comment below and I’ll make sure to fix them.\n","permalink":"http://localhost:1313/posts/spfx-timeline/","tags":["SPFx"],"title":"SharePoint Framework Timeline"},{"categories":["SharePoint"],"contents":"Introduction I love the SharePoint Design web site. It is a beautiful web site that provides design guidance on how to create beautiful and fast sites, pages, and web parts with SharePoint in Office 365.\nHowever, the site does not provide you with enough code samples to tell you how to create the beautiful web parts they show you.\nThis series is intended as a companion to the SharePoint Design site. It provides you with code samples and detailed how-to information for every design topic.\nIt should help you create web parts that look exactly like the ones on the SharePoint Design site.\nToday’s post is the third on property panes. In part I, we covered the various types of property panes. In part II we showed how to create non-reactive web parts and how to add a loading indicator.\nToday, we’ll look at out-of-the-box web parts and we’ll discuss how to replicate some of their property panes in your own web parts.\nIf you want to download the code samples used in this article, download the solution from the GitHub repo.\nCreate a choice group with images One of the most frequently asked questions I see with property panes is about the property pane choice groups with images.\nThe out-of-the-box Highlighted content, Hero, Image gallery are examples of how the choice group property field is used.\nHighlighted content web part with a choice group\nHero web part choice group\nYou should use the property pane choice group when you have a small number of choices — I recommend less than 7, no more than 9 choices — where the user may not be immediately able to understand the differences between the choices.\nFor example, the difference between the Brick, Grid and Carousel layout in the Image gallery web part may not be immediately obvious to everyone. Adding images to represent each choice makes it easier to understand:\nImage gallery web part choice group\nAs it turns out, it’s not very complicated to do.\nLet’s reproduce the Image gallery layout setting for our demo. To do so, follow these steps:\nIn your [YourWebPartName]WebPart.ts file, create a property to store the new setting you want. We’ll use layout. To make things easier to read, I’ll just use possible values of Brick, Grid, or Carousel, but feel free to use an integer value, an enum, or any other data type you want:\nexport interface IChoiceGroupWebPartProps { layout: \u0026#39;Brick\u0026#39;|\u0026#39;Grid\u0026#39;|\u0026#39;Carousel\u0026#39;; } At the top of the file, there should already an import statement for the @microsoft/sp-property-pane. To it, add an import for PropertyPaneChoiceGroup, which is the type of field we’ll need to use:\nimport { IPropertyPaneConfiguration, PropertyPaneChoiceGroup } from \u0026#39;@microsoft/sp-property-pane\u0026#39;; You’ll need an image or an icon for every choice you want to show in your choice group. I like to use SVG files with dimensions of 32px by 32px. I also like to store my web part images in a folder called assets in the [YourWebPartName] folder. For this sample, we’ll use brick.svg, grid.svg and carousel.svg. Feel free to store the images wherever you like.\nThe easiest way to include the image in your bundle is to use a require statement with the path to the file. Because I’ll need to use each image twice (for each choice’s imageSrc and selectedImageSrc), we’ll define a variable for each image we’ll need at the top of the getPropertyPaneConfiguration:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { const layoutBrick: string = require(\u0026#39;./assets/brick.svg\u0026#39;); const layoutGrid: string = require(\u0026#39;./assets/grid.svg\u0026#39;); const layoutCarousel: string = require(\u0026#39;./assets/carousel.svg\u0026#39;); ... Add a propertyPaneChoiceGroup if your property pane’s groupFields, making sure to pass the same image for the imageSrc and selectedImageSrc. Of course, you can have a different image for the selected and un-selected images if you’d like, but I don’t usually. You getPropertyPaneConfiguration method will look as follows:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { const layoutBrick: string = require(\u0026#39;./assets/brick.svg\u0026#39;); const layoutGrid: string = require(\u0026#39;./assets/grid.svg\u0026#39;); const layoutCarousel: string = require(\u0026#39;./assets/carousel.svg\u0026#39;); return { pages: [ { header: { description: null }, groups: [ { //groupName: strings.BasicGroupName, groupFields: [ PropertyPaneChoiceGroup(\u0026#39;layout\u0026#39;, { label: \u0026#34;Layout\u0026#34;, // don\u0026#39;t forget to localize your test in a real-world solution options: [ { key: \u0026#39;Brick\u0026#39;, text: \u0026#39;Brick\u0026#39;, selectedImageSrc: layoutBrick, imageSrc: layoutBrick, }, { key: \u0026#39;Grid\u0026#39;, text: \u0026#39;Grid\u0026#39;, selectedImageSrc: layoutGrid, imageSrc: layoutGrid, }, { key: \u0026#39;Carousel\u0026#39;, text: \u0026#39;Carousel\u0026#39;, selectedImageSrc: layoutCarousel, imageSrc: layoutCarousel, } ] }), ] } ] } ] }; } Note that in the above code, I did not localize the text to make the code easier to read. Please consider localizing all your text.\nI recommend that you define a default layout value in your [YourWebPartName]WebPart.manifest.json‘s preconfiguredEntries:\n\u0026#34;properties\u0026#34;: { \u0026#34;layout\u0026#34;: \u0026#34;Brick\u0026#34; } Remember that your changes to the manifest.json file will not take effect until you re-build your web part and re-add it to your workbench.\nIf you run gulp serve on your web part, you should see the following property pane:\nCreate a choice group with Fabric icons If you’re lucky enough to find Office UI Fabric icons that suit your needs, it is even easier to create a choice group with icons.\nTo do so, follow these steps:\nAdd a property to store your new setting. We’ll use shape and we’ll allow Circle, Square, or Triangle:\nexport interface IChoiceGroupWebPartProps { layout: \u0026#39;Brick\u0026#39;|\u0026#39;Grid\u0026#39;|\u0026#39;Carousel\u0026#39;; // ADDED: For icon choice group shape: \u0026#39;Circle\u0026#39;|\u0026#39;Square\u0026#39;|\u0026#39;Triangle\u0026#39;; // END: added } Add a PropertyPaneChoicegroup control in your getPropertyPaneConfiguration method, making sure to pass a iconProps value instead of an imageSrc and selectedImageSrc. The iconProps should contain a single property officeFabricIconFontName, which should be set to the name of the icon you wish to use:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { const layoutBrick: string = require(\u0026#39;./assets/brick.svg\u0026#39;); const layoutGrid: string = require(\u0026#39;./assets/grid.svg\u0026#39;); const layoutCarousel: string = require(\u0026#39;./assets/carousel.svg\u0026#39;); return { pages: [ { header: { description: null }, groups: [ { //groupName: strings.BasicGroupName, groupFields: [ PropertyPaneChoiceGroup(\u0026#39;layout\u0026#39;, { label: \u0026#34;Layout\u0026#34;, // don\u0026#39;t forget to localize your test in a real-world solution options: [ { key: \u0026#39;Brick\u0026#39;, text: \u0026#39;Brick\u0026#39;, selectedImageSrc: layoutBrick, imageSrc: layoutBrick, }, { key: \u0026#39;Grid\u0026#39;, text: \u0026#39;Grid\u0026#39;, selectedImageSrc: layoutGrid, imageSrc: layoutGrid, }, { key: \u0026#39;Carousel\u0026#39;, text: \u0026#39;Carousel\u0026#39;, selectedImageSrc: layoutCarousel, imageSrc: layoutCarousel, } ] }), // ADDED: For icon-based choice group PropertyPaneChoiceGroup(\u0026#39;shape\u0026#39;, { label: \u0026#34;Shape\u0026#34;, // don\u0026#39;t forget to localize your test in a real-world solution options: [ { key: \u0026#39;Circle\u0026#39;, text: \u0026#39;Circle\u0026#39;, iconProps: { officeFabricIconFontName: \u0026#39;CircleShapeSolid\u0026#39; } }, { key: \u0026#39;Square\u0026#39;, text: \u0026#39;Square\u0026#39;, iconProps: { officeFabricIconFontName: \u0026#39;SquareShapeSolid\u0026#39; } }, { key: \u0026#39;Triangle\u0026#39;, text: \u0026#39;Triangle\u0026#39;, iconProps: { officeFabricIconFontName: \u0026#39;TriangleShapeSolid\u0026#39; } } ] }) // END: Added ] } ] } ] }; } As before, I recommend that you define a default shape value in your [YourWebPartName]WebPart.manifest.json‘s preconfiguredEntries:\n\u0026#34;properties\u0026#34;: { \u0026#34;shape\u0026#34;: \u0026#34;Square\u0026#34; } Running gulp serve will give you the following:\nConditional field in property panes Sometimes, you want to show settings that are dependent on each other. If a user selects one choice, you may want to show a dependent setting, but if they select another choice, you may want to hide that setting.\nThe out-of-the-box Yammer web part does this by hiding or showing the Number of conversations to show setting depending on the conversation source the user selects.\nThis is what I’ll call conditional fields for the purpose of this conversation.\nMaking fields conditional can help improve the user experience by removing choices that do not apply, therefore reducing the complexity of choice (remember Hick’s law).\nHowever, there are some guidelines you should follow:\nMake sure that the user easily understands the reason why a field is shown or hidden. For example, the Yammer web part lets you see plainly that the Number of conversations is impacted by the conversation source. Make sure that fields that depend on each other are logically grouped/visible together. For example, do not place one field on a property pane page (or step) and the field that depends on it on another page. If you find it difficult to convey the relationship between two fields, you may wish to enable and disable the dependent field instead of hiding it. For bonus points, you should add some text (or, at least, some form of tooltip) that explains why the field is disabled. If you want some options to be available some times, and not available some other times, consider disabling the option instead of hiding it. If the option will never be available because of a specific condition (e.g.: user doesn’t have sufficient permissions, the wrong source selected, etc.), consider hiding the field instead. To demonstrate this concept, we’ll recreate the Select conversation source, Search for a sourcem and Number of conversations to show fields from the Yammer web part. To do so, follow these step steps:\nIn your [YourWebPartName]WebPart.ts, add properties to store the conversation source, the search criteria, and the number of conversations:\nexport interface IConditionalFieldWebPartProps { conversationSource: \u0026#39;Group\u0026#39;|\u0026#39;User\u0026#39;|\u0026#39;Topic\u0026#39;|\u0026#39;Home\u0026#39;; searchCriteria: string; numberOfConversations: number; } In the getPropertyPaneConfiguration, add the following code to render the property pane fields. Again, code is not localized to make it easier to read, please localize text in a real-world scenario:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: \u0026#34;Select conversation source from groups, topics, users, or home.\u0026#34; }, groups: [ { groupFields: [ PropertyPaneDropdown(\u0026#39;conversationSource\u0026#39;,{ label: \u0026#34;Select conversation source\u0026#34;, selectedKey: this.properties.conversationSource, options: [ { key: \u0026#34;Group\u0026#34;, text: \u0026#34;Group\u0026#34; }, { key: \u0026#34;User\u0026#34;, text: \u0026#34;User\u0026#34; }, { key: \u0026#34;Topic\u0026#34;, text: \u0026#34;Topic\u0026#34; }, { key: \u0026#34;Home\u0026#34;, text: \u0026#34;Home\u0026#34; }, ] }), PropertyPaneTextField(\u0026#39;searchCriteria\u0026#39;, { label: \u0026#34;Search for a source\u0026#34;, placeholder: \u0026#34;Type to search\u0026#34; }), PropertyPaneDropdown(\u0026#39;numberOfConversations\u0026#39;,{ label: \u0026#34;Number of conversations to show\u0026#34;, selectedKey: this.properties.conversationSource, options: [ { key: 4, text: \u0026#34;Small - 4 conversations\u0026#34; }, { key: 8, text: \u0026#34;Medium - 8 conversations\u0026#34; }, { key: 12, text: \u0026#34;Large - 12 conversations\u0026#34; } ] }) ] } ] } ] }; } To Make the Search for a source field hide if the conversation source field is set to Home, add this.properties.conversationSource !== \u0026quot;Home\u0026quot; \u0026amp;\u0026amp; in front of the line that begins with PropertyPaneDropdown('numberOfConversations'. Doing so says \u0026ldquo;Only execute the next line if the conversation source is not equal to Home\u0026rdquo;. The new getPropertyPaneConfiguration method should look like this:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: \u0026#34;Select conversation source from groups, topics, users, or home.\u0026#34; }, groups: [ { groupFields: [ PropertyPaneDropdown(\u0026#39;conversationSource\u0026#39;,{ label: \u0026#34;Select conversation source\u0026#34;, selectedKey: this.properties.conversationSource, options: [ { key: \u0026#34;Group\u0026#34;, text: \u0026#34;Group\u0026#34; }, { key: \u0026#34;User\u0026#34;, text: \u0026#34;User\u0026#34; }, { key: \u0026#34;Topic\u0026#34;, text: \u0026#34;Topic\u0026#34; }, { key: \u0026#34;Home\u0026#34;, text: \u0026#34;Home\u0026#34; }, ] }), // ADDED: conditional rendering for field this.properties.conversationSource !== \u0026#34;Home\u0026#34; \u0026amp;\u0026amp; PropertyPaneTextField(\u0026#39;searchCriteria\u0026#39;, { label: \u0026#34;Search for a source\u0026#34;, placeholder: \u0026#34;Type to search\u0026#34; }), PropertyPaneDropdown(\u0026#39;numberOfConversations\u0026#39;,{ label: \u0026#34;Number of conversations to show\u0026#34;, selectedKey: this.properties.conversationSource, options: [ { key: 4, text: \u0026#34;Small - 4 conversations\u0026#34; }, { key: 8, text: \u0026#34;Medium - 8 conversations\u0026#34; }, { key: 12, text: \u0026#34;Large - 12 conversations\u0026#34; } ] }) ] } ] } ] }; } No necessary for this example, but if you want the mimic the Yammer web part and enable/disable the Number of conversations field on the selection, add a isDisabled attribute to the PropertyPaneDropDown field, as follows:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: \u0026#34;Select conversation source from groups, topics, users, or home.\u0026#34; }, groups: [ { groupFields: [ PropertyPaneDropdown(\u0026#39;conversationSource\u0026#39;,{ label: \u0026#34;Select conversation source\u0026#34;, selectedKey: this.properties.conversationSource, options: [ { key: \u0026#34;Group\u0026#34;, text: \u0026#34;Group\u0026#34; }, { key: \u0026#34;User\u0026#34;, text: \u0026#34;User\u0026#34; }, { key: \u0026#34;Topic\u0026#34;, text: \u0026#34;Topic\u0026#34; }, { key: \u0026#34;Home\u0026#34;, text: \u0026#34;Home\u0026#34; }, ] }), this.properties.conversationSource !== \u0026#34;Home\u0026#34; \u0026amp;\u0026amp; PropertyPaneTextField(\u0026#39;searchCriteria\u0026#39;, { label: \u0026#34;Search for a source\u0026#34;, placeholder: \u0026#34;Type to search\u0026#34; }), PropertyPaneDropdown(\u0026#39;numberOfConversations\u0026#39;,{ //ADDED: To enable/disable field based on selection disabled: this.properties.conversationSource !== \u0026#34;Home\u0026#34;, label: \u0026#34;Number of conversations to show\u0026#34;, selectedKey: this.properties.conversationSource, options: [ { key: 4, text: \u0026#34;Small - 4 conversations\u0026#34; }, { key: 8, text: \u0026#34;Medium - 8 conversations\u0026#34; }, { key: 12, text: \u0026#34;Large - 12 conversations\u0026#34; } ] }) ] } ] } ] }; } Set default property values in your [YourWebPartName]WebPart.manifest.json, under preconfiguredEntries:\n\u0026#34;properties\u0026#34;: { \u0026#34;conversationSource\u0026#34;: \u0026#34;Group\u0026#34;, \u0026#34;searchCriteria\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;numberOfConversations\u0026#34;: 8 } Running a new gulp serve should give you a web part pane that behaves like the Yammer web part:\nThe logic for enabling/disabling and hiding/showing property pane fields in Yammer is more complicated than what we cover in this example, but I hope it’ll do for now.\nIn my opinion, the Yammer Number of conversations should probably tell you why it is disabled. If it is never supposed to be available from any other sources than Home, it should probably be hidden instead of disabled — but that’s my personal preference, not a hard rule.\nNote: Don’t worry, we’ll cover how to create a drop-down box with icons in a later post.\nCreating conditional property pane groups The out-of-the-box Quick chart web part allows users to choose between a Column chart or a Pie chart. If the user selects a Column chart, the property pane will show a Data property group and a Layout property group; If they choose Pie chart, the property pane will hide the Layout property group and only show the Data property group.\nBy hiding or showing only the property pane groups that are relevant to the user’s selected chart type, the Quick chart web part helps the user quickly configure the web part without presenting unnecessary settings.\nImagine if — instead of hiding the Layout property pane group — we disabled the property group entirely. The screen would be needlessly cluttered.\nA while ago, I created a Chartinator web part sample for the SharePoint sp-dev-fx-webparts samples repository, which extends on the Quick chart web part and allows users to configure 9 different types of charts. Depending on which chart type the user selects, multiple property pane groups appear and disappear to help users make sense of the options available to them. If we didn’t hide some sections, the property pane would be much too complicated to use.\nFor this code sample, we’ll emulate the Quick chart property pane and allow users to select one of two types of charts. Depending on the selection, we’ll hide or show the Layout property pane group. The Data property pane group will always be available.\nTo keep this sample simple, we won’t add any property fields in either property pane group — we’ll just put some text to illustrate the concept. If you really want to see how to implement the full Quick chart property pane, check out the Chartinator sample.\nTo mimic the Quick chart web part property pane, follow these steps:\nAs before, add a property to your web part to store the Chart type selection:\nexport interface IConditionalGroupWebPartProps { chartType: \u0026#34;Column\u0026#34; | \u0026#34;Pie\u0026#34;; } Change the getPropertyPaneConfiguration method to create an IPropertyPaneConfiguration variable to store the property pane configuration (instead of simply returning it) so that we can manipulate the content of the property pane configuration.\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { const chartDescription: string = this.properties.chartType === \u0026#34;Column\u0026#34; ? \u0026#34;Use a column chart to show data changes over time or comparisons among items. Categories are typically shown along the horizontal axis and values along the vertical axis.\u0026#34; : \u0026#34;Use a pie chart to show percentages of a whole. Best when used with fewer than seven categories.\u0026#34;; const configuration: IPropertyPaneConfiguration = { pages: [ { header: { description: \u0026#34;Select a chart type and then select a data source. You can enter up to 12 data points, or show up to 50 data points if you use a SharePoint list on this site as the data source.\u0026#34; }, displayGroupsAsAccordion: true, groups: [ { groupName: \u0026#34;Chart type\u0026#34;, groupFields: [ PropertyPaneChoiceGroup(\u0026#39;chartType\u0026#39;, { options: [ { key: \u0026#39;Column\u0026#39;, text: \u0026#39;Column chart\u0026#39;, iconProps: { officeFabricIconFontName: \u0026#39;BarChart4\u0026#39; } }, { key: \u0026#39;Pie\u0026#39;, text: \u0026#39;Pie chart\u0026#39;, iconProps: { officeFabricIconFontName: \u0026#39;PieDouble\u0026#39; } } ] }), PropertyPaneLabel(\u0026#39;chartType\u0026#39;, { text: chartDescription }), ] }, { groupName: \u0026#34;Data\u0026#34;, isCollapsed: false, groupFields: [ PropertyPaneLabel(\u0026#39;data\u0026#39;, { text: \u0026#34;This is some sample text for the data property group.\u0026#34; }), ] } ] } ] }; return configuration; } At the end of the same method, add some conditional logic to insert a new element in the groups array using push:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { const chartDescription: string = this.properties.chartType === \u0026#34;Column\u0026#34; ? \u0026#34;Use a column chart to show data changes over time or comparisons among items. Categories are typically shown along the horizontal axis and values along the vertical axis.\u0026#34; : \u0026#34;Use a pie chart to show percentages of a whole. Best when used with fewer than seven categories.\u0026#34;; const configuration: IPropertyPaneConfiguration = { pages: [ { header: { description: \u0026#34;Select a chart type and then select a data source. You can enter up to 12 data points, or show up to 50 data points if you use a SharePoint list on this site as the data source.\u0026#34; }, displayGroupsAsAccordion: true, groups: [ { groupName: \u0026#34;Chart type\u0026#34;, groupFields: [ PropertyPaneChoiceGroup(\u0026#39;chartType\u0026#39;, { options: [ { key: \u0026#39;Column\u0026#39;, text: \u0026#39;Column chart\u0026#39;, iconProps: { officeFabricIconFontName: \u0026#39;BarChart4\u0026#39; } }, { key: \u0026#39;Pie\u0026#39;, text: \u0026#39;Pie chart\u0026#39;, iconProps: { officeFabricIconFontName: \u0026#39;PieDouble\u0026#39; } } ] }), PropertyPaneLabel(\u0026#39;chartType\u0026#39;, { text: chartDescription }), ] }, { groupName: \u0026#34;Data\u0026#34;, isCollapsed: false, groupFields: [ PropertyPaneLabel(\u0026#39;data\u0026#39;, { text: \u0026#34;This is some sample text for the data property group.\u0026#34; }), ] } ] } ] }; // ADDED: To insert a conditional group // If the selected type is not Column, we don\u0026#39;t need to make any further changes if (this.properties.chartType !== \u0026#34;Column\u0026#34;) { return configuration; } // Get the list of property groups const { groups } = configuration.pages[0]; // Insert a property pane groups.push({ groupName: \u0026#34;Layout\u0026#34;, isCollapsed: false, groupFields: [ PropertyPaneLabel(\u0026#39;layout\u0026#39;, { text: \u0026#34;This is some sample text for the layout property group.\u0026#34; }), ] }); // END: added return configuration; } Make sure to define some default properties in your web part’s manifest.json file:\n\u0026#34;properties\u0026#34;: { \u0026#34;chartType\u0026#34;: \u0026#34;Column\u0026#34; } On your next gulp serve, you’ll have a web part property pane hides/shows conditional property groups just like the Quick chart web part:\nAt the risk of repeating myself: the sample does not localize the text to help keep the code easy to read. It is killing me to do this. Please localize your text in a real solution.\nConclusion In today’s post, we discussed how to create image choice groups, create conditional property pane fields and conditional property pane groups.\nAll the code samples for this post can be found in my sample solution from the GitHub repo.\nEvery time I created a web part for this series so far, I wanted to change the body of the web part to make it look better (instead of using the default styles rendered by the Yeoman generator). It took everything in me not to tinker with the web part body and create something that would be worthy of the SharePoint Design series.\nIn our next post, we’ll focus on the web part body.\nFinally!!!\n","permalink":"http://localhost:1313/posts/sharepoint-framework-design-series-property-panes-part-iii/","tags":["SPFx"],"title":"SharePoint Framework Design Series: Property Panes — Part III"},{"categories":["SharePoint"],"contents":"Introduction The SharePoint Design is a beautiful web site that provides design guidance on beautiful and fast sites, pages, and web parts with SharePoint in Office 365.\nUnfortunately, the SharePoint Design site does not tell you how to create the beautiful web parts they show you.\nThis series is intended as a companion to the SharePoint Design site, providing you with code samples and detailed how-to information for every design topic. It should help you create web parts that look exactly like the ones on the SharePoint Design site.\nToday’s post continues on my previous post. It discusses various aspects of property panes that you may find useful.\nLike the previous post, this is a companion to the Designing SharePoint web part page.\nIf you want to download the code samples used in this article, download the solution from the GitHub repo.\nReactive and non-reactive web parts By default, when you change settings in a property pane, the changes are immediately reflected within the web part on the page; the web part is considered reactive.\nReactive web parts are recommended because it follows the WYSIWYG (what you see if what you get) user experience principles for authoring.\nHowever, sometimes you may not want every change a user makes in the property pane to immediately be reflected in the web part.\nFor example, if your web part has to load data or call an API every when your user changes settings, you may want to make your web part non-reactive.\nWhen you make your web part non-reactive, your property pane will add an Apply button at the bottom of your property pane. Any changes users make in your property pane will not take effect until they select Apply.\nTo make your web part non-reactive, all you need to do define a disableReactivePropertyChanges function in your web part, and return true. To do so, follow these steps:\nIn your [YourWebPartName]WebPart.ts file, find the getPropertyPaneConfiguration function.\nAdd the following code before or after (it’s really up to you):\nprotected get disableReactivePropertyChanges(): boolean { return true; } That’s it!\nWhen you run your web part, the property pane will display the Apply button we discussed.\nShowing a property pane loading indicator You may have noticed that most web part property panes do not show a loading indicator. That’s because we always want web parts to appear fast and responsive.\nThis is what we mean by ‘Loading indicator’\nHowever, sometimes you need to make asynchronous requests to load some data for your property pane, which could take a long time. That’s when you should display a loading indicator to the end-user, so they don’t think your web part has crashed or has become unresponsive.\nHow long before a user thinks the system has crashed? According to the Doherty Threshold law of user experience, you should provide feedback within 400 milliseconds in order to keep your user’s attention and increase their trust in the system.\nIf your async requests take longer than 400 milliseconds, you should display a loading indicator.\nWhen I want to display a loading indicator in the property pane, I follow these steps:\nFirst, you’ll need a variable to store whether you should display the loading indicator or not (otherwise, your loading indicator will always display!). To do so, add a boolean variable to you [YourWebPartName]WebPart class:\nexport default class LoadingIndicatorWebPart extends BaseClientSideWebPart\u0026lt;ILoadingIndicatorWebPartProps\u0026gt; { // ADDED: To store whether we should display the loading indicator or not private showLoadingIndicator: boolean = true; // END: added ... In my code, I always initially set it to true because I usually only load my asynchronous data once — the first time a user displays the property pane.\nAdd an onPropertyPaneConfigurationStart method to your web part class if you don’t already have one. It will get called when preparing the property pane to display. This is where I like to make my asynchronous calls:\n// ADDED: To display the loading indicator when preparing the property pane protected async onPropertyPaneConfigurationStart(): Promise\u0026lt;void\u0026gt; { // Call your service // Remember that this method gets called *every time* before a user // displays the property pane. You should probably verify that your // data isn\u0026#39;t already loaded before calling your async method again this.loadedPlantList = await this.getPlantNames(); } // END: Added Note that in my code, I use an await statement to wait until my async call is complete. If you prefer, you could use this.getPlantNames().then(...), but await calls are quickly becoming the preferred way to handle async calls in React.\nOnce your data is loaded, set your showLoadingIndicator variable to false (line 10):\nprotected async onPropertyPaneConfigurationStart(): Promise\u0026lt;void\u0026gt; { // Call your service // Remember that this method gets called *every time* before a user // displays the property pane. You should probably verify that your // data isn\u0026#39;t already loaded before calling your async method again this.loadedPlantList = await this.getPlantNames(); //ADDED: To stop displaying the loading indicator // When done loading, set the loading indicator to false and refresh this.showLoadingIndicator = false; //END: Added } To make sure that your property pane updates when you turn the loading indicator on or off, make sure to call refresh on the property pane — otherwise it won’t take effect (line 12):\nprotected async onPropertyPaneConfigurationStart(): Promise\u0026lt;void\u0026gt; { // Call your service // Remember that this method gets called *every time* before a user // displays the property pane. You should probably verify that your // data isn\u0026#39;t already loaded before calling your async method again this.loadedPlantList = await this.getPlantNames(); // When done loading, set the loading indicator to false and refresh this.showLoadingIndicator = false; //ADDED: To force the property pane to refresh this.context.propertyPane.refresh(); //END: Addd } Finally, in your getPropertyPaneConfiguration, set the property pane’s showLoadingIndicator prop to the value of your showLoadingIndicator variable (line 4):\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { // ADDED: To display a loading indicator showLoadingIndicator: this.showLoadingIndicator, // END: Added pages: [ { header: { description: strings.PropertyPaneDescription }, groups: [ { groupName: strings.BasicGroupName, groupFields: [ PropertyPaneDropdown(\u0026#39;description\u0026#39;, { label: strings.DescriptionFieldLabel, options: this.loadedPlantList }) ] } ] } ] }; } That’s all you should need to do (in theory). In my code sample, I call a fake service to get a list of plant names and load it in a property pane drop-down box. This is what the final product looks like (note that I exaggerated the delay for demo purposes):\nDelaying the loading indicator As we discussed, we want to avoid showing the loading indicator if we can. We especially want to flash (i.e.: briefly show) a loading indicator every time we load the property pane.\nBut you also want to keep in mind the Doherty Threshold. Delay a response for longer than 400 milliseconds and people will start clicking around.\nLuckily, you can delay the loading indicator and do both!\nLet’s pretend that you make a call to a service which always returns with results within 300 milliseconds — except when everyone at work is watching YouTube, then it can take a lot longer. You may want to avoid showing a loading indicator as long as your async calls take less than 300 milliseconds, but start display an indicator if the calls take longer.\nAll you need to do is add a loadingIndicatorDelayTime value to your property pane configuration. The system will wait for whatever delay time you specified before displaying the loading indicator. If you turn off the loading indicator before the delay has elapsed (i.e.: when your async call returns within normal conditions), the loading indicator will never show. However, if you don’t turn off the indicator before the delay period, the loading indicator will automatically start showing.\nTo do so, change your code as follows:\nIn your web part’s getPropertyPaneConfiguration method, add the loadingIndicatorDelayTime (line 5):\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { showLoadingIndicator: this.showLoadingIndicator, // ADDED: To delay the loading indicator loadingIndicatorDelayTime: 300, // END: Added pages: [ { header: { description: strings.PropertyPaneDescription }, groups: [ { groupName: strings.BasicGroupName, groupFields: [ PropertyPaneDropdown(\u0026#39;description\u0026#39;, { label: strings.DescriptionFieldLabel, options: this.loadedPlantList }) ] } ] } ] }; } Two things to note:\nIf you don’t specify a loadingIndicatorDelayTime value, and your showLoadingIndicator is set to true, SharePoint will wait 500 milliseconds by default. The loadingIndicatorDelayTime also seems to delay displaying the property pane until either the delay has elapsed or your showLoadingIndicator is set to false. Conclusion Today we expanded a little on how to create professional property panes by making them reactive (or not) and by adding a loading indicator when necessary.\nThere is a lot more to cover on property panes, but we’ll covert it in our next post.\nI hope this helps?\n","permalink":"http://localhost:1313/posts/sharepoint-framework-design-series-property-panes-part-ii/","tags":["SPFx"],"title":"SharePoint Framework Design Series: Property Panes — Part II"},{"categories":["Dynamics 365"],"contents":"Introduction In Part I of this series, we discussed why you should adopt an acquisition model that re-uses what you already have, buys what you can’t re-use, and builds what you can’t buy.\nWe briefly discussed that one of the reasons why you shouldn’t just buy something by just looking at the price tag because of the total cost of ownership (TCO), but we didn’t go in details.\nThis article explains why you should consider TCO when looking at buying a new software.\nWhat is TCO? The term TCO was originally coined in the late 1980s by Gartner research to describe the cost of owning and deploying personal computers.\nTheir findings showed that each PC costs an enterprise nearly $10,000 per year.\nOriginally, it caused quite a stir in the technology community and among CFOs who scrutinized their methodology and — eventually — accepted it as a standard way to evaluate total costs.\nSimply put, TCO consists of the costs, direct and indirect, incurred throughout the life-cycle of an asset, including acquisition, deployment, operation, support and retirement.\nSome sources say that the amount on the price tag represents less than 10 percent of the total cost spent on IT assets over its lifetime.\nIn other words, the price tag of software is like the visible part of an iceberg, while the hidden costs are just like the submerged parts.\nTotal cost of ownership and icebergs have a lot in common\nLike other tools, TCO does not solve all problems. For example, TCO does not assess risk or help align technology investments with your strategic goals. Nevertheless, TCO is an important tool for the analysis of IT costs and for the management of those costs in an IT organization.\nCost areas When calculating your software’s total cost of ownership, consider two areas:\nObvious costs Hidden costs Obvious costs Those are the costs that everyone who was involved in planning and vendor selection is familiar with, such as:\nCapital expenses: License fees and/or subscription fees. If buying an on-prem solution, you may also need to purchase new hardware. Operating expenses: Services, support \u0026amp; maintenance fees to keep the equipment running. Consider additional license costs each year (or the price increase at the end of each term is purchasing a subscription) and the number of years until a major upgrade. Hidden costs These are the costs people usually forget about when planning to purchase new software.\nThe hidden costs are less obvious cost that are easy to overlook, but they can be very large.\nLarge enough to matter.\nWhen calculating your TCO, consider the following \u0026ldquo;hidden\u0026rdquo; costs:\nAcquisition costs: the costs of identifying, selecting, ordering, receiving, inventorying, or paying for something. Will you have to go through an RFP process to purchase your software? Consider the cost of preparing the RFP. Installation costs: Year one install \u0026amp; setup costs. Upgrade, enhancement, or initial setup costs: Most software may require some initial set-up, even if you don’t intend to customize them or integrate with other systems. Reconfiguration costs Customization \u0026amp; Integration: Keep in mind that the more you customize your software, the more you will have to maintain and update when major upgrades occur. Data migration: When deploying a new system, it’s often necessary to migrate your data from your existing system. The cost of this migration depends on the amount and format of the data. You may first need to convert the data to another format, consolidate it with other sources, or “scrub” it for duplicate, obsolete, or otherwise bad entries. When moving to the cloud, you also need to consider that some SaaS providers may charge egress costs which are often proportional to the amount of data transferred. Operating costs: for example, human (operator) labor. Change management costs: for example, costs of user orientation, user training, workflow/process change design and implementation. Training users is critical to get the most out of your new software. It may involve sending employees to training centers, bringing trainers on-site, participating in webinars, or creating custom courses and documentation. Keep in mind that you will also need to train new employees as they join your organization. Infrastructure support costs: for example, costs brought by the acquisition for heating/cooling, lighting, or IT support. Environmental impact costs: for example, costs of waste disposal/clean up, or pollution control, or the costs of environmental impact compliance reporting. Security costs: Physical security: If buying an on-prem solution, you may need to increase security measures in your building, including new locks, secure entry doors, closed-circuit television, and security guard services. Information security: for example, security software applications or systems, offsite data backup, disaster recovery services, etc. Financing costs: for example, loan interest and loan origination fees. Disposal / Decommission costs: Some jurisdictions may require you to pay disposal fees. You may also need to shred or demagnetize your electronic storage media. this is not a comprehensive list by any means. It is just a list of costs I’ve tallied up over the years. You may have to consider other areas specific to your own situation.\nHow does the saying go? \u0026ldquo;Your mileage may vary\u0026rdquo;.\nConclusion When purchasing new software, you have to consider more than just the price tag.\nThankfully, more and more software companies (and research companies) have created online TCO calculators to help you identify those hidden costs.\nI’ve found a couple so far:\nAzure TCO calculator Excel Total Cost of Ownership Calculator template Did I miss any obvious costs? Did you find any TCO calculators out there? Let me know in the comments.\nPhoto Credit Piggy Bank Image by 3D Animation Production Company from Pixabay\nIceberg Image created by: Ralph A. Clevenger\nCredit:© Ralph A. Clevenger/CORBIS\nCopyright:© Corbis. All Rights Reserved\n","permalink":"http://localhost:1313/posts/making-an-educated-decision-when-acquiring-software-part-ii-total-cost-of-ownership/","tags":null,"title":"Making an educated decision when acquiring software — Part II: Total Cost of Ownership"},{"categories":["SharePoint"],"contents":"Introduction The SharePoint Design is a beautiful web site that provides design guidance on beautiful and fast sites, pages, and web parts with SharePoint in Office 365.\nUnfortunately, the SharePoint Design site does not tell you how to create the beautiful web parts they show you.\nThis series is intended as a companion to the SharePoint Design site, providing you with code samples and detailed how-to information for every design topic. It should help you create web parts that look exactly like the ones on the SharePoint Design site.\nToday’s post is a companion to the Designing SharePoint web part page.\nWhat is a property pane? The property pane is a panel that appears when users select Edit on a web part. It allows users to enable and disable features, select a layout, connect to another web part, or set other options.\nThe property pane\nWhen visible, the property pane is 320 pixels, which makes it the perfect size to appear full-screen on a mobile device. On a tablet or desktop device, the page content area shrinks by 320 pixels and the content re-flows responsively to make room for the property pane.\nThe property pane in action\nWhen to use a property pane You should use a property pane when you need to offer options to your users to configure the web part.\nYou should not use a property pane to edit the web part’s content.\nDirectness is a user interface design principle which says that your users should be able to achieve their goals through a minimal set of actions. It also says that users should be able to manipulate the objects they’re working on in the most direct manner.\nIn other words, directness says that, whenever possible, you should allow users to edit the content of a web part where the content actually resides — in the web part’s content area.\nThat’s why the out-of-the-box Text and Hyperlink web parts make you edit content directly within the web part.\nText web part in action\nHyperlink web part in action\nIn contrast, the Image web part opens a pane to insert and edit an image, because there isn’t a natural way to create an image directly from the web part’s content area.\nImage web part’s use of the property pane\nIn some cases, you may wish to use the property pane to provide additional options for the selected content of the web part. For example, the Text web part uses the property pane to provide users with additional formatting options that would otherwise clutter the text editing toolbar. Users edit the content directly within the web part, but can also use additional formatting options in the property pane.\nThe text web part uses the property pane to provide additional formatting options\nThe best way to leverage property panes it to use it to provide options to your page authors that you don’t want other users (i.e.: readers) to see. Because SharePoint automatically hides or shows the Edit depending on the user’s permissions, you don’t have to build your own sophisticated security logic to hide or show options within your web part.\nIf in doubt about whether you should show an option within the web part body or within the property pane, ask yourself whether you want all users to be able to control that option. For example, if you want to allow all users to refresh a feed via a Refresh button, or if you want users to control whether they want their personal feed to be sorted in ascending or descending order, give the users the option to do that within the web part’s body.\nOn the other hand, if you only want page authors to control options that will affect all users, you should probably place that option within the property pane.\nTake a look at the various out-of-the-box web parts to see how they present their various options for inspiration.\nTypes of property panes When designing a property pane, you can use one of three property pane types:\nSingle pane Used for simple web parts with a few properties to configure. As the name implies, there is only one single pane without any grouping.\nAccordion pane Contains a group or groups of properties with many options, and where the groups result in a long scrolling list of options.\nFor example, you might have three groups named Properties, Appearance, and Layout, each with many options.\nSteps pane Group properties in multiple steps or pages. Used when web configuration needs to follow a precise order of steps, or when choices in the first step affect the options that display in next steps.\nThe property pane will display a Back and Next buttons at the bottom of the pane, along with an indication of how many steps there are, and which step is currently displayed.\nFor more information on each property pane type refer to the SharePoint Design site.\nCreate a single pane property pane To create a single pane property pane, follow these steps:\nDo nothing That’s because it is what the SPFx Yeoman generator automatically produces for you when you create a web part.\nLet’s take a second to explore the default code to understand it better.\nWhen you create a web part using the Yeoman generator, this is the standard getPropertyPaneConfiguration method that you get in your [YourWebPartName]WebPart class:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: strings.PropertyPaneDescription }, groups: [ { groupName: strings.BasicGroupName, groupFields: [ PropertyPaneTextField(\u0026#39;description\u0026#39;, { label: strings.DescriptionFieldLabel }) ] } ] } ] }; } If you aren’t familiar with SPFx, Typescript, or React, it may not be obvious what each part of the code does. The biggest reason is that the SharePoint team is being really nice to us and provides us with a template that encourages you to localize all your web part resources (i.e.: the text in your web parts). That’s why you see strings.PropertyPaneDescription as the description for the property pane. It is a great habit to follow, and I encourage you to keep localizing all your resources — even if your web part is only ever going to be in one language. It makes it easier to change the text (like when fixing spelling mistakes) without having to touch the code.\nTo make things easier, let’s replace the code and see what happens. Replace your existing getPropertyPaneConfiguration code with the following code:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: \u0026#34;This is the pane description\u0026#34; }, groups: [ { groupName: \u0026#34;This is the group name\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;description\u0026#39;, { label: \u0026#34;This is the field label\u0026#34; }) ] } ] } ] }; } When test your web part (using gulp serve), your property pane will look like this:\nIf we use our browser’s developer toolbar to explore the various elements, we can see the individual components:\nYou may have noticed that the property pane’s title isn’t configured anywhere. That’s because it uses the web part’s title, which is configured in the [YourWebPartName].manifest.json under preconfiguredEntries \u0026gt; title \u0026gt; default. If you change the title, remember that the settings won’t take effect until you re-bundle the web part (by running gulp serve again, or gulp build) and re-add the web part to your page.\nProperty pane page description I encourage you to use the page description to provide your users with instructions on what you expect them to do. For example, this is what the out-of-the-box Image property pane page description looks like:\nChange your image and image options. Turn on or off the display of text over your image, add a link, and add or modify alternative text.\nThe File viewer web part gives you different directions based on what type of file you select. This is what it says if you select a PowerPoint presentation:\nSelect the slide you want people to see first.\nAnd this is what you get if you selected a Word document:\nSelect the page you want people to see first.\nIf you didn’t select a file, however, this is what you’ll see:\nAdd a file to view on your page. You can select from a variety of file types including Excel, Word, PowerPoint, Visio, PDFs, 3D models, and more. You can also connect to a source to dynamically view files by selecting the ellipses (…) and Connect to source.\nLast example: this is what the Highlighted content web part page description says:\nSelect the content you want to highlight, and choose layout options.\nUse your property pane page description to provide users with useful guidance. If you don’t have anything useful to say, you can simply omit the page description by removing the line in your code:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { // REMOVED: to remove the description // header: { // description: \u0026#34;This is the pane description\u0026#34; //strings.PropertyPaneDescription // }, groups: [ { groupName: \u0026#34;This is the group name\u0026#34;, //strings.BasicGroupName, groupFields: [ PropertyPaneTextField(\u0026#39;description\u0026#39;, { label: \u0026#34;This is the field label\u0026#34; //strings.DescriptionFieldLabel }) ] } ] } ] }; } Which gets you this:\nProperty pane without a description\nFor the record, though, I encourage you to provide some helpful text instead of removing the description.\nProperty pane group Your property pane can have more that one group. However, when you use the single pane property pane when you have few options to present, otherwise you should use the accordion or steps property pane.\nYou may have noticed that some of the out-of-the-box web parts have no property pane groups. Or, rather, they have a single property pane group with no group header.\nThe image web part property pane has no group header\nThe text web part property pane has no group header either\nTo reproduce the same look, all you need to do is omit a group header in your code:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { // REMOVED: To hide the property pane page description // header: { // description: \u0026#34;This is the pane description\u0026#34; // }, groups: [ { //REMOVED: For single pane property pane //groupName: \u0026#34;This is the group name\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;description\u0026#39;, { label: \u0026#34;This is the field label\u0026#34; }) ] } ] } ] }; } Which produces the following web part property pane:\nCreate an accordion pane property pane Sometimes you have too many options to present to your users at one time.\nTake the out-of-the-box Highlighted content web part, for example. Imagine if showed all available options without any grouping. It would look like this:\nToo many options at once!\nNow take the same web part, but group the options logically. You get something like this:\nAh! Much easier to understand!\nIt makes sense to group your choices into smaller, collapsible sections known as accordion panes.\nWhy should you do this? It’s the law!\nHick’s Law, to be precise. Also known as the Hick-Hyman Law, it is named after a British and an American psychologist team of William Edmund Hick and Ray Hyman. In 1952, they found a relationship between the number of stimuli present and an individual’s reaction time to any given stimulus.\nSpecifically, they found that the more stimuli to choose from, the longer it takes the user to make a decision.\n(That’s what I like to call the Cheesecake Factory Law, because of how long it takes to decide what to eat when at the Cheesecake Factory. Have you seen how long their menu is?!)\nWhen you bombard your users with too many choices at once, they have to take time to interpret and decide, giving them work they don’t want.\nIf you have a lot of choices to offer your users, consider grouping them into smaller choices. For example, instead of giving you 7 configuration choices to pick from, the Highlighted content web part gives you three simple choices:\nContent Filter and sort Layout Within each of those three, you have two or three smaller choices to make. Making it easier for users to make sense of the choices that are available to them.\nNote that the rule only applies to choices that the user is unfamiliar with. For example, if you want to list the months of the year, don’t group them into smaller choices. Otherwise, you’ll actually increase the time it takes for a user to find the item they want.\nFor this sample, we have created 6 properties (demoProperty1 through demoProperty6) which we’ll group into three categories (Group 1, Group 2 and Group 3). Feel free to use your own categories and properties.\nIf you want to create an accordion pane property pane, follow these steps:\nIn your [YourWebPartName]WebPart.ts file, find the getPropertyPaneConfiguration function and create as many groups as you need, with fields within those groups.\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: \u0026#34;This web part demonstrates how to use an accordion property pane\u0026#34; }, groups: [ { groupName: \u0026#34;Group 1\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty1\u0026#39;, { label: \u0026#34;Property 1\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty2\u0026#39;, { label: \u0026#34;Property 2\u0026#34; }) ] }, // ADDED: Group 2 and 3 for accordion support { groupName: \u0026#34;Group 2\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty3\u0026#39;, { label: \u0026#34;Property 3\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty4\u0026#39;, { label: \u0026#34;Property 4\u0026#34; }) ] }, { groupName: \u0026#34;Group 3\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty5\u0026#39;, { label: \u0026#34;Property 5\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty6\u0026#39;, { label: \u0026#34;Property 6\u0026#34; }) ] } // END added ] } ] }; } The groups and groupFields nodes expect arrays of items, which means that we can have many groups and many fields within the groups.\nTo make the groups appear as accordions, add a displayGroupsAsAccordion property and set it to true, as follows (see line 9):\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: \u0026#34;This web part demonstrates how to use an accordion property pane\u0026#34; }, // ADDED: to turn groups into accordions displayGroupsAsAccordion: true, // END added groups: [ { groupName: \u0026#34;Group 1\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty1\u0026#39;, { label: \u0026#34;Property 1\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty2\u0026#39;, { label: \u0026#34;Property 2\u0026#34; }) ] }, { groupName: \u0026#34;Group 2\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty3\u0026#39;, { label: \u0026#34;Property 3\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty4\u0026#39;, { label: \u0026#34;Property 4\u0026#34; }) ] }, { groupName: \u0026#34;Group 3\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty5\u0026#39;, { label: \u0026#34;Property 5\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty6\u0026#39;, { label: \u0026#34;Property 6\u0026#34; }) ] } ] } ] }; } If you wish to make the groups initially appear as expanded or collapsed, you can specify the isCollapsed property at the group level and set it to true or false, as desired:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: \u0026#34;This web part demonstrates how to use an accordion property pane\u0026#34; }, displayGroupsAsAccordion: true, groups: [ { groupName: \u0026#34;Group 1\u0026#34;, // ADDED: to collapse group initially isCollapsed: true, // END added groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty1\u0026#39;, { label: \u0026#34;Property 1\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty2\u0026#39;, { label: \u0026#34;Property 2\u0026#34; }) ] }, { groupName: \u0026#34;Group 2\u0026#34;, // ADDED: to collapse group initially isCollapsed: true, // END added groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty3\u0026#39;, { label: \u0026#34;Property 3\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty4\u0026#39;, { label: \u0026#34;Property 4\u0026#34; }) ] }, { groupName: \u0026#34;Group 3\u0026#34;, // ADDED: to collapse group initially isCollapsed: true, // END added groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty5\u0026#39;, { label: \u0026#34;Property 5\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty6\u0026#39;, { label: \u0026#34;Property 6\u0026#34; }) ] } ] } ] }; } If you run gulp serve, you should get an accordion pane property pane:\nNote: To keep the code easier to read, we did not localize our text resources. Please don’t do this at home.\nCreate a steps pane property pane As we previously discussed, if you have a lot of configuration options in your web part, you should use an accordion pane and group your configuration options to make it easier for your users. Accordion panes work well when you want to allow your users to configure your web part in no particular order.\nSometimes, you need your users to configure your web part by following a specific sequence.\nThat’s when you should use steps pane property panes.\nTo prepare this sample, we created demoProperty1 through demoProperty10. We’ll show these options across 3 pages, divided into 5 groups. Feel free to use your own properties.\nJust like the groups and groupField property, the pages property expects an array. You can define more than one page and they will be displayed in the same order that you defined them in the code.\nTo create our sample steps pane property pane, follow these steps:\nIn your [YourWebPartName]WebPart.ts file, find the getPropertyPaneConfiguration function and create as many pages as you need, with groups and group fields within those pages:\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { pages: [ { header: { description: \u0026#34;This is the first page.\u0026#34; }, displayGroupsAsAccordion: false, groups: [ { groupName: \u0026#34;Group 1\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty1\u0026#39;, { label: \u0026#34;Property 1\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty2\u0026#39;, { label: \u0026#34;Property 2\u0026#34; }) ] }, { groupName: \u0026#34;Group 2\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty3\u0026#39;, { label: \u0026#34;Property 3\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty4\u0026#39;, { label: \u0026#34;Property 4\u0026#34; }) ] } ] }, // ADDED: To add steps { header: { description: \u0026#34;This is the second page.\u0026#34; }, displayGroupsAsAccordion: false, groups: [ { groupName: \u0026#34;Group 3\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty5\u0026#39;, { label: \u0026#34;Property 5\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty6\u0026#39;, { label: \u0026#34;Property 6\u0026#34; }) ] }, { groupName: \u0026#34;Group 4\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty7\u0026#39;, { label: \u0026#34;Property 7\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty8\u0026#39;, { label: \u0026#34;Property 8\u0026#34; }) ] } ] }, { header: { description: \u0026#34;This is the third and final page.\u0026#34; }, displayGroupsAsAccordion: false, groups: [ { groupName: \u0026#34;Group 5\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty9\u0026#39;, { label: \u0026#34;Property 9\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty10\u0026#39;, { label: \u0026#34;Property 10\u0026#34; }) ] } ] } //END added ] }; } By default, the web part will start the property pane on the first page. If you’d like to override this (for example, if you want to bring attention to a specific page to encourage a user to solve an issue), specify the currentPage property as follows (see line 4):\nprotected getPropertyPaneConfiguration(): IPropertyPaneConfiguration { return { // ADDED: To change the default current page currentPage: 3, // END added pages: [ { header: { description: \u0026#34;This is the first page.\u0026#34; }, displayGroupsAsAccordion: false, groups: [ { groupName: \u0026#34;Group 1\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty1\u0026#39;, { label: \u0026#34;Property 1\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty2\u0026#39;, { label: \u0026#34;Property 2\u0026#34; }) ] }, { groupName: \u0026#34;Group 2\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty3\u0026#39;, { label: \u0026#34;Property 3\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty4\u0026#39;, { label: \u0026#34;Property 4\u0026#34; }) ] } ] }, // ADDED: To add steps { header: { description: \u0026#34;This is the second page.\u0026#34; }, displayGroupsAsAccordion: false, groups: [ { groupName: \u0026#34;Group 3\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty5\u0026#39;, { label: \u0026#34;Property 5\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty6\u0026#39;, { label: \u0026#34;Property 6\u0026#34; }) ] }, { groupName: \u0026#34;Group 4\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty7\u0026#39;, { label: \u0026#34;Property 7\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty8\u0026#39;, { label: \u0026#34;Property 8\u0026#34; }) ] } ] }, { header: { description: \u0026#34;This is the third and final page.\u0026#34; }, displayGroupsAsAccordion: false, groups: [ { groupName: \u0026#34;Group 5\u0026#34;, groupFields: [ PropertyPaneTextField(\u0026#39;demoProperty9\u0026#39;, { label: \u0026#34;Property 9\u0026#34; }), PropertyPaneTextField(\u0026#39;demoProperty10\u0026#39;, { label: \u0026#34;Property 10\u0026#34; }) ] } ] } //END added ] }; } Try to avoid skipping directly to another page without a valid reason, otherwise, your users may be a bit confused. If you choose to skip to a page other than page 1, help the users understand why you did it — perhaps with a little message at the top of the page.\nOnce completed, you should get a property pane with three pages (I kept the default page to page 1, in case you’re wondering:\nConclusion That’s probably enough for one day.\nAs you hopefully noticed, creating property panes isn’t very difficult. Most of the work is already done for you.\nThe code for this post is available on the SharePoint Framework Web Part Design Series repo.\nIn our next post, we’ll continue discussing property panes with some advanced options, such as adding images to property pane headers, showing loading indicators, and making responsive/non-responsive property pane web parts. We’ll also discuss what the text within these property panes should look like.\nThen we’ll discuss more exciting stuff, like creating conditional property pane groups and fancy property pane fields.\nI hope this helps?\n","permalink":"http://localhost:1313/posts/sharepoint-framework-design-series-property-panes-part-1/","tags":["SPFx"],"title":"SharePoint Framework Design Series: Property Panes — Part I"},{"categories":["Dynamics 365"],"contents":"Introduction A tale, inspired by a true story Once upon a time, there was an IT guy who had been tasked to buy a piece of software. He wasn’t asked to do research or to investigate whether his company had the required infrastructure (or staff) to run the software. He was told to buy it and not to ask any questions.\nThe boss had already made up his mind. He wanted this software because the adverts in the magazine told him it would solve all his problems. He had already talked to the salespeople over a game of golf and a lavish dinner with copious amounts of alcohol.\nThe salespeople — really nice and friendly folks — had assured the boss that the software would not need any configuration or installation, and it wouldn’t affect any of his systems or cause any downtime.\nWhen the IT guy started asking questions about whether the software the boss wanted was the right choice, the boss pretty much told him that if he didn’t want to take care of it, the boss would find someone who would. From what he had seen from the marketing videos on YouTube, the boss was pretty sure that even he could do it himself.\nEventually, the IT guy gave in and installed the software.\nBut not before discovering that the software required a whole bunch of new servers and needed to run on an operating system that no one in the IT department had any experience managing. So they hired a new IT guy that knows that particular operating system.\nMeanwhile, the database administrators found out that the only database platform that was supported by this new software was not the database platform the company had standardized on. They bought more servers and hired a new DBA that was familiar with that database platform.\nWhen it came time to customize the software to meet the company’s needs, they found out that none of the application development team had the time or the skills required to do such customization. Luckily, one of the top contractors in that programming language happened to be available and could start immediately — at a premium rate.\nOne day, as the exasperated IT guy was eating a sandwich and staring blankly at the lunchroom wall, the Webmaster guy — who usually works on another floor, but was in the neighborhood for a meeting — walked in.\n– \u0026ldquo;Whoa, you look like you have had a rough few months!\u0026rdquo; said the webmaster. It was meant as a joke, but it was also true.\nThe IT guy and the webmaster had known each other for a long time. They worked together when the IT department was just a handful of guys. Back then, the webmaster was just running the company’s web site, but he had since started managing the company’s intranet and portal.\n– \u0026ldquo;Agh! I just found out that we’re going to have to start a nightly export of our user data because the [expletives deleted] isn’t compatible with our Active Directory. Of course!\u0026rdquo;, was the IT guy’s response. \u0026ldquo;And our first migration to the new system is going to take a lot longer than we expected and we’ll need to ask the accounting department to stop working for two whole weeks while we migrate the system. And they’re unhappy because it is the end of the fiscal quarter.\u0026rdquo;\nThe webmaster asked cautiously: \u0026ldquo;And… what exactly does this new software do?\u0026rdquo;\nThe IT guy explained what the new software did.\n– \u0026ldquo;Uh, you mean like what our current portal platform has available out of the box?\u0026rdquo; asked the webmaster. \u0026ldquo;That’s what [redacted]’s team has been using for about two years now. The boss even sent an email congratulating the team for doing such a good job. I even demoed it to the boss!\u0026rdquo;.\nThe rest of the tale isn’t appropriate for this blog. But there was a lot of cursing and yelling. Let’s just say that they lived miserably forever after, having to maintain that software that never truly worked the way it was intended.\nSadly, this kind of scenario happens more often than you’d think. You may have experienced this yourself where you work.\nThis post will explain some of the tips and tricks to use when buying new software that will help you make an educated decision.\nSoftware acquisition model I often hear people talk about \u0026ldquo;Buy vs Build\u0026rdquo; when discussing their software acquisition model.\nIn reality, you should always consider Re-use, Buy, and Build.\nst=\u003estart: Start\rd1=\u003econdition: Can I re-use?\rd2=\u003econdition: Can I buy?\re1=\u003eend: Re-use\re2=\u003eend: Buy\re3=\u003eend: Build\rst-\u003ed1(no)-\u003ed2(no)-\u003ee3\rd1(yes)-\u003ee1\rd2(yes)-\u003ee2\rRe-use Do you already own a piece of software that will meet your needs? It may be an unused part of something you already bought, or it may be an internal application that another department has already developed.\nYou should also consider open-source solutions as part of the re-use decision. Can you re-use open-source software that already exists out there, for free, to meet your needs?\nIs there an add-on feature available for of the software you already own that would meet your needs? Even if it would cost you a little more to enable that feature?\nIf the answer is yes (or mostly yes), you should explore the possibility of re-using what’s already available before buying.\nDon’t compromise, but don’t miss what’s already right in front of you either.\nI recently went through this process with a client that uses Office 365 — with SharePoint, Flow, and PowerApps at their disposal. They wanted to buy a piece of software because it called a third-party API and made it possible to trigger data workflows from the results of the API… which is something that they could already do with Flow.\nThey just didn’t know that feature was available.\nBefore considering to buy a new piece of software, it is a good idea to take an inventory of what you already have.\nBuy If you can’t re-use — or doing so would deliver a less-than-optimal solution — by all means buy something!\nHowever, before you pull out your credit card, make sure to do a proper gap analysis. Compare what your existing software (if any) actually offers against what you really need it to do. Then use that same gap analysis criteria to compare with the software you want to purchase.\nWhen considering buying, keep in mind the Total Cost of Ownership of that comes with every piece of software.\nDon’t know what Total Cost of Ownership means? Check this blog for an upcoming post on the subject.\nAfter considering your gap analysis and total cost of ownership, if you can’t find software that meets your needs (within the budget you’ve been given), consider building something.\nWhatever you do, resist the urge to skip the buying option and go straight to building.\nBuild Don’t listen to developers (like me) who’ll tell you \u0026ldquo;Oh, that’ll take me a couple of weeks to build\u0026rdquo;. Because it never does.\nThis may sound weird coming from someone who considers himself a developer at heart, but it is true.\nThey’re not lying to you on purpose to protect their jobs. And it isn’t a reflection of their skills. They really do mean well.\nBut most organizations suck at building software projects.\nDon’t take my word for it: The Standish Group is an organization that publishes a yearly Chaos Report. The report describes the state of the software development industry and seeks to identify the scope of software project failures, the major factors that cause software projects to fail, and the key ingredients that can reduce project failure. I highly recommend that you buy your own copy — it is worth it. And I am not affiliated with The Standish Group in any way.\nLast time I bought the report, a staggering 31.1% of software projects will be cancelled before they ever get completed. 52.7% of projects will cost 189% of their original estimates.\nBack in 1995, the Standish Group estimated that American companies and government agencies spent $81 billion for cancelled software projects. They paid an additional $59 billion for software projects that were being completed but exceeded their original time estimates.\nThe average number of software projects that are completed on-time and on-budget is only 16.2% — a number that goes a low as 9% in larger companies.\nAnd once completed, those \u0026ldquo;successful\u0026rdquo; projects will only deliver approximately %42 of the originally-proposed features and functions.\nIt doesn’t need to be an all-or-nothing situation Nowadays, software is so much more open and versatile than it was many years ago. Yet, we still deal with software acquisitions as a giant monolith that cannot integrate with anything.\nThe ideal solution for your needs may very well be a hybrid solution: using the software you already own (re-use), adding a component or an app that meets most of your needs (buy), and making minor customizations to meet your exact needs.\nAlthough this post isn’t about Office 365, I often see organizations running Office 365, SharePoint Online and Dynamics 365, but they fail to fully recognize the capabilities available at their disposal.\nTake a look at the various Office add-ins and Dynamics 365 AppSource for solutions that you can buy that will handle most of your needs. And, with Flow and PowerApps, you can easily configure your solutions to do exactly what you want. There are countless connectors available that may allow you to build a low-code or no-code solution that can adapt as your company’s needs evolve.\nThe same applies to other products — not just Office 365. Understand what you have so that you can fully leverage it before you look at buying or building something new.\nConclusion Impulse buying is something that may be suitable for a pack of gum while you’re waiting to pack at the grocery store, but it should never be an option when it comes to enterprise applications.\nMake an educated decision, and follow an acquisition model that will help you find the ideal solution for your organization’s needs.\nI hope this helps?\nSources The Chaos Report. The Standish Group, 2014. Image Credit Image by Arek Socha from Pixabay\n","permalink":"http://localhost:1313/posts/making-an-educated-decision-when-acquiring-software/","tags":null,"title":"Making an educated decision when acquiring software — Part I: Acquisition Model"},{"categories":["SharePoint"],"contents":"Introduction The SharePoint Design is a beautiful web site that provides design guidance on beautiful and fast sites, pages, and web parts with SharePoint in Office 365.\nUnfortunately, the SharePoint Design site does not tell you how to create the beautiful web parts they show you.\nThis series is intended as a companion to the SharePoint Design site, providing you with code samples and detailed how-to information for every design topic. It should help you create web parts that look exactly like the ones on the SharePoint Design site.\nToday’s post is a companion to the Titles and descriptions for SharePoint web parts\nWhat is a Web Part Title? A Web Part title is a heading that appears above a web part to visually separate the web part from other content and to provide information to users about the purpose of a web part.\nMost often, web parts provide a default title that page authors can override (or remove) to customize the web parts to suit their needs.\nWhat is a Web Part Description The Web Part description is often smaller text within the web part that describes the web part content. For example, the caption element in the Image web part.\nJust like the title, page authors can override or omit the web part description to suit their needs.\nIt is important to not confuse description with alternative text. The description is optional, but it is always visible.\nThe alternative text is something that you should always provide for visual content (such as images, charts, etc.). We’ll discuss alternative text in a later post.\nWhy use titles and descriptions? Understanding Back in my McKinsey \u0026amp; Company days, a wise person told me:\nWhen you leave it up to your audience to make an assumption, you lose control over that assumption\nSeems kind of obvious, but what they meant was that if you present information to users and expect them to make a conclusion from it, they may make the wrong conclusion.\nDon’t assume your users are stupid, but don’t assume that by just putting a web part on the page that they will understand the purpose of the web part is.\nTitles and descriptions are a consistent way to indicate to your users the purpose of your web part.\nAccessibility When I tell people about accessibility requirements in software design, most people’s initial reaction is often something like:\n\u0026ldquo;We don’t have any blind people [who work here], so we don’t need to worry about accessibility\u0026rdquo;\nUnfortunately, accessibility is more than about blindness. It is estimated that more than 10% of the population live with a disability.\nAccessibility is actually broken down into 4 categories:\nVisual: This can include blind (or non-sighted) users, but also includes users with low-vision, users with obstructed vision, or age-related visual impairment. This includes color blindness, which affects 1 in 12 men (or about 8%) and 1 in 200 women. Auditory: This includes hearing-impaired users. Motor: People with motor impairments includes people with Repetitive Stress Injuries, Cerebral palsy, Parkinson’s and Muscular dystrophy. Cognitive: which relates to the ease processing of information. It includes people with autism, Down’s syndrome, Dyslexia, or global developmental delay. Consider stroke victims and concussion victims as well. Accessibility may be a permanent or temporary condition. People often (wrongly) assume that web accessibility is only for people with permanent or long-term disabilities, but accessibility benefits people with or without disabilities. For example, it may impact the following people:\nPeople who are not fluent in English. People who do not have or are unable to use a keyboard or mouse. People with temporary disabilities due to accident or illness. Older people. New users. Plus, in some countries, you are now legally obligated to provide accessible resources to your employees.\nLucky for you, the use of titles and descriptions in web parts help alleviate some of the accessibility issues by providing headings, plenty of white space on the page, visually grouping information together, and even tackling colour contrast requirements on the page — to name only a few benefits.\nWhen should you use titles Let’s pretend for a second that we are not talking about SharePoint, but Microsoft Word instead. You can add things in a Word document that will make the body of the document. Things like text, images, hyperlinks, page breaks, etc. When you insert such elements in a Word document, you want them to blend in together and print nicely.\nIf your web part is intended to blend in with other content within your SharePoint page, you probably don’t need a title. For example, the following out-of-the-box web parts do not need a title:\nText Image File viewer Link Embed Divider Markdown On the other hand, if your web part provides a new set of information that should be visually distinctive from the rest of your page content, it should probably provide a title.\nFor example, if you add the Events web part or the Document library web part in a page, you probably don’t want to dump a list of events or documents in between two paragraphs without providing context to your users.\nThis decision tree may help. You can tell that it was written by a consultant because one of the answers is \u0026ldquo;it depends\u0026rdquo;.\nst=\u003estart: Does my web part need a title?\re=\u003eend: No title needed\rcond=\u003econdition: Does your web part need to blend in?\rcond2=\u003econdition: Does it need to visually\rgroup information?\rio=\u003eparallel: No title needed\rpara=\u003eend: Title is recommended\rst-\u003econd\re3=\u003eend: It depends :-)\rcond(yes)-\u003ee\rcond(no)-\u003econd2(yes)-\u003epara\rcond2(no)-\u003ee3\rWhen should you use descriptions Unlike the web part title, the description is not intended to visually distinguish the web part. It is purely intended to help understand the purpose or context of a web part. I recommend providing the option for a description in your web parts if the body of your web part mostly consists of images or graphics. For example, a chart web part, or an image.\nIn my Comparer web part, which allows users to compare two images side-by-side, I allow editors to provide a description for each image.\nHow to add a web part title to your web part If you want to see the sample web part I’m building in this post, visit the GitHub repo and open the WebPartTitles solution. The web part is called EditableTitle\nI chose the web part title as the first in this series because it is probably the easiest one to implement. That’s because the PnP Reusable Controls library provides a perfect Web Part Title component.\nHere is how to add the web part title in your SPFx web part solution using React:\nUsing your Node.js Command Prompt (or whatever terminal you wish to use), make sure that you’re in your web part solution’s root directory. (It should be the same folder where your solution’s package.json is located).\nType the following command to add the PnP Reusable Controls library to your project:\nnpm install @pnp/spfx-controls-react Note: most instructions tell you to use npm install @pnp/spfx-controls-react --save --save-exact, but the --save parameter is considered obsolete now. Feel free to use what you feel most comfortable with.\nIn your web part class (the one that extends BaseClientSideWebPart), add a property to store your web part’s title. If your web part is called EditableTitle, you would open the EditableTitleWebPart.ts file, and look for the IEditableTitleWebPartProps interface (usually located at the top of the file. Add the following code:\nexport interface IEditableTitleWebPartProps { description: string; // BEGIN Add to support web part title title: string; // END Add } In your render method, your web part will need to pass the web part title, the displayMode (to determine whether the web part is in Edit Mode or Read Mode), and a function to handle changes to the title. All these things get passed to the component that is responsible for rendering the body of your web part. Your new render method will look like this:\npublic render(): void { const element: React.ReactElement\u0026lt;ieditabletitleprops\u0026gt; = React.createElement( EditableTitle, { description: this.properties.description, // BEGIN: Add to support web part title // Don\u0026#39;t forget that you need to add a comma at the end of the previous line title: this.properties.title, displayMode: this.displayMode, updateTitle: (value: string) =\u0026gt; { this.properties.title = value; } //END: Add } ); ReactDom.render(element, this.domElement); } If you get a nasty error message when you add the code, don’t worry. We just haven’t defined a title, displayMode, and updateTitle property for your component yet.\nDon’t worry about this error message, we’ll fix it soon\nOpen your component’s I[YourWebPartName]Prop interface (located under src\\webparts\\[YourWebPartName]\\components\\I[YourWebPartName]Props.ts). Since my web part is called editableTitle, I’ll open src\\webparts\\editableTitle\\components\\IEditableTitleProps.ts and add an import for the DisplayMode at the top of your file:\nimport { DisplayMode } from \u0026#39;@microsoft/sp-core-library\u0026#39;; Add the properties your component will need to support the web part title in your I[YourWebPartName]Props interface:\nexport interface IEditableTitleProps { description: string; //BEGIN: Add support for web part title title: string; displayMode: DisplayMode; updateTitle: (value: string) =\u0026gt; void; //END: Add } Open the web part’s component TSX file (located under src\\webparts\\[YourWebPartName]\\components\\[YourWebPartName].tsx) and add an import for the WebPartTitle control:\nimport { WebPartTitle } from \u0026#34;@pnp/spfx-controls-react/lib/WebPartTitle\u0026#34;; In your [YourWebPartName]‘s render method, add the WebPartTitle control. You should add it immediately after the first opening \u0026lt;div\u0026gt;:\npublic render(): React.ReactElement\u0026lt;ieditabletitleprops\u0026gt; { return ( \u0026lt;div classname=\u0026#34;{styles.editableTitle}\u0026#34;\u0026gt; {/* BEGIN: Add to support web part title */} \u0026lt;webparttitle displaymode=\u0026#34;{this.props.displayMode}\u0026#34; title=\u0026#34;{this.props.title}\u0026#34; updateproperty=\u0026#34;{this.props.updateTitle}\u0026#34;\u0026gt; {/* END: Add */} \u0026lt;div classname=\u0026#34;{styles.container}\u0026#34;\u0026gt; \u0026lt;div classname=\u0026#34;{styles.row}\u0026#34;\u0026gt; \u0026lt;div classname=\u0026#34;{styles.column}\u0026#34;\u0026gt; \u0026lt;span classname=\u0026#34;{styles.title}\u0026#34;\u0026gt;Welcome to SharePoint!\u0026lt;/span\u0026gt; \u0026lt;p classname=\u0026#34;{styles.subTitle}\u0026#34;\u0026gt;Customize SharePoint experiences using Web Parts.\u0026lt;/p\u0026gt; \u0026lt;p classname=\u0026#34;{styles.description}\u0026#34;\u0026gt;{escape(this.props.description)}\u0026lt;/p\u0026gt; \u0026lt;a href=\u0026#34;https://aka.ms/spfx\u0026#34; classname=\u0026#34;{styles.button}\u0026#34;\u0026gt; \u0026lt;span classname=\u0026#34;{styles.label}\u0026#34;\u0026gt;Learn more\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/webparttitle\u0026gt;\u0026lt;/div\u0026gt; ); } Note: some people prefer to add the web part title within the second div — the one with the container CSS class. I’ll be removing that div in future code samples, but feel free to do as you please.\nRun gulp serve to test your web part and try editing your web part’s title\nAdding a default title To make things easier for your users, you should provide a default title for your web part. Try to use a title that users won’t immediately have to change (like Insert Title Here). For example, if your web part retrieves a list of recently added documents, try using Recent documents. If your web part displays events, try Upcoming events or Events.\nSince the web part title is stored in a web part property (we called it title in our sample above), the easiest way to add a default title is to use your web part manifest’s preconfiguredEntries to provide a default title.\nTo do so:\nOpen the [YourWebPartName]WebPart.manifest.json file (located under the src\\webparts\\[YourWebPartName] folder)\nLocate the preconfiguredEntries JSON node\nUnder the \u0026quot;properties\u0026quot; node, add the default web part title as follows:\n\u0026#34;properties\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;EditableTitle\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;My Default Web Part Title\u0026#34; } Run gulp serve again. If your solution was already running, you need to stop the existing gulp serve and start a new one, otherwise, the updated manifest won’t be reflected in your web part.\nIf your web part was already running, remove it from the workbench, refresh the page, and re-add the web part. You should see your updated web part, now with a default title:\nAdding a placeholder title If your web part title is optional, or you prefer to start with a blank title, you should add a placeholder.\nFor example, the People web part uses People profiles for the placeholder title. It shows the title placeholder when your page is in Edit mode, but if you don’t specify a title and save your page to view it in Read mode, the title will disappear.\nPeople web part in edit mode shows placeholder\nPeople web part in reading mode hides placeholder\nTo implement this functionality, follow the same steps you did to add the web part title, but don’t provide a default title. Then:\nIn the [YourWebPartName].tsx file, find your WebPartTitle component in the render method.\nAdd the placeholder prop with the placeholder title you want to use.\n\u0026lt;webparttitle displaymode=\u0026#34;{this.props.displayMode}\u0026#34; title=\u0026#34;{this.props.title}\u0026#34; updateproperty=\u0026#34;{this.props.updateTitle}\u0026#34; placeholder=\u0026#34;{\u0026#34;Web\u0026#34; part=\u0026#34;\u0026#34; placeholder\u0026#34;}=\u0026#34;\u0026#34;\u0026gt; Note: please consider localizing your placeholder text. I’ll explain localizing in a later post.\nIf you want to see the sample web part I’m building in this post, visit the GitHub repo and open the WebPartTitles solution. The web part is called PlaceholderTitle\nHow to add a description Unfortunately, there isn’t a WebPartDescription component that you can use to easily add a description section to your web part.\nFortunately, we can cheat and use the WebPartTitle component and apply some CSS magic to get the same results.\nHere is how:\nIf you haven’t done so already, add the PnP Reusable Controls library to your project by typing the following command:\nnpm install @pnp/spfx-controls-react In your web part class (located under src\\webparts\\[YourWebPartName]\\[YourWebPartName]ts. Add a property to store your description. Since the default web part already has a description prop, I used webPartDescription, but in real life, I’d use the description prop for that purpose.\nexport interface IEditableTitleWebPartProps { description: string; // BEGIN Add to support web part description webPartDescription: string; // END Add } In your render method, your web part will need to pass the web part description, the displayMode (to determine whether the web part is in Edit Mode or Read Mode), and a function to handle changes to the description. All these things get passed to the component that is responsible for rendering the body of your web part. Your new render method will look like this:\npublic render(): void { const element: React.ReactElement\u0026lt;ieditabletitleprops\u0026gt; = React.createElement( EditableTitle, { description: this.properties.description, // BEGIN: Add to support web part description // Don\u0026#39;t forget that you need to add a comma at the end of the previous line webPartDescription: this.properties.webPartDescription, displayMode: this.displayMode, updateDescription: (value: string) =\u0026gt; { this.properties.webPartDescription = value; } //END: Add } ); ReactDom.render(element, this.domElement); } Open your component’s I[YourWebPartName]Prop interface (located under src\\webparts\\[YourWebPartName]\\components\\I[YourWebPartName]Props.ts). Since my web part is called webPartDescription, I’ll open src\\webparts\\webPartDescription\\components\\IWebPartDescriptionProps.ts.\nIf you haven’t done so already, add an import for the DisplayMode at the top of your file:\nimport { DisplayMode } from \u0026#39;@microsoft/sp-core-library\u0026#39;; Add the properties your component will need to support the web part description in your I[YourWebPartName]Props interface:\nexport interface IWebPartDescriptionProps { description: string; //BEGIN: Add support for web part description webPartDescription: string; displayMode: DisplayMode; updateDescription: (value: string) =\u0026gt; void; //END: Add } Open the web part’s component TSX file (located under src\\webparts\\[YourWebPartName]\\components\\[YourWebPartName].tsx).\nIf you haven’t done so already, add an import for the WebPartTitle control:\nimport { WebPartTitle } from \u0026#34;@pnp/spfx-controls-react/lib/WebPartTitle\u0026#34;; In your [YourWebPartName]‘s render method, add the WebPartTitle control where you would like the description to appear. We also add a placeholder (Add a description to override the default Web Part Title placeholder that comes with the WebParttitle component). In my sample, I’ll add it below the container div:\npublic render(): React.ReactElement\u0026lt;iwebpartdescriptionprops\u0026gt; { return ( \u0026lt;div classname=\u0026#34;{\u0026#34; styles.webpartdescription=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt; \u0026lt;div classname=\u0026#34;{\u0026#34; styles.container=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt; \u0026lt;div classname=\u0026#34;{\u0026#34; styles.row=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt; \u0026lt;div classname=\u0026#34;{\u0026#34; styles.column=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt; \u0026lt;span classname=\u0026#34;{\u0026#34; styles.title=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt;Welcome to SharePoint!\u0026lt;/span\u0026gt; \u0026lt;p classname=\u0026#34;{\u0026#34; styles.subtitle=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt;Customize SharePoint experiences using Web Parts.\u0026lt;/p\u0026gt; \u0026lt;p classname=\u0026#34;{\u0026#34; styles.description=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt;{escape(this.props.description)}\u0026lt;/p\u0026gt; \u0026lt;a href=\u0026#34;https://aka.ms/spfx\u0026#34; classname=\u0026#34;{\u0026#34; styles.button=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt; \u0026lt;span classname=\u0026#34;{\u0026#34; styles.label=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt;Learn more\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/* BEGIN: Add to support web part description */} \u0026lt;webparttitle displaymode=\u0026#34;{this.props.displayMode}\u0026#34; title=\u0026#34;{this.props.webPartDescription}\u0026#34; updateproperty=\u0026#34;{this.props.updateDescription}\u0026#34; placeholder=\u0026#34;{\u0026#34;Add\u0026#34; a=\u0026#34;\u0026#34; description\u0026#34;}=\u0026#34;\u0026#34;\u0026gt; {/* END: Add */} \u0026lt;/webparttitle\u0026gt;\u0026lt;/div\u0026gt; ); } To change the CSS for the web part description, we’ll add some CSS. Open the [YourWebPartName].module.scss (located under src\\webparts\\[YourWebPartName]\\components\\[YourWebPartName].module.scss) and add the following CSS just above the .container class:\n.descriptionElement textarea { font-size: 14px; font-weight: 400; line-height: 1.6em; overflow-x: hidden; text-overflow: ellipsis; color: $ms-color-neutralPrimary; } .descriptionElement__NoMargin textarea { margin-bottom: 0; } .descriptionElement__centerAlign textarea { text-align: center; } We’re defining three CSS classes here: descriptionElement to render a smaller font, descriptionElement__NoMargin to remove the bottom margin, and descriptionElement_centerAlign to align the description at the center of the web part. You can use all three CSS styles, or only descriptionElement as it suits you.\nGo back to your [YourWebPartName].tsx.\nAdd a reference to the css() function at the top of the file.\nimport { css } from \u0026#34;@uifabric/utilities/lib/css\u0026#34;; The css() function allows you to combine multiple CSS classes. To do so, I added. If you want to read more about the css() function, read my post.\nAdd the CSS prop to the WebPartTitle you added in step 9. Use whatever combination of the three CSS classes we defined earlier as you desire (I use all three here):\n{/* BEGIN: Add to support web part description */} \u0026lt;webparttitle displaymode=\u0026#34;{this.props.displayMode}\u0026#34; title=\u0026#34;{this.props.webPartDescription}\u0026#34; updateproperty=\u0026#34;{this.props.updateDescription}\u0026#34; placeholder=\u0026#34;{\u0026#34;Add\u0026#34; a=\u0026#34;\u0026#34; description\u0026#34;}=\u0026#34;\u0026#34; classname=\u0026#34;{css(styles.descriptionElement,\u0026#34; styles.descriptionelement__nomargin,=\u0026#34;\u0026#34; styles.descriptionelement__centeralign)=\u0026#34;\u0026#34; }=\u0026#34;\u0026#34;\u0026gt; {/* END: Add */} Run gulp serve and test your web part.\nYou should get something that looks like this:\nNote: I really dislike the default shadowy border that comes with every Yeoman-generated SPFx web part because it isn’t found anywhere else in the out-of-the-box SharePoint web parts. I always remove it from my projects. Although this is outside of the scope of this post, if you want to remove it, simply comment out the box-shadow line in the .container CSS class of your [YourWebPartName].module.scss. You’ll get the following result:\nIf you want to see the code for this web part, visit the GitHub repo and open the WebPartTitles solution. The web part is called WebPartDescription. I know, I didn’t think the web part name through when I built it.\nUI text guidelines for Titles and descriptions I’ve mostly copied this from the UI text guidelines for SharePoint web parts, but I include it here (and will continue to include the relevant sections throughout this series) because it is important to use consistent User Interface (UI) text within your web parts.\nCapitalization Use sentence casing (the first letter of the first word is capitalized, the rest all lowercase) for all titles.\nAlways capitalize:\nThe first word of a web part title or description The word following a colon in a title. For example, \u0026ldquo;Step 1: Begin by entering your account information.\u0026rdquo; Proper nouns, such as the names of people, cities, and so on. Punctuation Don’t use periods in titles. For other punctuation types, follow the basic rules of punctuation.\nVoice and tone If you want your users to fall in love with your web parts, make sure to use the right tone in your UI text. It will help build a strong, lasting relationship with your users.\nTry to keep your words crisp and clear, warm and relaxed, and approachable.\nFollow these simple tips:\nUse a casual, conversational tone in the UI. Use contractions. For example, use \u0026ldquo;can’t\u0026rdquo; instead of \u0026ldquo;cannot\u0026rdquo;. Read your UI text out loud to test the tone. Does it sound like everyday language? Use simple words. Remove technical details if they’re not relevant to the user experience. Use \u0026ldquo;Please\u0026rdquo; only if you are inconveniencing the user. Avoid overuse. Use \u0026ldquo;Sorry\u0026rdquo; only in error messages in SharePoint that result in serious problems for the customer. Pronouns Avoid pronouns if you can.\nIf you must use pronouns, follow these rules:\nUse second person (\u0026ldquo;you\u0026rdquo; or \u0026ldquo;your\u0026rdquo;) when you’re presenting something that belongs to the user. For example, \u0026ldquo;Your drafts\u0026rdquo; or \u0026ldquo;Your images\u0026rdquo;. Use the first person (\u0026ldquo;me\u0026rdquo; or \u0026ldquo;my\u0026rdquo;) for UI in which the user instructs the service to do something. For example, \u0026ldquo;Alert me when someone responds to my post.\u0026rdquo; Use \u0026ldquo;they\u0026rdquo; or \u0026ldquo;their\u0026rdquo; as a singular possessive modifier to avoid awkward \u0026ldquo;he/she\u0026rdquo; or \u0026ldquo;his/her\u0026rdquo; constructs. Ideally, rewrite the sentence as plural if possible. Avoid using \u0026ldquo;them\u0026rdquo;; instead, use words like \u0026ldquo;someone\u0026rdquo; or \u0026ldquo;people\u0026rdquo;. For example, \u0026ldquo;Enter a user name and domain to give someone permission to use this PC.\u0026rdquo; If you want to sound really cold and snobby, use third person references. Instead of saying \u0026ldquo;Users can change the layout\u0026rdquo;, use a phrase like \u0026ldquo;You can change the layout\u0026rdquo;.\nHint text Hint text, or ghost text, is the text element you display in a UI element to help the user interact with the UI.\nIn the case of titles and descriptions, your hint text is your placeholder attribute. It should give information about what the user should enter.\nYou should try to use hint text sparingly, and only if it helps the user. Because titles and descriptions are not usually visible on a web part if they are empty, this is an instance where you should definitely use hint text.\nConclusion This post described how to add titles and descriptions to your web parts in accordance with the SharePoint Design Principles.\nIn future posts, I’ll explain the other design areas… but since the other design areas are a bit more complicated, I’ll break each down into a few smaller posts.\nI hope this helps?\nThanks This post wouldn’t have been possible without the amazing work from the SharePoint team. The technical writers don’t often get the glory, so we should especially thank Linda Caputo and David Chestnut for their contributions.\nMore Information I could have gone on for days about some design topics in this article, but I’ll let the actual experts do the talking:\nSerra, M. \u0026amp; Muzio, J. (2002). The IT support for acquired brain injury patients: The design and evaluation of a new software package. Proceedings of the 35th Hawaii International Conference on Systems Sciences – 2002. Jiwnani, K. (2001). Designing for users with cognitive disabilities. Universal Usability in Practice. [online] Available: http://www.otal.umd.edu/uupractice/cognition/ Hudson, R., Weakley, R. \u0026amp; Firminger, P. (2005). An accessibility frontier: Cognitive disabilities and learning difficulties. Webusability – Accessibility and Usability Services. Online [available]: http://www.usability.com.au/resources/cognitive.php Brewer, J. (Ed.). (2005). How people with disabilities use the web: Working group internal draft, 5 May 2005. W3C. [online] Available: http://www.w3.org/WAI/EO/Drafts/PWD-Use-Web/ Nielsen, J. (2005). Lower-literacy users. Alertbox. [online] Available: http://www.useit.com/alertbox/20050314.html DL (2003a). Making materials useful for people with cognitive disabilities. Southwest Educational Development Laboratory (SEDL) Research Exchange Newsletter, 8(3). Online [available]: http://www.ncddr.org/du/researchexchange/v08n03/2_materials.html Branigan, C. (2003). New study reveals 187 key web design rules. eSchool News. Online [available]: http://www.eschoolnews.com/news/showStory.php?ArticleID=4772 Rowland, C. (2004). Cognitive disabilities part 2: Conceptualizing design considerations. Webaim – Accessibility in Mind. [online] Available: http://webaim.org/articles/cognitive/conceptualize/ Web Part Title PnP Reusable Control: https://sharepoint.github.io/sp-dev-fx-controls-react/controls/WebPartTitle/ ","permalink":"http://localhost:1313/posts/sharepoint-framework-design-series-web-part-titles-and-descriptions/","tags":["SPFx"],"title":"SharePoint Framework Design Series: Web Part Titles and Descriptions"},{"categories":["SharePoint"],"contents":"Introduction Sometimes you just need to figure out what version of the SPFx Yeoman generator is installed on someone’s machine.\nI got tired of having to look it up all the time, but I can never find the command (probably because it is too obvious for most people to write it down?).\nSo here is a note for myself, but I hope it helps somebody else too one day.\nGetting the version number To find the version of your SPFx Yeoman generator, follow these steps:\nLaunch a Node.js command prompt command or whatever terminal you use\nType the following command:\nnpm ls -g --depth=0 @microsoft/generator-sharepoint Wait…\nThe response should look a little like this:\nThe command isn’t specific to the SPFx Yeoman generator. It can be used for any NPM package. Here is what it really does:\nnpm indicates a Node Package Manager command. ls means to list packages -g means that you want to list the global packages. If you don’t use -g, you’ll only list the packages installed in the current solution (assuming that you’re currently in a folder that contains a solution) --depth=0 means that you only want the top-level modules. In other words, you don’t want to list all modules that includes the package you’re looking for. @microsoft/generator-sharepoint is the actual package you want to list. You can actually put whatever package you want here. For example, npm ls -g --depth=0 yo would tell you what version of the Yeoman generator is globally installed, and npm ls --depth=0 office-ui-fabric-react would tell you what version of Office UI Fabric React is currently installed in your current solution. How to check if Yeoman has an update for you As Stefan Bauer pointed out, if you don’t want to know which version of the SPFx Yeoman generator you have installed, but you want to see if there is an update, you can follow these steps:\nLaunch a Node.js command prompt command or whatever terminal you use\nType the following command:\nyo Yeoman will greet you. If you have an update available, Yeoman should tell you right away (see how my Office generator has an update in the screen shot below)\nSelect Update your generators\nYeoman will prompt you to select the generators you want to upgrade. Use the spacebar to toggle which generators you want to update, then press Enter\nYeoman will do its thing, then will tell you I’ve just updated your generators. Remember, you can update a specific generator with npm by running npm install -g generator-______. Good to know Yeoman, good to know.\nConclusion This article shows you how you can use a standard NPM command to query what version of the SPFx Yeoman generator is installed on a workstation.\nYou can use the same command for any NPM package, but in my particular case, I just wanted to remember how to diagnose the version of the SPFx Yeoman generator.\nThere may be an easier/faster way to do this. If you know a different way, please share with the rest of the class.\nI hope it helps?\nUpdate Thanks to Stefan Bauer (https://n8d.at/) for confirming that there aren’t any faster ways to do this, and for also suggesting that I explain how the command works. The section about using yo to update your generators was also his idea. Stefan is someone that I respect immensely and I truly appreciated his feedback! ","permalink":"http://localhost:1313/posts/how-to-tell-what-version-of-the-spfx-yeoman-generator-is-installed/","tags":["SPFx"],"title":"How to tell what version of the SPFx Yeoman generator is installed"},{"categories":["SharePoint"],"contents":"Introduction In my last two posts, I covered how to use the SharePoint Get items action in Flow and how to tell if the SharePoint Get items action returned items (by counting them).\nI really wanted to provide a real-life sample how one would use the two concepts together in Flow.\nSince we just had a national holiday and I completely forgot about it (got ready to go to work and everything), I thought I’d create a sample flow that automatically runs on a schedule and prompts users to do something, except when today’s date is a holiday.\nThe workflow logic looks a little like this:\nst=\u003estart: Start (every n days)\re=\u003eend: End\rop2=\u003eoperation: Get today's date\rop3=\u003eoperation: Find statutory holidays\rwith today's date\rop4=\u003eoperation: Today is not a holiday\rsub1=\u003esubroutine: (Do something)\rcond=\u003econdition: Is today a holiday?\r(Did you find any items)\rio=\u003eoperation: Today is a holiday\r(Do nothing)\rst-\u003eop2-\u003eop3-\u003econd\rcond(yes)-\u003eio-\u003ee\rcond(no)-\u003eop4-\u003esub1-\u003ee\rLet’s get started by creating the environment we need for this workflow.\nCreating a list of statutory holidays In this example, we’ll create a SharePoint list which will contain an entry for every statutory holiday. We’ll use a list because it allows our HR folks to maintain it without needing a special app. We can also show the list on our SharePoint site so all employees can see what days are statutory holidays.\nYou can also use your own database, or an API, or even a static Excel spreadsheet if you want, but I wanted to use a SharePoint list to show how to use the SharePoint Get items action in Flow.\nTo create the list, follow these steps:\nFrom a SharePoint site, go to Site contents via the local navigation or the Settings option. In the Site contents, select + New then choose List from the drop-down menu. In the Create list pane, enter Statutory Holidays as the list’s Name. Check or uncheck Show in site navigation depending if you want your users to see the list or not. Select Create to create the list In your newly created list, select + Add column then select Date from the drop-down list. In the Create a column pane, enter Date for the column Name. Set Include time to No and select Require that this column contains information to Yes under More options. This list doesn’t make much sense if you don’t require a date for each stat holiday. Select Save to create the column. If you need to support statutory holidays for multiple states/provinces/countries, feel free to add more columns to your list to support your needs. I wanted to keep this list as simple as possible.\nWhy didn’t I use a calendar list? I didn’t want to add the extra columns that come with a calendar list. If you really want a calendar view, just add it as a custom view for your list.\nUse your list’s Quick edit to enter your statutory holidays. I use this site to get the list of statutory holidays for every year.\nWhen you’re done, you should have a list that looks like this:\nNow let’s create a scheduled flow that uses the list!\nCreating a scheduled flow From https://flow.microsoft.com, go to My flows to view your list of flows. From the + New menu, select Scheduled–from blank In the Build a scheduled flow window, give your flow a descriptive Flow name. I named mine Prompt managers to approve timesheets. Under Run this flow, select the schedule that suits your needs. I want mine to go once a week on Mondays, so I selected 1 week under Repeat every, then selected M under On these days and unselected every other day.\n. Select Create to create your workflow. Your workflow will be created and open in the workflow editor. I renamed the Recurrence action to Every Monday because I always want my workflows to be easy to understand without having to expand every action.\nUnfortunately, Flow won’t let you save until you add another action.\nFunny, cause that’s exactly what we’ll do next!\nConnecting to the Statutory Holiday SharePoint list Before we can access the Statutory Holidays list in SharePoint, we need to add a connection to SharePoint by following these steps:\nFrom within your flow editor, select +New step at the bottom of the flow.\nIn the Choose an action prompt, type Get items in the Search connectors and actions. Search is case insensitive.\nSelect the Get items action with a SharePoint logo from the list of Actions that appears. If the search query returns too many actions and you can’t find the SharePoint Get items, you can filter out all other connectors by clicking on SharePoint just below the search bar.\nAs soon as you select Get items, the Choose an action box will transform into the Get items box.\nIf you haven’t created a connection to SharePoint yet, you’ll be prompted to Sign in to create a connection to SharePoint. Click Sign in to sign in with the account that you wish to use to access SharePoint.\nThe account you use here specifies who will access SharePoint. Make sure that you use an account that can see the site and the list where you want to get items from. It is a good idea to use a service account that isn’t using your own credentials to connect.\nOnce connected, enter URL to the site that contains your list under Site address. If you experience problems typing or pasting the URL, try selecting Enter a custom value from the drop-down; it will turn the drop-down box into a text box.\nIf the site URL you entered is valid and the credentials you supplied are correct, you should be able to pick the Statutory Holidays list from the List Name drop down.\nAdding a filter to retrieve today’s statutory holidays If you ran the flow now, it would retrieve every statutory holiday in the list.\nWe want SharePoint to return only statutory holidays on the days the flow runs. To do this, we’ll add an ODATA filter by following these steps:\nIn the new Get items action you just created, select Show advanced options In the Filter Query field, enter Date eq datetime''. Place your cursor between the two single quotes you just typed and select Add dynamic content Select the Expression tab Scroll to the Date and time category and select See more, then select formateDateTime(timestamp, format) to insert it in the expression field. Making sure your cursor is between the two parentheses of the formatDateTime function, find the utcNow() function in the Date and time category. After utcNow() but before the last ), type ', 'yyyy-MM-ddT00:00:00') and select OK to insert the expression. In the Top Count field, enter 1 — we only need to know if there is a statutory holiday or not, so we don’t need to return more than one. In the Limit Columns by View, select All Items. This will ensure that we only return the Title and Date columns, instead of returning every single column in the list.\nIf you want to test your flow, save it and use Test in the upper right corner. You can add a temporary list item in your statutory holidays list with today’s date to see that SharePoint returned something.\nIf everything goes well, your flow is now able to retrieve statutory holidays from the SharePoint list every time your flow runs.\nNow let’s add logic to detect whether something was returned or not…\nBut before we do, let’s rename the Get items action to Retrieve statutory holidays for today’s date to make it easier to read. Hey, my blog, my naming conventions 🙂\nCount how many statutory holidays were returned for today’s date As I explained in my previous post, I like using variables to make my flows easier to debug and easier to understand. We’ll store the number of items returned in a variable called Number of statutory holidays.\nSince this is the first time we set the variable, we’ll use Initalize variable using the following steps:\nIn the flow editor, select +New step\nFrom the Choose an action box, type variable in the search box.\nFrom the list of suggested actions, select Initialize variable.\n4.An Initialize variable box will replace the Choose an action box. Give your variable a descriptive Name. For example: Number of statutory holidays.\nIn the Type field, select Integer — because we’ll be storing the number of items returned.\nWe’ll write the expression to calculate the number of items returned the Value field. If the dynamic content pane doesn’t show, select Add dynamic content, the select Expression.\nLook for the length(collection) function in the Collection category and select it to insert it in the expression box. The length function is specifically designed to calculate how long a collection of items is — and that’s what the Get items action returns: a collection of items.\nMake sure your cursor is positioned between the two parantheses () in the length function. Select the Dynamic content tab and look for the value dynamic content for the Retrieve statutory holidays for today action.\nFlow will automatically insert body('Retrieve_statutory_holidays_for_today''s_date')?['value'] inside your length() function. The final expression should be:\nlength(body('Retrieve_statutory_holidays_for_today''s_date')?['value'])\rSelect OK to insert the value.\nSave and test your flow. Mine returned 1 item:\nTesting if any items were returned Now that you have a variable that contains the number of statutory holidays, you can use it anywhere you want.\nLet’s create a conditional branch to do something if today is not a statutory holiday:\nIn the flow editor, select +New step From the Choose an action box, select Control then Condition. A Condition box will replace the Choose an action box. Give your condition a descriptive name. For example: Is today a statutory holiday. If the Choose a value box, use Add dynamic content to select the variable you created earlier. In the next field, select is greater than In the next field (Choose a value) enter 0.\nSave and test your flow. If everything worked well, the Expression value from your condition should return true if SharePoint found items, and false if nothing was found. My test returned true.\nThat’s it! Now you can insert actions under If no to do something when today isn’t a statutory holiday.\nYou could even add something under If yes to delay the flow until next day, but that’s another post.\nConclusion You can use Scheduled flows to run every n days and easily query a SharePoint list containing statutory holidays to skip running when the current date is a statutory holiday.\nNote that in today’s sample, I didn’t deal with timezones by setting the start time of my workflow so that it is later than midnight in UTC time. If you run your workflow across multiple timezones, you should keep this into consideration.\nI hope this helps you create workflows that know when to take it easy.\nBecause everyone deserves a vacation once in a while!\nPhoto credits Image by Free-Photos from Pixabay\n","permalink":"http://localhost:1313/posts/configuring-scheduled-flows-to-skip-holidays/","tags":["Power Automate"],"title":"Configuring scheduled Flows to skip holidays"},{"categories":["SharePoint"],"contents":"Introduction Anyone who has worked with me on a SharePoint project knows that I firmly believe that a good custom web part must be indistinguishable from the out-of-the-box SharePoint web parts. They need to look and behave like they were written by whichever awesome team at Microsoft is responsible for writing those things.\nSomeone at Microsoft must feel the same way as I do because they took the take to create a nice SharePoint Design web site dedicated to the SharePoint design principles; not just for web parts, but for sites and pages as well.\nIf you haven’t visited it yet, I encourage you to do so now. Go ahead, I’ll wait.\nI like that Microsoft is documenting their design principles for web part look and feel, but they do not explain how to achieve the awesome look they show.\nThat’s why I’ve created this series of posts on how to build SharePoint web parts, using SPFX, that follow the Microsoft design principles. Each post is intended as a companion to their respective section in the SharePoint Design site.\nAt the end of this series, you’ll be able to build beautiful web parts that will conform to Microsoft’s design principles and that will be indistinguishable from the out-of-the-box web parts.\nIn other words, the perfect web part.\nWhy should I follow Microsoft’s design principles for SharePoint web parts? Luke Wroblewski, a Product Director at Google once wrote:\n“Getting in the way of a speeding freight train usually doesn’t end well. It takes a lot of effort to shift the course of something with that much momentum. Rather than forcing people to divert their attention from their primary task, come to where they are.”\nEvery web part with custom styles, fonts, and designs that are hosted within a page competes for your user’s attention — in a bad way. You’re asking your users to learn a new user interface with every custom-layout web part you create.\nInstead of focusing on your content, your users have to struggle just to make sense of your user interface.\nIn UX (user experience) circles, that’s a concept called Cognitive overload.\nCognitive overload is often caused by overstimulation. If you want a good example of overstimulation, go visit LingsCars.com and notice how you’ll have to struggle to take in all the information on that page.\nLingsCars.com\nIn user experience, it is often said that:\nThe best user experience is the one the user doesn’t notice\nIn SharePoint, your users are already familiar with the web part user interface and layout. They know where to look for the \u0026ldquo;Show all items\u0026rdquo; option, or what happens when they click on the pencil icon.\nIn this awesome article on cognitive load, they say that a way to reduce cognitive overload is to Follow time-proof conventions:\nDon’t reinvent the wheel. Users don’t wanna take another driving lesson.\nDana Kachan\nFollowing the SharePoint design principles for web parts is to follow an existing convention established in SharePoint and Office 365.\nBuilding trust Many years ago, I was working with a brilliant developer. Well, he did all the work while I attended meetings and demoed all his hard work, pretty much.\nOne day, he figured out a problem to a very difficult issue. I can’t remember what it was, but it was one that most people we talked to said that it couldn’t be solved.\nWhen he demoed it to me, I was impressed, and I told him so. But then I pointed out that he was using the wrong font and colors, and that there was a spelling mistake on his screen.\n(I’m talking comic sans with italic and ugly green fonts. Yuck!!!)\nHe was shocked. He had just solved an impossible problem and I was complaining about a minor user interface issue?!!?\nI explained to him that when we’ll demo his code to the client — who has no appreciation for how complicated the issue was and how amazing the solution was — all he will see is the ugly fonts, colors, and spelling mistakes. Instead of seeing a professional-looking solution, he’ll see something that looks amateurish. It will break — or at least chip away at — the trust he has in us.\nA more recent example of this is when Game of Thrones was in its last season, people got really upset about a coffee cup that was visible in one of the scenes.\nEverybody knows that Game of Thrones was not really filmed in a fantasy time where dragons existed, right?\nSo why did people get upset?\nBecause the coffee cup that was carelessly forgotten in a shot chipped away at people’s trust and respect for what was otherwise a beautifully produced show. It happened in the last season of the show when people were starting to criticize the writing and the rushed pace of the final episodes, and many people couldn’t overlook it.\nWhen you design your own look and feel within SharePoint, you’re also chipping away at your user’s trust.\nWho should read this series? If you’re a designer who’s anti-Microsoft and says \u0026ldquo;SharePoint looks like crap\u0026rdquo; and \u0026ldquo;I can do a better job myself\u0026rdquo;, you’re absolutely right. You don’t need to read this series of blog posts.\nIf you’re a developer who is new or somewhat experienced with creating SPFx web parts, but typically doesn’t pay attention to how your web parts look — as long as they work, you may find this series of posts useful.\nNext article Join me tomorrow for the first real article in the series: Web Part Titles.\n","permalink":"http://localhost:1313/posts/introducing-the-sharepoint-framework-design-series/","tags":["SPFx"],"title":"Introducing the SharePoint Framework Design Series"},{"categories":["SharePoint"],"contents":"Introduction In my previous post, I explained how to use the SharePoint Get items action in Flow. As the name implies, it retrieves items from a SharePoint list.\nSometimes you need to know if your Get items action returned any items. For example, if you wanted to update an existing item or create a new item in none was found.\nIn this post, I’ll show you how to count how many items were returned by SharePoint and how to test if any items were found.\nAnd don’t worry, this post won’t be as long as the last one.\nCounting results from SharePoint Get items For the purpose of this example, we’ll assume that you already created a flow with a SharePoint Get items action. If you haven’t done so yet, take a look at my previous post.\nWhen I have to use fancy formulas in many places within my flow, I like to define a variable. That way, I can just refer to the variable instead of re-entering the formula in many places.\nYou should always strive to make your flows easy to read so that if someone else has to maintain it (or if you have to come back to it later), it will be easy to understand what the flow does. Make sure to give your actions a descriptive name (not Get items like in my example, use something like Get existing responses from current user, for example). Using variables is another way to make your flows easier to use.\nWhen using variables in flow, you use a different action to define a variable the first time (Initialize variable) than you would to set the variable or change its value (Set variable, Increment variable, and Decrement variable for example).\nSince this is the first time we set the variable, we’ll use Initialize variable using the following steps:\nIn the flow editor, select +New step\nFrom the Choose an action box, type variable in the search box.\nFrom the list of suggested actions, select Initialize variable.\n4.An Initialize variable box will replace the Choose an action box. Give your variable a descriptive Name. For example: Number of existing items.\nIn the Type field, select Integer — because we’ll be storing the number of items returned.\nWe’ll write the expression to calculate the number of items returned the Value field. If the dynamic content pane doesn’t show, select Add dynamic content, the select Expression.\nLook for the length(collection) function in the Collection category and select it to insert it in the expression box. The length function is specifically designed to calculate how long a collection of items is — and that’s what the Get items action returns: a collection of items.\nMake sure your cursor is positioned between the two parantheses () in the length function. Select the Dynamic content tab and look for the value dynamic content for the Get items action (or whatever your SharePoint Get items action is called).\nFlow will automatically insert body('Get_items')?['value'] inside your length() function. The final expression should be:\nlength(body('Get_items')?['value'])\rSelect OK to insert the value.\nSave and test your flow. Mine returned 1 item:\nTesting if any items were returned Now that you have a variable that contains the number of items, you can use it anywhere you want.\nFor example, if you wanted your flow to do something if any items were returned, and something else if nothing was returned you would follow these steps:\nIn the flow editor, select +New step From the Choose an action box, select Control then Condition.\nA Condition box will replace the Choose an action box. Give your condition a descriptive name. For example: Are there any existing items.\nIf the Choose a value box, use Add dynamic content to select the variable you created earlier. In the next field, select is greater than In the next field (Choose a value) enter 0\nSave and test your flow. If everything worked well, the Expression value from your condition should return true if SharePoint found items, and false if nothing was found.\nOf course, you would want to add actions to your If yes and If no paths, but that’s for another post.\nConclusion The key to testing if the SharePoint Get items action returned items it to understand that Get items returns a collection of items. Using the length() function against the return value of your Get items action will tell you the length of your collection of items.\nI could have avoided using a variable and just entered the length(body('Get_items')?['value']) formula directly in the condition, but I wouldn’t be able to tell how many items were returned when I was testing the flow. This sample was an easy one, and I really didn’t need to evaluate how many items were returned more than once — so I really didn’t need a variable — but in more complicated flows, you’ll find it a lot easier to define variables and use the variables throughout instead of copying the same formula every time.\nI hope this helps?\n","permalink":"http://localhost:1313/posts/how-to-count-number-of-items-returned-by-sharepoint-getitems-action-in-flow/","tags":["Power Automate"],"title":"How to count number of items returned by SharePoint GetItems action in Flow"},{"categories":["SharePoint"],"contents":"Introduction I love Flow (and Logic Apps)!\nFavourite thing to do with Flow is doing demos and workshops!\nWhen I meet a new customer who tells me they have a business problem, I love to put together a quick proof of concept how to solve their business problem using a no-code solution, involving SharePoint, PowerApps, and Flow — right there, in front of them, while projecting. No safety nets, PowerPoint or scripted demos.\nThe SharePoint connector is by far my most frequently-used connector, because it allows me to quickly query, create, and update content in SharePoint as part of my solutions.\nEven if I have used this connector many times, I sometimes get demo blindness and I forget how to use it when I’m in the middle of a demo.\nThis article explains how to use the SharePoint connector and the GetItems action to retrieve items from a SharePoint list.\nHopefully, next time I forget how to use it in the middle of a demo, this article will show up in the search results.\nNOTE: This article focuses on Microsoft Flow, but you can use the connector in Logic Apps in (almost) the same way, and PowerApps with these instructions.\nCreating a Test Flow For this article, we’ll assume you want to connect to SharePoint to get one or more items in a list from within an existing Flow.\nIf you already have an existing flow you can use to follow along, go ahead and skip to the next section.\nIf you don’t have an existing flow, let’s create a Flow that you can manually trigger by following these steps:\nFrom https://flow.microsoft.com, navigate to My Flows. Select New then Instant — from blank to create a flow that we’ll be able to trigger at any time to test. Feel free to use any other type of flow here.\nIn the Build an instant flow dialog, enter a Flow name and select From Microsoft Flow when prompted Choose how to trigger this flow and select Create.\nYour new flow will be created. Note that you need to insert at least one step before you can save or test it.\nGood thing that’s what we’re doing next!\nAdding a SharePoint connection Before we can access SharePoint items, we need to add a connection to SharePoint by following these steps:\nFrom within your flow editor, select +New step at the bottom of the flow. You can also click on the + button that appears between two existing flow steps.\nIn the Choose an action prompt, type Get items in the Search connectors and actions. Search is case insensitive.\nSelect the Get items action with a SharePoint logo from the list of Actions that appears. If the search query returns too many actions and you can’t find the SharePoint Get items, you can filter out all other connectors by clicking on SharePoint just below the search bar.\nAs soon as you select Get items, the Choose an action box will transform into the Get items box.\nIf you haven’t created a connection to SharePoint yet, you’ll be prompted to Sign in to create a connection to SharePoint. Click Sign in to sign in with the account that you wish to use to access SharePoint. If your instance of SharePoint is on-prem, you can check Connect via on-premises data gateway — but that’s for another post.\nThe account you use here specifies who will access SharePoint. Make sure that you use an account that can see the site and the list where you want to get items from. It is a good idea to use a service account that isn’t using your own credentials to connect.\nOnce connected, enter URL to the site that contains your list under Site address. If you experience problems typing or pasting the URL, try selecting Enter a custom value from the drop-down; it will turn the drop-down box into a text box.\nIf the site URL you entered is valid and the credentials you supplied are correct, you should be able to pick the list you want to use from the List Name drop down. In my example, I only have one list called Parking Lot Passes.\nIf you get a GUID in your List Name instead of a friendly name, make sure that the connection you’re using has permissions to access the list. You can change the connection by selecting the elipsis (***) at the top of the Get items box and using the My connections section to change or add a new connection.\nLet’s test it!\nSelect Test from the top toolbar. If it is disabled, you may need to Save it first.\nFrom the Test Flow pane, select I’ll perform the trigger action and select Save \u0026amp; Test.\nThe Run Flow dialog will prompt you to confirm the conneciton information. Make sure everything is correct and select Continue\nOnce you confirmed the connection, you’ll get prompted again. It usually only happens the first time you create or change a connection. Select Run flow.\nIf everything went well, you should see Your flow run successfully started. Select See flow run activity to see if everything went well.\n. You’ll get a Run history for your flow, usually sorted by newest at the top. Select the top (and most likely only) one by clicking on the start time.\nFrom your flow history page, you should see green checkmarks next to every step in your workflow. If you get a red x, check your connection information.\nClick on the Get items action to see what SharePoint returned. You want to see a 200 Status code, and a Body that returns value items.\nYou now have a connection to your SharePoint list. Now let’s add a filter to get only the items you want from the list.\nBuilding an ODATA filter For this article, I’ll use a list I had created for a Park Pass request application. It has a Text column called Make, a Person column called RequestedBy, and Date and Time columns called From and To. You can use whatever list you want in your workflow.\nPro Tip: when creating a column that has a space (or any other funny characters) in the name, create the column without the space first, then rename it with a space. That way, you’ll avoid funny column names like Requestedx20By. In my example the Requested By, was created as RequestedBy (no spaces) first, then renamed it to Requested By.\nThe Get Items action allows you to specify an ODATA filter query to filter returned items from a list. To specify a filter, select Show advanced options from the Get items action.\nIf you aren’t familiar with ODATA filters, you can read the article about using ODATA query operations in SharePoint REST requests, or read below to find how I build my ODATA filters.\nIn most cases, you can write your query as [columnname] [operator] [value]. Where [operator] is one of the following keywords:\nLt: Less than Le: Less than or equal to Gt: Greater than Ge: Greater than or equal to Eq: Equal to Ne: Not equal to For example, to retrieve all cars where the Make is Canyon Arrow, you would write:\nMake eq 'Canyon Arrow`\rIf you wanted to retrieve any Make but the Canyon Arrow, you would write:\nMake ne 'Canyon Arrow`\rIf you can’t figure out why your ODATA filter doesn’t work, here is a mostly foolproof way to build your ODATA filter:\nUsing your browser, navigate to: [https://[yourtenant].sharepoint.com/sites/%5Byoursite%5D/_api/lists/getbytitle('%5BYour](https://yourtenant/sites/%5Byoursite%5D/_api/lists/getbytitle('%5BYour) list title']). For example, my if my tenant is ashbay16, my site is TestPowerApps and my list is titled Parking Lot Passes, my URL would be:\nhttps://**ashbay16**.sharepoint.com/sites/**TestPowerApps**/_api/lists/getbytitle(‘**Parking%20Lot%20Passes. If you entered the right URL, you should see information about the list in XML format. Add /fields at the end of the URL you created in step 1 to get all the fields names in your list. For example, my URL is now https://ashbay16.sharepoint.com/sites/TestPowerApps/_api/lists/getbytitle(‘Parking%20Lot%20Passes’)/fields You may want to use an XML editor (like Visual Studio Code) to view the XML results from the previous step. Find the field you want to filter on by searching the XML file for the field title. While you’re looking at the XML definition for the field, take a look at the d:Filterable node to see if it is filterable (it should be true). Also, take a look at the d:TypeAsString node to see what type of field you’re dealing with. Finally, look at d:EntityPropertyName — that’ll be how you refer to that field in your filter. For example, to filter by Approval Status, you would use OData__ModerationStatus. Note that the column names are case sensitive. Look at the ODATA query syntax chart below to see what possible filter you can use to build your filter. I’ve grayed out the parts that don’t apply below:\nDepending on your field’s d:TypeAsString, you can use the following queries: Text: lt, le, gt, ge, eq and ne, plus startswith() and substringof(). For example, substringof('S', Model) will return all entries where the Model column contains the letter S. Note that the field name is the second parameter with substringof and startswith. Number: lt, le, gt, ge, eq or ne DateTime: day(), month(), year(), hour(), minute(), second(). You can also use datetime to compare a date. For example SubmittedDate gt datetime'2019-06-14T00:00:00' to get items where the SubmittedDate column is greater than June 14, 2019. User: Use lt, le, gt, ge, eq and ne, plus startswith() and substringof() to evaluate against the user’s display name, or specify the user’s attribute. For example: RequestedBy/EMail eq 'hugo.bernier@contoso.com' to find items where the email address of the RequestedBy user is hugo.bernier@contoso.com. Test your filter in your browser by replacing /fields with /items?$filter=[yourfilter]. For example, if my filter is Make eq 'Canyon Arrow', my URL would be [https://ashbay16.sharepoint.com/sites/TestPowerApps/_api/lists/getbytitle('Parking%20Lot%20Passes\u0026amp;#039](https://ashbay16.sharepoint.com/sites/TestPowerApps/_api/lists/getbytitle('Parking%20Lot%20Passes\u0026amp;#039);)/items?$filter=Make%20eq%20%27Canyon Arrow%27. Notice that when I type spaces and single quotes, the browser will url encode the values for me — meaning Canyon Arrow becomes Canyon%20Arrow. Once you have built your ODATA filter, add the filter to your Get Items action.\nSpecifying the ODATA filter Now that you have your ODATA filter, go back to your flow and:\nSelect Show advanced options on your Get items action. In the Filter Query enter your ODATA filter. For example, I entered Make eq 'Canyon Arrow'\nSave and test again. Your results should now be filtered!\nSpecifying a dynamic ODATA filter Flow allows you to enter dynamic values pretty much anywhere. Let’s say we wanted to filter items that were previously submitted by the user who triggered the workflow.\nIn your Get items action, make sure that the advanced options are showing. If not, select Show advanced options. In the Filter Query field, enter SubmittedBy/EMail eq '' Position your cursor between the two single quotes and select Add dynamic content to show the list of possible dynamic values you can use. From the list of dynamic content, find User Email from the Manually trigger a flow category\n. Save and test your workflow. Note, you could also have simply used SubmittedBy eq '[User name]' from the dynamic content list, but I specifically wanted to compare by email in this example.\nYour results should contain only items that were submitted by you (since you triggered the workflow).\nDealing with results from Get Items The SharePoint Get Items action always returns an array of items — whether it found 1 record, zero records, or a whole bunch of records.\nIf you insert a new action that uses the results from Get Items, Flow will automatically wrap the action in a loop, iterating through each record that was returns from Get Items.\nFor example, let’s pretend we wanted to email the person who submitted every SharePoint list item where the To column contains a date that is earlier than today (or utcNow() in Flow). You would first set your query as follows:\nIn the Get items action, enter To lt datetime'' in the Filter Query field. Place your cursor between the two single quotes. This time, instead of using Dynamic content, select the Expression tab. In the list of possible expressions, select utcNow() from the Date and time category. Between the parentheses, type 'yyyy-MM-ddTHH:mm:ssZ'. Your final expression should be utcNow('yyyy-MM-ddTHH:mm:ssZ'). Click Update to insert your expression.\nImmediately below the Get items action, select +New step and insert a Send an email action from the Office 365 Outlook group.\nIn the newly inserted Send an email action, select the To field and use Add dynamic content to select Requested by Email (or whatever field you want) from your Get items action. You’ll notice that as soon as you select dynamic content from the Get items action, Flow converts your Send an email into an Apply to each loop.\n. Finish writing your test email and test your workflow. (Be careful that you don’t send emails to a whole bunch of people, they might not appreciate it!). Caution: Throttling When using the SharePoint Get items action, your Flow may get throttled (i.e.: slowed down) if you exceed more than 600 calls within 60 seconds. You may want to keep that in mind when designing your flow.\nConclusion In this long post (too long!), I explained how to use the SharePoint Get items action within Flow.\nThere is still a lot to cover (for example, how to detect if any items were returned, how to reduce chances of throttling by specifying the columns to return and the number of items to return, etc.), but I hope that you’ll be able to get started using Get Items.\nHave fun!\n","permalink":"http://localhost:1313/posts/using-the-sharepoint-getitems-action-in-flow/","tags":["Power Automate"],"title":"Using the SharePoint GetItems action in Flow"},{"categories":["SPFx"],"contents":"Introduction I think that custom SharePoint web parts should always look like they belong to SharePoint; I want my users to be unable to tell my custom web parts from the ones that come out-of-the-box (O.O.B.) with SharePoint. I think that it helps users by presenting a common interface that they are already familiar with.\nSometimes, I’ll even go as far as examine the HTML, CSS and even analyze the network traffic an O.O.B. SharePoint web part produces to make sure mine behave consistently.\nWhen testing a SharePoint web part on the SPFx workbench, analyzing network traffic using your web browser’s developer tools can get pretty overwhelming; there are so many telemetry calls every few seconds that it becomes impossible to figure out what calls are real API calls, and which ones are telemetry calls.\nFor example, I added a test web part on my workbench page and refreshed the page, then took a screenshot of the number of telemetry calls the page made (non-telemetry calls are greyed out):\nI left the page running while I wrote this introduction, and took another screenshot of the network traffic the page logged; this is what it looks like now:\nThe page is filled with telemetry calls! Every little tick in the timeline pane above the list is a telemetry call.\nFortunately, you can temporarily disable telemetry while you’re debugging your web parts on the SPFx workbench!\nWhat is telemetry SPFx uses telemetry to collect measurements (such as performance and usage) and automatically sends that data at regular intervals automatically. It normally does not affect performance and can be quite useful to the Engineering team to detect (and resolve) potential issues.\nWhen using your browser’s developer tools, on the Network tab, you can see a bunch of harmless Ajax calls to a link that looks like: https://spoprod-a.akamaihd.net/files/sp-client-prod_2019-06-21.008/3.vendors~sp-client-telemetry-aria_d335ca85ff1f5f8fcce5.js\nDisableTelemetry=true If you want to debug a web part on your SPFx workbench (https://localhost:5432/workbench or https://yourtenant.sharepoint.com/_layouts/15/workbench.aspx ), you can simply append ?disableTelemetry=true to the your query string to temporarily disable telemetry calls.\nNotice how there are no more telemetry calls on my page’s network traffic below? No more regular dots in the timeline means no more regular Ajax calls.\nThat’s all!\nConclusion Telemetry can be super useful, but sometimes it can be annoying — especially when you’re trying to analyze a page’s network traffic.\nThe disableTelemetry=true query string parameter only seems to work on SPFx workbench pages, but that’s fine with me.\nI hope it helps you?\nImage Credit Image by swooshed from Pixabay\n","permalink":"http://localhost:1313/posts/disabling-telemetry-network-traffic-on-spfx-workbench/","tags":["React","SPFx"],"title":"Disabling Telemetry network traffic on SPFx workbench"},{"categories":["SharePoint"],"contents":"Introduction Sometimes, you need to create a view in a SharePoint list where the items are sorted using a custom sort order. For example, if you had a list of items that needs to be sorted by Rating where the possible choices are High, Medium, and Low, your list items would appear in the following order: High, Low, and Medium because SharePoint will want to sort your Rating values alphabetically.\nPoor SharePoint, it doesn’t know that you want a custom sort order!\nFirst instinct is to change the possible choices so that the list gets sorted in the right order. For example, renaming Low to 1 – Low, Medium to 2 – Medium, and High to 3 – High. It will force SharePoint to sort by category in the right order.\nBut sometimes you don’t want to change the values in your metadata just so that it sorts properly.\nThis post will explain a quick method I use to sort list items in a view using a custom sort order.\nIt is so easy, it is almost embarrassing.\nSolution All you need to do is simply add a calculated column where you assign a numerical equivalent to the column you wish to sort on.\nHere are the steps:\nFrom your list, select Add column\nWhen prompted to choose a column type, select More…\nIn the Create Column page, select a Column name that suits you. I usually call it [Choice column] Sort, where the [Choice column] is the name of the choice column you want to sort on. For example, to sort by Rating, I would call the column Rating Sort. Feel free to use whatever name you like.\nFor The type of information in this column is:, select Calculated\nLet’s skip the formula for a second, we’ll get back to it. For The data type returned from this formula is:, select Number and select 0 for the Number of decimal places\nFor the Formula, use a whatever logic you want to assign a numerical value to the item. For example, to sort Ranking, I would assign 1 to Low, 2 to Medium, and 3 to High by using the following formula:\n=IF(Rating=\u0026quot;Low\u0026quot;,1,If([Rating] = \u0026quot;Medium\u0026quot;, 2, 3))\rSelect OK to create your column.\nTest that your column is returning the right values:\nIf you’re getting the right numerical values, change your view to sort by the column you just created by going to Settings | List settings and selecting the view you want to change under Views.\nIn the Edit View page, make sure to de-select the column you created (we don’t actually want to show it!)\nScroll to the Sort section and select your new column as the sort order.\nSelect OK to save your view.\nTest your view. It should short your items sorted using your sort logic.\nConclusion I told you it was simple!\nAll you have to do is add a calculated column that calculates the sort value you want, and sort by that column!\nI hope this helped?\nMore Information The example in this post uses the IF function.\nThe IF syntax is as follows:\nIF(logical_test,value_if_true,value_if_false)\rSo, if you want to return 1 if the [Rating] column is equal to Low, otherwise return 2 you would write:\nIF([Rating] = \u0026quot;Low\u0026quot;, 1, 2)\rYou can nest IF statements too. For example, if the value of [Rating] isn’t Low, it could be Medium or High. To return the appropriate value, we nest a second IF in the first IF‘s value_if_false parameter, as follows:\nIF([Rating] = \u0026quot;Low\u0026quot;, 1, IF([Rating] = \u0026quot;Medium\u0026quot;, 2, 3))\rHowever, it’ll suck if you have a lot of choices to pick from. For example, if you wanted to sort by month, you would have to do something ugly like this:\nIF([Month] = \u0026quot;January\u0026quot;,1 , IF([Month] = \u0026quot;February\u0026quot;, 2, IF([Month] = \u0026quot;March\u0026quot;, 3, IF([Month] = \u0026quot;April\u0026quot;, 4, IF([Month] = \u0026quot;May\u0026quot;, 5, IF([Month] = \u0026quot;June\u0026quot;, 6, IF([Month] = \u0026quot;July\u0026quot;, 7, IF([Month] = \u0026quot;August\u0026quot;, 8, IF([Month] = \u0026quot;September\u0026quot;, 9, IF([Month] = \u0026quot;October\u0026quot;, 10, IF([Month] = 11, 12)))))))))))\rBut that’s ugly!\nYou don’t have to use IF to calculate your numerical equivalent. For example, I like to use FIND to find the value in a long string.\nThe FIND syntax is as follows:\nFIND(find_text,within_text,start_num)\rWhere:\nFind_text is the text you want to find.\nWithin_text is the text containing the text you want to find.\nStart_num is the character at which to start the search. If you omit it, default is 1.\nSince FIND returns the location in the string where it found the value you’re searching for, you just need to make sure your possible values are in order (and unique). For example, this is how I would sort by month:\nFIND([Month], \u0026quot;January February March April May June July August September October November December\u0026quot;)\rWhich would return 1 for January, 9 for February, 18 for March, etc.\nSure, the numbers aren’t sequential, but we don’t care, as long as they get bigger with each value!\n","permalink":"http://localhost:1313/posts/sorting-sharepoint-list-items-using-a-custom-sort/","tags":null,"title":"Sorting SharePoint List Items Using a Custom Sort"},{"categories":["SPFx"],"contents":"Introduction A while ago, I wrote an SPFx Application Customizer that allows you to insert custom CSS on your SharePoint modern pages and posted about it.\nThe solution is now a sample in the SharePoint SharePoint Framework Extensions Samples \u0026amp; Tutorial Materials repo.\nI received lots of feedback, comments and questions about the article so I decided to write an updated article to answer the most frequently asked questions.\nI have since updated the solution to SPFx 1.8 and created a simple automated deployment script to (hopefully) reduce issues.\nThis blog post walks you through how to deploy your custom CSS using the deployment scripts and use the application extender to inject custom CSS on SharePoint.\nThis blog post focuses on deploying the pre-packaged version of the application extender. The source code is available for anyone who wishes to create their own version of the solution; if you want to build your own version, I encourage you to read the README.MD in the solution’s repository.\nYou’ll need to follow 3 steps:\ngraph LR\rA[Prepare CSS] ==\u003eB(Deploy solution)\rB ==\u003e C[Activate Application Customizer]\rPrepare your CSS Fair warning: you should customize your SharePoint CSS as a last resort. If this was a feature that Microsoft wanted to support, they would have built it in already. Do not call Microsoft (or me, for that matter) to complain that your custom CSS broke your SharePoint pages.\nFirst things first, you should prepare your custom CSS by following these steps:\nUsing your favorite file editor, create a custom CSS file that meets your needs. For example, this CSS will change the feedback button’s background color to orange. .sitePage-uservoice-button { background-color: orange; } Upload the CSS file as custom.css to your Styles Library of the root site collection (i.e.: https://\u0026lt;your-tenant\u0026gt;.sharepoint.com/Style%20Library/Forms/AllItems.aspx). For example, the CSS provided above will make the feedback button appear as follows:\nIf you need help finding what CSS classes you should change, read the last update where I provide some steps.\nDeploy the solution Deploying the solution adds the application extension to your app catalog. Once the application extension is in your app catalog, you can add it to your sites — either one site at a time, or all sites at once.\nThere are two ways to deploy the solution:\nManually Using PowerShell Before you begin either, download the pre-packaged solution.\nYou will also need to know your tenant’s app catalog. The app catalog is where you can deploy custom and third-party solutions for your SharePoint tenant.\nFinding your app catalog URL If you don’t know where your App Catalog is, you can find out using the PnP PowerShell Cmdlets and running the following commands from your PowerShell console:\nConnect to your tenant (make sure to replace yourtenant with your own tenant name):\nconnect-pnponline https://yourtenant.sharepoint.com -UseWebLogin Adding -UseWebLogin will use the Office 365 browser-based login window, which is crucial if your tenant uses two-factor authentication. You can omit it if you’d like.\nGet your tenant’s app catalog URL:\nGet-PnPTenantAppCatalogUrl The URL it returns is the URL to your app catalog site collection. If it returns nothing, your tenant doesn’t have an app catalog configured. Follow these steps from Microsoft to configure your tenant’s app catalog.\nYou can get to your app catalog by selecting Apps for SharePoint in the site navigation (or selecting Distribute apps for SharePoint on the home page.\nYour app catalog should look a little like this (except that it may be empty):\nManual Deployment Upload the react-application-injectcss.sppkg you downloaded from the pre-packaged solution or drag and drop the file onto the library.\nIn the Do you trust react-application-inject-client-side-solution? dialog, select whether you want to Make this solution available to all sites in the organization or not, the select Deploy. As long as you trust me, of course.\nNOTE: as per Henry Radke’s comments on my previous post, make sure to use https:// not http:// when you upload the solution to your app catalog. Thanks Henry for the tip!\nAutomated deployment If you have not done so already, install the PnP PowerShell Cmdlets Download the DeployApplicationCustomizer.ps1 PowerShell script from the GitHub repo. You should save it in the same folder as the react-application-injectcss.sppkg you downloaded from the pre-packaged solution. Edit the DeployApplicationCustomizer.ps1 file and change line 1 to point to your tenant. You should be replacing \u0026lt;your-tenant\u0026gt; for your own tenant name. From a PowerShell console, run the DeployApplicationCustomizer.ps1 script. The script will make the extension available to all sites. You will be prompted to enter your credentials. After providing your credentials, the extension will be deployed Activate Application Customizer If you selected Make this solution available to all sites in the organization or used the automated deployment option above, the extension should already be activated for all sites.\nNOTE: It can take up to 20 minutes for the application customizer extension to activate on all sites. Be patient.\nVerifying a tenant-wide extension If you wish, you can verify that the extension is activated tenant-wide using the following steps:\nFrom your App Catalog site collection, select Site contents from the site navigation In the Site contents, select Tenant Wide Extensions From the Tenant Wide Extensions list, you should see one entry called InjectCSS\nActivating extension for a site If you wish to activate the application customizer extension on a site-by-site basis, you’ll need to use the following steps:\nDownload the EnableApplicationCustomizer.ps1 from the GitHub repo. On line 3, change \u0026lt;your-tenant\u0026gt; to your actual tenant. On the same line, change \u0026lt;your-site\u0026gt; to the site URL for the site where you want to activate the extension. The PowerShell script assumes that you uploaded the CSS as custom.css to your Styles Library of the root site collection (i.e.: [https://\u0026lt;your-tenant\u0026amp;gt](https://\u0026lt;your-tenant\u0026amp;gt/);.sharepoint.com/Style%20Library/Forms/AllItems.aspx). If you chose a different name or path, make sure to change line 1 to match the location of your custom CSS. Run the PowerShell script. You will be prompted to enter credentials. Once you provide your credentials, the application customizer extension will be activated on your site. Conclusion My InjectCSS application customizer extension allows you to inject custom CSS on your SharePoint tenant.\nRemember to use this feature responsibly; Microsoft may change the page structure and CSS classes at any time, which may break your customizations.\nThank you to all who sent me emails, tweets, GitHub issues and left feedback on my previous posts. I am always happy to help (but be prepared to get a lecture about how you should only make CSS changes as a last resort).\nI would love to see what customizations you have done. Leave some comments!\nI hope this helps?\n","permalink":"http://localhost:1313/posts/more-updates-inject-custom-css-on-sharepoint-modern-pages-using-spfx-application-extensions/","tags":["React","SPFx"],"title":"MORE UPDATES: Inject Custom CSS on SharePoint Modern Pages using SPFx Application Extensions"},{"categories":["Microsoft 365"],"contents":"Introduction Every once in a while, I write a blog post as a note to myself about something that I couldn’t find easily with the hope that next time I (or someone else in need) look for it, it’ll be easy to find.\nThis is the case with this one.\nYesterday, I was helping to set up a new Office 365 tenant for a company that has their head offices in Toronto.\nWe created some sites and used the SharePoint Online Provisioning Service but found it annoying that the time zone for every site was UTC -8. We wanted UTC -5, or Eastern Standard Time as our default time zone.\nIt’s almost as if the company that wrote this product was based in Seattle, or something.\nBut when it came time to set the default time zone, I couldn’t remember where the setting was. I’ve done it so many times before, but it was as if all my past with all the previous versions of SharePoint got mixed together. Throw in the additional confusion by considering the differences between the on-premises and online versions, and I just could not remember where it was.\nThis post is to make sure I don’t have to look it up anymore.\nFinding the setting My brain is too small to remember things that I can look up or easily deduce. The location of the setting for the default time zone for new SharePoint sites is not something easily deduced.\nI clicked around and couldn’t find the setting. It must’ve been a case of demo blindness, a condition that often occurs in professional consultants during demos where they can’t see something that it plainly in front of them.\nI eventually searched it online and found an article that Mark D. Anderson, someone I respect immensely, wrote in 2018.\nThe setting is in the SharePoint Admin Center (located at https://**yourtenant**-admin.sharepoint.com/), under Settings and Site Creation (site creation is the last setting on that page):\nIn the Site Creation pane, you’ll find Default time zone:\n.\nSelect the time zone you want and select Save.\nNote that this setting will not overwrite the time zone setting for existing sites. It will only affect new sites created after you apply the setting.\nConclusion The setting is in the SharePoint Admin Center, under Settings and Site Creation.\n","permalink":"http://localhost:1313/posts/setting-the-default-timezone-for-sharepoint-online/","tags":["SharePoint"],"title":"Setting the default timezone for SharePoint Online"},{"categories":["Community"],"contents":"Introduction I love the Office 365 Dev Community.\nMy career has been dedicated to the IT industry, and I have always been passionate about technology. I’ve spent a great deal of time sharing that passion with others through my consulting work practice, mentoring, blogging, and various speaking engagements.\nRecently, I received a very kind message from someone I worked with many years ago, thanking me for sharing my thoughts and experiences through my blog posts.\nWhen we first met, he was just getting started in IT. He didn’t know a lot about programming, but he was smart, driven and humble, and he used those gifts to drive himself to always find a solution. He was tenacious in his pursuits, he had the hallmarks of success.\nWhile we no longer work together, I have continued to check in on him from time to time. I very pleased to see that he is a very successful SharePoint guru who works with some of the most brilliant people I have ever met.\nHe deserves all the praise for his success and I am happy to have played a small role in that by giving him an opportunity to be engaged, empowered, and to expand his skills.\nHe did the rest.\nThe Office 365 Dev Community is one of those online communities that also engages and empowers their members, and gives them the opportunity to expand their skills.\nI have already written about the SharePoint Developer Community in my post titled Open Source Contributors are People Too! and talked about how people tend to take the great work the Office 365 Dev Community does for granted.\nThis blog post explains why I think the Office 365 Dev Community is awesome and why you should consider becoming part of it.\nMy SharePoint Journey This blog post isn’t about me.\nBut in order to explain the impact the Office 365 Dev Community has, I need to start with my experience with SharePoint.\nSite Server Many years ago, I had just finished an e-commerce implementation for one of the largest telecommunications providers in Canada using Microsoft Site Server.\nDuring the project, the team and I had to install (and re-install) MS Site Server many times. It was back when installing a server product required us to perform ritual sacrifices to appease the installation Gods or nothing would work.\nSite Server came with a sample site called the Knowledge Management site that seemed more appropriate for intranet implementations.\nAt the same time, Microsoft had a Web Part framework that really consisted of XML, XSLT, and VBScript. It was just a framework on its own that didn’t connect with anything else.\nBy the end of the project, we successfully implemented a cool Knowledge Management instance of Site Server and used web parts in our solution. It was really cool.\nTahoe My next opportunity came with McKinsey \u0026amp; Company, as a Senior Associate. I was hired in the e-Business Building practice with the mandate of helping the Firm advise their clients about e-commerce technologies, best practices, and their ongoing e-commerce initiatives.\nMcKinsey was famous (and still is) for their PDNet — a Lotus Notes-based knowledge-management platform that allows some of their greatest minds to share their research with other consultants within the Firm.\nAs part of an internal initiative, my team and I were tasked to research Knowledge Management (KM) best practices to see what new technologies, if any, could be used to help improve KM within the Firm.\nIt was an audacious goal. We had 6 weeks, a small team, and an office in Singapore to prepare a presentation on our findings.\nSince we were all e-Business Builders, we thought that we should build a prototype instead of a boring presentation. After all, I had just built a cool KM solution using Site Server.\nWhen we started building the solution, we found out that Microsoft was separating the \u0026ldquo;Knowledge Management\u0026rdquo; template from Site Server into a new product called Tahoe; The \u0026ldquo;Commerce\u0026rdquo; component of Site Server would become Commerce Server, at least that’s how our Microsoft rep had explained it to us.\nWe received access to an early preview of the product and engaged with two talented MS Consulting (MCS) developers, associates from the Singapore office to get started.\nHere we were, two Toronto guys, a few Singapore team members, a Californian (who still thinks that SharePoint is a fad), and a genius webmaster from Helsinki who worked insane hours to build a working prototype of something that would change our lives and our careers immeasurably.\nIf you don’t know the limits of something, there are no limits Tahoe Server was awesome. It was also the first Microsoft product that came with (almost) the entire library of source code — because it was all built using VBScript and ASP pages.\nI read the entire source code, because I could. And I’m a geek.\nWe quickly found the limitations of Tahoe Server and since we had access to the source code, we could overcome these challenges and make it do what we wanted it to do.\nSo, we added the ability for self-service site creation. We indexed Active Directory users to create user profiles with skills matrices (to make it easy to find experts on a given topic). While many of those features became available in SharePoint 2003, we had the opportunity to build our own in Tahoe.\nWe created our own replication engine to replicate our Tahoe servers between the United States, Australia and Germany, thus making sure that every user would have a fast experience using our portal regardless of where they were in the world.\nWe even got a little cheeky and added the ability to access the portal with a mobile phone using SMS and/or WAP. Because we could.\nWhen we demoed the prototype in Budapest in front of the entire e-Business Building community, they didn’t believe that it was a fully working product. They thought we had people behind the curtains helping us create a fake demo.\nGiven the success of the demo, we received approval to implement the solution on a larger scale.\nOver the next few years, we built more and more functionality for our portal. Tahoe was released as Sharepoint Portal Server 2001. Microsoft flew people from Redmond to Singapore twice to see what we were building. We moved the team to Helsinki, then Munich where our focus was operationalizing our portal.\nThe first time I went to demo our portal to the team in Munich, I took the first flight out from Helsinki so that I would get there in time for an early morning meeting.\nWhen I got in my taxi at the Flughafen München, I gave the address to the Munich office in my broken German. I had the wrong address and the wrong phone number.\nI tried calling people from the Helsinki office to get the proper address, but it was too early and the office hadn’t opened yet.\nThen, I remembered that I was coming to demo the portal and we had implemented functionality that would allow us to use text messages to query SharePoint using simple messages like \u0026ldquo;WHO person’s name\u0026rdquo;, \u0026ldquo;WHAT document name\u0026rdquo;, and \u0026ldquo;WHERE office name\u0026rdquo;. So, with taxi driver waiting and growing impatient, I nervously texted \u0026ldquo;Where Munich\u0026rdquo; to our mobile portal.\nThe response came back within seconds with the right address for the Munich office. I triumphantly gave the address to the driver who immediately said:\n\u0026ldquo;Ah! McKinsey!\u0026rdquo;\nMoving on Once we were done, the team parted ways. One of the MCS guys moved to MS Corp to build their own version of the portal (eKM/ICE). I moved back to Toronto to build a similar portal for Microsoft Canada.\nI continued to build SharePoint portals for three of the top management consulting firms globally and had the opportunity to travel all over the world to do what I loved.\nMy next challenge was to help architect and implement a large SharePoint service offering for a provincial government — with over 75,000 users and had the opportunity to implement some of the first and largest Office 365 implementations in Canada.\nShortly thereafter, Microsoft approached me to become a Microsoft Virtual Technology Specialist for SharePoint. In this role, Microsoft would introduce me to their clients as a pretend Microsoft employee to conduct workshops with their clients, where we would build a solution to their problems within less than a day live, and without safety nets.\nNone of that work would really give me the satisfaction that I really wanted, which was to contribute to the greater SharePoint community.\nUntil SPFx came about.\nSPFx and the Office 365 Dev Community I was working on a large Office 365/SharePoint project implementing a student portal for a large college. We had specific needs mobile, responsive, and accessibility, that weren’t available to us when we started. We chose to integrate the Office UI Fabric by hand into our web parts to give the site a consistent look and feel.\nAs we built the portal, we discovered that a SharePoint page loaded with dozens of custom provider-hosted SharePoint web parts was insanely slow.\nWhen I found out about this new upcoming SharePoint Framework thingy, it had the promise to resolve many of our challenges and requirements.\nFaster web parts, responsive, mobile, accessible, and with built-in support for Office UI Fabric?!?!\nEverything I wanted!\nHungry to know more about the upcoming SPFx, my team and I started attending the SharePoint Development Community calls as often as we could.\nI was always a Microsoft/.NET guy. I had always dismissed React, Node.js and GitHub as not as good because Microsoft wasn’t doing it. Now Microsoft was telling me that the new way to build SharePoint web parts would be to use React, Node.js and Typescript? And in order to find out more about SPFx, I had to use GitHub?!\nWhat the heck, Microsoft?\nI had a lot of learning to do.\nFortunately, every Office 365 Dev Community call started with 15-20 minute from Vesa and/or Patrick telling us that we could submit issues and questions in GitHub. Everyone was invited to demo cool stuff they had done. Most calls ended with Q\u0026amp;As that gave us the opportunity to ask questions.\nWhen we asked questions, our questions were given the consideration they deserved. No one was ever ridiculed for their questions. Not from the people hosting the calls, not from the guest presenters, and not from the other attendees.\nThere were even some calls where we, the attendees, were asked about our opinion!\nIt was the first time in over 20 years of working closely with Microsoft that I felt that Microsoft was actually listening.\nDemoing my first SPFx web part When SPFx was officially released and supported on SharePoint Online, our portal team had been learning SPFx and eagerly anticipated the opportunity to rebuild most of our web parts to SPFx.\nOur project was Agile/SCRUM and we delivered our code in two-week sprints. We dedicated entire sprints to converting our web parts to SPFx, forcing everyone to jump in the deep end.\nWe quickly found what worked and what didn’t. Some SPFx web parts never saw the light of the day, and some others were easily converted. We even rebuilt one web part that took a few months to build over a weekend!\nWhen we demoed what we had done to our Microsoft reps, they asked us to do the same demo to other colleges and universities.\nArmed with demoable web parts, I accepted to take Vesa and Patrick’s invitation to contribute to the SPDev calls seriously. I sent an insanely long email to them (I wasn’t actively using Twitter) and offered to demo some of the web parts we had done.\nThat was one year ago today.\nI didn’t expect to hear back from them. And I didn’t, for about two weeks. It turns out that cool people don’t use email.\nEventually Vesa sent me a response and I was scheduled for an upcoming call. My demo went okay, however the response from the attendees was amazing! I had people reaching out to me to find out how I had done this or that. Some people wanted me to share my code.\nWhat value could I add to the community, except for some cool web parts? I thought that I didn’t have anything worth blogging or tweeting about.\nContributing to the community When I said that to a friend of mine, someone who I respect immensely (except, maybe, for the fact that he insists on sprinkling Salt \u0026amp; Vinegar seasoning on his popcorn), he explained that while I may not feel like I have anything of value to share with others, there are others who are just starting with SharePoint and SPFx who may benefit from my sharing what I have learned thus far, with them.\nWith this in mind, I wrote an SPFx sample to help others with some of the problems I had experienced when I started learning SPFx, and submitted it to the Samples repo. It was nothing amazing or earth-shattering, it was just a simple example of how to solve a small problem.\nMy sample got accepted.\nThen I demoed it on a call.\nAnd I found that, as my friend with the nasty pop-corn habit had predicted, other people did benefit from my contribution.\nI built more samples based on solutions to challenges I had encountered when I started with SPFx and submitted them. They were always graciously accepted. Every time I demoed one of them, the community was always insanely supportive and kind.\nGaining confidence in the community, I wrote some PnP reusable controls that I wished were available, fixed some mistakes in the documentation, and added a very small command to the Office365-CLI. (In fact, my RichText control was just released today!)\nNo matter how small my contributions were, they were always welcome.\nAny time I wasn’t sure how to contribute, there was someone who was willing to help. If I made a mistake, nobody made me feel small or insignificant.\nEveryone was always gracious and supportive.\nMost of my career now has been spent being passionate about SharePoint, and I had finally found a place where other people who are just as passionate congregate and help each other.\nEngage, Empower and Expand That \u0026ldquo;kid\u0026rdquo; I hired over ten years ago became an expert because of his hard work. He took the opportunity to get engaged in our company and did great. He was empowered to make a difference and he did, beyond expectations. He was able to expand his skills and responsibilities beyond what (I suspect) he even believed he could, to become the best version of himself.\nThe Office 365 Development Community gives each of us the ability to do the same.\nThe various bi-weekly and monthly calls, videos and presentations engage us.\nWe are all empowered to do demos, create samples, contribute to the many repos out there. You don’t have to be an MVP, to know someone at Microsoft, or to be an employee of a big company to participate.\nWe can all expand the capabilities of SharePoint/O365, and supporting tools by submitting feedback, creating new components, command-lines, tools, web parts, and more.\nWe have the opportunity to make SharePoint the best platform by collaborating together!\nWelcome to the Office 365 Dev Community If you would like to find out more what’s new in the SharePoint development space, you should visit the SharePoint Developer Community (SharePoint PnP) resources. You’ll find videos, blog posts, and social media resources that will help.\nIf you’d like to meet other people who are passionate about SharePoint development, consider attending one of the various community calls.\nIf you want to see what other people in the community have done, or if you want to contribute, visit the list of open-source projects.\nEvery single one of us in the Office 365 Dev Community started as a newbie at some point. As long as you do the same, everyone will treat you kindly and with respect.\nEvery one of us has something important to say for someone else. We all have different backgrounds, experiences, and industries that make us unique. As long as you don’t act like you know better than everyone else, and you don’t try to sell anything, people will listen.\nAs long as you genuinely want to share with the rest of the community, not for the purpose of self-promoting, people will appreciate your contributions.\nWe’ve all had project deadlines and demanding customers, and we understand the pressures that you’re under when you ask for help. We’re also under the same pressure, but someone will surely try to help you if you need help.\nWelcome to the Office 365 Dev Community. I think you’ll like it here.\nConclusion My SharePoint journey has been a long one. At times, I felt more like a crazy person on a soap-box telling those who didn’t want to listen to how awesome SharePoint is.\nMaybe I am such a crazy person, but the Office 365 Dev Community is filled with other crazy people who feel the same way.\nTo all of you in the Office 365 Dev Community, thank you for being awesome and supportive.\nI’m proud to be one of you.\n","permalink":"http://localhost:1313/posts/why-i-heart-officedevpnp/","tags":null,"title":"Why I ♥ the Office 365 Dev Community"},{"categories":["SharePoint"],"contents":"Introduction When migrating from SharePoint on-premises to SharePoint Online/Office 365, you may find that some users have a checked-out file called spcommon[1].png. If you ask users about it, they’ll have no idea what you’re talking about.\nAs it turns out, this isn’t a bug. It is possible for users to check-out this file without knowing they did it.\nBut for this issue to occur, you need a \u0026ldquo;perfect storm\u0026rdquo; to happen: a series of things that occur that are seemingly unrelated that results in the issue we’re discussing today.\nWhat is spcommon[1].png spcommon.png is an image that SharePoint uses to render things like checkboxes, arrows, gears, and pretty much any icon that you see on a SharePoint page.\nIf you download the file, it looks like a bunch of icons in one bigger image:\nThose types of images are called sprites; they usually consist of many images grouped together as a single image. That image is bigger to download than individual images, but since most browsers try to avoid re-downloading a file it has already downloaded (something known as caching — pronounced cashing) — making the entire page load faster.\nSharePoint uses the giant sprite and hides irrelevant parts of the image (by setting a background-url and background-position CSS styles).\nOn a typical SharePoint page, the spcommon.png image may be shown dozens of times.\nSo why do I get a spcommon[1].png file that gets checked out by users?\nPerfect Storm This issue will typically happen in document libraries that either Require check-out before editing files or that have a mandatory property.\nI’ve seen this issue in SharePoint 2013 and SharePoint 2016 migrations, but it could potentially happen in SharePoint 2019 as well.\nAs you already know, users can drag and drop documents unto a document library using their browsers, and SharePoint will try to upload the document.\nIf you try drag and drop a document to a library that requires checking in or one that has mandatory properties, the newly uploaded document will be checked out until the user provides values for the mandatory properties and checks the document in.\nMost browsers also allow you to select an image from a web page and drag and drop it. (Try it now with an image on this page!).\nIf you try to drag and drop an image onto a document library page, it will try to upload that image into the document library. If that library has mandatory properties, the image will be uploaded but checked-out.\nHere is where it gets crazy: if a user tries to click on the checkmark next to a document and accidentally drags the mouse instead — even for a few pixels — the browser will think that the user meant to upload the image to the document library.\nAnd the image used to display the checkbox is — you guessed it —spcommon.png.\nIt often happens too quickly for users to notice, but here is what happens if you slow it down and take a screen shot of a user dragging the checkmark icon in a document library:\nAnd since most browsers will try to uniquely name dragged files, the spcommon.png file is automatically renamed to spcommon[1].png.\nConclusion The issue with a mysterious checked-out spcommon[1].png file in a document library requires a lot of factors to happen.\nFortunately, It seems that newer versions/patches of SharePoint prevent this issue from happening by giving users an error message saying \u0026ldquo;Folders and invalid files can’t be dragged to upload\u0026rdquo;, meaning that you’re less likely to find this issue in future migrations.\nIf you see this error when migrating files to SharePoint Online, you can safely ignore it.\n","permalink":"http://localhost:1313/posts/the-mysterious-case-of-the-checked-out-spcommon1-png/","tags":["Bug Investigation"],"title":"The Mysterious Case of the Checked-Out spcommon[1].png"},{"categories":["SPFx"],"contents":"This article was written in collaboration with Eric Skaggs\nIntroduction In today’s SharePoint Dev Ecosystem (PnP) Bi-Weekly Call, Eric Skaggs asked a question I’ve heard many times before:\nDo you have an example that shows how to go from a JavaScript SPFx web part to a SPFx React web part?\n(I’m paraphrasing)\nI had been looking for an opportunity to write such as article, so I told Eric to DM me on Twitter to see if he had an example of a web part he’d like to convert.\nAs it turns out, Eric has such a web part: his GitHub Badge WebPart is a great example of a JavaScript-only SPFx web part.\nEric’s SPFx web part works great, and there is really no need to convert it to React. We’ll convert it to React simply to demonstrate the process and to highlight some of the design differences between a JavaScript only web part and a React web part.\nIt is also important to point out that every developer has their own coding styles and preferred approaches that do not affect the final product. In this article, I’ll try to point out where I applied my own coding style.\nThis article is written as if you’re following along and converting the application yourself. Feel free to skip to the end to get the code and compare Eric’s JavaScript-only SPFx web part with my React version of the same web part.\nStarting from scratch The SPFx framework is constantly improving. In fact, the framework went from 1.8 to 1.8.1 two days ago!\nBecause of this, I like to make sure that I create a new solution every time I start converting a web part (I do this a lot, as it turns out).\nStart by making sure that your environment is configured to create SPFx solutions. If you haven’t done so yet, follow these steps to get you started.\nIf you were already set up, make sure to update your version of the Yeoman generator to the latest. To do so, use the following command from your Node.js command prompt:\nnpm install -g @microsoft/generator-sharepoint Once this is completed, I followed the instructions from the SharePoint Framework documentation except, you know, with React GitHub Badge as the solution name:\nCreate a new project directory in your favorite location.\nmd react-github-badge Your web part solution does not need to start with react-. I just named it that way because it is the naming convention in the SP-Dev-Fx-WebParts repository\nGo to the new folder you created:\nmd react-github-badge Create the React GitHub Badge web part by running the Yeoman SharePoint Generator.\nyo @microsoft/sharepoint When prompted:\nAccept the default react-github-badge as your solution name, and then select ENTER. Select SharePoint Online only (latest), and select ENTER. Select Use the current folder for where to place the files. Select N to allow the solution to be deployed to all sites immediately. Select N on the question if solution contains unique permissions. Select WebPart as the client-side component type to be created. The next set of prompts ask for specific information about your web part:\nEnter GitHub Badge as your web part name, and then select ENTER. Enter Displays information from GitHub for a specified user as your web part description, and then select ENTER. For framework you would like to use, select React, and then select ENTER. You’ll know it has completed when you see the following message:\nOnce it has completed, run:\ngulp serve to test your web part. (It should work). You should see something like this:\nIt isn’t pretty, but it’s a start.\nFixing potential vulnerabilities If you paid attention as the Yeoman generator created the solution, you may have noticed a nasty message like this one:\nadded 1759 packages from 1071 contributors and audited 565045 packages in 63.66s found 1957 vulnerabilities (1806 low, 36 moderate, 115 high) run npm audit fix to fix them, or npm audit for details Unfortunately, that\u0026rsquo;s the nature of building solutions with open-source components.\nI don\u0026rsquo;t like it, so I typically run the following command to fix as many issues as possible:\nnpm audit fix Once completed, you should see less scary exploits:\nRun your web part again and make sure it still works:\ngulp serve Separating Web Part and Component Eric’s no-framework web part has all the code for retrieving a user’s GitHub profile, managing web part properties, and rendering in the GitHubBadgeWebPart.ts. That’s how it is done with \u0026ldquo;no-framework\u0026rdquo; web parts.\nIn SPFx React solutions, the web part will be broken into smaller components:\nGitHubBadgeWebPart.ts: The Web Part, which is responsible for storing and retrieving web part properties, displaying the property pane, and calling components to render the web part. GitHubBadge.tsx: The main component, which renders the content of the web part. We’re going to take Eric’s code and move the content to GitHubBadge.tsx, and leave the web part code in GitHubBadgeWebPart.ts.\nAdding a web part property to store the GitHub user name Using your favorite code editor, open GitHubBadgeWebPart.ts (located under src\\webparts\\gitHubBadge and find the following code that was generated by Yeoman:\nexport interface IGitHubBadgeWebPartProps { description: string; } Since we don’t need a description property for our web part, let’s rename it to gitHubUserName. The code should look like this:\nexport interface IGitHubBadgeWebPartProps { gitHubUserName: string; } If you use Visual Studio Code, simply place your cursor over description and hit F2. Type in gitHubUserName and hit ENTER\nIf you do not use Visual Studio Code, you should look for a line that says:\ndescription: this.properties.description and replace it for:\ndescription: this.properties.gitHubUserName Find the code inside the getPropertyPaneConfiguration function that looks like this:\ngroupFields: [ PropertyPaneTextField(\u0026#39;description\u0026#39;, { label: strings.DescriptionFieldLabel }) ] and rename the description property to gitHubUserName. The code should look as follows:\ngroupFields: [ PropertyPaneTextField(\u0026#39;gitHubUserName\u0026#39;, { label: strings.DescriptionFieldLabel }) ] Finally, let’s rename the localized label for the DescriptionFieldLabel to GitHubUserNameFieldLabel by using the F2 method. Doing so will also rename the localized variable in src\\webparts\\gitHubBadge\\loc\\mystrings.d.ts. If you don’t use Visual Studio Code, make sure to rename the DescriptionFieldLabel to GitHubUserNameFieldLabel.\nAs a general rule, I always name the localized variable for all my properties as [PropertyName]FieldLabel. So, GitHubUserName becomes GitHubUserNameFieldLabel. Feel free to use your own naming convention.\nWe’ll also need to change the localized text! Go to src\\webparts\\gitHubBadge\\loc\\en-us.js and find the line that looks like this:\n\u0026#34;DescriptionFieldLabel\u0026#34;: \u0026#34;Description Field\u0026#34; And change it to:\n\u0026#34;GitHubUserNameFieldLabel\u0026#34;: \u0026#34;GitHub user name\u0026#34; As always, run gulp serve to test your changes and make sure your web part didn’t self-destruct.\nIf you click on your web part’s edit button, you should see the following:\nSo far, so good.\nYour web part’s manifest contains a section for pre-configured properties in case you want to provide default properties when users add the new web part to their page. Let’s go make Eric’s username the default GitHub username:\nOpen src\\webparts\\gitHubBadge\\GitHubBadgeWebPart.manifest.json and find the properties in the preconfiguredEntries section. Replace the following line:\n\u0026#34;description\u0026#34;: \u0026#34;GitHub Badge\u0026#34; to this:\n\u0026#34;description\u0026#34;: \u0026#34;skaggej\u0026#34; JSON files don’t support comments, and Visual Studio Code will kindly remind you of that by showing the file in red. For bonus points, find all the comments (starting with \\\\) in that file and remove them. Visual Studio Code will reward you with a nice green file name instead.\nWhen you change the manifest, you won’t notice the difference until you stop and restart gulp serve, remove then re-add the web part to your page. I wasted a lot of time trying to debug this issue before I learned this the hard way.\nDisabling reactive property changes By default, SPFx web parts apply property changes as soon as you make them.\nIn this example, we don’t want the web part to retrieve the GitHub user’s profile until we’re done entering the name.\nWe can do this by adding an Apply button to the property pane. To do so, open the Web Part’s code at src\\webparts\\gitHubBadge\\GitHubBadgeWebPart.ts and add the following code just above the getPropertyPaneConfiguration() function:\nprotected get disableReactivePropertyChanges(): boolean { return true; } When you refresh your web part, you’ll get a nice Apply button at the bottom of your property pane.\nAdding GitHubUserName property to the GitHubBadge props Now that we’ve renamed the web part’s Description property to GitHubUserName, we need to do the same to the property that gets passed into the GitHubPage component.\nTypically, your React component will define a I[ComponentName]Props to store properties, and a I[ComponentName]State to store the component’s state.\nBy default, the Yeoman generator will have created the IGitHubBadgeProps interface for you, which should be placed in the src\\webparts\\gitHubBadge\\components\\IGitHubBadgeProps.ts file.\nBecause I learned React from reading the Office UI Fabric code, and they already have awesome Coding Style, React and TypeScript guidelines, I tend to follow their standards.\nIn Office UI Fabric, they often group all types related to a component in a file called [ComponentName].types.ts.\nYou don’t have to do this, but I prefer to do the same by storing both my I[ComponentName]Props and I[ComponentName]State interfaces in the same file called [ComponentName].types.ts.\nIn this case, I’ll just rename the IGitHubBadgeProps.ts to GitHubBadge.types.ts by selecting the file in the Visual Studio Code explorer pane and hitting F2 then typing GitHubBadge.types.ts followed by ENTER.\nWe’ll add the IGitHubBadgetState interface later.\nFor now, though, let’s open the newly renamed GitHubBadge.types.ts file and find the following line in the IGitHubBadgeProps interface:\ndescription: string; and rename the description property to gitHubUserName by using the trusty F2 rename shortcut.\nIf all goes well, you’ll notice that both src\\webparts\\gitHubBadge\\GitHubBadgeWebPart.ts and src\\webparts\\gitHubBadge\\components\\GitHubBadge.tsx will update where they refer to the description property to point to the new gitHubUserName property.\nRendering static HTML So far, I haven’t used any of Eric’s code.\nThat’s about to change.\nOpen:\nFind the following code in the render function and select it:\n\u0026lt;div className={ styles.container }\u0026gt; \u0026lt;div className={ styles.row }\u0026gt; \u0026lt;div className={ styles.column }\u0026gt; \u0026lt;span className={ styles.title }\u0026gt;Welcome to SharePoint!\u0026lt;/span\u0026gt; \u0026lt;p className={ styles.subTitle }\u0026gt;Customize SharePoint experiences using Web Parts.\u0026lt;/p\u0026gt; \u0026lt;p className={ styles.description }\u0026gt;{escape(this.props.gitHubUserName)}\u0026lt;/p\u0026gt; \u0026lt;a href=\u0026#34;https://aka.ms/spfx\u0026#34; className={ styles.button }\u0026gt; \u0026lt;span className={ styles.label }\u0026gt;Learn more\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Notice that the line that looks like:\n\u0026lt;div className={ styles.gitHubBadge }\u0026gt; and the last \u0026lt;/div\u0026gt; isn’t included in the selected code.\nCopy the following code from Eric’s sample over the selected code:\n\u0026lt;div class=\u0026#34;${ styles.container }\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;${ styles.row }\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;${ styles.column }\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;gitHubUserProfilePic\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;gitHubUserName\u0026#34; class=\u0026#34;${ styles.title }\u0026#34;\u0026gt;${this.properties.gitHubUserName}\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;login\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;id\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;node_id\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;avatar_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;gravatar_id\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;html_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;followers_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;following_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;gists_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;starred_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;subscriptions_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;organizations_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;repos_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;events_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;received_events_url\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;type\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;site_admin\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;name\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;company\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;blog\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;location\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;email\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;hireable\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;bio\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;public_repos\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;public_gists\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;followers\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;following\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;created_at\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;updated_at\u0026#34; class=\u0026#34;${ styles.label }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;notfound\u0026#34; class=\u0026#34;${styles.label}\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; You will get some errors. Don’t panic.\nReact doesn’t like it when you use the word class to define the CSS class name. It is a reserved word. Instead, you must use className. Luckily, you can replace all instances of the word class by using a trick I’ve described in my multi-cursor editing in Visual Studio Code article. Select the first instance of the word class= (including the = sign) and hit CTRL-SHIFT-L, then type className= instead, followed by the ESC key to stop multi-cursor editing. This should replace all instances of class to className.\nThe keyword properties is also unique to the WebPart-derived classes. In React, the properties for a component are called props. Find the line that looks like this:\n\u0026lt;div id=\u0026#34;gitHubUserName\u0026#34; className=\u0026#34;${ styles.title }\u0026#34;\u0026gt;${this.properties.gitHubUserName}\u0026lt;/div\u0026gt; and replace it for this:\n\u0026lt;div id=\u0026#34;gitHubUserName\u0026#34; className=\u0026#34;${ styles.title }\u0026#34;\u0026gt;{this.props.gitHubUserName}\u0026lt;/div\u0026gt; In Eric’s code, he defines an ID for all the elements he wants to populate with data and dynamically inserts the text once he has retrieved it by calling every element by ID. It is a really efficient way to dynamically update web part content.\nAlthough you technical can refer to HTML elements by IDs in React, it is rarely encouraged. One of the reasons for this is that if you add the web part twice on the same page, you’ll get conflicts.\nInstead, we’ll later bind each element to the component’s state, then populate the state when we receive the data from GitHub.\nFor now, let’s just get rid of all those ID on every element.\nThankfully, you can do this by using multi-cursor editing!\nFrom the code, select the first instance of id=\u0026quot;. Make sure to include the = and the double quotes \u0026quot;. Just like you did before hit CTRL-SHIFT-L to select all instances of the currently selected text. You should see that all instances of id=\u0026quot; got selected. Now hold SHIFT and CTRL and press the RIGHT arrow key. It should automatically select the word to the right of id=\u0026quot;. (SHIFT means to extend the selection, while CTRL-RIGHT selects the next word). Hold SHIFT again (you can let go of CTRL) and hit the RIGHT arrow again. That should select the last double-quotes (\u0026quot;) to the right of the text you’ve already selected. Hit BACKSPACE to delete the text you have selected. If you want, hit BACKSPACE once more to remove the extra space that is left after every \u0026lt;div. Isn’t multi-cursor editing cool?\nTSX files in React TypeScript projects make it easy to combine HTML with React. To insert dynamic text as an HTML attribute, you just need to use { }. You don’t even need the quotes around the attribute. This means that every instance of className=\u0026quot;${ in Eric’s former JavaScript code can be simply replaced by className={.\nYou can do so by using multi-cursor editing again:\nIn the code, find the first instance of \u0026quot;${ and select it. Hit CTRL-SHIFT-L to select all instances. Hit DEL to delete the selected text. Type { instead and hit ESC to stop multi-cursor editing. Go to the end of the className attribute, and select }\u0026quot; Hit CTRL-SHIFT-L to select all instances of }\u0026quot;. Hit DEL and type } instead, followed by ESC. The final render function should look like this:\npublic render(): React.ReactElement\u0026lt;IGitHubBadgeProps\u0026gt; { return ( \u0026lt;div className={ styles.gitHubBadge }\u0026gt; \u0026lt;div className={ styles.container }\u0026gt; \u0026lt;div className={ styles.row }\u0026gt; \u0026lt;div className={ styles.column }\u0026gt; \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.title }\u0026gt;{this.props.gitHubUserName}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={styles.label}\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } Finally, open replace the content of the src\\webparts\\gitHubBadge\\components\\GitHubBadge.module.scss with Eric’s original SCSS:\n@import \u0026#39;~@microsoft/sp-office-ui-fabric-core/dist/sass/SPFabricCore.scss\u0026#39;; .gitHubBadge { .container { max-width: 700px; margin: 0px auto; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.2), 0 25px 50px 0 rgba(0, 0, 0, 0.1); } .row { @include ms-Grid-row; @include ms-fontColor-white; background-color: $ms-color-themeDark; padding: 20px; } .column { @include ms-Grid-col; @include ms-lg10; @include ms-xl8; @include ms-xlPush2; @include ms-lgPush1; } .title { @include ms-font-xl; @include ms-fontColor-white; } .subTitle { @include ms-font-l; @include ms-fontColor-white; } .description { @include ms-font-l; @include ms-fontColor-white; } .button { // Our button text-decoration: none; height: 32px; // Primary Button min-width: 80px; background-color: $ms-color-themePrimary; border-color: $ms-color-themePrimary; color: $ms-color-white; // Basic Button outline: transparent; position: relative; font-family: \u0026#34;Segoe UI WestEuropean\u0026#34;,\u0026#34;Segoe UI\u0026#34;,-apple-system,BlinkMacSystemFont,Roboto,\u0026#34;Helvetica Neue\u0026#34;,sans-serif; -webkit-font-smoothing: antialiased; font-size: $ms-font-size-m; font-weight: $ms-font-weight-regular; border-width: 0; text-align: center; cursor: pointer; display: inline-block; padding: 0 16px; .label { font-weight: $ms-font-weight-semibold; font-size: $ms-font-size-m; height: 32px; line-height: 32px; margin: 0 4px; vertical-align: top; display: inline-block; } } } You deserve a reward! Run gulp serve again from your Node.js command prompt and refresh your web part. You should see something that looks like this:\nWe’re getting there!\nLet’s retrieve the data next!\nCreating an IGitHubServices interface Eric’s example keeps things simple by putting the code to retrieve the user’s GitHub profile in the web part class.\nHowever, React solutions benefit from breaking things into smaller components with a clear division of responsibilities.\nFor example, the code that calls the GitHub API to retrieve the GitHub user’s profile can be separated from the code that is responsible for rendering the profile information.\nThis is done because React makes it easy to create individualized components that do specific things. By keeping the code that retrieves the data separate from the code that renders the data, we could re-use the GitHub profile component in different ways.\nIt also makes it easier to create unit tests and mock services without having to change your GitHub profile component.\nIt doesn’t make the React code better than the no-framework code. It’s just a different approach.\nSince the purpose of this example is to demonstrate converting a no-framework web part to a React web part, I’ll show you the extra steps of creating a separate IGitHubService interface, with a mock service and a real service.\nFirst, let’s create a new folder called services under the src folder. It should be at the same level as the webparts folder. You may find other examples that place their services under the web part folder for the web part that calls it, but I like to design my services so that they can be used by more than one web part — hence placing it at the same level as the webparts folder. Feel free to place it where you prefer.\nUnder the src\\services folder, create another folder called GitHubServices.\nIn the src\\services\\GitHubServices folder, create a new file called GitHubServices.types.ts\nLet’s create an interface that represents the returned data from GitHub APIs. From your browser, visit [https://api.github.com/users/skaggej](https://api.github.com/users/skaggej). It will return the JSON for Eric’s profile.\nCopy the content of the JSON. It should look like this:\n{ \u0026#34;login\u0026#34;: \u0026#34;skaggej\u0026#34;, \u0026#34;id\u0026#34;: 1846656, \u0026#34;node_id\u0026#34;: \u0026#34;MDQ6VXNlcjE4NDY2NTY=\u0026#34;, \u0026#34;avatar_url\u0026#34;: \u0026#34;https://avatars1.githubusercontent.com/u/1846656?v=4\u0026#34;, \u0026#34;gravatar_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej\u0026#34;, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/skaggej\u0026#34;, \u0026#34;followers_url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej/followers\u0026#34;, \u0026#34;following_url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej/following{/other_user}\u0026#34;, \u0026#34;gists_url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej/gists{/gist_id}\u0026#34;, \u0026#34;starred_url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej/starred{/owner}{/repo}\u0026#34;, \u0026#34;subscriptions_url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej/subscriptions\u0026#34;, \u0026#34;organizations_url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej/orgs\u0026#34;, \u0026#34;repos_url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej/repos\u0026#34;, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej/events{/privacy}\u0026#34;, \u0026#34;received_events_url\u0026#34;: \u0026#34;https://api.github.com/users/skaggej/received_events\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;User\u0026#34;, \u0026#34;site_admin\u0026#34;: false, \u0026#34;name\u0026#34;: \u0026#34;Eric Skaggs\u0026#34;, \u0026#34;company\u0026#34;: \u0026#34;http://www.catapultsystems.com\u0026#34;, \u0026#34;blog\u0026#34;: \u0026#34;http://www.ericskaggs.net\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;Phoenix, AZ\u0026#34;, \u0026#34;email\u0026#34;: null, \u0026#34;hireable\u0026#34;: null, \u0026#34;bio\u0026#34;: \u0026#34;Fuse Solution Architect at Catapult Systems\u0026#34;, \u0026#34;public_repos\u0026#34;: 29, \u0026#34;public_gists\u0026#34;: 3, \u0026#34;followers\u0026#34;: 8, \u0026#34;following\u0026#34;: 33, \u0026#34;created_at\u0026#34;: \u0026#34;2012-06-13T14:01:52Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2019-04-09T00:18:35Z\u0026#34; } (don’t worry too much if there are minor differences)\nIf you don’t have the awesome JSON to TS extension for Visual Studio, go install it now. It will allow us to convert the JSON you just copied into a TypeScript interface. (Did I mention I’m the world’s laziest developer?)\nPlace your cursor in the GitHubServices.types.ts file. We’re about to insert some code in there.\nWith JSON to TS installed, hit F1 to launch the Visual Studio Code command line and start typing JSON to TS. You should see **JSON to TS: Convert from clipboard. Select it and be patient. The extension will insert a TypeScript Interface called RootObject` that contains a property for every attribute returned by the GitHub API. The code should look like this:\ninterface RootObject { login: string; id: number; node_id: string; avatar_url: string; gravatar_id: string; url: string; html_url: string; followers_url: string; following_url: string; gists_url: string; starred_url: string; subscriptions_url: string; organizations_url: string; repos_url: string; events_url: string; received_events_url: string; type: string; site_admin: boolean; name: string; company: string; blog: string; location: string; email?: any; hireable?: any; bio: string; public_repos: number; public_gists: number; followers: number; following: number; created_at: string; updated_at: string; } Rename the RootObject to IGitHubUserProfile and export the interface so that it can be accessed in other files. The code should look like this:\nexport interface IGitHubUserProfile { login: string; id: number; node_id: string; avatar_url: string; gravatar_id: string; url: string; html_url: string; followers_url: string; following_url: string; gists_url: string; starred_url: string; subscriptions_url: string; organizations_url: string; repos_url: string; events_url: string; received_events_url: string; type: string; site_admin: boolean; name: string; company: string; blog: string; location: string; email?: any; hireable?: any; bio: string; public_repos: number; public_gists: number; followers: number; following: number; created_at: string; updated_at: string; } We use the convention I[Something] to indicate that this is an interface, not a class. That way, we can take any TypeScript object that implements the properties defined in the interface (login, id, node_id, avatar_url, etc.) — regardless of how it was created. That way, we’ll be able to convert the JSON we retrieved from the GitHub API to the IGitHubUserProfile interface and pass it around.\nWe’ll add an IGitHubService interface to the same file. The interface will implement one method called getUserProfile that receives an alias string and returns an asynchronous promise of an IGitHubUserProfile. Just paste the following code below the IGitHubUserProfile:\nexport interface IGitHubService { getUserProfile(alias: string): Promise\u0026lt;IGitHubUserProfile\u0026gt;; } Again, we use an interface so that we can later have a MockGitHubService and a (real) GitHubService that both implement the IGitHubService. Our component won’t care whether it is using a real service or a mock service, because it will expect an object that implements IGitHubService.\nFor your reference, the entire content of GitHubServices.types.ts should look like this:\nexport interface IGitHubUserProfile { login: string; id: number; node_id: string; avatar_url: string; gravatar_id: string; url: string; html_url: string; followers_url: string; following_url: string; gists_url: string; starred_url: string; subscriptions_url: string; organizations_url: string; repos_url: string; events_url: string; received_events_url: string; type: string; site_admin: boolean; name: string; company: string; blog: string; location: string; email?: any; hireable?: any; bio: string; public_repos: number; public_gists: number; followers: number; following: number; created_at: string; updated_at: string; } export interface IGitHubService { getUserProfile(alias: string): Promise\u0026lt;IGitHubUserProfile\u0026gt;; } Now let’s create the mock service!\nCreating MockGitHubService We’ll use a mock service to return test data so that we don’t have to worry about getting blocked by GitHub for calling the API too many times when we’re testing the look and feel of the web part. The mock service will be interchangeable with the real service at a later time.\nIn the src\\services\\GitHubServices folder, create a new file called MockGitHubService\nIn the now empty file, paste the following code:\nimport { IGitHubService, IGitHubUserProfile } from \u0026#34;./GitHubServices.types\u0026#34;; export class MockGitHubService implements IGitHubService { public getUserProfile(alias: string): Promise\u0026lt;IGitHubUserProfile\u0026gt; { // This space for rent } } The import { IGitHubService, IGitHubUserProfile } from \u0026quot;./GitHubServices.types\u0026quot;; line tells the TypeScript transpiler that those two interfaces are located in another file in the same folder.\nThe export class MockGitHubService implements IGitHubService says that this class (MockGitHubService) will do (or implements) everything the IGitHubService interface does, and that it should be available outside of this file by other files (or exported).\nLet’s add some code to return sample data after simulating some delays.\nIn the code, replace the line that says // This space for rent with the following code:\nreturn new Promise\u0026lt;IGitHubUserProfile\u0026gt;((resolve) =\u0026gt; { // pretend we\u0026#39;re getting the data from the GitHub API by adding a delay setTimeout(() =\u0026gt; { const fakeProfile: IGitHubUserProfile = { login: \u0026#34;skaggej\u0026#34;, id: 1846656, node_id: \u0026#34;MDQ6VXNlcjE4NDY2NTY=\u0026#34;, avatar_url: \u0026#34;https://avatars1.githubusercontent.com/u/1846656?v=4\u0026#34;, gravatar_id: \u0026#34;\u0026#34;, url: \u0026#34;https://api.github.com/users/skaggej\u0026#34;, html_url: \u0026#34;https://github.com/skaggej\u0026#34;, followers_url: \u0026#34;https://api.github.com/users/skaggej/followers\u0026#34;, following_url: \u0026#34;https://api.github.com/users/skaggej/following{/other_user}\u0026#34;, gists_url: \u0026#34;https://api.github.com/users/skaggej/gists{/gist_id}\u0026#34;, starred_url: \u0026#34;https://api.github.com/users/skaggej/starred{/owner}{/repo}\u0026#34;, subscriptions_url: \u0026#34;https://api.github.com/users/skaggej/subscriptions\u0026#34;, organizations_url: \u0026#34;https://api.github.com/users/skaggej/orgs\u0026#34;, repos_url: \u0026#34;https://api.github.com/users/skaggej/repos\u0026#34;, events_url: \u0026#34;https://api.github.com/users/skaggej/events{/privacy}\u0026#34;, received_events_url: \u0026#34;https://api.github.com/users/skaggej/received_events\u0026#34;, type: \u0026#34;User\u0026#34;, site_admin: false, name: \u0026#34;Eric Skaggs\u0026#34;, company: \u0026#34;http://www.catapultsystems.com\u0026#34;, blog: \u0026#34;http://www.ericskaggs.net\u0026#34;, location: \u0026#34;Phoenix, AZ\u0026#34;, email: null, hireable: null, bio: \u0026#34;Fuse Solution Architect at Catapult Systems\u0026#34;, public_repos: 29, public_gists: 3, followers: 8, following: 33, created_at: \u0026#34;2012-06-13T14:01:52Z\u0026#34;, updated_at: \u0026#34;2019-04-09T00:18:35Z\u0026#34; }; resolve(fakeProfile); }, 500); }); The entire content of the MockGitHubService.ts file should be as follows:\nimport { IGitHubService, IGitHubUserProfile } from \u0026#34;./GitHubServices.types\u0026#34;; export class MockGitHubService implements IGitHubService { public getUserProfile(alias: string): Promise\u0026lt;IGitHubUserProfile\u0026gt; { return new Promise\u0026lt;IGitHubUserProfile\u0026gt;((resolve) =\u0026gt; { // pretend we\u0026#39;re getting the data from the GitHub API by adding a delay setTimeout(() =\u0026gt; { const fakeProfile: IGitHubUserProfile = { login: \u0026#34;skaggej\u0026#34;, id: 1846656, node_id: \u0026#34;MDQ6VXNlcjE4NDY2NTY=\u0026#34;, avatar_url: \u0026#34;https://avatars1.githubusercontent.com/u/1846656?v=4\u0026#34;, gravatar_id: \u0026#34;\u0026#34;, url: \u0026#34;https://api.github.com/users/skaggej\u0026#34;, html_url: \u0026#34;https://github.com/skaggej\u0026#34;, followers_url: \u0026#34;https://api.github.com/users/skaggej/followers\u0026#34;, following_url: \u0026#34;https://api.github.com/users/skaggej/following{/other_user}\u0026#34;, gists_url: \u0026#34;https://api.github.com/users/skaggej/gists{/gist_id}\u0026#34;, starred_url: \u0026#34;https://api.github.com/users/skaggej/starred{/owner}{/repo}\u0026#34;, subscriptions_url: \u0026#34;https://api.github.com/users/skaggej/subscriptions\u0026#34;, organizations_url: \u0026#34;https://api.github.com/users/skaggej/orgs\u0026#34;, repos_url: \u0026#34;https://api.github.com/users/skaggej/repos\u0026#34;, events_url: \u0026#34;https://api.github.com/users/skaggej/events{/privacy}\u0026#34;, received_events_url: \u0026#34;https://api.github.com/users/skaggej/received_events\u0026#34;, type: \u0026#34;User\u0026#34;, site_admin: false, name: \u0026#34;Eric Skaggs\u0026#34;, company: \u0026#34;http://www.catapultsystems.com\u0026#34;, blog: \u0026#34;http://www.ericskaggs.net\u0026#34;, location: \u0026#34;Phoenix, AZ\u0026#34;, email: null, hireable: null, bio: \u0026#34;Fuse Solution Architect at Catapult Systems\u0026#34;, public_repos: 29, public_gists: 3, followers: 8, following: 33, created_at: \u0026#34;2012-06-13T14:01:52Z\u0026#34;, updated_at: \u0026#34;2019-04-09T00:18:35Z\u0026#34; }; resolve(fakeProfile); }, 500); }); } } Adding an index.ts file to GitHubServices Now that we’ve defined some exports in our GitHubServices, we’ll want to make it easy for the component to use them.\nThe problem is that if we want to import our IGitHubService, IGitHubUserProfile and MockGitHubService in our GitHubBadge component, we’ll have to import each item from the files that contain them, like this:\nimport { IGitHubService, IGitHubUserProfile } from \u0026#39;../../../services/GitHubServices/GitHubServices.types\u0026#39;; import { MockGitHubService } from \u0026#39;../../../services/GitHubServices/MockGitHubService\u0026#39;; However, if we ever decide to move the various elements of the GitHubServices to different files, we’ll have to update all the import statements in all the components that use the services.\nBut why should the components know about the internal structure of the GitHubServices? Wouldn’t it be better to abstract all that stuff from the components?\nLuckily, we can use index.ts to do just that!\nIn the src\\services\\GitHubServices folder, add a new file called index.ts.\nIn the index.ts file, export all the things that you want the components to have access to, as follows:\nexport * from \u0026#39;./GitHubServices.types\u0026#39;; export * from \u0026#39;./MockGitHubService\u0026#39;; Now we can just add the following line in our src\\webparts\\gitHubBadge\\components\\GitHubBadge.tsx file to import everything we need:\nimport { IGitHubService, IGitHubUserProfile, MockGitHubService } from \u0026#39;../../../services/GitHubServices\u0026#39;; Adding some state to GitHubBadge State is a funny concept in React.\nIt allows us to temporarily capture the information we need to support the different \u0026ldquo;ways\u0026rdquo; we want our component can be in (I’m really trying hard not to use the word state here).\nFor example, our GitHubBadge component potentially has 5 states:\nNot configured Loading Loaded with data Error because the user was Not found Error while calling GitHub API (network, throttling, etc.) This is something that’s represented as follows:\nTitle: GitHubBadge States\rNot configured-\u0026gt;Loading: When user sets web part properties\rLoading-\u0026gt;Loaded: Normal scenario\rLoading--\u0026gt;Not found: Invalid user name\rLoading--\u0026gt;Error: Exception with GitHub API I promised Eric I’d keep this simple, so I’ll ignore the Not configured and we’ll combine the Not found and Error states for now. (I can’t promise I won’t come back to this in a later article though).\nTo represent these states in out GitHubBadge component, we’ll use the following variables:\nisLoading: a boolean that will be set to true when the web part loads. userProfile: a IGitHubUserProfile variable that can be set to undefined (if there is no data to show) errorMessage: a string containing an error message that can also be set to undefined if nothing went wrong. If isLoading is false, it will mean that the service call is complete. If errorMessage contains a message, it means there was an error. Otherwise, if userProfile contains data, it means that we received our data and that we want to show it.\nLet’s start implementing this by creating an IGitHubBadgeState interface in our src\\webparts\\gitHubBadge\\components\\GitHubBadge.types.ts file:\nOpen the GitHubBadge.types.ts file\nAdd the following code below the IGitHubBadgeProps interface:\nexport interface IGitHubBadgeState { isLoading: boolean; userProfile?: IGitHubUserProfile; errorMessage?: string; } Make sure to add the following line at the top of the file:\nimport { IGitHubUserProfile } from \u0026#34;../../../services/GitHubServices\u0026#34;; The ? at the end of the variable names means that the variables can be nullable.\nNow let’s use the state in our component!\nAdding state to the GitHubBadge component Now we’re finally getting somewhere!\nLet’s start by telling the GitHubBadge that is has a state:\nOpen the src\\webparts\\gitHubBadge\\components\\GitHubBadge.tsx file\nAt the top of the file, replace the following line:\nimport { IGitHubBadgeProps } from \u0026#39;./GitHubBadge.types\u0026#39;; for this:\nimport { IGitHubBadgeProps, IGitHubBadgeState } from \u0026#39;./GitHubBadge.types\u0026#39;; Replace the following line:\nexport default class GitHubBadge extends React.Component\u0026lt;IGitHubBadgeProps, {}\u0026gt; { with this:\nexport default class GitHubBadge extends React.Component\u0026lt;IGitHubBadgeProps, IGitHubBadgeState\u0026gt; { This tells the GitHubBadge class that it should use IGitHubBadgeProps for its properties, and IGitHubBadgeState for its state.\nAdd a constructor to define a default state by adding the following code below the code you just changed, and above the public render() method:\nconstructor(props:IGitHubBadgeProps) { super(props); this.state = { isLoading: true }; } Note that the constructor is the only time you can change the state directly by using this.state = . Everywhere else, you’ll only be able to use this.setState().\nFor now, let’s some conditional rendering logic in the render method so that when the web part is loading (i.e.: isLoading equals true), we’ll write \u0026ldquo;Loading…\u0026rdquo; in the top of the web part. Replace the following line (just below \u0026lt;div className={ styles.column }\u0026gt;:\n\u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; with this:\n\u0026lt;div\u0026gt;{ this.state.isLoading \u0026amp;\u0026amp; \u0026#34;Loading...\u0026#34; }\u0026lt;/div\u0026gt; If you try to use gulp serve now, you’ll notice that the web part always displays \u0026ldquo;Loading…\u0026rdquo; because the isLoading state variable is set to true at in the constructor and we never change that.\nBut we’ll fix that right now…\nLoading and displaying mock data React applications typically try to be responsive (as in \u0026ldquo;fast\u0026rdquo;) by avoiding any delays in rendering the components.\nIt is better to render a \u0026ldquo;Loading…\u0026rdquo; web part and immediately change it to show the data that’s you just retrieved than not rendering anything until the data has returned.\nTo achieve this, we’ll call the getUserProfile method from the MockGitHubService after the GitHubBadge is mounted. Once the MockGitHubService returns data, we’ll call this.setState() and set isLoading to false and populate the userProfile state variable with whatever data we received.\nCalling this.setState will automatically trigger any elements that are bound to state variables on the component to re-render.\nTo the code!\nIn src\\webparts\\gitHubBadge\\components\\GitHubBadge.tsx, add a method called componentDidMount above the render method, as follows:\npublic componentDidMount(): void { } (It will still work if you put the code after the render method, I suggest where to put it in the code so that your code looks like mine once completed).\nAdd the following code inside the componentDidMount function:\n// Create an instance of the GitHub service const service: IGitHubService = new MockGitHubService(); // Call the GitHub service // In real-life, we would only call it when we\u0026#39;re sure that there is a username service.getUserProfile(this.props.gitHubUserName).then((results: IGitHubUserProfile)=\u0026gt;{ // Set the userProfile with the results we got and isLoading to false, because we\u0026#39;re done // loading. It\u0026#39;ll make things redraw magically. this.setState({ userProfile: results, isLoading: false }); }); Replace the entire render function with the following code. Don’t worry, I’ll explain shortly:\npublic render(): React.ReactElement\u0026lt;IGitHubBadgeProps\u0026gt; { const { userProfile, isLoading, errorMessage } = this.state; return ( \u0026lt;div className={ styles.gitHubBadge }\u0026gt; \u0026lt;div className={ styles.container }\u0026gt; \u0026lt;div className={ styles.row }\u0026gt; { isLoading \u0026amp;\u0026amp; \u0026lt;div className={ styles.column }\u0026gt; \u0026lt;div\u0026gt;Loading...\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; } { !isLoading \u0026amp;\u0026amp; userProfile \u0026amp;\u0026amp; \u0026lt;div className={ styles.column }\u0026gt; \u0026lt;div\u0026gt;\u0026lt;img src={userProfile.avatar_url} alt=\u0026#34;GitHub User Profile Picture\u0026#34; /\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.title }\u0026gt;{this.props.gitHubUserName}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{ userProfile.login}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.id}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.node_id}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.avatar_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.gravatar_id}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.html_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.followers_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.following_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.gists_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.starred_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.subscriptions_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.organizations_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.repos_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.events_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.received_events_url}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.type}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.site_admin}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.name}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.name}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.company}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.location}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.email}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.hireable}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.bio}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.public_repos}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.public_gists}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.followers}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.following}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.created_at}\u0026lt;/div\u0026gt; \u0026lt;div className={ styles.label }\u0026gt;{userProfile.updated_at}\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; } { !isLoading \u0026amp;\u0026amp; errorMessage \u0026amp;\u0026amp; \u0026lt;div className={ styles.column }\u0026gt; \u0026lt;div className={styles.label}\u0026gt;WARNING - error when calling URL https://api.github.com/users/{this.props.gitHubUserName}. Error = {errorMessage}\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; } \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } Now save your code and treat yourself to a gulp serve. Refresh your web part and you should see the web part say Loading… for half a second, then load Eric’s profile.\n\u0026ldquo;But that was a lot of weird code you just introduced!\u0026rdquo;, you’ll say. I know! Let me walk you through it.\nThe first line in the render function:\nconst { userProfile, isLoading, errorMessage } = this.state; defines a \u0026ldquo;shortcut\u0026rdquo; to the state variables isLoading, userProfile, and errorMessage. That way, in the rest of the code, we don’t have to say this.state.userProfile, we can simply use userProfile.\nThe first section:\n{ isLoading \u0026amp;\u0026amp; \u0026lt;div className={ styles.column }\u0026gt; \u0026lt;div\u0026gt;Loading...\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; } says: \u0026ldquo;if isLoading is true, render the HTML between { and }\u0026rdquo;.\nSimilarly, this line:\n{ !isLoading \u0026amp;\u0026amp; userProfile \u0026amp;\u0026amp; says \u0026ldquo;If isLoading is not true, and there is a userProfile render the HTML between the {}.\nGuess what:\n{ !isLoading \u0026amp;\u0026amp; errorMessage \u0026amp;\u0026amp; does? It only renders the HTML between the {} if the web part is done loading and there is an error message.\nEverywhere else in that function uses {} to bind to a state or prop. For example:\n\u0026lt;div\u0026gt;\u0026lt;img src={userProfile.avatar_url} alt=\u0026#34;GitHub User Profile Picture\u0026#34; /\u0026gt;\u0026lt;/div\u0026gt; Renders an image that binds the src attribute to the avatar_url attribute of the userProfile state variable, while:\n\u0026lt;div className={ styles.label }\u0026gt;{userProfile.login}\u0026lt;/div\u0026gt; Insert the value of the login attribute of the userProfile state variable inside the \u0026lt;div/\u0026gt; element.\nEverywhere else in the render function works the same way.\nWe’re almost done! We just need to retrieve the real data by passing the HTTP context and implementing the GitHubService to use it to call the real GitHub API.\nPassing HTTP Context In order to make HTTP requests, the component needs to use the HttpClient object exposed by the web part.\nThat means that the GitHubBadge component needs to add an HttpClient variable to its IGitHubBadgeProps interface.\nLet’s do this:\nOpen src\\webparts\\gitHubBadge\\components\\GitHubBadge.types.ts\nAt the top, import HttpClient from ‘@microsoft/sp-http’, as follows:\nimport { HttpClient } from \u0026#39;@microsoft/sp-http\u0026#39;; Add a prop variable that will store the HttpClient to the IGitHubBadgeProps. The GitHubBadge.types.ts file will look as follows:\nimport { IGitHubUserProfile } from \u0026#34;../../../services/GitHubServices\u0026#34;; import { HttpClient } from \u0026#39;@microsoft/sp-http\u0026#39;; ```typescript\rexport interface IGitHubBadgeProps {\ngitHubUserName: string;\nhttpClient: HttpClient;\n}\nexport interface IGitHubBadgeState {\nisLoading: boolean;\nuserProfile?: IGitHubUserProfile;\nerrorMessage?: string;\n}\n4. In the `src\\webparts\\gitHubBadge\\GitHubBadgeWebPart.ts` web part, pass the new prop to the GitHubBadge component by changing the render as follows:\r```typescript\rpublic render(): void {\rconst element: React.ReactElement\u0026lt;IGitHubBadgeProps\u0026gt; = React.createElement(\rGitHubBadge,\r{\rgitHubUserName: this.properties.gitHubUserName,\rhttpClient: this.context.httpClient\r}\r);\rReactDom.render(element, this.domElement);\r}\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\r\u0026lt;blockquote\u0026gt;\r\u0026lt;p\u0026gt;You may have seen some samples that pass the entire web part context to the components (including some of my samples). Waldek has a \u0026lt;a href=\u0026#34;https://blog.mastykarz.nl/dont-pass-web-part-context-react-components/\u0026#34;\u0026gt;great article\u0026lt;/a\u0026gt; that explains why you shouldn\u0026#39;t. In this example, we choose to pass the \u0026lt;code\u0026gt;HttpClient\u0026lt;/code\u0026gt; object from the web part\u0026#39;s \u0026lt;code\u0026gt;context\u0026lt;/code\u0026gt; instead of passing the entire \u0026lt;code\u0026gt;context\u0026lt;/code\u0026gt;.\rAs a general rule, always listen to Waldek :-)\u0026lt;/p\u0026gt;\r\u0026lt;/blockquote\u0026gt;\r\u0026lt;h2\u0026gt;Creating the GitHubService\u0026lt;/h2\u0026gt;\r\u0026lt;p\u0026gt;The moment of truth!\u0026lt;/p\u0026gt;\r\u0026lt;ol\u0026gt;\r\u0026lt;li\u0026gt;Go to the \u0026lt;code\u0026gt;src\\services\\GitHubServices\u0026lt;/code\u0026gt; folder and add a file called \u0026lt;code\u0026gt;GitHubService.ts\u0026lt;/code\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li\u0026gt;At the top of the file, add the following imports:\r\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-TypeScript\u0026#34;\u0026gt;import { IGitHubService, IGitHubUserProfile } from \u0026#34;./GitHubServices.types\u0026#34;;\rimport { HttpClient, HttpClientResponse } from \u0026#39;@microsoft/sp-http\u0026#39;;\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li\u0026gt;Create the \u0026lt;code\u0026gt;GitHubService\u0026lt;/code\u0026gt; class that implements the \u0026lt;code\u0026gt;IGitHubService\u0026lt;/code\u0026gt; interface:\r\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-TypeScript\u0026#34;\u0026gt;\rexport class GitHubService implements IGitHubService {\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;/ol\u0026gt;\r\u0026lt;p\u0026gt;}\u0026lt;/p\u0026gt;\r\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;4. Add a \u0026lt;code\u0026gt;private\u0026lt;/code\u0026gt; variable of type \u0026lt;code\u0026gt;HttpClient\u0026lt;/code\u0026gt; that will be used to store the HTTP client object passed into the GitHubService:\r```typescript\rexport class GitHubService implements IGitHubService {\rprivate _httpClient: HttpClient;\r} Add a constructor that receives the HttpClient object and stores it to the private variable:\nconstructor(httpClient: HttpClient) { this._httpClient = httpClient; } Finally, implement the getUserProfile method that calls the GitHub API using the HttpClient\npublic getUserProfile(alias: string): Promise\u0026lt;IGitHubUserProfile\u0026gt; { const gitHubUrl: string = \u0026#34;https://api.github.com/users/\u0026#34;+alias; // call the GitHub API return this._httpClient.get(gitHubUrl, HttpClient.configurations.v1, {}).then((response: HttpClientResponse) =\u0026gt; response.json()) .then((profile: IGitHubUserProfile) =\u0026gt; { return profile; }); } The code almost seems magical: it calls the API and converts the received JSON to an IGitHubUserProfile interface automatically.\nThe final GitHubService code looks like this:\nimport { IGitHubService, IGitHubUserProfile } from \u0026#34;./GitHubServices.types\u0026#34;; import { HttpClient, HttpClientResponse } from \u0026#39;@microsoft/sp-http\u0026#39;; export class GitHubService implements IGitHubService { private _httpClient: HttpClient; constructor(httpClient: HttpClient) { this._httpClient = httpClient; } public getUserProfile(alias: string): Promise\u0026lt;IGitHubUserProfile\u0026gt; { const gitHubUrl: string = \u0026#34;https://api.github.com/users/\u0026#34;+alias; // call the GitHub API return this._httpClient.get(gitHubUrl, HttpClient.configurations.v1, {}).then((response: HttpClientResponse) =\u0026gt; response.json()) .then((profile: IGitHubUserProfile) =\u0026gt; { return profile; }); } } To allow the GitHubBadge component to access the GitHubService, we need to add GitHubService to the src\\services\\GitHubServices\\index.ts, making the entire index.ts as follows:\nexport * from \u0026#39;./GitHubServices.types\u0026#39;; export * from \u0026#39;./MockGitHubService\u0026#39;; export * from \u0026#39;./GitHubService\u0026#39;; Note that unlike the MockGitHubService, the GitHubService needs the HttpClient to work. Because the getUserProfile function is defined in the IGitHubService interface, we can’t change the function to pass the HttpClient when we need it.\nHowever, we can change the constructor of the GitHubService to accept the HttpClient object we need.\nCalling the GitHubService To change the code in the GitHubBadge component to use the GitHubService, we simply need to change the componentDidMount by following these steps:\nOpen the src\\webparts\\gitHubBadge\\components\\GitHubBadge.tsx file\nChange the import statement at the top to include GitHubService:\nimport { IGitHubService, IGitHubUserProfile, MockGitHubService, GitHubService } from \u0026#39;../../../services/GitHubServices\u0026#39;; In the componentDidMount function, comment out this line:\nconst service: IGitHubService = new MockGitHubService(); and add the following line just below:\nconst service: IGitHubService = new GitHubService(this.props.httpClient); Nothing else needs to change.\nRun gulp serve and try the web part. The data will be really coming from GitHub.\nHowever, if you try to change the user name property and click Apply, you won’t see any changes unless you refresh the page.\nWe can fix that.\nResponding to changing props While React is happy to automatically redraw the components when their state changes, our component only changes the state once it receives the data from the GitHubService.\nAnd the GitHubService is only called once after the component is mounted.\nTo call the GitHubService when the component is mounted and when the gitHubUserName prop changes, we need to move some code around.\nTo do so:\nIn the src\\webparts\\gitHubBadge\\components\\GitHubBadge.tsx file, add a private function called getUserProfile that calls the web service:\nprivate getUserProfile() { // Create an instance of the GitHub service //const service: IGitHubService = new MockGitHubService(); const service: IGitHubService = new GitHubService(this.props.httpClient); // Call the GitHub service // In real-life, we would only call it when we\u0026#39;re sure that there is a username service.getUserProfile(this.props.gitHubUserName).then((results: IGitHubUserProfile)=\u0026gt;{ // Set the userProfile with the results we got and isLoading to false, because we\u0026#39;re done // loading. It\u0026#39;ll make things redraw magically. this.setState({ userProfile: results, isLoading: false }); }); } Change the componentDidMount function to call the getUserProfile private function:\npublic componentDidMount(): void { this.getUserProfile(); } Add a componentDidUpdate that will compare if the previous props are different than the current props and will call the private getUserProfile function if it is different:\npublic componentDidUpdate(prevProps: IGitHubBadgeProps, prevState: IGitHubBadgeState): void { if (prevProps.gitHubUserName !== this.props.gitHubUserName) { this.getUserProfile(); } } componentDidUpdate gets triggered any time the component’s state or props change. In this case, we use it to compare gitHubUserName and react accordingly.\nTry your changes now using gulp serve and see it all work when you update the GitHub user name.\nThe final result looks like this:\nConclusion In this article, we took the GitHub Badge WebPart that Eric Skaggs wrote using only JavaScript (no framework!) and converted it to a React web part that does the same thing.\nWe took a few detours on the way to convey some different concepts in React, but the result is mostly the same.\nThere are still a few things the sample web part should do:\nAdd error handler Add a \u0026ldquo;Loading…\u0026rdquo; spinner Add a placeholder when the web part isn’t configured Cache the results to avoid getting throttled by GitHub for making too many calls.\n…but this article is already long enough. You can find the entire solution on my GitHub repo.\nThanks again to Eric for writing such an awesome sample web part. I hope that I did your sample justice with the React version.\n","permalink":"http://localhost:1313/posts/converting-spfx-from-javascript-to-react/","tags":["JavaScript"],"title":"Converting SPFx Web Part from JavaScript to React"},{"categories":["SPFx"],"contents":"Introduction Recently, Microsoft announced a plan to rename Office UI Fabric to Microsoft UI Fabric. The Fabric React Component that have become ubiquitous on Microsoft web applications will be updated to give the Fabric controls that new cool Fluent style — eventually aligning the desktop and web app look and feel to give users a consistent experience.\nTo help understand how the controls will change with the Fluent style, the UI Fabric team created a Preview web site. On it, there is a component that allows you to compare how the controls will appear before and after the Fluent style update by dragging a slider left to right. Although it isn’t a standard UI Fabric component, the comparer component looks and feels like it belongs to UI Fabric.\nAt that time, I was putting together a demo for a client that needed to compare two images on their SharePoint site. I thought I’d re-create the comparer component into an SPFx web part.\nAs I was building the web part, I decided to add the ability for users to pick the Before and After images using a file picker like the one available in SharePoint.\nThe out-of-the-box file picker allows users to pick files from their recent files, web search, OneDrive, the current site they’re on, an uploaded file, or a hyperlink. Perfect for my needs!\nBeing the World’s Laziest Developer, I looked for a standard control within the SPFx libraries, Fabric UI, the PnP Reusable React controls for SPFx solutions, and the PnP Reusable SPFx property pane controls .\nBut I found nothing.\nWhat I lack in being lazy, I make up in being stubborn. So I decided to write my own File Picker control.\nThe web part came out OK, but I was pretty happy with the File Picker.\nThis article will describe some of the techniques and approaches I used to reverse engineer the out-of-the-box File Picker to create my own.\nIf all you need is to see the code, you can find the React Comparer web part on the SharePoint SP-Dev-Fx-WebParts Sample Repository.\nDesign Criteria Before I set out to build the File Picker, I defined some rules that I would have to stick to no matter what:\nTo the best of my ability, the File Picker had to look and feel exactly like the out-of-the-box File Picker. That includes copying some of the weird inconsistencies in the out-of-the-box component — I’ll get to those later. Even though I only cared about picking images, the File Picker must be designed to eventually support picking documents as well as images. I wouldn’t be spending any time testing the picker using documents, but I would spend every effort to make sure I would be able to add full support for documents later. The control should be easy to re-use in other solutions. Eventually, it should be easy to add it to the PnP Reusable SPFx property pane controls — as long as anybody else shows interest in it. Using the File Picker control should not require setting custom permissions or prompt the user to enter their credentials — or any other weird behavior (see #1). Should be designed to support mobile browsing in the future, but no testing on mobile device. The File Picker control should be easy to extend without disrupting the user experience. For example, I would like to add a Camera tab to allow users to insert an image from their camera, but I’d want the tab to look like the feature came out-of-the-box. With all the above rules established (why do I do this to myself, again?), I started coding!\nWhat kind of control? When I first started trying to figure out how I’d go about doing this control, I thought I’d do a regular control that I’d launch when clicking on the property pane button. I thought I’d use the @microsoft/sp-webpart-base‘s PropertyPaneButton and the onClick handler to display a UI Fabric Panel control.\nThe problem with this approach is that I would need to track whether the panel was opened or not to determine when to render the panel. Since I had no control over the state of the PropertyPaneButton control, I would have to store that information in the web part properties — something that I didn’t want to do.\nBut if I created a custom property pane control, I could render the button to open the dialog and add the state of the dialog to the property pane control’s state.\nLuckily, there is a great training module called SharePoint Framework training package – Working with the Web Part Property Pane that teaches you how to use and develop your own property pane controls. The PnP\nReusable SPFx Property Pane Controls source code is also a great place to look for examples to get started.\nUltimately, I mimicked the code from PnP (after all, I’m planning on submitting the control to PnP!) and created the property control.\nTaking inspiration from existing controls Since my goal was to reproduce the exact same look and I feel, I started rebuilding the same component structure by using the out-of-the-box file picker and examining the HTML it produced.\nUsing your browser’s Developer Toolbox (F12 on Chrome and Edge) Elements tab, you can navigate through the page elements and determine what kinds of controls are used.\nFor example, the navigation which allows users to select whether to pick a file from OneDrive, the Site, upload, etc. has the ms-Nav-group CSS class.\n.\nA quick search for ms-Nav-group in the UI Fabric source code pointed to the UI Fabric Nav component.\nBy comparing the samples, I was able to find the sample that matched the look of the out-of-the-box control the closest and started with that.\nWhen to split components Since React makes it easy to create controls that are made up of many components, it can be difficult to figure out when a group of HTML elements are from a single control, and when they aremade of individual controls.\nLuckily, the majority of controls usually consist of the control’s .tsx file, and a .scss file that contains all the CSS classes needed to render that control.\nWhen React renders a control in a web page, it adds the control’s CSS to the page. To prevent one’s control’s CSS from interfering with another control’s CSS, React uniquely names each CSS class by appending a unique suffix to each class name.\nIn the example below, the nav CSS class is rendered as nav_b427d4d7. If you look closely at the parent elements of the nav_b427d4d7 element, you’ll find there is an element with a class focusTrapZone_b427d4d7 — with the same _b427d4d7 suffix.\nElements with the same class name suffix are generally rendered from the same React control. By navigating up and down the HTML elements, I was able to determine which items were rendered together.\nCopying styles While I was reverse engineering the controls I would need, I was also able to extract the styles I needed for each element by looking at the Developer Toolbar’s Styles pane in the Elements tab:\nI simply gave my HTML elements the same CSS class names that I would see in the Developer Toolbar (minus the unique suffix) and used the same styles.\nWith a bit of tweaking, I was able to make the control look exactly the same.\nListening In Once I got the HTML to look the way I wanted, I had to figure out where SharePoint got the results.\nOnce again, the browser’s Developer Toolbars came to the rescue. By loading the out-of-the-box file picker and using the Network tab, I was able to see what REST calls SharePoint makes to retrieve documents.\nAfter filtering through many XHR calls, I was able to find which calls returned the data I was looking for.\nI used the @pnp/sp library to re-create the calls in my components and return the same data that the SharePoint file picker control returned.\nDiscrepancies By analyzing the file picker, I noticed some discrepancies how each tab was rendered. For example, the OneDrive tab and the Site tab may look very similar, but a closer look reveals minor differences between the two.\nFor example, the Site tab shows folders within the site with no file count:\nMeanwhile, the OneDrive tab shows a file count within each file and offers users the ability to select which view they wish to use (in the upper right corner):\nThe HTML behind each tab is also very different.\nI chose to keep the same discrepancies between tabs, even if I was tempted to clean up and optimize the code. I suspect the each tab was created by a different team members (or teams?) within Microsoft, which explains the lack of consistency.\nConclusion The value proposition of SPFx is that it gives third-party developers (like me) the same set of tools that first-party developers (like Microsoft) can use.\nBy using the browser’s developer tools and a bit of elbow grease, you can reproduce the look and feel of SharePoint components and make them do whatever you want them to do.\nIf you want to find out more on how I wrote the File Picker control, take a look at the code.\nI hope this helps?\nUpdates The FilePicker control is now available in the Pnp reusable controls, woo hoo! I can’t take the credit for submitting the re-usable control, but I’m super proud that members of the PnP community were able to get together to make this happen… and that I was able to help! ","permalink":"http://localhost:1313/posts/file-picker-creating-a-custom-component-for-spfx-web-parts/","tags":null,"title":"File Picker: Creating a Custom Component for SPFx Web Parts"},{"categories":["SharePoint"],"contents":"Introduction I know, I know, there are already tons of SharePoint migrations to Office 365 \u0026ldquo;Best Practices\u0026rdquo; articles out there. My evil twin even wrote an article on how to fail a migration recently, which received much more attention than it deserved.\nI have done many large scale migrations and given many presentations on the topic, but I didn’t want this article to be a \u0026ldquo;things Hugo says you should do\u0026rdquo; article. There are many other authors who are much more insightful and eloquent.\nThis article is a compilation of the best \u0026ldquo;best practices\u0026rdquo; articles I could find. I have included the list of articles at the end.\nBy all means, do not trust that my conclusions are accurate or unbiased. Feel free to read all the referenced articles and make your own conclusions — and then comment below!\nOverview Approach I searched for SharePoint to Office 365 Migration Best Practices on Google and Bing and compiled all results.\nI did not include articles that were behind a paywall, or those that required you to provide an email to get access to the article/download anything.\nI also excluded any articles that were purely technical (e.g.: the ones that show you how to use a migration tool).\nAfter carefully reading each article, I create a table listing each article with every \u0026ldquo;best practice\u0026rdquo; idea discussed in the article.\nWhen looking for best practice criteria, I looked for articles that focused on the following outcomes:\nIncreased user adoption of Office 365 Increased user satisfaction No loss of productivity/increased productivity No loss of data Accuracy of migrated data Reduced risks I tabulated the best practices that appeared in 3 or more articles.\nI focused on the top 10 best practices but ended up with 11 topics. I chose to separate Clean Files and No \u0026ldquo;as-is\u0026rdquo; because — while they are arguably similar — most authors discussed both points separately.\nAnalysis The list below provides links to each of the articles reviewed. I chose to use a legend (instead of writing each best practice in the header) because I wanted the table to be easy to see at a glance.\nLegend\nThe following letters correspond to a best practice idea. We’ll discuss each idea below.\nA\nIncremental\nB\nInform Users\nC\nAnalyze/Audit\nD\nPlan\nE\nNo “As-Is”\nF\nAccurate Estimates\nG\nClean-up\nH\nTrain Users\nI\nInformation Architecture\nJ\nNot just an IT initiative\nK\nTest\nL\nChampions\nArticle Author A B C D E F G H I J K L 5 common mistakes when migrating to Office 365 lightningtools83 ☑ ☑ ☑ 5 Key Steps for Migrating SharePoint to the Cloud Steve Marsh ☑ ☑ ☑ 5 Mistakes To Avoid When Migrating from SharePoint to Office 365 Maggie Swearingen ☑ ☑ ☑ ☑ Adoption and SharePoint migrations – it’s a thing! Shafina Hassam ☑ ☑ ☑ ☑ ☑ ☑ ☑ ☑ Anatomy of a SharePoint Migration [INFOGRAPHIC] Joanne Klein ☑ ☑ ☑ ☑ ☑ ☑ Best Practices for a Smooth Office 365 Migration Michael Pichna ☑ ☑ ☑ Best way to implement SharePoint in a large organization Gregory Zelfond ☑ ☑ ☑ ☑ How to Migrate Documents to SharePoint and Office 365: Step-by-Step Instructions Gregory Zelfond ☑ ☑ ☑ ☑ Migrating SharePoint to Office 365 – Best (Recommended) Practices Veenus Maximiuk ☑ ☑ ☑ ☑ ☑ ☑ ☑ ☑ Migrating to SharePoint Online? Get this ULTIMATE checklist ready! Arut Selvan ☑ ☑ ☑ ☑ ☑ Moving file shares to SharePoint on-premises to SharePoint Online isn’t a simple lift and shift Tervela ☑ ☑ ☑ Recommended Best Practices for Migrating SharePoint to Office 365 Veenus Maximiuk ☑ ☑ ☑ ☑ ☑ ☑ ☑ ☑ ☑ SharePoint Migration Infographic GTconsult A Team ☑ ☑ ☑ ☑ Top 5 Mistakes to Avoid When Migrating to Office 365 David Davidov ☑ ☑ ☑ Findings Incremental Many authors agree that you should migrate your content incrementally, or in batches, rather than migrating everything at once.\nFor example, you should consider migrating content on a team-by-team basis. Doing so gives you the opportunity to properly analyze and audit the data to be migrated, clean up the data and re-organize it as you migrate, and spend quality time with the users to inform them and train them.\nIt also gives you the opportunity to test each migration and — more importantly — to get your content owners to verify (and possibly sign-off) on the migration.\nGetting sign-off from content owners is a great way to help speed up the decommissioning of the old data (which is a re-occurring best practice, but didn’t make the top list).\nInform Users The topic of \u0026ldquo;Informing Users\u0026rdquo; and \u0026ldquo;Communicating\u0026rdquo; was one of the most common best practices. Most experts agree that you should inform your users in advance about the exciting new platform they’ll soon be using, describe the benefits of the new platform, and inform them of timing.\nMigrating to Office 365 impacts users. Your users may make up their minds to \u0026ldquo;boycott\u0026rdquo; the new platform before they even see what’s coming.\nThis is often due to fear of the unknown from your users.\nTake the time to explain to your users what’s coming, how they will benefit from this migration, and when it will happen.\nYou can’t expect users to drop everything they’re doing for your migration. Try migrating the accounting department during fiscal year end and you’ll see just how much push back you can get from your users.\nAnalyze/Audit The # 1 best practice seems obvious, but it is often forgotten.\nBefore migrating, you should perform an in-depth analysis of the content you’ll be migrating. Don’t just count how many files there are!\nConsider the following :\nCustom solutions Business processes that will be affected Security/permissions Deprecated features File path length (see this article to understand why you should care) Metadata How much space will be needed to migrate Not all content needs to be migrated (see Clean Up, below), but every piece of content should be accounted for. While most of your files may be migrated, some may be archived or skipped because they are duplicate. Keeping an audit of all your content, along with their migration status will help ensure that all your content is accounted for.\nPlan A successful migration begins with creating a migration plan.\nThis is what I typically put in my migration plans:\n- Objectives and Goals\r* Business-Related Goals\r* Migration-Related Goals\r- Migration Strategies\r* Strategy 1\r* Tools\r* Implications\r* Strategy 2\r* Tools\r* Implications\r* ...\r* Strategy n\r* Tools\r* Implications\r- Migration Environment\r- Migration Guidelines\r- Migration Process\r* Preparation\r* Migration Step 1\r* Migration Step 2\r* ...\r* Migration Step n\r* Migration Execution \u0026amp; Validation\r* Decommissioning of Replaced Resources\r* Rollback Plan Your migration plan should include going to each team in your organization and identify their processes, the custom solutions they use, the files they need and plan how and where you will migrate everything.\nNo \u0026ldquo;As-Is\u0026rdquo; Let me be clear: none of the best bet articles I listed above explicitly say \u0026ldquo;No As-Is\u0026rdquo;.\nMost experts agree, however, that doing a simple \u0026ldquo;lift and shift\u0026rdquo; is a bad idea.\nDon’t simply copy the documents over \u0026ldquo;as-is\u0026rdquo;. Take the time to re-evaluate the Information Architecture to take advantage of the capabilities that SharePoint Online offers with Office 365.\nConsider moving the sub-sites within sub-sites to a flatter site structure.\nConsider using hubs to group sites together.\nConsider distributing sub-folders to different document libraries.\nLook for long file URLs and make sure that they’ll fit within the URL length limits once migrated.\nJust make sure that you don’t accept the status quo.\nAccurate Estimates Failed migrations often underestimate the effort involved in migrating content to Office 365.\nTo paraphrase George W. Bush, \u0026ldquo;don’t misunderestimate the effort involved\u0026rdquo;.\nAs Joanne Klein explains in her article, don’t underestimate the time it takes to plan the migration.\nYou also need to estimate the time you will need to migrate the files.\nWhat’s the best way to estimate the migration effort? Perform test migrations with real files.\nYou can actually test the migration in your new Office 365 tenant. If you’re concerned about \u0026ldquo;tainting\u0026rdquo; your production environment, just migrate a site to a temporary destination in your production environment (e.g.: HR to HRTest) and delete the site after your tests are complete.\nOnce you have performed a test migration you can extrapolate the time it took to perform the test (including the time it took to do the analysis and planning) to get a better estimate.\nClean-up As we discussed above (see No \u0026ldquo;As-Is\u0026rdquo;), you should not simply lift and shift your files.\nTake this opportunity to clean up files as you go. Remove duplicates, remove old files and other files that have no business being moved to the new environment.\nIf your business folks have a \u0026ldquo;let’s keep files forever\u0026rdquo; retention policy, now is a great opportunity to encourage them to adopt an adequate retention policy.\nWhile you’re at it, look for documents that have the words \u0026ldquo;Final\u0026rdquo; or \u0026ldquo;Draft\u0026rdquo; in them. Then look for documents with the same name — but without \u0026ldquo;Final\u0026rdquo; and \u0026ldquo;Draft\u0026rdquo; in them (they often have dates or version numbers in the file names as well). They usually indicate users who don’t quite understand how versioning works in SharePoint.\nThat’s also a sign that you should train your users.\nTrain Users With the number of training resources available out there, there are no excuses for not training your users.\nThe only valid reason for not training your users is if you want your migration to fail.\nInformation Architecture Take the time to create an Information Architecture for your migrated content.\nIf you don’t take the time to develop an Information Architecture that will help your users find the content they need, they’ll blame SharePoint for not being able to find documents and you’ll get poor user adoption.\nIf you need help with developing an Information Architecture, I’ve written a few articles on the subject — but there are plenty of resources out there.\nNot just an IT initiative “Be prepared to answer the question \u0026ldquo;how much of my time/my staff’s time will you need?\u0026rdquo;. Someone will ask.\nMigrating SharePoint to Office 365 is more than just moving files and server resources. You need to change how your users will work too.\nDon’t approach your migration as an IT-only initiative. It should not be.\nGet executive buy-in, involve your stakeholders, involve your users.\nThe IT team can lead the migration initiative, but you need to involve other departments as well.\nConsult the teams as you move their content and make sure that you listen to their pain points. Find a way to alleviate their pain points in Office 365.\nAs we said before, don’t forget that other departments also have jobs to do. They aren’t waiting at your beck and call. Be considerate of their time.\nBe prepared to answer the question \u0026ldquo;how much of my time/my staff’s time will you need?\u0026rdquo;. Someone will ask.\nTest Most experts will encourage you to test your migration.\nBy \u0026ldquo;testing\u0026rdquo;, we don’t mean counting how many files are in the source and — after migration — counting how many files are in the destination to see if it matches.\nBefore the real migration, perform a test migration with real documents to your real production environment and verifying that everything that was supposed to migrate did migrate.\nAfter migration, get your content owners to test finding and opening documents.\nVerify that you didn’t lose metadata when you migrated.\nVerify that permissions are accurate and that users who shouldn’t see files won’t see those files.\nVerify that those files with the longest URLs can be opened on a user’s workstation without any issues.\nChampions Along the same lines as Not just an IT initiative and Train Users, consider finding users who are willing to be your first test subjects.\nThey’ll become your champions later.\nDon’t let some executive name their favorite people who don’t have any real experience using the old SharePoint site. Find actual users who are suffering so much that they’re willing to spend extra time testing the new platform, finding all warts and bugs — just for the possibility that the new platform will make their lives better.\nFind those users who aren’t afraid to complain loudly, but who are willing to listen.\nFind those who are influential among their peers. They’re the ones that will encourage other users to adopt your new platform.\nWorking with champions usually consists of three phases:\nEngage: Get the champions involved in the decision process. Show them the possibilities. Try giving them choices (\u0026ldquo;would you prefer A or B?\u0026rdquo;) and avoid asking questions that require them to be Office 365 experts to answer (\u0026ldquo;what content types do you need?\u0026rdquo;). Empower: Give your champions permissions to manage their own site. Give them room to make mistakes and to recover from them. Extend: Encourage your champions to extend their use of SharePoint Online. Encourage them to create new document libraries, to invite other users, and to push the boundaries of how they’ll use what’s at their disposal. Remember: users don’t always tell you what they need, they often tell you what they think you want to hear — letting your champions extend how they use their new site may reveal requirements that were never discussed. If you find that your users tell you that they don’t have time for you, that they’re too busy, it is probably because you didn’t try to find champions first.\nOnce your champions find how awesome Office 365 is, they’ll tell other users. Those users who were too busy and didn’t have time for you will soon be begging to work with you because they want to have all the cool stuff the champions got.\nConclusion Every expert has their own perspective on what best practices exist when it comes to migrating SharePoint to Office 365, but there are common ideas that they all seem to agree with.\nI would love to make this list even more comprehensive. If you have found an article that you believe should be included in this article, please let me know in the comments. I’ll keep growing the list and updating the research.\n","permalink":"http://localhost:1313/posts/compilation-of-sharepoint-to-office-365-migration-best-practices/","tags":["Migration"],"title":"Compilation of SharePoint to Office 365 Migration Best Practices"},{"categories":["Visual Studio Code"],"contents":"Introduction A few days ago, I was showing a co-worker on how to localize a web part using SPFx. I had a series of words to copy and move into a JSON structure.\nI selected the whole text and inserted a \u0026quot; in front of every word, a \u0026quot; after every word, and a , at the end of every line in about 5 keystrokes.\nHOW DID YOU DO THAT?!\n\u0026ldquo;HOW DID YOU DO THAT?!\u0026rdquo; my co-worker asked, inappropriately too loud for a quiet office setting.\nI could have produced a rabbit from the computer and he wouldn’t have been more impressed.\nHe had never used multi-cursor editing before — or, apparently, seen anyone use it.\nThen I remembered another time, a few months ago, when I had shown the same feature to a friend of mine. Someone that I have looked up to and respected for over 15 years, who has more to teach me than I could ever teach him. He had said, \u0026ldquo;you should blog about this!\u0026rdquo;.\nI had completely forgotten about it.\nThis article will demonstrate how to use multi-cursor editing. I don’t think it is particularly earth-shattering, but I do hope that someone else will learn ways to save some keystrokes.\nMultiple Cursors in Visual Studio Code for Windows Multiple cursors is a feature that is available out-of-the-box within Visual Studio Code. (It is also available in Visual Studio, but some of the shortcut keys are different).\nYou use multiple cursors by creating multiple cursors in your editing window (selecting all instances of text you wish to edit), and editing your text.\nOnce you have multiple cursors in place, you can move them just like you would a single cursor, by using the arrow keys.\nTo go back to single-cursor editing, just hit ESCAPE.\nIt takes a while to get used to it, but once you get the hang of it, it can save you quite a bit of time.\nCTRL+ALT+ ↑ / ↓: Select next/previous line If you have a bunch of text in consecutive lines, you can simply start on a line and add cursors on the lines before or after by using CTRL-ALT-↑ or CTRL-ALT-↓.\nALT-CLICK: Create cursors If you want to insert multiple cursors throughout a document that aren’t on consecutive lines, you can simply hold ALT and click on each line.\nCTRL-U: Undo last cursor operation Picture this: you carefully selected over one hundred lines by alt-clicking and — as you get ready to click on the last line — you click on the wrong line. You may think that alt-clicking again will deselect the line, but you’d be wrong. And don’t try to let go of the ALT key to de-select the wrong line because you’ll lose your entire selection!\nSimply hit CTRL-U to under your last cursor operation. You can continue hitting CTRL-U to undo more cursor operations.\nCTRL-SHIFT-L: Select current match You can insert cursors in every instance of the selected text by clicking CTRL-SHIFT-L. It saves you from having to manually find every instance of a word and Alt-click on every word. Fast!\nCTRL-F2: Select current word To select all instances of the current word hit CTRL-F2.\nSHIFT-ALT-→ / ←: Expand/shrink selection If you select a word and want to include the quotes (or brackets, or anything that surrounds a word), you can use SHIFT-ALT-→ to expand your selection. For example, if your cursor is in the middle of every word, hitting SHIFT-ALT-→ will select the entire words. Hitting SHIFT-ALT-→ again will select the quotes around each word, and it will continue extending the selection every time you hit SHIFT-ALT-→. To shrink your selection, using SHIFT-ALT-←.\nRectangular Selections You can use rectangular selections to edit … well, rectangular areas of text.\nSHIFT-ALT-Drag: Create rectangular selection If you hold SHIFT and ALT while dragging your mouse, it will create a rectangular selection area, regardless whether there is text under the selection or not.\nSHIFT-ALT-CTRL-Arrows: Create rectangular selection (keyboard-only) You can also select a rectangular area from your current cursor position by using your arrow keys while holding SHIFT-ALT-CTRL.\nYou can also use SHIFT-ALT-CTRL-PG UP and SHIFT-ALT-CTRL-PG DN to extend your rectangular selection by an entire page.\nOther shortcuts to use with multi-cursor These shortcut key combinations are not unique to multi-cursor editing, but — when used with multi-cursor editing — they can be quite useful.\nCTRL-L: Select entire line You can select the entire line where your cursor(s) sit by hitting CTRL-L.\nCTRL-→ / ←: Select to word boundary Holding CTRL while using the left and right arrow will move the cursor to the next word boundary. A word boundary is anything that’s not an alpha-numeric character, like space, quote, hyphen, etc. If you hold SHIFT while doing CTRL-→ or CTRL-←, it will select from your current cursor position to the next word boundary.\nConclusion Editing multiple with cursors in Visual Studio Code allows you to increase productivity by reducing repetitive steps and keystrokes.\nI hope that you’ll enjoy using multiple cursors in the future!\n","permalink":"http://localhost:1313/posts/multi-cursor-editing-in-visual-studio-code/","tags":null,"title":"Multi-Cursor Editing in Visual Studio Code"},{"categories":["SharePoint"],"contents":"Introduction A few years ago, my son fell in love with a song on the radio. He kept on asking us to play the song for him.\nThe problem is: like me, he is on the Autism Spectrum. He isn’t always good at communicating.\nHe’s incredibly sweet and incredibly caring, but he wasn’t a very good singer.\nHe didn’t know what the song was called. He couldn’t sing it for us. He just called it the \u0026ldquo;nehbie decktur\u0026rdquo; song.\nWhen we asked what song he meant, he would just repeat the same sound over — in a sing-songy way.\n\u0026ldquo;Nehbie decktur\u0026rdquo;\nIf you’ve ever tried to Google something when you don’t have the right keywords, you know how hard it is to find information.\nI searched and searched everywhere for that damned song.\nI tried to get him to hum the song in one of the various tune-matching search engines. No luck.\nUntil one day, the song came on the radio and my son heard it.\nThat song was Rude by Magic!.\nThe part where they sing \u0026ldquo;Marry that girl\u0026rdquo;, in his mind, sounded like \u0026ldquo;Nehbie decktur\u0026rdquo;.\nTo this day, we still call that song Nehbie decktur.\nThe Problem When we design Information Architecture (IA), we often assume that people find content in one way.\nIf they know exactly what they’re looking for, they’ll search for content.\nBut if a user doesn’t know what keywords to use in their search query, it can be very difficult to find the content they need.\nIn this article, we’ll describe how we find content in different ways and how to design your Information Architecture to accommodate the various ways users find content.\n3 Ways We Find Content When looking for content, we use one of 3 approaches:\nBrowsing Searching Subscribing We’ll describe each approach below.\nBrowsing Browsing allows users to find content through discovery.\nLet’s use an example: Nancy the New Employee recently started at Contoso Inc.\nShe isn’t familiar with the organization structure, the department names, or even the company’s lingo. She can’t search because she doesn’t know what keywords to use.\nBrowsing isn’t only for new employees. It allows users to find content in an area of expertise that they aren’t familiar with.\nFor example, your company may reimburse eligible daycare expenses for employees. Your Human Resource professionals, who are subject of matter experts on all things HR, may call this Childcare support plan.\nHowever, your employees probably look terms like daycare, babysitting, or pre-school. Unless your HR folks used those keywords in their content, your users won’t find what they need.\nBut if you have a SharePoint site that lists all benefits in one place (maybe grouped by life events, like getting married, having children, retiring, etc.), it will allow your employees to find the content they need without being experts in Human Resources.\nTo support browsing, make sure that users can access every piece of content by following links.\nThere shouldn’t be any secret stash of content anywhere that can only be accessed through search.\nHow to design for browsing Read up on navigation fundamentals for SharePoint. Consider using megamenu navigation. Use hub sites to logically group sites together. Use news to highlight recently added content. Use the hero web part to highlight important content. Avoid creating navigation that mimics your company’s org chart, but consider creating a site (or a page) that lists your organization’s divisions and departments. Consider creating a glossary site (or page) that shows your company-specific and industry-specific terms. Searching When users know exactly what they’re looking for, they use search. It is the fastest and most direct way to get to the content they need.\nMicrosoft’s own Overview of search in SharePoint Online is a good place to get started with search best practices, including:\nMake sure content can be found Make sure results look great Show relevant search results There are a few other things to consider:\nContent consumers don’t always share the same domain of expertise as creators In our previous example our consumer, Nancy the New Employee, isn’t a Human Resource professional. She doesn’t know that the proper keyword should be childcare.\nUnfortunately, the HR professionals (i.e.: the creators of content) use the proper terms in their documentation.\nWe can’t expect the content creators to start tagging every single document with every single keyword that users might be thinking of.\nOne way to design for Search that satisfies the needs of both consumers and creators of content is to use managed metadata, particularly synonyms.\nFor example, to create synonyms for childcare, you would follow these steps:\nGo to your SharePoint tenant admin site (i.e.: https://**yourtenantname**-admin.sharepoint.com) From the SharePoint Admin Center, find term store in the left navigation. You can create your own term set (I created one called Human Resources) or use an existing one. Select the term set you wish to use and select Create term from the context menu.\nThe new term will be created in the navigation tree, just type the keyword your content creators will use. For example: childcare.\nIn the right pane, while your new term is selected, find the Other labels field in the General tab and enter all the terms your consumers will use. You can type more than one keyword, just use the Enter key to create a new line. In our example, I typed daycare and babysitting.\nHit Save to save your changes. When users look for childcare or babysitting, they will find documents that also contain the word daycare.\nSometimes your consumers will use newer terms than your creators used. During the first H1N1 flu outbreak started making the news. My client’s SharePoint servers started getting queries for H1N1 with no results found. However, the company already had detailed documentation on flu prevention and preventing outbreaks.\nBy monitoring search queries (the No Result Queries by Day and No Result Queries by Month, in your Admin center’s Search \u0026gt; Search Reports are a good place to start), we were able to notice the increased number of searches for H1N1. After a bit of research, we found that all we had to do was to create synonyms for flu, influenza, \u0026ldquo;orthomyxovirus and H1N1**. Just like that, users were able to find existing content for** H1N1** they could not find the day before.\nConsider search in your custom SPFx web parts If you create custom SPFx web parts that use custom properties to store displayable content, your users may want to find the page containing your web part.\nFor example, I created a web part sample that allows users to create sequence diagrams and flowcharts using simple text. One of the web part sample, the Sequence diagram, exposes the text of the diagram as searchable by SharePoint.\nIn order to make the content of the web part searchable, I exposed the accessibleTitle and the accessibleText properties as isSearchablePlainText. (My web part creates an accessible equivalent of the diagram for users who use screen readers).\nTo do so, simply add a get propertiesMetadata method in your web part class which returns a list of property names and isSearchablePlainText: true.\nprotected get propertiesMetadata(): IWebPartPropertiesMetadata { return { \u0026#39;accessibleText\u0026#39;: { isSearchablePlainText: true }, \u0026#39;accessibleTitle\u0026#39;: { isSearchablePlainText: true } }; } If your property contains HTML text, you can also use isHtmlString: true in the same fashion.\nSubscribing The last way people find content is when the system finds content that the user has indicated they are interested in — either explicitly or implicitly — and returns that content.\nThis can be done explicitly by users creating Alerts or by Following a site.\nBut it can also be done by SharePoint recommending content on the SharePoint Home, SharePoint News showing aggregated news posts from sites the user belongs to or even Delve analyzing the user’s interests via emails, tasks, etc.\nThe important point here is that if you design your information to be \u0026ldquo;subscribable\u0026rdquo;, your users will find that information when they need it.\nFor example, if your company has offices in Toronto, Helsinki and Melbourne, you could create a single News site and post office news from all three offices on that site. But when someone posts news about the Helsinki office that is really intended for folks from the Helsinki office (\u0026ldquo;Freshly baked korvapuusti at reception!\u0026rdquo;), do we really want everyone in the company to get that news post?\nNote: that’s probably not a good use of SharePoint news, but korvapuusti (a yummy cinnamon-bun-type-thing with pearl sugar on top) and coffee is worth broadcasting!\nUntil audience targeting is available in News (which was announced recently, but then went missing from the announcement), you could create 3 sites (one for each office), and post news in each respective site.\nOnly users who follow the Helsinki office will see the news about the cinnamon \u0026ldquo;ear buns\u0026rdquo; promoted to them, while the other two offices will be blissfully ignorant.\nHeikki, if you’re reading this, I could use some korvapuusti right about now. Oh and some ruispala, kiitos.\nAnother way to create \u0026ldquo;subscribable\u0026rdquo; content is to break it into smaller elements.\nFor example, maybe I want to have a list of items listed somewhere that people would want to know right away if something new is added.\nYou could simply use the rich-text editing feature on a modern page and list all the items, but it will require users to actively subscribe to the page in order to get notified. If the page has other content on it, they’ll get notified every single time any part of the page changes.\nThe other option is to create that list of items in a Custom list. Your page can use the List web part to embed the list. Now your users can subscribe to that list to get notified.\nConclusion I have barely scratched the surface of how to design your Information Architecture for browsing, searching, and subscribing, but I hope that I managed to convey that people don’t all find content the same way, and that taking some extra time to consider how people find content will help you design a better SharePoint.\nAs for me, I suddenly have a craving for cinnamon buns. I have to go make a batch for tomorrow morning! (Sugar-free, of course)\nI hope this helps?\n","permalink":"http://localhost:1313/posts/information-architecture-in-sharepoint-3-ways-we-find-content/","tags":["Information Architecture","IA"],"title":"Information Architecture in SharePoint: 3 Ways We Find Content"},{"categories":["Personal"],"contents":"Introduction I have known this couple for many years. They are both great friends and got the opportunity to work on engagement with both (at separate times — I’m not getting involved in a husband/wife at work situation!).\nA few years ago, they learned that their son was diagnosed with Autism Spectrum Disorder (ASD).\nIt was hard news for both, but the mother took the news especially hard.\nIn her mind, it was as if her son had been sentenced to never achieve any form of independence, to never fit in socially, and to never be able to have a job. Her son would never marry, have 2.4 kids, and buy that white picket fence.\nWhen she shared her fears with her husband, he told her: \u0026ldquo;You know that Hugo is Autistic, right?\u0026rdquo; (I’m sure he said it with a lot more sensitivity than I did, but I’m the one telling the story). \u0026ldquo;He’s successful at his job. He traveled the world for his work! He got married. He has kids.\u0026rdquo;\nI’m sure that it didn’t take her pain away, but — at that moment — it helped her to know that someone she knew, someone she had worked with, who was ok at his job, who had a weird sense of humor also shared an ASD diagnosis.\nI read her blog today. She chronicles her journey as a parent of a child with ASD, and her own son’s journey. She writes beautifully poignant stories.\nI asked her why she didn’t share her blog.\n\u0026ldquo;I write for me. It’s therapeutic\u0026rdquo;, she replied.\nI encouraged her to share her blog, telling her that other parents of children with ASD would benefit from reading her blog.\nThen it occurred to me that I was being hypocritical. I encouraged her to share her story, but I have never discussed my own ASD.\nI don’t like talking about it (unless I use it as an excuse to act like a jerk, then I blame my autism). But just like my friend’s blog can help others, I hope that my writing about being a professional IT consultant with ASD will help someone else.\nI don’t rock myself back and forth, insist on pancake Tuesdays, have the ability to instantly count toothpicks on the floor (246), or many other things people think is associated with autism.\nI’m not especially smart. I’m not violent (unless you stand between me and my first coffee), and I’m not a savant. I’m not particularly good with numbers (ask my accountant). I’m not cold or lack empathy (but I don’t always agree with everyone being so emotional about everything either).\nDon’t get me wrong: I’m still weird. I’m still socially awkward. But I’m also independent, I haven’t had to look for work in over 20 years, I often do public speaking engagements, blog regularly, and I found an amazingly loving wife who tolerates my quirks.\nI also have three beautiful children, two of which are also on the autistic spectrum.\nNone of the things I have achieved in life make me prouder than seeing my children become amazing human beings.\nBeing autistic does not mean being condemned to never achieve anything in life. It comes with its own set of challenges, neither better nor worse than any person — neuro-typical or not.\nThe Reason I Jump The title of my post is a play on the book The Reason I Jump: The Inner Voice of a Thirteen-Year-Old Boy with Autism, by Naoki Higashida. If you haven’t read the book yet, I strongly recommend it.\nIt amazes me how the author, as a 13-year old, was able to express his answers to the questions he imagines others most often wonder about him in a way much more eloquent than most of us with ASD would ever be able to. And he did so with the use of an alphabet grid to painstakingly spell everything out.\nI cannot hope to have the same clarity or eloquence as he does in his book. He writes with such insights into the inner workings of his mind that reading his book helped me gain insights into my own mind.\nIt often feels like more of an autism user’s manual than a book.\nWhere I have been The purpose of this article is not to brag about the things I have done. I’m not trying to make people feel bad for me. I’m not trying to excuse the things I do or who I am.\nI’m just trying to establish a bit about myself.\nI grew up near Quebec city, speaking French. I started playing with computers when I was 12. It started as a way to bond with my dad — he would read code from one of those old computer magazines, and I would type the code in. It quickly became my passion, because I felt that I could express myself through code.\nI started consulting when I was 16. I eventually moved to Ontario to learn to speak English and I’ve been busy ever since.\nIf a 16-year old was hired to come into your place of work to teach you how to do your job — which you have been doing longer than he has been alive — you would probably resent it. I had to deal with people who felt threatened by me — some even threatened to beat the crap out of me.\nTo avoid getting beat up, I learned to develop consulting \u0026ldquo;tricks\u0026rdquo; to integrate better with the clients’ staff and achieve better success. I subtly mirrored people’s postures and gestures, picked up the same way of speaking, used \u0026ldquo;us\u0026rdquo; (versus \u0026ldquo;us\u0026rdquo; and \u0026ldquo;them\u0026rdquo;). I learned time management skills, presentation skills, and anything else that would make me appear more \u0026ldquo;professional\u0026rdquo; (instead of \u0026ldquo;just a kid\u0026rdquo;).\nAt first, I was one of those geeky IT people who did not tolerate people who don’t understand computers or software.\nIt wasn’t until I joined McKinsey \u0026amp; Company as a Senior Associate that I learned to appreciate the giant gap between business (i.e.: the people who did not understand computers), and technology (i.e.: the techy bits).\nI had to learn to explain technical stuff to C-level executives in a way that would make them excited about technology and explain \u0026ldquo;business-y\u0026rdquo; stuff to developers and IT folks in a way that would make them understand the business needs.\nIn other words, I learned to be one of those geeky IT people who tolerate people who don’t understand computers and software.\nI had found a niche, it seems. At a time when 16% of software projects were delivered on-time, on-budget, and met the business needs, I learned to bridge that gap between business and technology — which happened to be one of the leading causes for software project failures.\nMy work took me all over the world: China, Japan, Singapore, Hungary, Germany, France, UK, Finland, Malaysia, Indonesia, Australia, South-Africa, United States and Canada — that’s just the ones I can remember.\nI have worked in various industries: Healthcare, Finance, Energy, Transportation, Education, Government, Manufacturing, Professional Services. Each with their own domains of expertise and processes.\nI like to keep my engagements pretty short because I get bored when things are no longer challenging.\nUsually, by the time a company brings me in to help with their projects, they have tried to implement a software solution and failed 2 or 3 times before.\nEvery engagement is different: different language, place, industry, company, background, problem and solution.\nIn fact, the only common thing about my work is the unknown.\nSo how does someone affected by a developmental disorder that predisposes them to fear the unknown and react negatively when faced with unpredictable situations make a living embracing the unknown and unpredictable solutions with every new engagement?\nDealing with Chaos In his book, Naoki Higashida compares having autism with being in a room filled with radios that are all tuned to different radio stations, each one with the volume at full blast (I’m paraphrasing here, the author is much more eloquent than that).\nAutism people often have difficulty prioritizing the various inputs. Sounds, smells, textures, colours are all like one of those radios blasting to compete for attention.\nIt requires a lot of focus and self-control to learn to prioritize each of those stimuli so that we can process the information.\nAs Higashida-san puts it best:\n“When you see an object, it seems that you see it as an entire thing first, and only afterwards do its details follow on. But for people with autism, the details jump straight out at us first of all, and then only gradually, detail by detail, does the whole image float up into focus.”\nNaoki Higashida, The Reason I Jump: The Inner Voice of a Thirteen-Year-Old Boy with Autism\nI deal with the unknown of every new engagement by applying a pre-established framework for everything.\nSeriously. It’s annoying. (Well, to everyone but me, I’m sure)\nWant to migrate to Office 365? I have a migration framework.\nProject has a risk that we should address? I have a risk management framework.\nNeed to gather requirements? I have a framework.\nPresentation needed? Framework.\nAnd it goes on.\nI didn’t invent those frameworks. I have learned to stand on the shoulders of giants and use pre-established frameworks that people who are much more intelligent than I have developed.\nI even have a framework for dealing with the unknown. One for solving problems.\nNote that I call them frameworks, not methodologies or processes because they consist of a series of pre-established guidelines that evolve and adapt to changing needs and not a rigid set of steps that do not evolve.\nKnowledge that does not evolve is dogma.\nIf I don’t have a framework for something, I’ll have an eponymous law to explain my recommendation.\nTalking about user experience? There’s Fitts’s Law, Miller’s Law, Hick’s Law, etc.\nWork durations? Parkinson’s Law.\nPeople and skills? Dunning-Krueger.\nTo quote my friend Luis: \u0026ldquo;Hugo has a law for everything\u0026rdquo;. It usually sounds more of annoyed observation than a compliment, but I choose to accept it as a compliment.\nI’m sure it is annoying to everyone who has to work with me, but it helps give credibility to your ideas when you can refer to a higher authority. It’s not Hugo that says you should lay things out on a page to accommodate for the left-to-right, z-pattern movement of the eyes when looking at evenly distributed items, it’s Gutenberg. He’s a lot more credible than I am.\nThese laws, frameworks and rules help me make sense of the chaos and the unknown and give me structure. If you want to see me lose my cool, try taking that structure away.\nMy frameworks are the safety blankets that help me deal with the scary unknown.\nAnd when I finally figure out what the solution to a problem is, and it involves coding, I get to convert those ideas into a language that computers can understand.\nWith code, there is no grey area. There are only zeroes and ones.\nDone and not done.\nIt really upsets me when a co-worker says to me that there is a random bug. That \u0026ldquo;for some weird reason\u0026rdquo; something doesn’t work. Or that a bug \u0026ldquo;just went away\u0026rdquo;.\nIt’s not random, it just appears random to us. It’s not a weird reason, it’s a very logical reason that we haven’t quite figured out yet. It didn’t go away, the condition that causes the bug went away temporarily — the bug is still there.\nBut then I relish the idea of breaking down the problem and methodically find the problem until we solve the issue.\nStandards of Success The standard by which I measure my success is different from yours.\nI get to play with computers every day. I get paid for doing that. At least I think I get paid.\nI get to talk to audiences about my passion. I get to bond with people over software, just as I did when I was a kid.\nOn the other hand, I can’t drive a car. I have a driver’s license, but I don’t drive. Instead of a feeling like a room filled with radios at full blast, driving is like a car filled with horns blasting in my ears.\nI can’t do taxes or most forms of paperwork. The questions are too vague. Yet, I can design forms for a complicated business process.\nI can’t talk on the phone. I can do conference calls because they’re scheduled and the topic is often pre-defined, but I can’t do a one on one call, because I can’t see some of the social cues that I’ve learned to rely on. I could be on the phone and someone would say \u0026ldquo;Sorry I missed our meeting, I was at my mom’s funeral\u0026rdquo; and I might say something stupid like \u0026ldquo;Haha, that’s funny!\u0026rdquo;, or \u0026ldquo;That’s great!\u0026rdquo;.\nI don’t get some social conventions. For example, I won’t say \u0026ldquo;Bless you\u0026rdquo; when you sneeze, because I don’t actually believe that your soul escaped your body. I’m not trying to be rude — just rational.\nI’m diabetic, and if I don’t eat at regular intervals and control my blood sugar, I crash. Yet, when I’m working, I completely forget to eat, sleep, and go to the bathroom (until the very last possible moment).\nPeople will say \u0026ldquo;why don’t you just go eat when you’re hungry?\u0026rdquo; but they don’t seem to understand that the organ that’s responsible for producing insulin in your body is also responsible for alerting you that you’re running low on sugar. If you’re diabetic, that organ is defective (for some weird reason).\nIf you’re autistic and diabetic, your body is not doing a good job at warning you that you need to eat, and your brain isn’t doing a good job at listening to those warnings.\n\u0026ldquo;Why don’t you set an alarm?\u0026rdquo;, they’ll suggest. That sound of an alarm blaring in the background may not even register when competing against the sound of the air conditioner fan, the electrical buzzing somewhere in the house, or the computer fan right in front of me. Any sort of rhythmic sound or pattern takes over — even the sound of your own heartbeat — and forces you to dig deeper and shut the world out just so it does not drive you crazy. An alarm isn’t going to make a difference.\n(Thankfully, I have a loving wife who once in a while makes sure I still have a pulse).\nSome of these skills might be someone’s idea of being a successful grown-up. They might even be vital to one’s survival (like eating when one’s blood sugar is low). I have learned to accept that they aren’t part of my criteria for success.\nAnd I’m ok with that. (Although I’m sure my wife would be happier if I drove)\nConclusion I love my work. Occasionally, I have to deal with Lindas, but it is mostly awesome 🙂\nI love it because it allows me to approach every problem with a structure. It gives me a sense of security, well-being, and self-worth that I crave when I’m not working.\nI try to teach my kids to question everything and to try to find what makes them truly happy. If they can do\nsomething that makes them happy, they’ll never really work a day in their lives. It will always feel fun.\nTo quote Naoki Higashida:\n“To give the short version, I’ve learnt that every human being, with or without disabilities, needs to strive to do their best, and by striving for happiness you will arrive at happiness. For us, you see, having autism is normal — so we can’t know for sure what your ‘normal’ is even like. But so long as we can learn to love ourselves, I’m not sure how much it matters whether we’re normal or autistic.”\nNaoki Higashida, The Reason I Jump: The Inner Voice of a Thirteen-Year-Old Boy with Autism\nIf your children have been diagnosed with ASD, you can help them succeed and be happy by helping them make sense of the world around them.\nI’m not implying that every autistic child will end up a public speaker or an IT consultant — I understand that autism is a spectrum, and I have had it pretty easy compared to others — but a diagnosis does not instantly mean that they will never live a happy life either.\nRemember that your \u0026ldquo;normal\u0026rdquo; isn’t necessarily their \u0026ldquo;normal\u0026rdquo;. Your idea of success may not be the same as theirs, but as long as they’re happy, you should be too.\nCredits Header image by Gerd Altmann from Pixabay\n","permalink":"http://localhost:1313/posts/the-reason-i-consult-the-inner-voice-of-a-40-something-year-old-with-autism/","tags":["Autism","ADHD"],"title":"The Reason I Consult: The Inner Voice of a 40-Something-Year Old with Autism"},{"categories":["Software Development"],"contents":"By Oguh Reinreb, Evil Consultant\nNOTE: Today’s post was written by Hugo’s evil twin Oguh. The views, information, or opinions expressed in this guest post are solely those of the evil twin involved and do not necessarily represent those of Hugo Bernier.\nIntroduction Everybody can migrate SharePoint to Office 365, right?\nAll you need is a credit card to create an Office 365 tenant and an old SharePoint instance and you can get started migrating your files!\nBut if you’re looking for job protection — or if you’re offering professional services — you probably don’t want the migration to happen too fast.\nWhy would you want the migration to complete quickly when you can just let it drag longer than it should?\nThis article will give you pro tips to guarantee your migration from SharePoint to Office 365 will fail.\nThis list is a compilation of pearls of wisdom that I have learned over the years with dealing with people who know better.\nFollow this list and you’ll be able to bleed your employer/client of all their money and not deliver anything of value. And if you do deliver something, it’ll be completely useless.\nYou can always blame Microsoft if it doesn’t work.\nWhat do we mean by failing? The best way to fail is to avoid establishing any kind of success metrics. If people don’t know how to measure your success, they’ll never know you failed.\nBut to make sure you fail real good, let’s establish some failure criteria:\nCosts overruns and delays: a study by Deloitte (I think it was Deloitte, but who cares, 82% of statistics are made up on the spot — who will check?) found that the common practice of awarding a contract to the lowest bidder usually results in project delays and spending over budget. In fact, the average cost is equivalent to 5 times higher than the price of the highest bidder. Now that’s something to strive for! Poor user adoption: if you improve your user’s lives and made them more productive, they’ll keep on expecting more from you. Make sure that the migration you did is so bad that your users won’t want to use SharePoint and that they’ll find alternate ways to store documents and collaborate. That’s what email is for anyways. Lost files and metadata: If your old SharePoint library had 1,000 files, just make sure that you migrate 1,000 files over. That’s enough QA. Nobody needs metadata. Don’t involve your users Ugh. Talking to users is such a waste. of. time.\nWhy should you spend your valuable web-surfing time at work to interview your users and find out what their pain points are? That’s like saying \u0026ldquo;please whine some more\u0026rdquo;.\nJust because your users spend all their time doing their daily job doesn’t mean that they understand what they need better than you. I mean, they don’t know anything about IT, probably less about SharePoint, so how can they possibly add value?\nRemember: you know better\nThe worst part about interviewing your users and asking them for their pain points is that it would give you something to measure your success with. Users might actually expect you to deliver everything they ask for.\nMy advice: don’t talk to users. You do you. They’ll just have to adapt.\nAnd don’t even think about nominating so-called \u0026ldquo;Champions\u0026rdquo;. They’re the worst. \u0026ldquo;Champions\u0026rdquo; (read with air quotes) might think of things that you didn’t think of and identify gaps, just because they know sooooo much about how they need to do their jobs. They might even help change other users’ opinion by talking to their peers (and then everybody will expect you to deliver stuff).\nIf someone insists that you need to identify \u0026ldquo;Champions\u0026rdquo; in the organization, get the Executives to name people that don’t really know anything — don’t let them name people who will actually use the system.\nAnd whatever you do, if a group of people approaches you and they want to be early testers on your migration, steer clear of them! I’ve seen it too many times before: they may find issues before everybody else gets to use the system (and then you’ll be expected to fix the issues !).\nEven worse: \u0026ldquo;keeners\u0026rdquo; (that’s what I call them) might generate excitement in the organization. The may get other groups (who would otherwise leave you alone) to get jealous, to get excited about features they have been whining about for a long time, and demand to be early adopters.\nDon’t communicate This is just common sense. If you tell people that a new version of SharePoint is coming, they’ll just get worried about the coming changes and they’ll make your life miserable.\nRemember that your users have jobs to do. They have probably worked really hard to learn the last version of SharePoint (they change everything between versions, don’t they?) and if you tell them about the upcoming SharePoint migration, they’ll fight you.\nEven worse if you tell them about moving to the cloud! Remember: users don’t know anything about the cloud, and they probably have concerns over safety and security. If you tell them in advance what’s coming, you’re probably going to have to explain to them why the cloud is better, blah, blah, blah.\nLet the rumors fester. If you let users guess what’s happening, they’ll make up stuff and may not even have to deliver anything because they’ll fight the migration before you even get started!\nBest strategy: hope that your users enter a deep coma until your migration is done. When they wake up, dump the new platform on them and let them fend to themselves.\nIf you’re a consultant and you were brought in to migrate, try to can keep the rest of the IT department in the dark. It is fun to watch them squirm and think that they’re going to get laid off.\nAnd they’re always trying to show off with all the stuff they know about their legacy systems and why you shouldn’t do this and that. Yecch!!!\nProbably the best way to make your life easy is to never explain to users about the benefits of moving to the cloud and using Office 365. Don’t tell them what’s in it for them. Because they’ll expect stuff from you!\nDon’t waste your time on a content audit Why would you take the time to list all the sites, subsites, document libraries and file shares that you’ll have to migrate when a cursory glance at the data will give you enough to make up an estimate?\nTrust me, if you do an audit, people will expect you to make educated decisions about what content needs to move. Or even worse, they might expect you to consult them to find out what you should move.\nStatus Quo is good Copy and paste. Don’t think!\nDon’t start going through the content and try to identify duplicates, or content that you should migrate. Don’t look at permissions and folder structure. That would be using your brain, and we don’t want that.\nSo what if your users have eleventy layers of folders and sub-folders, that’s their problem.\nAnd if you move from a file share to SharePoint and change the folder structure, your users might whine that you lost \u0026ldquo;implicit metadata\u0026rdquo; (i.e.: metadata that is implied by where a document resides in a file structure). You would have to take extra time to apply metadata to documents, and that sounds like too much work.\nJust copy and paste the documents the exact same way they are at the source. Don’t start spring cleaning — you can always clean next time you migrate.\nEstimates are for losers Estimates are hard. Like \u0026ldquo;work\u0026rdquo; hard.\nWhy would you take the time to analyze the data thoroughly to estimate what the effort will be to migrate the content when all you have to do is give an estimate that your boss/client/stakeholders will be happy with? Go ahead, underestimate.\nMost cloud migrations take 6 to 9 months to be done right, but if you tell your bosses that, they won’t like it and they’ll demand smaller estimates. It is better to give them an estimate that they want to hear (like 1 month or 3 weeks).\nOnce they signed off on starting the migration, it’s not like they can do anything if you take longer, right?\nYou know as well as I do that they won’t stop asking you for shorter and shorter estimates until you tell them what they want to hear. Why go through the trouble when you can just skip to the estimate they want.\nFor extra bonus points, once you gave them a short estimate that you have no hope of meeting, try to rush the migration to keep deliver to that ridiculous timeline you committed to. The best part about that approach is that nothing will be done right, and you may spend the next several months or year (usually more than your most pessimistic estimate) fixing all the issues.\nYou could try to give them a reasonable estimate based on actual calculations, and ask your stakeholders to give you enough time to perform a few test migrations so that you can improve your estimates, but that sounds like too much like adulting.\nOh, and whatever you do: don’t keep a master risk list or, if you’re using Agile, a risk registry.\nIf you tell people about the risks, you’ll need to have uncomfortable discussions about why you think something may impede your migration.\nThey might even expect you to create a mitigation plan to prevent risks from happening, or contingency plans to do if the risk actually happens. Sounds like more work to me!\nBest thing to do: cover you’re a* and mention the issue once, casually, whenever you have a chance. The less formal the better. For example, tell your boss when he’s late for a meeting. Don’t offer a constructive way to solve the issue, just complain*.\nThat way, if something goes wrong, you can always say \u0026ldquo;I told you so!\u0026rdquo;.\nGap analysis shmanalysis Gap analyses are so overrated!\nWho needs to look at the differences between the old version of SharePoint and the new version.\nFor example, if you found out that your old sandbox solutions are no longer supported, or that your mission-critical application built on Access Services won’t work anymore, people are going to expect you to find an alternative solution.\nDon’t waste your time with migration tools Why would you use a migration tool when you can just drag and drop the documents from the old SharePoint to the new SharePoint Online?\nArrgh! Those annoyingly demanding users are going to complain that all the documents’ Last Modified date and Author have changed.\nAnd you better hope they don’t notice that you lost their version history either!\nI guess you can always look at Microsoft’s free SharePoint Migration Tools, which handles migrating sites and file shares. But how good can it be when it is free?\nI mean, what incentive can Microsoft possibly have to spend time and money building a decent tool to migrate to Office 365?\nMy advice: don’t even look at the tools. If someone tells you about the free SharePoint Migration Tools, you can always use the age-old IT consultant trick. Just say the following words:\nI’ve heard that [INSERT PRODUCT NAME HERE] is slow and buggy\nNo one will ever argue with you. If you say it is slow and buggy, it must mean that you used it and nobody will ever doubt your IT knowledge ever again.\nDon’t waste time researching the various tools available. Don’t look at how well they support their products or how they take time to educate their users to migrate successfully.\nDon’t evaluate whether the tools support scripting or automation. That way, no one will expect you to test your migrations and save them to a script that you can re-run without introducing issues.\nNah. If you have to use migration tools, pick the first one you heard of without worrying about why it is better than any other tool. It’s not like you’re spending your money, right?\nIf the tool doesn’t work, you can always blame the tool.\nUsers love surprises If you tell your users that you are going to migrate their stuff, they will pester you with questions.\nIt is better to hope that you never have to talk to your users, and just migrate stuff without telling them.\nThey can’t stop what they don’t know about, amiright?\nIf you start telling people what you’re doing, I can promise you that a lot of the managers and directors of employees who may be affected by your migration will start asking you hard stuff. Like \u0026ldquo;how much time do you need from my staff to help?\u0026rdquo;. They may even ask you to schedule meetings in advance!\nPro tip: Users don’t have anything better to do. When you finally realize that you need their help, just expect them to drop everything. They’ll be excited at the opportunity to take on additional duties to help you.\nDon’t schedule maintenance windows… that’s what lunch breaks are for If you’re pretty sure that nothing is going to go wrong, don’t even bother telling people when you’re migrating stuff. I mean, everything should go perfectly, so why worry users?\nIf they lose something important that they were working on, we have a backup, right?\nUh, I never really checked that the backups actually work.\nJust wait until people are away from their desks (lunchtime or late Friday afternoon is a great time to do this), that way you can hope that if you have to reboot a server or if you affect the network or server performance, users won’t notice it.\nTraining is for babies We’ve discussed this before: anything that you can do to avoid telling your users what’s coming will reduce the risk of them asking more questions and demanding answers.\nThe best training strategy is: throw them in the deep end and expect them to swim.\nDon’t waste money and time on training people. That’s time you can’t be Facebooking or Instagramming.\nSure, Microsoft has tons of customizable training materials available for free, but how good can it be, really? I mean: it’s free.\nLet users figure it out on their own. They’re all technical experts, right?\nUsers are stupid Start with the assumption that users are stupid.\nAlso: feel free to make decisions to disable functionality because people won’t understand it. Don’t reward users who are more technologically savvy. Instead, assume that if you give your users too many options, they will spend so much brain power trying to understand that they will probably lose basic motor functions and be unable to maintain bladder control.\nI always admire it when a manager or a director says \u0026ldquo;oh, our users will never understand that\u0026rdquo;. They understand how you and they are intellectually superior to everyone else and don’t even give users the opportunity to learn.\nFor example, don’t give people access to Microsoft Teams, because they are too stupid to understand how to use chat applications.\nDon’t let people post profile pictures, because they’ll instantly post pictures of their private parts. Instead of revising your \u0026ldquo;IT Acceptable Usage Policy\u0026rdquo;, just disable those functions immediately.\nAnd don’t get me started about letting people use emoticons and comments in sites. So unprofessional! Better to spend all your efforts finding ways to disable those features, otherwise every single one of those previously professional people will suddenly lose all sense of proper conduct.\nIt’s a wonder that they never thought of doing this with email? I mean, e-mail was invented in 1971 and we let people send emails to \u0026ldquo;All employees\u0026rdquo; and external email addresses and it hasn’t occurred to them that they could send inappropriate emails before? Stupid people.\nI know that the workplace landscape is changing and that some statistics (somewhere, can’t be bothered to check) say that over the next 3 years, 48% of the working population will reach retirement age. It means that the new wave of people entering the workforce will be used to new modern tools, but what do they know — they’re young.\nKeep your antiquated old views You started using SharePoint back in 2001. How much can it have changed?\nDon’t waste time learning new features that Office 365 offers. True SharePoint gurus stick to the OG functionality.\nFor example, when you create a new Team Site or Communication Site in SharePoint Online, it creates a new Site Collection. Talk about overkill! They’re called \u0026ldquo;Sites\u0026rdquo;, not \u0026ldquo;Site Collections\u0026rdquo; for a reason!\nMicrosoft could just create one giant site collection with all your sites in one place.\nIf a feature didn’t work well in a previous version of SharePoint, don’t waste time to see if it has improved; just dismiss it completely and never go back to it. That feature is dead to me.\nI mean, really, all that the SharePoint team has done since then is make it look uglier. So much whitespace!\nIf you wrote a book or a blog article even remotely related to SharePoint 10 years ago, you are absolutely absolved from having to learn anything new. Just hold on to those views, just like you’ve been holding on to your BlackBerry because let’s face it, it’s better.\nAlso, grey areas are for sissies. You need to have an unwavering opinion about every topic, and it needs to be absolutely black or white. No wiggle room to account for the customer’s unique needs.\nFor example, folders are bad. Period. Immediately dismiss the opinion of anyone who says otherwise. Don’t even waste time to think about whether there are acceptable scenarios where folders should be used.\nI once worked with someone who refused to learn this new \u0026ldquo;SharePoint\u0026rdquo; thing we were implementing at her work (even though her new role was \u0026ldquo;SharePoint Administrator\u0026rdquo;). When I asked her why she didn’t want to learn it, she said: \u0026ldquo;because I’m retiring in 5 years and I want things to stay the same\u0026rdquo;. Be more like that: don’t learn anything new.\nMore wisdom Here are more pearls of wisdom I have learned from people.\nWaste valuable time trying to rename SharePoint.com When you had your old SharePoint on premises, you had full control over your SharePoint’s domain name and server name. You could call it sharepointy_mc_sharepoint_face if you wanted to.\nWhen you switch to Office 365, your new SharePoint domain will be yourcompanyname.sharepoint.com.\nThat will confuse everyone. People won’t be able to handle it. There will be desks flipped over and people will set things on fire.\nThe best thing to do is to spend all your energy to find a creative way to rewrite your SharePoint online URL to something that won’t confuse users.\nNever mind that Microsoft doesn’t support this, they just don’t know any better.\nRebrand SharePoint completely Office 365 and SharePoint support the use of themes and some limited organization profile colors.\nAgain, Microsoft doesn’t know any better and hasn’t spent any time researching how to optimize content for legibility, accessible contrast, etc.\nIf you don’t completely rebrand your SharePoint site so that it meets your corporate designs, your users will not understand that SharePoint is a tool for work.\nIf they aren’t constantly reminded of what company they work for with a giant logo occupying the top 1/3 of the screen, they may even forget who they work for.\nBest advice: do everything you can to rebrand SharePoint to meet your corporate design.\nMicrosoft says that you shouldn’t change the master pages or inject CSS in the page because (read this next part in a whiny/mocking voice) \u0026ldquo;they reserve the right to change the page structure at any time\u0026rdquo;.\nSo what, for example, if you change the master page to suit your designs and it blocks you from receiving any new features/fixes Microsoft releases? It’s not like they release new features, and updates twice a week, right?\nI mean, can Microsoft really have this whole release thing down so that they technically have the ability to do multiple releases a day? I don’t think so!\nDon’t worry about what’s supported. Do what feels right.\nSpend time disabling features you don’t understand If you don’t understand a feature that Microsoft offers, and they don’t provide you with a way to disable it, spend as much energy and resources as possible to disable that feature, regardless of the impact.\nFor example, if you don’t understand the benefits of using the News feature in SharePoint, you should stop every single team from using it.\nEven if you have practically unlimited storage space in Office 365, don’t let users create groups. God forbid they create a collaboration space where they can do their work.\nI mean, people are going to stop doing all their work and spend their entire days creating team sites and groups and put bad content in there, and then they’ll leave it there.\nNo, instead of spending time trying to create a proper governance process, and quotas and other easy solutions to help prevent issues, disable those functions completely.\nDon’t use all the tools at your disposal Don’t even look at the tools and features that are included in your Office 365 subscription. That would require you to spend time understanding what they do and — sigh — explain to people how to use them.\nFor example, don’t use the built-in voice, video, and whiteboard features of Microsoft Teams that integrate natively into pretty much everything. Instead, insist on using another third-party video conferencing tool that you have to pay extra for without understanding what the gaps are. (Remember, say it is slow and buggy).\nInstead, spend all your efforts to try to get integrate a third-party tool.\nDon’t use Advanced Threat Analysis features of Data Loss Prevention features. Insist on forcing users to use your old, unpatched VPN solution.\nThat way, Microsoft’s machine learning algorithms can’t identify potential threats and immediately take counter-measures to protect your information. That’s something that’s best left to a human.\nDon’t worry about URL limits… or any other kinds of limits When you’re planning your migration, don’t worry that the URL of your documents may be over 400 characters (because your old file structure is like a Russian nesting doll of folders within folders).\nYour users won’t know the difference. They’ll find out that their files are missing way too late to force you to do anything about it.\nForce every single person to go on your home page When users log in to Office 365, they can choose what their landing page is going to be.\nFor example, their SharePoint page can get them the list of news and updated documents that are relevant to them based on their group memberships and other smart algorithms.\nThat means that you can’t force people to go to your home page and see what you decided was important to them.\nYou could configure an organizational news source and use the Set-SPOOrgNewsSite PowerShell command to help push your corporate news in the user’s news feeds where it will reach them (SharePoint Home, Team Sites, Communication Sites, Hub Sites, Microsoft Teams, Mobile App), but isn’t it better to find an unsupported way to force everyone to go to whatever page you deem important for your users?\nEven better, you should force your user’s workstations to launch a browser to your mandatory home page. It’s not like you can make SharePoint become such a mission-critical tool for them that they’ll naturally want to log-in to it every day.\nRemember, they don’t know any better.\nConclusion I hope that I have given you enough material today to help you ensure a failed SharePoint migration to Office 365.\nRemember that if you succeed, people will expect you to deliver again and again. If you’re busy working, when are you going to surf the internet and watch videos on YouTube?\nIf anyone accuses you of trying to fail a SharePoint migration, don’t forget that according to CMS Wire, you’re in good company: nearly 50 percent of all Enterprise Content Management programs fail just from a technology perspective. And of the 50 percent that succeeds, half of those fail to really provide value to the business.\nYou can hardly be blamed for failing.\nWhat other tips do you have to help ensure your SharePoint migration to Office 365 fails? Let me know in the comments — as long as you don’t expect me to read it or anything.\nWhatever you do, don’t read these articles Avert your eyes! You might actually learn something and I’ll have written this post for nothing\n5 Mistakes To Avoid When Migrating from SharePoint to Office 365. Pffft, what do they know?!\n5 Common Mistakes Migrating to Office 365\nTop 5 Mistakes to Avoid When Migrating to Office 365\n25 Mistakes to Avoid in SharePoint or Office 365 (and How to Fix Them) — they’re actually trying to fix problems?! What’s wrong with them?!!!\nThe Why of ECM Failure and the How of ECM Success\nUpdate Thanks, everyone for your feedback, I’ve added a section on keeping your antiquated views by popular (i.e.: more than zero) demand.\n","permalink":"http://localhost:1313/posts/surefire-ways-to-fail-a-sharepoint-migration-to-office-365/","tags":["Software Estimate"],"title":"Surefire ways to fail a SharePoint migration to Office 365"},{"categories":["Software Development"],"contents":"Introduction In software projects, we have a tendency to repeat the same mistakes over and over again.\nStakeholders ask for estimates. Usually something along the lines of \u0026ldquo;we don’t know what we want. When can you have it done and how much will it cost?\u0026rdquo;.\nSometimes we manage to extract some requirements before we answer, but often we just resolve ourselves to providing an estimate — based on absolutely nothing.\nWe have that nagging feeling that we’re doing something terribly wrong. We had that bad feeling on our last project, and our estimates ended up being wrong.\nBut we tell ourselves:\n\u0026ldquo;this time, it’ll be different\u0026rdquo;.\nSo we foolishly give our estimates.\nAnd the estimates end up being wrong. Again.\nSomehow we manage to get through the project. We cut corners (\u0026ldquo;we can just take out that buffer\u0026rdquo;, or \u0026ldquo;we don’t need QA, right?\u0026rdquo;). We apologize for being late. But we get through it (most of the time).\nAfter a well-deserved break (a.k.a. a weekend off), your stakeholders ask for another estimate.\nAnd we tell ourselves:\n\u0026ldquo;This time, it’ll be different\u0026rdquo;.\nWhy do we repeat these mistakes over and over again?\nThe Cone of Uncertainty At the beginning of a software project, we know almost nothing about the product or work results, and so estimates are subject to large uncertainty.\nAs we do more research, we learn more information and the uncertainty decreases. Our estimates become more accurate.\nWhen we start writing code, that uncertainty decreases even more. The more features we complete, the more that uncertainty decreases.\nEventually, the uncertainty reaches 0% — when all risks have been mitigated.\nThis usually happens by the end of the project (when we no longer need an estimate)\nThis is a concept that Steve McConnell described as the \u0026ldquo;Cone of Uncertainty\u0026rdquo; in his book Software Project Survival Guide (McConnell 1997).\nSoftware teams regularly sabotage their own projects by making commitments too early in the project cycle. An estimate at the project Inception stage is possibly wrong by a factor of 2 to 4 times. They invariably undermine predictability, increase risks, and reduce the chances that the project will be successful.\nBy the Elaboration stage, the estimates can already be twice as accurate as they were in the Inception phase. They can still be off by a factor of 2, but they are suitable.\nAn effective team will delay their estimates until they have done enough work to force the Cone of Uncertainty to narrow.\nUnfortunately, stakeholders typically don’t want to wait to get their estimates. They want to find out how much budget they should allocate (or to know how much they’ll get for their budget).\nThe curse of estimates Let’s try an experiment, shall we?\nTake a look at the two squares below. Without using any tools, estimate how big, in pixels, each square is.\nDon’t cheat. Don’t use your browser tools or any rulers. Just try to estimate, with all your knowledge and skills, how many pixels each square is.\nPretty difficult, right?\nA lot of things affect your ability to answer accurately. The blurry lines and the imperfect squares make it pretty hard to determine where your measurements should start and end.\nLet’s try again with cleaner, well-defined squares:\nStill difficult to guess their exact dimensions in pixels, right?\nUnless you’re a cyborg or a robot (in which case I salute our robot overlords), you do not have the ability to detect the square dimensions accurately.\nNow let’s try again with the fuzzy squares, but this time answer the following question: how much bigger is square B compared to square A?\nYou probably guessed that square B is twice as big as square A (or 4x as big if you’re comparing areas.)\n.\nSee what happened? Even if the squares were fuzzy (i.e.: requirements not clearly defined), and even if you didn’t have measuring tools, you were able to guess their relative size to each other.\nThat’s one of the key concepts to agile estimation: as humans, we’re really bad at estimating absolute sizes, but we’re naturally good at estimating relative sizes.\nAs humans, we’re really bad at estimating absolute sizes, but we’re naturally good at estimating relative sizes.\nThe value of sprints By breaking your work into smaller units of deliverable functionality, and delivering that functionality in small iterations (1 to 2 weeks), you can establish a baseline for your estimates.\nStart by estimating the relative size (something that is often described as Story Points) of some the product backlog item that you will deliver in your first sprints.\nFor example, you and your team may estimate that product backlog item B is twice as big as product backlog item A.\nYou can assign relative values of 1 story point to item A, and 2 story points to item B.\nDeliver as many items within your first sprint as you can using a normal pace of work.\nAt the end of the sprint, add how many story points you delivered for all the product backlog items that got completed within the sprint.\nLet’s say that you delivered the following product backlog items (PBI):\nPBI # Estimate (Story Points) A 1 B 2 C 2 D 3 E 2 Total 10 If your sprint was 2 weeks long (10 working days), you can estimate that your velocity is 1 story point per day.\nAs you plan your second sprint, you can base your estimates by comparing the story point estimates for the work that you already did against the product backlog items you’ll be delivering during this next sprint.\nFor example, let’s pretend that you delivered a total of 8 story points in the second sprint:\nPBI # Estimate (Story Points) F 1 G 1 H 2 I 2 J 2 Total 8 Your sprint velocity for sprint #2 was 0.8 story points per day. Your average velocity is 0.9 (or 10+8 / 20) story points per day.\nOn your third sprint, you repeat again. This time, let’s pretend you managed to deliver 12 story points (what can I say, your team is good!). Your average velocity is back to 1 story point per day (10+8+12/30).\nAs you do more sprints, your average sprint velocity average will become more and more accurate. Your estimates will also become more accurate.\nBest of all, given your velocity average, you can start estimating how much longer it will take to deliver the rest of the product backlog items (as long as you have story point estimates for your backlog).\nAs we established earlier: even if the requirements are fuzzy (like those squares), you can still get a pretty good idea of the relative size estimates. As your requirements become clearer (for example, when you clarify the product backlog item prior to sprint planning), your estimates become more accurate.\nConclusion Stop treating software estimates as a precise prediction of a project’s outcome. It isn’t.\nThe best scenario would be to fund enough of the project to establish a baseline (or velocity) so that your future estimates can be more accurate (because you can compare your remaining Product Backlog Items against the work you’ve already done and build relative estimates.\nBest thing to do is be honest. Tell them that you don’t know how long it will take. Tell them that your estimate is your best guess, but that at this time it can be off by as much as 4 times. Ask them to give you enough time to complete 2 or 3 sprints, after which time you’ll be able to provide them with a more accurate estimate.\nDo yourself (and everyone else in IT) a favor: stop treating your estimates as a precise calculation and start having a \u0026ldquo;Cone of Uncertainty\u0026rdquo; conversation. In my experience, most stakeholders are smart enough to understand that your estimates will become more accurate as the project evolves.\nAs Steve McConnell says:\nThe primary purpose of software estimation is not to predict a project’s outcome; it is to determine whether a project’s targets are realistic enough to allow the project to be controlled to meet them.\n—Steve McConnell, Software Estimation: Demystifying the Black Art\nReferences The Cone of Uncertainty, Construx Software.\n","permalink":"http://localhost:1313/posts/the-cone-of-uncertainty/","tags":["Software Estimate"],"title":"The Cone of Uncertainty"},{"categories":["Visual Studio Code"],"contents":"Introduction I recently published the list of developer tools that I use as a SharePoint Framework developer. The list was inspired from Scott Hanselman’s own list — he deserves all the credit for the idea.\nI received tons of great feedback about the article, and many of you gave me great suggestions. Thanks to everyone for helping, and I hope that — together — we can make a list that anyone starting with SPFx can use as a starting port.\nSam Culver kindly pointed out that the Fira Code font makes a great choice for the default font in Visual Studio Code:\nSam Culver (@samculver)\nReplying to @bernierh and @vesajuvonen\nFira Code is also great in Visual Studio Code\nHe’s absolutely right! I have it as my default font and I thought I should show the very simple steps to configure it as your default font in Visual Studio Code.\nTo configure Fira Code as your default Visual Studio Code font If you haven’t done so, download Fira Code and install it by following these steps:\n1.1. Extract the Zip file you just downloaded\n1.2. In the files you just extracted, find and open the ttf folder\n1.3. For every .ttf file in that folder, double-click to install the font.\nOnce you have installed the fonts, open Visual Studio Code. If you already had Visual Studio Code opened, you will need to restart it before it can use the newly installed fonts. From the Visual Studio Code menu, select File | Preferences | Settings. Alternatively, press CTRL+,\nFrom the Settings window, under Commonly Used, find the Editor: Font Family setting. In the text box, replace what is there for ‘Fira Code’ (including the single quotes). Alternatively, you can simply add ‘Fira Code’, at the start of the existing setting. You’ll end up with ‘Fira Code’, Consolas, ‘Courier New’, monospace. Keep the settings open if you want to enable font ligatures…\nEnabling font ligatures Font ligatures is a typography term to describe when two or more characters (or graphemes) are joined as a single glyph. For example, instead of: === you’ll get: It can help make your code more legible (and thus easier to spot bugs). Take a look at this example from FiraCode’s GitHub repo:\nSome people love ligatures. Some people can’t stand them.\nIf you’d like to use ligatures, follow these steps:\nFrom the Settings page in Visual Studio Code, scroll to the Text Editor | Font section and look for Font Ligatures. (Or search for Ligatures in the search box). Check the checkbox labelled Enables/Disables font ligatures. That’s it.\nJust uncheck the box if you don’t want ligatures anymore.\nConclusion Enabling Fira Code as your default Visual Studio Code font is incredibly easy, and barely deserves its own blog post.\nI wish to thank Sam Culver for reminding me that I should document this. Sometimes I just tend to configure things on auto-pilot and I don’t even notice it!\nI hope that you’ll enjoy Fira Code and ligatures in Visual Studio Code, and I hope that this will become one of those settings that you end up automatically doing without having to think about it.\nIf you like the idea of ligatures, but you aren’t a fan of Fira Code, the good folks at Fira Code list some alternative fonts you may like.\nAlso, if you enjoy Fira Code, you should consider supporting them\n","permalink":"http://localhost:1313/posts/setting-fira-code-as-your-default-visual-studio-code-font/","tags":null,"title":"Setting Fira Code as your default Visual Studio Code font"},{"categories":["SharePoint"],"contents":"Introduction In my previous post on Information Architecture (IA) in SharePoint, I explained that you should build your IA on 3 dimensions.\nI discussed how you should build the physical dimension around your authors, by creating sites, document libraries and — if you must — folders optimized for those who create and maintain content.\nIn this article, we’ll discuss the logical dimension of IA.\nReaders If the physical dimension is for authors, the logical dimension is for readers — those who consume your SharePoint content.\nAuthors are usually subject of matter experts on a given domain. For example, your Human Resources department people are experts in all things HR-related. They understand the subject, and they even use jargon that is specific to their domain of expertise.\nIn contrast, readers may not be subject of matter experts. They don’t care about how to maintain content — they just want to find the content.\nAnd, unlike authors, readers don’t share a common knowledge of a domain of expertise. That means that every reader navigates through content using their own logic.\nFor example, your company has employee benefits. Your Human Resources department handle some of those benefits, while your Finance department handles other benefits. Maybe your IT department offers additional benefits (like providing phones and computers for home use).\nThe HR folks, Finance folks, and IT folks maintain information about the respective benefits their department offer. Based on what we learned earlier, you would build a physical IA that would allow each department to store documents where it makes sense to them.\nTo keep things simple, let’s pretend that you created three SharePoint team sites:\nFinance Human Resources Information Technology And let’s pretend that, on each of those sites, you created a document library called Benefits.\nPeople from the Finance department can update benefits documents in the Finance team site. People from the HR department can do the same in their Human Resources team site, and so on.\nMeet Nancy Nancy, the New Employee is a fictitious person.\nEveryone that has worked with me knows the I like to build personas to help gather requirements.\nShe’s a typical new employee. She’s excited, nervous, and eager to learn.\nNancy is fresh out of college. She joined as a Junior Accountant. She recently got engaged. Like most people of her generation, she wants to get recognized for her hard work, but she also wants a proper work/life balance.\nOne of the reasons she accepted her new job with your company is because of the amazing employee benefits it offers.\nThis is Nancy’s first real \u0026ldquo;grown-up\u0026rdquo; job. She’s never had real employee benefits before. She doesn’t know what to expect, or where to get started with taking advantage of her benefits.\nNancy doesn’t care what department offers what benefits. She doesn’t want to go through Finance, HR, and IT sites to learn about benefits.\nShe just wants a place the shows her everything related to benefits in a single, convenient location.\nIn other words: Nancy doesn’t care where the benefits documents are physically located, as long as they are available together logically.\nNancy’s Information Architecture needs as a reader are very different than those of an HR employee’s IA needs as an author.\nThat’s the difference between the physical dimension and the logical dimension.\nHow to design your IA’s Logical dimension The secret to building the ideal logical IA is to understand your users and their goals.\nTo do so, I always use a slightly modified version of the process I use for gathering Use Cases.\nHere is the Use Case process:\ngraph LR\rA[Identify actors] --\u003e B[Identify goals]\rB --\u003e C[Define main success scenario]\rC --\u003e D[Identify extension conditions]\rD --\u003e E[Define recovery steps]\rHere is the modified process for logical IA design:\ngraph LR\rA[Identify actors] --\u003e B[Identify roles]\rB--\u003eC[Identify goals]\rC--\u003eD[Identify information requirements]\rD--\u003eE[Define logical structure]\rLet’s discuss each step in details.\nIdentify actors graph LR\rA[Identify actors] --\u003e B[Identify roles]\rB--\u003eC[Identify goals]\rC--\u003eD[Identify information requirements]\rD--\u003eE[Define logical structure]\rstyle A fill:#f9f,stroke:#333,stroke-width:4px\rI use the term actor instead of user because I don’t ever want people to get confused give me a list of every single person who logs on to SharePoint.\nIn a play, an actor can often play multiple roles. Many people can also play the same role (think: understudies).\nSo, in our IA design process, an actor is a person who plays many roles. Your actors can be real people, or they can be fictitious people that you create for the IA design process.\nFor example, Nancy the New Employee is a fictitious actor we’ll use to represent real new employees. We don’t want to have a list of every single new employee, we just want to use Nancy as a proxy for all the other new employees.\nKeep going through until you find all your actors. Resist the temptation to move on to the next step. If you move on to the next step now, you’ll have an IA that suits one actor very well, but doesn’t work for others.\nIf you’re struggling to identify, here are some tips:\nLook for extremes Your actors should almost be caricatures of your real users. Look for people in your company that are stereotypical users.\nFind the worst and the best people in your organization.\nI once did this exercise for one of the top 5 accounting firms in the world.\nThe Firm had many partners, who –rightfully so– ran everything.\nPartners were often older men who were at the top of their profession.\nMost of them were nice, but some of them were just grumpy old men.\nMost of them didn’t trust computers and wanted their assistants to print everything for them.\nWe took the oldest, grumpiest partner we knew, and used him as an actor. Of course, we changed his name to Perry the Partner.\nLook for opposites One trick is so easy it almost feels like cheating: find the opposite of an actor you already have.\nYou have a new employee actor, create an old employee actor — their needs are different. The new employee doesn’t know anything about the organization structure yet, the policies, the people. The old employee knows everyone in the company, knows every department, every policy, etc. They’ll look for information differently.\nYou have a grumpy old partner that doesn’t like technology actor, maybe you need a *younger partner who is technically savvy.\nPrimary actors and secondary actors This is another trick I borrowed from capturing requirements: primary actors, and secondary actors.\nPrimary actors are the reason why your system exists. Without them, you wouldn’t need SharePoint. This one is obvious — that’s probably everyone you have identified so far.\nSecondary actors exist because the system exists. In this case, secondary actors are people who support SharePoint, create content, etc.\nBut secondary actors could also be people who already existed, but whose jobs become more important because of your new system.\nRemember Peter the Partner? He hates technology. He needs everything printed (which I disagree with, but that’s another topic). Who prints everything for him?\nHis assistant, Allison.\nDon’t confuse Primary and Secondary as Important and Less important. For our IA, Allison the Assistant is just as important as Peter if not more. Without Allison, Peter won’t use the system.\nLook for evidence I’m a big fan of evidence-based requirements gathering.\nWhen you interview people to gather requirements, they tend to tell you what they think you want to hear. They talk about features instead of goals. They try to translate things in geek speak for you because that’s what they think you want to hear.\nEvidence, doesn’t lie. It doesn’t change because you’re looking (although Quantum physics disagrees)\nIf you want to get a list of typical people who use the system, look for evidence.\nWhat kinds of evidence are there?\nActive Directory groups Distribution list Newsgroups Be careful: I have been in many organizations where the distribution groups and security groups combined outnumber the number of employees.\nLook for life events Remember we started this whole example about employees finding benefits.\nWhat most HR professionals will tell you is that benefit needs for an employee tend to change around life events.\nFor example:\nGetting married Having a child Getting divorced Getting sick Getting older Retiring Not every employee will experience the same life events, but life events definitely help shape a person’s goals.\nFor example, Nancy recently got engaged. She will get married soon. She’ll be thinking about adding her husband to her benefits. She might want to change her last name.\nAfter getting married, her next life event might be to get pregnant. She’ll want to find information about pregnancy leave, child care benefits, etc.\nPlease don’t send me angry emails about my antiquated views of the world or calling me sexist. I know that it isn’t always the case, and I agree with you. Those are the life event patterns HR professional often consider.\nIn our previous example, Perry the Partner is probably pondering his prospective retirement. (That’s a lot of \u0026ldquo;p\u0026rdquo;).\nLife events can also be professional events. For example:\nGetting hired Promotion Certification Becoming a manager Getting a bad performance review Consider accessibility Many countries have (or will have) a legal requirement for accessibility. How do people who are visually impaired access your information? How about those who can’t use a mouse? What about people with cognitive impairments?\nWhen I create my actors, I always create an actor with accessibility requirements. It may not affect our IA, but it will definitely impact our designs. But that’s a different post.\nHow many actors should I get? It depends on how different types of people you have. I tend to aim for 12 actors at most. Why? Because I’m lazy. If you aren’t lazy, feel free to do more than 12, but I’m not sure how much more value you’ll get.\nFor bonus points If you’re up to it, create little posters with each one of your actors.\nI usually create a fictitious profile, complete with picture, of each actor.\nI post them around the team room so that everyone that works on my project sees the posters every day. They serve as a gentle reminder to our team that we’re building this for people, not computers.\nI’ll often hear team members having discussions where they use our actors as if they were real people:\n\u0026ldquo;Nancy will never know how to do this! Remember, she’s new, she doesn’t know what benefits are available to her yet!\u0026rdquo;\nI bet you that if you talked to the people who worked with me on that accounting firm project, they’d remember Nancy the New Employee.\nThat’s the point of defining actors: we’re not building an IA in a vacuum. We’re building it for people (even if those people are fictitious).\nIdentify roles graph LR\rA[Identify actors] --\u003e B[Identify roles]\rB--\u003eC[Identify goals]\rC--\u003eD[Identify information requirements]\rD--\u003eE[Define logical structure]\rstyle B fill:#f9f,stroke:#333,stroke-width:4px\rNow that you have your list of actors, you can define roles for each one of them.\nWe’re not talking about security roles here. We’re talking about purposes or unique traits that will affect their goals.\nIn our example, Nancy plays many roles:\nNew employee Junior accountant Accounting department staff Bride to be \u0026ldquo;Why do we do all this work to define an IA?\u0026rdquo; you may ask. Or \u0026ldquo;Why identify actors just so that we can identify their goals\u0026rdquo;. Your actors are there to serve as a reminder that you’re building this for people.\nIf you define memorable actors for you and your team, your actors will become the litmus test for every design decision you make.\nRoles help you identify goals in a way that helps you focus. Trust me, you’ll get a more complete list of requirements by listing goals on a role-by-role basis than you would if you just spewed a list of random goals for your entire system.\nWhat if you get duplicate roles? It happens. You should try to create actors with distinct roles, but don’t stress about it. During this step, we often realize that we have duplicate roles and we combine multiple actors together, or trade roles between actors to make them more unique.\nOnce again, resist the urge to go to the next step before you complete this one.\nWhy?\nIf you move to the next step, you will not have any idea of the scale of effort involved in completing your IA. You will have an incomplete IA and no clue how much you didn’t accomplish.\nInstead, your goal should be to have a complete list of roles. That way, you’ll know how much work is ahead of you and it will help you plan accordingly.\nIdentify goals graph LR\rA[Identify actors] --\u003e B[Identify roles]\rB--\u003eC[Identify goals]\rC--\u003eD[Identify information requirements]\rD--\u003eE[Define logical structure]\rstyle C fill:#f9f,stroke:#333,stroke-width:4px\rFor every role you identified, list the possible goals.\nComplete this sentence \u0026ldquo;As a [role] I want to use SharePoint to ____\u0026rdquo;.\nNotice that this step isn’t identify requirements. It is identify goals.\nWhat’s the difference?\nEvery single engagement I take on, there will be at least one person who will insist that \u0026ldquo;search\u0026rdquo; or \u0026ldquo;searching\u0026rdquo; is a goal.\n\u0026ldquo;Search\u0026rdquo; isn’t a goal. It is a requirement.\nNo one ever says \u0026ldquo;I think I’ll go to Google and search for something and do nothing with the results\u0026rdquo;.\nYou search because your goal is to find something.\nSo don’t write \u0026ldquo;Search\u0026rdquo;. Write \u0026ldquo;Find [something]\u0026rdquo;. How you find something is through search, but keeping the end goal in mind may help shape your IA differently.\nHere are some tips:\nOne role at a time: give each role the consideration they deserve. Resist the urge to describe the goals in further details: you can do that later. We want speed and quantity here. Duplicates are good: you may find the many roles have the same goal. That’s a good thing. Write it down for every role. A goal that appears for multiple roles is a goal that is more probably important. When it comes time to implement, you may want to focus on common goals first. Write the out of scope goals: Keep that list going. Include things that are obviously out-of-scope. You can always mark that goal as out-of-scope later. If that goal comes back over and over again, you should consider including it in scope. Don’t let the tools get in your way: I often find that people get stuck on the tool they should use for this step. This phase is more about brainstorming. You should use whatever tool allows you to capture goals as quickly as possible without worrying about fonts, formatting, or structure. I like to use a mind mapping tool or OneNote. I loooove OneNote. For example, the new employee role might want to accomplish the following goals:\nLearn about the company Learn about the organization structure Find out what my benefits are Apply for benefits Learn about policies and procedures I should know about Learn about my team members Learn the company jargon Get office supplies Learn about holidays The bride to be role might want to accomplish these goals:\nLearn about benefits for spouses or dependents Add a beneficiary Book time off (for wedding and honeymoon) The junior accountant role’s goals might be:\nGet my certification Complete my training Get promoted Identify information requirements graph LR\rA[Identify actors] --\u003e B[Identify roles]\rB--\u003eC[Identify goals]\rC--\u003eD[Identify information requirements]\rD--\u003eE[Define logical structure]\rstyle D fill:#f9f,stroke:#333,stroke-width:4px\rOnce you have an extensive list of goals, you can consolidate it into common goals. You can also filter out the list of goals that are out-of-scope.\nFor every goal, try to answer this question: \u0026ldquo;How will users accomplish [this goal]?\u0026rdquo;. Or \u0026ldquo;What information do users need to accomplish [this goal]?\u0026rdquo;.\nAs tempting as it may be, I’ll resist the urge to list example information requirements.\nJust think about every document, list, news, and people you may need to accomplish a goal.\n\u0026ldquo;Wait a minute! Didn’t you say in a previous post that people are knowledge?\u0026rdquo;\nWow, I didn’t know you read that! Thank you! But no, people hold knowledge. Listing the people who know stuff is just information. Remember: I can write everything I know about a subject, it becomes information. You need to apply your own experience to make it your own knowledge.\nDefine logical structure graph LR\rA[Identify actors] --\u003e B[Identify roles]\rB--\u003eC[Identify goals]\rC--\u003eD[Identify information requirements]\rD--\u003eE[Define logical structure]\rstyle E fill:#f9f,stroke:#333,stroke-width:4px\rI would love to be able to give you a magical formula to define your logical structure. Unfortunately, I don’t, because every IA is different.\nHowever, I can give you some tips:\nEstablish success criteria Define what success will be before you even start.\nFor example, I always start with 3 clicks or 30 seconds.\nThat means that every actor should be able to achieve their goals within 3 clicks on their landing page, or within 30 seconds.\nAs you build your logical IA, test it with goals you identified in the previous step and see if it meets your success criteria.\nDuplicates are OK Let me be clear: in the physical IA, duplicating content is a no-no. You don’t want two physical copies of the same data because it will invariably lead to content getting out of sync.\nLogically, I should be able to see content in multiple places.\nEvery user will navigate your IA differently, so why force them down a path that doesn’t make sense for them?\nThink of a news post. It may physically be on an HR site, but it may show up logically on your SharePoint tenant’s root site news feed, in the user’s own news feed, in the HR site’s news feed, etc.\nMe-centric, not organization centric I can’t stress this enough. Build an IA that is centered around the users. Don’t try to copy your Org Chart.\nDo an open card sorting workshop If you need help getting started, try writing all the goals on individual index cards (or sticky notes).\nInvite groups of actual users to review the goals and physically group the cards into groups that make sense to them. They can work together, or they can work individually. Tell them that they can to move other people’s cards too.\nThen watch how they work.\nSee if people disagree or fight about where a particular goal should go. Make sure to remember any contentious points.\nWhen they are finished, ask them to give each group of goals a name they would use to describe it.\nRecord the results and repeat with different user groups. You’ll be surprised to find some similar patterns, while some groupings will wildly vary across different user groups.\nThis will give you a good indication of how your users see your information.\nIMPORTANT: Ask the users to do this. Avoid the we know better attitude.\nI once conducted this workshop with folks from the IT department, then asked the actual users to do the same exercise. The results were wildly different. Embarrassingly so.\nDo a closed card sorting workshop If you think you have defined your logical IA, try it with users.\nJust as before, print some user goals on index cards or sticky notes. If you want to change things up, you can list some of the information you identified in the previous steps instead of goals.\nNow draw your logical IA on a giant whiteboard or on different color index cards laid out on a big table.\nInvite groups of users to read each user goal (or types of information), and to place each one where they think it belongs on your logical IA.\nIf they instinctively place the cards where you intended them to go in your logical IA, you’re doing great.\nIf they struggle, your IA needs more work.\nConclusion Your physical IA is for authors. Your logical IA is for readers.\nBuild your logical IA with users in mind.\nRemember that every user has a different perspective when looking for information.\nIn our next article, we’ll discuss the last dimension of IA: Metadata.\n","permalink":"http://localhost:1313/posts/information-architecture-in-sharepoint-the-logical-dimension/","tags":["Information Architecture","IA"],"title":"Information Architecture in SharePoint: The Logical Dimension"},{"categories":["SharePoint"],"contents":"Introduction Information Architecture (IA) is the structural design of shared information environment (source: Wikipedia).\nIn this series on Information Architecture, we discussed how a bad IA can affect your SharePoint success.\nIf your SharePoint users can’t find the information they need quickly, they’ll get frustrated.\nIn our first article, we explained why trying to create an IA that has only one dimension leads to creating the lowest common denominator IA instead of giving your users the best-of-breed experience they deserve.\nOur second article explained how you should build an IA on 3 dimensions. We described how the physical IA should cater to authors. If you don’t create an IA that allows your authors to place content in the right place, you’ll end up with messy, unstructured data. Yes, it is data, not information, because it loses all meaning.\nIn the last article, we looked at the logical IA. While the physical IA caters to your authors, the logical IA should cater to your readers.\nBut there is one more dimension to consider: the metadata dimension.\nThe metadata dimension The metadata dimension of IA helps the system deliver information for specific purposes.\nFor example, imagine that the HR department has a document library for their HR policies. Before employees can see the latest version of a policy document, they must be approved.\nMarie the HR Manager is responsible for approving HR policy documents.\nWhen she launches SharePoint, her HR site tells her how many documents are waiting for her approval.\nIf Mary clicks on a document waiting for her approval, it takes her directly to the document. From there, she can approve or reject the updated policy document.\nSharePoint does not keep documents waiting for Mary’s approval in a separate physical location. Yet, from Mary’s perspective, SharePoint appears to bring all documents waiting for her approval in one convenient place for her.\nIn other words, the physical location of her documents doesn’t change. SharePoint uses the metadata to identify which documents need Mary’s approval. SharePoint then presents the documents in a separate logical location.\nThat’s what creating the metadata IA is all about: making sure that your documents have the metadata they need to support specific goals.\nYou might say \u0026ldquo;Ok, I get it, so we just use the goals we identified when we [designed to logical IA]( (/2019/02/22/information-architecture-in-sharepoint-the-logical-dimension/) and create the metadata we need to support it?\u0026rdquo;\nWell, yes …and no.\n(Remember, I’m a consultant. The answer is always \u0026ldquo;It depends\u0026rdquo;)\nProgressive Disclosure In user experience (UX) design, there is a design pattern called Progressive Disclosure. It is a strategy for managing information complexity by gradually (or progressively) revealing more information as users indicate they wish to see more.\nIn other words, show only the information that is necessary at every point of interaction.\nBy reducing the amount of unnecessary information you show to users down to the essential, you make it easier for users to make sense of that information.\nYou see this all the time when using SharePoint. For example, the More button in the document library toolbar is a form of progressive disclosure. We don’t need to show every single option in the toolbar. We only need to show the most common options. If users tell us they want to see more choices, we reveal more options.\nThe News web part in SharePoint works the same way. When you go to a team site or communication site, you see the latest news. If users want to see more news, they can use the See all link, in the upper right corner.\nSummary, List, Details When designing your metadata IA, you should consider creating the metadata structure required to build progressive disclosure in your design.\nAn easy way to do this is to present the information in 3 distinct views:\nSummary List Details We’ll describe each view below.\nSummary As you evaluate every actor goal, ask yourself:\nWhat is the least amount of information that this actor will need to meet their goal.\nAnother way to ask this question is:\nHow do I summarize the information this actor needs to meet their goal quickly\nIn our example, Mary the HR Manager needs to know quickly when documents need her approval.\nWe don’t need to show her every single document. We just need the documents that have not been approved yet.\nKeeping this in mind, we don’t even need to show the Size, or Date Created. We probably only need the document’s Title, Date Modified, and Modified By.\nWhen building a summary view, consider providing the user information that will help them prioritize their tasks. For example, we can show Mary the list of documents that have been waiting for her approval the longest. Or, we can show the list of documents by how recently they were submitted for approval.\nEvery summary view should allow users to do at least two things:\nGet the full information about an item in the summary (a.k.a. the Details view) Get the full list of items (a.k.a. the List view) Both are discussed further below.\nHow do I sort my summary view? Almost every client engagement I work on, there is at least one business stakeholder who insists that their summary view of [whatever] must be sorted alphabetically — from A to Z.\nTheir argument is usually \u0026ldquo;people need to be able to find [whatever] quickly. Sorting by alphabet is the fastest way to let them find it\u0026rdquo;.\nIt may be a good approach for a list view of [whatever], but the summary view should boil it down to what matters now.\nInstead, consider showing the list of latest [whatever]. Sorted in reverse descending date (i.e.: newest first). Doing so will allow repeat visitors to see the newest [whatever]. If they scan down the list, they may eventually see an item that they’ve seen before and assume that they have seen everything below that item.\nConsider the alternative: users have to scan through the entire list of [whatever] to see if there is anything new.\nHow many items in my summary view? There are no set rules for the number of items to show in a summary view. Luckily, there are brilliant people who have done some research on this.\nThe first rule is known as Miller’s Law. In summary:\nThe average person can only keep 7 (plus or minus 2) items in their working memory.\nMiller’s Law is often misinterpreted. It doesn’t mean that you should only present 7 (+/- 2) items only. If you need to present more, consider chunking the information into groups of 7 (+/- 2) items.\nThe second rule is Hick’s Law. Hick’s law says:\nThe time it takes to make a decision increases with the number and complexity of choices.\nIn other words: the more choices you give people, the longer it takes for them to make a decision.\nSo, when I build a summary view, I try to limit it to 7 +/- 2 items.\nSometimes I show 5, sometimes I show 7, and rarely I’ll show 9 items. If I need more than 9 items, I’ll always try to group the items into subsets of 5-9 items.\nThe more information I need to present with each item, the fewer items I’ll show in my summary view.\nDoing so will ensure that every user can make sense of the entire list and that they will make a decision quickly.\nList The list view allows users to view all items, possibly without filters or restrictions.\nBut don’t think that you can just create a All items or All documents view and be done with your list view.\nKeeping your user’s goals in mind, you should design one or more list views to help your users accomplish their goals quickly without having to scan through the entire list of items.\nFor example, I’ll often create views like:\nLatest [whatever] My [whatever] [Whatever] waiting for my approval [Whatever] by approval status [Whatever] about to expire …and the list goes on.\nAs with the summary view, you need to consider what metadata you’ll need to support each list view.\nEvery item in the list should provide users with a link to the Details view for that item.\nDetails The details view should provide all the information needed on an item so that users can achieve their goals.\nMost often, the details view for a document is really the document itself — because, most often, the user’s goal is to read the document.\nSometimes, you need a different details view. For example, let’s say we want to allow executives to do a second-level approval for expenses that approved by managers who report to them.\nInstead of showing the full document, we’d need to show the expense summary, amount, manager’s approval, and approval date. The view would probably make it easy to approve the expense without having to open it.\nKeeping in mind progressive disclosure, and providing users with Summary, List, and Details views of information will help your users make decisions quickly and accomplish their goals.\nImplicit metadata If you’re planning an IA to migrate a network file share to SharePoint, heed this warning:\nDon’t simply relocate document. The location of a document in a file share is a form of metadata that you may lose if you relocate documents.\nThat’s implicit metadata.\nLet’s say that your file share contains legal cases for case management purposes. You have a folder for every case your company has ever processed.\nBecause of the large number of cases your company processes every year, there is a folder for every year in your file share. Cases are then placed in their respective folders, according to when you received the case.\nYour company gives each case a unique number, e.g.: CA123456. To ensure privacy, case numbers do not convey any information about who the case parties are.\nTo make things even easier for your users to work through open cases only, your network file share groups every year folder into an Open cases, Closed cases, and Pending approval.\nThe folder structure looks as follows:\nCases Open case 2017 CA123456 CA123459 CA123464 … 2018 CA133456 CA123559 CA121464 … 2019 CA233456 CA323359 CA124464 … Closed cases 2017 … 2018 … 2019 … Pending approval 2019 … Because the documents you want to migrate are in a network file share, there may not be a lot of metadata — if any — for your documents.\nBut if you look carefully, the location of each document provides implicit metadata about each document: the status of the case, the year the case was received, and the case the document belongs to.\nIf you migrate your file share to SharePoint, you need to consider a way to apply the implicit metadata to each document.\nYou might say: \u0026ldquo;If I keep the same folder structure, I won’t lose the implicit metadata\u0026rdquo;. Sure, but what happens when users are looking for a document and use search? The only way they will be able to see that implicit metadata about every document in their search results is if they look at the document location for every. single. document.\nConclusion As I have hopefully conveyed in today’s post, you need to consider your metadata IA structure to support your users’ goals.\nThe metadata dimension also needs to support both the physical and logical IA.\nIn my next post, I will explain how to put all this theory together using SharePoint’s capabilities.\nFor More Information The Most Important Rule in UX Design that Everyone Breaks, Jeff Davidson Miller’s Law, Laws of UX Hick’s Law, Laws of UX ","permalink":"http://localhost:1313/posts/information-architecture-in-sharepoint-the-metadata-dimension/","tags":["Information Architecture","IA"],"title":"Information Architecture in SharePoint: The Logical Dimension"},{"categories":["GitHub"],"contents":"Introduction I’ve been working in IT for 32 years.\nMost of my time in IT has been focusing exclusively on Microsoft technologies.\nOver 18 years of this time was working with SharePoint and CRM.\nBut something is happening at Microsoft. It has been happening for a while, but it is definitely happening.\nMicrosoft is changing from the company everyone (but me) loves to hate, and it is becoming cool. Well, cooler.\nA shift to open-source Microsoft is shifting its focus to open source.\nSince 2004, Microsoft has increased its number of open-source projects. Their products and components went from closed-source that gave little consideration to third-party developers to open-source.\nIn fact, Microsoft is now the biggest open-source contributor in GitHub. Over Facebook, Google, Docker.\nI never thought I’d see the day.\nThese open-source initiatives attract talented contributors. Developers who feel passionate enough to spend their own time and donate their time to make the products better.\nThose contributors (Microsoft employees and volunteers) work together. Regardless of who they work for, where they live, their culture, or their degrees of expertise. Even people who work for competitors put their \u0026ldquo;differences\u0026rdquo; aside and work together.\nAnd then something amazing happens: they become a community.\nThey work together to help each other. They also help anyone who wants to use the repositories for their own projects. They answer questions, they fix bugs, they help people diagnose issues.\nThe SharePoint Development Community One such community is the SharePoint Development Community.\nThe SharePoint Development Community is a community built around an initiative called Patterns \u0026amp; Practices (PnP). The PnP initiative includes guidance on best practices around SharePoint, code samples, Office 365 APIs, Office Add-ins, SharePoint Frameworks, developer controls, starter kits — and many more.\nSomeone who played a big role in making the community what it is today is Vesa Juvonen.\nVesa is a Senior Program Manager within SharePoint engineering. He works with the team responsible for the SharePoint customizatin model. He also leads the virtual teams who created the various (and awesome) PnP initiatives.\nPatrick Rodgers, who is a Senior Program Manager with Microsoft FastTrack, and a lead for PnPJs also plays a big part in this community. Apparently, he’s a mediocre bowler, but he’s a great community builder.\nI’m sure that there are many other people at Microsoft who deserve the credit for this, but Vesa and Patrick are the two \u0026ldquo;faces\u0026rdquo; that you see in most calls, presentations, videos, conferences, etc.\nIf anyone knows who else at Microsoft deserve credit for the SharePoint Development Community, please let me know. They definitely deserve our thanks.\nPatrick, Vesa, and their teams do an amazing job educating and sharing with the community, but also listening to the community.\nThey also work hard empowering the community to build something better. If the times that Vesa accepts and closes pull requests on the SharePoint repos is any indication, they work above and beyond 9 to 5, Monday to Friday.\nThey don’t have to go the extra mile. They don’t have to be entertaining and engaging. They could just ignore non-Microsoft people and build a product without asking the community. After all, that was the standard m.o. for Microsoft for the longest time.\nSuperstars And then there are all the other superstars of the SharePoint Development Community. Those who don’t even work for Microsoft, but take an active role in the community.\nPeople like (pulled from the top contributors in GitHub):\nAndrew Connell Chris Kent Elio Struyf Joel Rodrigues Mikael Svenson Russell gove Simon-Pierre Plante — a fellow French-Canadian. Stefan Bauer Waldek Mastykarz …and many more. There are too many to list (I actually feel guilty not listing everyone here. I’m sorry if I missed anyone).\nAll whom have real jobs. Most of them maintain active blogs, tweet, and contribute to the SharePoint Development Community. Oh, and they probably have a families and have to sleep, some time. (I also secretly believe that one of them works with SharePoint during the day, and fights crime at night).\nAll those people contribute because they care. Because they are passionate. Because they want to help.\nMore importantly: they are welcoming. I’ve contributed a few tidbits in the PnP and SharePoint repos and they have never made me feel out of place. I’ve never felt like I was an outsider trying to get in a tight clique.\nDon’t be nasty So why am I writing such a lengthy post about the SharePoint Development Community?\nBecause I’ve noticed that people are getting nasty.\nMore and more, I see new issues in the various GitHub repos where people post rude comments, or use an otherwise unkind tone.\nI don’t know if it is because they think that every contributor is a Microsoft paid employee, and that it is everyone’s job to drop everything to help them, or because they were raised by wolves, but there is no need to be nasty.\nIf you open a sample web part that someone built over a year ago — code that they shared with everyone to help grow the community — and it doesn’t work because the libraries have since changed, you don’t need to get offended.\nThey didn’t break the web part on purpose.\nIf you try to use a PnP API and it doesn’t quite work the way you expected, they didn’t plan to break it so that it would ruin your day.\nIf the documentation for something that changes every week is not quite up-to-date, don’t get offended. We don’t keep a second set of secret documentation that is more accurate just to mess with you.\nDon’t turn this into a evil-Microsoft-is-at-it-again thing.\nThe people who contribute are all people, like you and I, who have jobs and families.\nBe considerate I get it.\nYour boss is bugging you to get stuff done. Your clients are all in a hurry to see something delivered.\nYou run into an issue with SPFx, PnP, code samples, or documentation. It is frustrating.\nEveryone who contributes to the repositories have experienced the same thing.\nEveryone is willing to help. Otherwise, they wouldn’t contribute.\nSo if you submit an issue, be kind. Be considerate.\nWe want to help. Don’t submit an issue that says:\nThis stupid thing doesn\u0026#39;t work or\nIt doesn\u0026#39;t work …because we can’t help you.\nFollow instructions Help us help you!\nTake the time to fill the issue forms. They all have guidance. Take a second to read the guidance and follow instructions.\nFor example, here is the start of the sp-dev-fx-webparts issue form:\nUse the following form to submit an issue only if it’s related to samples in this repo. If you have an issue related to the SharePoint Framework or its documentation, please submit the issue at https://github.com/pnp/sp-dev-docs/issues/new. This will help us respond to your issue faster.\nThank you for reporting an issue or suggesting an enhancement. We appreciate your feedback – to help the team to understand your needs, please complete the below template to ensure we have the necessary details to assist you.\n_(DELETE THIS PARAGRAPH AFTER READING\nNotice that it says DELETE THIS PARAGRAPH AFTER READING ? Go ahead, delete it before submitting your issue.\nWhy? Because everyone who follows the repository gets a notification when you file an issue. If they are like me, they probably receive a notification on their mobile device. They check the issue on their way to a meeting, or while waiting for the barista to mess up their names again.\nYou have very little of their time to get their attention. All that text you didn’t remove gets mixed up with whatever information you provided about your issue. If they can’t make sense of your issue, they may put your issue aside until they have time to make sense of it.\nIf you see a section like this:\n## Category\r- [ ] Question\r- [ ] Bug\r- [x] Enhancement Just put a x in the right category and leave the other ones empty (with a space between the [ and the ]). It helps those who want to help quickly categorize and triage your issues.\nIf you have a problem with any of the Web Part Samples, take the time to fill the Authors section of the issue form. The instructions are quite clear:\nBecause of the way this repository is setup, samples authors do not get a notification when you create an issue. It makes it less likely for you to get your issue resolved or to get help. For the section above @mention any author of the sample. Authors’ GitHub handle can be found on the main sample documentation page, under the \u0026ldquo;solution\u0026rdquo; section. Use the PREVIEW tab at the top right to preview the rendering before submitting your issue.\nFor example, if I messed up one of my sample web parts, make sure to add @hugoabernier in that section. It will notify me, and I’ll gladly help. As would almost every other person who contributed a sample.\nContribute and give back If you find an error in the documentation of the code, feel free to make the changes and submit a pull request. The contributors are people just like you.\nAnd if you can’t contribute, because you’re too busy or you don’t know what the fix should be, keep in mind that everybody else who contributes probably doesn’t have time, or may not have the right answer — just like you. They all have to make the time to find a fix and make the changes.\nMore ahead of us than behind us Microsoft has come a long way.\nSharePoint — from codename Tahoe to what it is today — has changed a lot too. It constantly becomes better.\nSomeone at Microsoft took a leap of faith one day and decided to build this amazing SharePoint Development Community. They broke all the rules, broke from tradition, and gave us a place where — together — we can all build something even better. From what I would guess, they probably spent a lot of their own time to make this happen before gaining support from management.\nWhoever took the first step, and all those who supported them (and continue to support them) deserve our thanks.\nEveryone else who contributes to the community makes every one of our jobs easier every day by paving the way with samples and best practices.\nThey all deserve our respect and thanks as well.\nI truly hope that other areas of Microsoft take the example from the SharePoint Development Community and builds their own community. I’m looking at you, Dynamics 365 — we could use a CRM Framework to build better CRM solutions. (And I’ll help!)\nUntil it becomes a widely adopted model at Microsoft, we should all appreciate what we have and treat everyone kindly and respectfully.\nPlease forward this message to everyone who deserves our gratitude.\nSincerely,\nHugo\nPhoto credit Image by Eak K. from Pixabay\nUpdates Thanks to Yannick Plenevaux (who, frankly, also deserves to be on this list) for pointing out that I forgot to mention Bert Jansen in the list of Microsoft people who go above and beyond. Bert is a SharePoint service engineer who does a lot of work with SharePoint PnP (processing pull requests, issues, running test automation and teletry). To quote Yannick: \u0026ldquo;[Bert]’s an amazing coder! The father of modernization tooklit\u0026rdquo;.\n","permalink":"http://localhost:1313/posts/open-source-contributors-are-people-too/","tags":["PnP","GitHub","Community"],"title":"Open Source Contributors are People Too!"},{"categories":["SharePoint"],"contents":"Introduction \u0026ldquo;One size fits all\u0026rdquo; doesn’t work for Information Architecture.\nEspecially not in SharePoint.\nIn a previous post, I discussed a lot of bad SharePoint implementations are due to bad Information Architecture.\nAs a general rule, if your users complain that they can’t find the information they need, it is most likely because your Information Architecture (IA) needs tweaking.\nYour IA may have been great when it was first implemented. But things change.\nYour customers’ needs change, and your business needs to change to adapt — if you want to stay in business.\nWhen your business changes, your IA should change as well.\nIn this article, I’ll discuss how to avoid the \u0026ldquo;One size fits all\u0026rdquo; approach for IA, and how it should constantly evolve.\nIA does not equal the Org Chart The first instinct when building an IA is to mimic your company’s Org Chart.\nThat would be good… if your company suddenly became sentient and started browsing your SharePoint site. If Contoso Inc became a living thing, it would feel right at home navigating an IA that looks like its Org Chart.\nBut you don’t build IAs for companies.\nYou build them for people.\nYour SharePoint users are those who will need to find information. They’re the ones that need to be able to get to the stuff they need to do their jobs.\nSo, here is my bold statement:\nInformation Architectures need to be User-centric, not Organization-centric.\nNow many of you are probably saying: \u0026ldquo;Do you expect us to build different navigation for every single person in my company?\u0026rdquo;\nIdeally, yes! But it isn’t as simple as that.\nAnd how do you fit different navigations for every user in your IA? Won’t it get too complicated to make sense?\nLimitations of file structures In the olden days, when people tried to build IAs for network file shares, there was only one dimension to work with. The folder structure.\nWith folders, if you want to create a folder structure that caters to different types of people, you don’t have a lot of flexibility.\nLet’s take an example: employee benefits.\nMost organizations offer various types of employee benefits. Here are some examples:\nHealth care Retirement Workplace flexibility Wellness program Tuition reimbursement The Human Resources department handles some of the benefits above. Finance department handles some others.\nWhen creating the folder structure, you want to give a place for our HR folks to share benefits information. Things like brochures, forms, standard operating procedures (SOPs), etc.\nBut you don’t want people from the Finance dept to mess with HR’s files. And you don’t want HR people to mess with Finance’s files.\nSo you create another folder for the Finance department to share information about the benefits they take care of. Another folder with brochures, forms, SOPs, etc.\nBut how do employees find information about benefits if all you have is a file folder structure? They need to know that there are files in both the HR and Finance department benefits folders.\nThat’s the problem with using a file folder structure. If you don’t want to duplicate documents, you need to put them in one place.\nSo you end up creating the lowest common denominator structure that will cater to most people.\nBut what if you could use more that one Information Architecture?\nTo be continued As it turns out, your SharePoint Information Architecture has 3 different dimensions! That’s 3 different types of Information Architecture at your disposal.\nIn our next article, we’ll discuss the 3 dimensions of Information Architecture in SharePoint.\n","permalink":"http://localhost:1313/posts/information-architecture-in-sharepoint-one-size-does-not-fit-all/","tags":["Information Architecture","IA"],"title":"Information Architecture in SharePoint: Data, Information, Knowledge"},{"categories":["SharePoint"],"contents":"Introduction 2 words.\nThat’s all people see when they scan links and headlines on your pages.\n11 characters, on average.\nThat’s all you get to attract people’s attention on your SharePoint site.\nThat’s what a Nielsen Norman Group study found when they studied how users read online content.\nWhy should you care?\nLet’s take the SharePoint news list for Contoso:\nI’m sure you’ll agree that every news article on the list above is important. Right?\nNow, if people really see the first 11 characters of a headline, let’s show what they actually see when they scan the news articles:\nHmmm, doesn’t make much sense, does it?\nThe average length of Fortune 1000 company names is 14 characters long. Even if you don’t work for a Fortune 1000, chances are your company name takes valuable space in headlines.\nThat’s attention-grabbing space you could use to get your employees to pay attention to.\nIn this article, we’ll discuss how to create news that will make your employees pay attention to.\nDon’t read further My mentor at McKinsey \u0026amp; Co once gave me the definition of communicate:\nTo communicate is to convey a message that results in a change in behavior.\nIf you don’t get the desired change in behavior, you’re making noise. You’re not communicating.\nThis article assumes that you want to write news and headlines because you want a change in behavior:\nStart doing something they haven’t been doing. Stop doing something they have been doing. Change their perception of things. Raise their awareness. If you don’t care about changing behaviors, you don’t need to read this article. You can post a comment to say how great this article was and I won’t tell anyone.\nOtherwise, read on!\nReaders don’t give a F In another study, Neilsen Norman Group found that when people read online content, they read in a F-pattern.\nThat is: when reading online, people take some time to read the first few items in a list. As they continue to read through the list, they read less and less.\nEye-tracking study, source: Nielsen Norman Group\nEventually, they scan through the left side of the list.\nThat’s when they only see the first few words of a list item. They’ll see a little more if you use shorter words, and less if you use long words.\nThey don’t actually count 11 characters and stop reading.\nAlso, the F-shaped pattern is not the only reading pattern. There are others.\nOne thing is clear: people scan content when they read.\nThe importance of microcontent Microcontent is a type of content that consists of short text fragments. You find microcontent in page titles, headlines, email subjects, etc.\nIn SharePoint, the News web part is a bunch of microcontent.\nMicrocontent is often shown out of context. For example, the aggregated news in your SharePoint start page, or in search results.\nMicrocontent helps readers when they scan. It lets them decide what they should click on.\nMicrocontent also helps readers search and save. They may find your news through search results and open each result in a new tab. Or they may add the links to their favorites. When they come back to your links, you need to provide them with context.\nWhatever they do, you need to write your content so that it makes sense for users.\nElements of a news article Every news article in your SharePoint site should consist of two microcontent elements:\nHeadline (or Hede) The short text that grabs the user’s attention. SharePoint uses the title of your news article as the headline.\nWhen you write headlines, you should consider the following tips:\nUse plain language: resist the temptation to be fancy. Even highly-educated users want succinct information that is easy to scan. Remove non-essential words: to improve scanning. Keywords at the front: to catch people’s attention. Follow a convention: write headlines in a consistent manner. It will help your users guess the rest of the sentence. Even if they only read the first 11 characters. Use numerals: if you have to use numbers in your headline, don’t write out the number. Write 2 instead of Two. It takes less valuable attention-grabbing space. Don’t be clever: be meaningful. Consider skipping these words:\nThe A To Even better, skip these words too:\nAnnouncing Introducing Exclusive Special And any other made-up jargon that tempts you Lead (or Lede) The one or two paragraphs below the headline.\nIf the headline’s job is to attract attention, the lead’s job is to convince the user to click on the article.\nThey should be:\nUseful: Be specific and provide facts to get your users interested. Urgent: Provide a sense of urgency to push your users to read the article. Now company policy? Give them the deadline to adopt it. Unique: fight information overload. Make it easy for your readers to know if they have already read this article. Ultra-specific: use real numbers, real names and real ideas. Most important: resist the temptation not to write a lead. Tell users what’s in it for them.\nLinks are promises Remember that links are promises. Every time a user clicks on a link, they expect that whatever page they go to will match what they clicked on.\nEvery time you break a promise by taking a user somewhere different than what they clicked. When you do, you chip away at their trust.\nIf you want people to use SharePoint, it needs to become a trusted and authoritative source of information. Every time you break users’ trust, you lose credibility. People will stop going to SharePoint to find information.\nYou should allow your users to confidently predict what they’ll get if they click. Do not be misleading or promise too much.\nDon’t click here Whatever you do, don’t use \u0026ldquo;Click here\u0026rdquo; in your headline or lead. That’s soooo 1995!\nOther than being uncool, here are reasons why you shouldn’t use \u0026ldquo;Click here\u0026rdquo;:\nIt isn’t informative: when people scan your content, hyperlinks tend to grab attention. If your hyperlink doesn’t say anything useful, chances are that users won’t spend the time to find out if the link is worth their time. Not action-oriented: remember how we said that to communicate is to [get] a change in behavior? This is your opportunity to tell people what you expect them to do. Insulting: people know what links are. They know what to expect. If you tell them to \u0026ldquo;Click here\u0026rdquo;, you tell your users that you don’t trust their intelligence. Accessibility: Users who are visually-impaired often rely on screen readers. When navigating a web page using a screen reader, it will often read out the hyperlinks. You end up with a screen reader that says \u0026ldquo;Click here, click here, click here…\u0026rdquo;. Crappy search results: Remember that people scan search results as well. If all your headlines contain \u0026ldquo;Click here\u0026rdquo;, you’re making it more difficult to find results. How to create a SharePoint news item with a headline and a lead Enough theory. Let’s create a news article!\nFrom your SharePoint site, select New followed by News post\n(optionally, you can select Add from the News web part, then News post)\nFrom the New Page page, enter the headline where it says Name your news post.\nFrom the toolbar at the top, select Page details\nIn the Page details pane that opens, enter your lead in the Description field. Do. Not. Skip. This. Write your content. When done, select Post news (or Save as draft if you aren’t quite ready to publish).\nEnjoy your new news article!\nHow to create a link to a news article Sometimes you just need to link people to news that are hosted somewhere else. You don’t need an article, you just need a link.\nHere’s how to do this:\nFrom your SharePoint site, select New followed by News link (or Add|News link from the News web part)\nIn the News link pane, enter the URL in the Link field. Make sure to include the https:// (or http://) prefix.\nSharePoint will attempt to verify the link and retrieve the news link’s headline and lead. Make sure to update the Title and Description field with your headline and lead\nSelect Post. Conclusion SharePoint News is an awesome new feature of SharePoint modern sites.\nIf you want your employees to read your news, make sure your headlines attract attention.\nIn this article, I focused on headlines and leads. I did not discuss other aspects of the news. That’s for another article.\nI hope this article will help create news that will improve your SharePoint experience!\nFor more information First 2 Words: A Signal for the Scanning Eye, Jakob Nielsen. F-Shaped Pattern of Reading on the Web: Misunderstood, But Still Relevant (Even on Mobile), Kara Pernice. Writing Digital Copy for Domain Experts, Hoa Loranger and Kate Moran. Subheads: Now the Rest of the Story, Will Newman. ","permalink":"http://localhost:1313/posts/effective-sharepoint-news-posts-that-employees-will-read/","tags":null,"title":"Effective SharePoint news posts your employees will read"},{"categories":["SharePoint"],"contents":"Introduction In my previous post on Information Architecture (IA), I explained how using your organization’s Org Chart leads to bad IA.\nThe best IA is one that allows every user, regardless of their job title, to find the information they need fast.\nUnfortunately, creating an IA that caters to every user in your organization, then trying to fit it all in a single navigation structure would be difficult to achieve.\nAs a result, organizations usually end up adopting a single, one-size-fits-all IA, hoping that it will meet the needs of most people.\nWhat you get is usually the lowest common denominator IA. An IA that meets the bare minimum for everyone.\nIn case I’m not making myself clear: lowest common denominator is bad.\nLuckily, there is a solution.\nThe answer is simple. Don’t try to fit it all in a one-dimensional IA.\nCreate an IA that has 3 dimensions:\nPhysical Logical Metadata Physical The Physical dimension of information represents how you store your information physically. Your folder structure, document libraries, sites, and site collections are the physical dimension.\nExcept that the physical dimension isn’t for everyone. It is for authors, the creators of content. Those who will maintain the information in SharePoint.\nGo to each department and look at their files. Look at their file shares, their folder structure.\nThat’ll be the start for your physical IA.\nWhen people start creating their folders (because they need to do their jobs), they don’t stop and think \u0026ldquo;What is the most efficient way to store my files\u0026rdquo;.\nNo. They create folders that make sense to them.\nIt won’t be perfect. People tend to do silly things sometimes.\nBut it is a good start. It helps you understand the needs of authors.\nYou need to apply a bit of finesse and break things down into sites, document libraries, and folders.\nBut how do you decide when you should create a site, a document library, or a folder?\nConsider the following:\nSecurity Look at who should have access to edit files, and who should have access to view files.\nTry to group documents into \u0026ldquo;containers\u0026rdquo; so that those with the same permissions stay together. I say \u0026ldquo;containers\u0026rdquo; because, at this point, we don’t know exactly if we need sites, document libraries, folders, or subfolders.\nAvoid the temptation to build a structure that requires individual permissions on every document.\nFor example, instead of assigning individual permissions on documents, try creating document libraries. Assign permissions to those document libraries. When people place documents in those document libraries, the documents will inherit permissions.\nMagic!\nIf you need to change permissions, you can do so at the document library-level, instead of trying to manage individual document permissions.\nSome SharePoint experts who are way smarter than I will tell you to avoid folders and sub-folders. According to them, folders make things more difficult to find.\nI’m ok with folders, as long as you don’t abuse them. If you need to create folders instead of document libraries, do so.\nTry to keep it to less than 3 folders deep, otherwise, people will never find the information they need.\nMetadata If you need to store documents with custom metadata, you should.\nCreate content types, if you want. You should.\nKeep one thing in mind: avoid putting documents with different custom properties in the same containers. By containers, I mean documents libraries or folders.\nMake it easy for authors to know what metadata you’ll expect them to enter by keeping documents with the same (or similar) metadata in the same document libraries. Documents with mandatory fields \u0026ldquo;Client Name\u0026rdquo;, \u0026ldquo;Project Name\u0026rdquo;, and \u0026ldquo;Project Code\u0026rdquo; shouldn’t go with documents with \u0026ldquo;Department\u0026rdquo; and \u0026ldquo;Policy\u0026rdquo;.\nOtherwise, when users drop new documents in a library, they won’t know what metadata they’re expected to enter.\nSure, you can add many content types in that library, but make sure they need similar metadata.\nUsers that spent a few hours writing a document don’t want to filter through 72 custom properties to see what they need to enter.\nThey’ll either pick the wrong content type, or they’ll enter bad metadata just to get things over with.\nI should make something clear: I’m not saying that you can’t do it. I’m saying that you shouldn’t.\nThe success of your IA depends on how well people use it. If authors get confused when creating new content, you’ll get a mess.\nGarbage in. Garbage out.\nWorkflows Put documents with similar workflows together.\nBy workflows, I mean whatever business process gets triggered when someone creates or updates a document. It could be whether documents need approval, or it could be a Microsoft Flow process.\nImagine if you have a document library that has super-important documents. Everyone in the company should see them as soon as possible.\nBut some documents in that library need publishing approval before everyone can see them. Some other documents don’t need approval.\nSomeone is bound to make a mistake. They’ll create a super-important document and upload it to the document library, expecting it to be visible right away. But the document doesn’t get approved and sits there, invisible to everyone who needs it.\nOr the other extreme: someone drops a draft copy of a document in that same document library. They think the document will need approval before it shows up for everyone. But it doesn’t and becomes visible to everyone.\nKeep it consistent: keep documents with similar workflows together. That way, content authors will know what behavior to expect when they create new content.\nConclusion The best SharePoint Information Architecture doesn’t try to fit everything into a single navigation structure.\nIt relies on 3 dimensions.\nIn this article, we discussed how the Physical dimension targets the authors.\nLet’s be bold:\nWhen building the physical dimension of your IA, your primary goal is to make life easy for authors.\nIf authors are happy, chances are your content will be better.\nWe’ll take care of readers in the next article.\n","permalink":"http://localhost:1313/posts/information-architecture-in-sharepoint-3-dimensions-of-ia/","tags":["Information Architecture","IA"],"title":"Information Architecture in SharePoint: 3 Dimensions of IA"},{"categories":["SharePoint"],"contents":"Introduction When I tell people that I do most of my work with SharePoint and Dynamics 365, I’ll often hear something like:\nOh, we have the SharePoint at work. It sucks!\nTo which I usually respond something like:\nOh, I just remembered! You’re boring, and I’m leaving!\n(…and then blame my autism for being so blunt).\nOther times, I take the time to explain that SharePoint is actually a great product. They have seen a bad implementation of it.\nBut how bad can an implementation of SharePoint be? How hard is it to install SharePoint? And if you use SharePoint in Office 365, what’s your excuse?\nThe answer is that the installation of SharePoint is not wrong. It is the content inside of SharePoint that lacks proper structure.\nFor example, let’s look at Excel: when you launch Excel, you get a blank worksheet with empty columns and rows.\nYou don’t blame Excel. You don’t say \u0026ldquo;Excel sucks!\u0026rdquo;.\nYou start putting your data in, write some formulas, and format some cells. Then you get value out of Excel.\nThe key is to put your data in Excel in a way that makes sense. Putting all data about an item is on the same row. Arranging the data into columns, so that you can sort, group, and filter the data in a way that you can make sense of it.\nIf you feel fancy, you can even format the data into tables, highlight cells, or create charts.\nThat’s how you get value out of using Excel; By giving it some structure.\nSharePoint works the same way: it starts with a (mostly) blank canvas, and you get to add your content.\nBut if you don’t take the time to structure your content, you end up with a mess.\nIf you allow other people to create content without proper governance, you get a bigger mess. People can’t find content, and whatever they find is often old, wrong, or duplicated.\nThat’s what Information Architecture (IA) is all about. IA is designing a structure for your information so that users can use your site and find the content they need.\nThis is the first in a series of articles discussing various aspects of IA within SharePoint.\nBy the end of this series, I hope to prove that SharePoint doesn’t suck — maybe your IA does?\nData, Information, Knowledge People often confuse the terms data, information, and knowledge and use them interchangeably.\nInformation and library scientists say that we should not confuse data, information, knowledge. They are very different. This is something called the DIKW Pyramid.\nTo build a better IA, you need to understand the difference between those terms.\nData Data are the facts of the world. Data has no meaning, it is a description of things. We perceive data with our senses For example, if you kept track of every time I refueled my car and how much it cost, that’s all you have. But that in itself has no meaning.\nInformation When you take data and put it in context, it starts having meaning.\nFor example, if you look at the data you collected earlier in the context of time and dates, you may notice a pattern. You may notice that I refuel my car every Mondays and Fridays. That means that I probably commute for my work (because I empty a full tank in 5 days) and that I travel on the weekend (because I use the same amount of fuel within two days)… or maybe that I should buy a new car because that’s a lot of refueling!.\nSee what happened here? We took data that had no meaning in itself, added some context (time and date) and got information.\nIn order words:\nKnowledge Knowledge consists of what we know. We start with information, then add our own experience, beliefs, rules of thumbs. It becomes our knowledge.\nIn other words:\nIf I take everything I know and write it down, it becomes information again. Someone else has to use their own experience to make it their knowledge.\nUnfortunately, we can’t store knowledge in computers (yet).\nSample scenario If you dump stuff in a SharePoint site, without structure. you create data.\nI know, I know, I said that documents are information. If people can’t make sense of the content in your site, it becomes data because it has no meaning.\nIf you want your content to have meaning, you need to put it in context.\nFor example, let’s imagine the following scenario:\nYou keep a list of customers in SharePoint somewhere You have a document library containing customer contracts, proposals, and specs. You have a list of customer-related projects, with status reports, deliverables, etc. You have an RSS feed web part somewhere that has industry news, customer news, etc. There are account managers in your organization who each own one or more customers. You have a list of which account manager has what customer You have a list of experts and their industry expertise Your customers work across many industries You experience the following problems:\nYour site users complain that they can’t find the documents they need. Account managers send the wrong versions of proposals You find many copies of the same document, with file names containing _finalversion, _final_final, and _thisisreallythefinalversioniswear Users don’t know about the RSS feed web part, or they don’t use it. People find it difficult to find the right experts for a given industry. One of the ways that you could re-arrange the information would be to put it in the context of customers.\nFor example, imagine if you had a place for every customer. For now, let’s call it a site, but that’s not the point of this exercise.\nEvery site would have the same information:\nCustomer information Customer documents Links to customer projects An RSS feed that shows news about the customer, the customer’s competitors, and their industry. A contact card for the account manager Contact cards for experts in the customer’s industry Somewhere else, you would have a list of all customers with a link to their individual sites.\nFinally, every account manager would see a My Customers web part. The web part would show them their list of customers and links to their customer sites.\nHere is a potential usage scenario:\nAndrew is an account manager. He logs in to the SharePoint first thing in the morning.\nAndrew is about to visit his customer and wants to see what’s going on. He clicks on the customer’s name in the My Customers web part to get the customer’s site.\nOn the customer’s site, he can review the status of the latest proposal and project status.\nAs he’s getting to leave, Andrew looks at the RSS news. He notices that the customer’s competitor is in the news for declaring bankruptcy. It may impact the proposal Andrew prepared.\nAndrew wants to make sure is not affected.\nAndrew looks at the list of experts and sees that Edward is an expert in the customer’s industry. He sees that Edward is currently online and available. He chats with Edward to understand the impact of the competitor’s news. Edward explains how Andrew should change the proposal.\nAndrew makes the changes to the proposal. When he leaves for his customer meeting, he does so knowing he is well prepared.\nThis scenario is actually derived from an implementation I built many years ago. It uses the same data that already existed, but by putting it in the context of a customer, it has meaning for its users.\nBy putting the customer list in the context of each user, it helps account managers. They can get to their customer information with fewer clicks.\nAdding a list of industry experts makes it possible to get in touch with the people with knowledge.\nWhat it means Add context The secret to creating content that has meaning (information) is to give it context. Otherwise, it is data.\nTo avoid data overload — and useless SharePoint content — make sure that you put data in context.\nAdd links to people You can’t store people’s knowledge in SharePoint. But if you provide links to people — who have the knowledge, you will make it easier for your users to reach experts.\nPersonalize Personalization is not adding the person’s name on the top of the page and say Hello, [user]. That’s useless — I know my own name (except, maybe on Mondays)!\nThink of personalization as putting data in the context of a user. What does the user care about? What information do they need to do their jobs?\nFor example, one of my clients had offices across the world, with head offices in Toronto. Every day, users would log in to the SharePoint and would see announcements like this:\n\u0026ldquo;IMPORTANT: Parking structure will closing this weekend\u0026rdquo; \u0026ldquo;Pastries in the lunchroom\u0026rdquo; \u0026ldquo;Cafeteria menu for today is chili!\u0026rdquo; \u0026ldquo;CEO to announce new deal today\u0026rdquo; You think that people in Honduras cared about the parking lot closures or the pastries in the lunchroom? No! They do care about the CEO announcing the new deal, though.\nPeople in the head office got value out of the announcements (chili day was always popular). Everybody else in the company — those who made money for the company — felt as if they were less important. They felt the news didn’t matter to them.\nAs a result, most people outside of the Toronto offices didn’t read the news. To them, the news became data, not information.\nThe fix was simple: create corporate news for everyone, and office news for each office, then roll them up as News. Combine corporate news with news related to the user’s office. That way, every user could see all the news that matter to them.\nIf someone wanted to see news for other offices, they could visit the site for that office. The default behavior was to show people the news in the context of their office.\nConclusion People often confuse data, information, and knowledge. Content without context has no value. It becomes data — noise that they have to filter through to get to what matters to them.\nInformation architecture strives to take all data and create context. It makes it information and gives it meaning.\nYou will find that by adding a little context to your content.\nWhat if dictionaries contained all the words in the English language, but in random order? They would be useless.\nSearching for a word would need you to scan the entire dictionary before you could find it.\nIt would be frustrating.\nIf you met me and I told you that I write dictionaries for a living, you would probably say:\nOh, we have dictionaries at work. They suck!\nIn our next articles, we’ll discuss specific ways to create an information architecture. We’ll focus on creating an information architecture that makes sense for users.\nWe’ll also discuss how you can use SharePoint to create targeted content. You know, stuff that matters to users.\nI hope this helps?\nFor more information The DIKW Pyramid, Wikipedia\n","permalink":"http://localhost:1313/posts/information-architecture-in-sharepoint-data-information-knowledgei/","tags":["Information Architecture","IA"],"title":"Information Architecture in SharePoint: Data, Information, Knowledge"},{"categories":["SPFx"],"contents":"Introduction SharePoint client-side web parts (SPFx) allow you to define custom properties that your users can use to customize your web parts.\nYou can set default values in your web part’s manifest.json file so that the web part is already pre-configured when a user adds your web part to a page.\nFor example, the following (fictitious) Deflatinator web part — which allows you to shoot a beam that will deflate everything within the Tri-state area has three custom properties:\ndeflateBeachBalls (boolean, default true) controls if it will deflate beach balls deflateBlimps (boolean, default true) controls if it will deflate blimps maxMirrorBounce (number, default 3) controls if the beam can bounce of mirrors (and increase chances that something will go wrong) curseYou (string, default Perry! (what else?)) controls who will be cursed if your plans go wrong. Your web part’s props will be defined as follows:\nexport interface IDeflatinatorWebPartProps { deflateBeachBalls: boolean; deflateBlimps: boolean; maxMirrorBounce: number; curseYou: string; } Your Deflatinator.manifest.json file would include a preconfiguredEntries section that looks like this:\n\u0026#34;preconfiguredEntries\u0026#34;: [{ \u0026#34;groupId\u0026#34;: \u0026#34;5c03119e-3074-46fd-976b-c60198311f70\u0026#34;, \u0026#34;group\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Other\u0026#34; }, \u0026#34;title\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Deflatinator\u0026#34; }, \u0026#34;officeFabricIconFontName\u0026#34;: \u0026#34;Pinned\u0026#34;, \u0026#34;description\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Deflates everything within the Tri-state area.\u0026#34; }, \u0026#34;properties\u0026#34;: { \u0026#34;deflateBeachBalls\u0026#34;: true, \u0026#34;deflateBlimps\u0026#34;: true, \u0026#34;maxMirrorBounce\u0026#34;: 3, \u0026#34;curseYou\u0026#34;: \u0026#34;Perry!\u0026#34; } }] Every time a user adds your Deflatinator web part, it will have those default values. If you configured your custom properties, your users will be able to customize the values as they wish.\nThe default values defined in your manifest.json are static — that is, the default value your users will receive will always be the same unless you change your manifest.json.\nBut what if you want different pre-configurations to be available to users?\nBetter yet, what if you want default values that change dynamically, depending on the user’s language, permissions, or preferences? How about the SharePoint environment, current date, the content of a list, or anything else?\nLuckily, SPFx supports this!\nSpecifying multiple (but static) pre-configured entries The first — and easiest — way to offer different configurations is to define multiple pre-configured entries in your manifest.json file.\nFor example, here is my Deflatinator.manifest.json file with two versions of the web part: one that deflates blimps by default (deflateBlimps is true), and one that does not (deflateBlimps is false):\n\u0026#34;preconfiguredEntries\u0026#34;: [{ \u0026#34;groupId\u0026#34;: \u0026#34;5c03119e-3074-46fd-976b-c60198311f70\u0026#34;, \u0026#34;group\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Other\u0026#34; }, \u0026#34;title\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Deflatinator\u0026#34; }, \u0026#34;officeFabricIconFontName\u0026#34;: \u0026#34;Pinned\u0026#34;, \u0026#34;description\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Deflates everything within the Tri-state area.\u0026#34; }, \u0026#34;properties\u0026#34;: { \u0026#34;deflateBeachBalls\u0026#34;: true, \u0026#34;deflateBlimps\u0026#34;: true, \u0026#34;maxMirrorBounce\u0026#34;: 3, \u0026#34;curseYou\u0026#34;: \u0026#34;Perry!\u0026#34; } }, { \u0026#34;groupId\u0026#34;: \u0026#34;5c03119e-3074-46fd-976b-c60198311f70\u0026#34;, \u0026#34;group\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Other\u0026#34; }, \u0026#34;title\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Deflatinator -- No blimps\u0026#34; }, \u0026#34;officeFabricIconFontName\u0026#34;: \u0026#34;Pinned\u0026#34;, \u0026#34;description\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Deflates everything except for blimps within the Tri-state area.\u0026#34; }, \u0026#34;properties\u0026#34;: { \u0026#34;deflateBeachBalls\u0026#34;: true, \u0026#34;deflateBlimps\u0026#34;: false, \u0026#34;maxMirrorBounce\u0026#34;: 3, \u0026#34;curseYou\u0026#34;: \u0026#34;Perry!\u0026#34; } }] When users open the web part catalog, they will see two entries: Deflatinator and Deflatinator — No blimps. Depending on which web part entry they choose, the web part will either deflate blimps by default or not.\nThis is a good approach if you have a web part that can be used in a lot of different ways (like a web part with different views, or an Embed web part that allows you to embed different types of things in a page).\nIt is also a good way to emphasize different functionality within your web part.\nHowever, it can also lead to over-crowding of your web part catalog. Imagine if we needed one pre-configured Deflatinator web part for every possible first name in the curseYou property?)\nSpecifying dynamic defaults Luckily, you can define default properties when the user adds your web part to their page at run-time using the onInit event in your web part code.\nDuring the onInit event, you can set the default properties any way you want.\nThe only tricky bit is that onInit expects a Promise\u0026lt;void\u0026gt; response — but don’t let that scare you!\nHere is some code that sets the same default values as above:\nprotected onInit(): Promise\u0026lt;void\u0026gt; { // create a new promise return new Promise\u0026lt;void\u0026gt;((resolve, _reject) =\u0026gt; { // set a default if Deflate Beach Balls has not been defined if (this.properties.deflateBeachBalls === undefined) { this.properties.deflateBeachBalls = true; } // set a default if Deflate Blimps has not beed defined if (this.properties.deflateBlimps === undefined) { this.properties.deflateBlimps = true; } // set a default if Mirror Bounce has not beed defined if (this.properties.maxMirrorBounce === undefined) { this.properties.maxMirrorBounce = 3; } // set a default if Curse You name hasn\u0026#39;t been defined if (this.properties.curseYou === undefined) { this.properties.curseYou = \u0026#39;Perry!\u0026#39;; } // resolve the promise resolve(undefined); }); } Of course, make sure to update your manifest.json file as follows:\n\u0026#34;preconfiguredEntries\u0026#34;: [{ \u0026#34;groupId\u0026#34;: \u0026#34;5c03119e-3074-46fd-976b-c60198311f70\u0026#34;, \u0026#34;group\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Other\u0026#34; }, \u0026#34;title\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Deflatinator\u0026#34; }, \u0026#34;officeFabricIconFontName\u0026#34;: \u0026#34;Pinned\u0026#34;, \u0026#34;description\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;Deflates everything within the Tri-state area.\u0026#34; }, \u0026#34;properties\u0026#34;: { } }] NOTE: If you find that your changes to the manifest.json file dont seem to take effect when debugging your solution, you may need to stop debugging, rungulp bundle`, then restart debugging.\nUsing localized default values The code above does exactly the same thing as if you defined default values in your manifest.json. If that’s all you need, stick to setting the default values the manifest.json.\nLet’s try setting the default curseYou property to a localized name:\n// assumes that when you created your web part it defined your localized strings // and that you added a DefaultCurseYouName property import * as strings from \u0026#39;DeflatinatorWebPartStrings\u0026#39;; ... protected onInit(): Promise\u0026lt;void\u0026gt; { // create a new promise return new Promise\u0026lt;void\u0026gt;((resolve, _reject) =\u0026gt; { // set a default if Deflate Beach Balls has not been defined if (this.properties.deflateBeachBalls === undefined) { this.properties.deflateBeachBalls = true; } // set a default if Deflate Blimps has not beed defined if (this.properties.deflateBlimps === undefined) { this.properties.deflateBlimps = true; } // set a default if Mirror Bounce has not beed defined if (this.properties.maxMirrorBounce === undefined) { this.properties.maxMirrorBounce = 3; } // set a default if Curse You name hasn\u0026#39;t been defined if (this.properties.curseYou === undefined) { // BEGIN CHANGED: use the localized default name this.properties.curseYou = strings.DefaultCurseYouName; // END CHANGED } // resolve the promise resolve(undefined); }); } Using current date and time Ok, let’s make things a bit more complicated; Let’s pretend that your web part has a countdown (to indicate when the Deflatinator will trigger, of course) and that you want to store the triggerTime in a web part property.\nYou could update your IDeflatinatorWebPartProps to include a triggerTime prop:\nexport interface IDeflatinatorWebPartProps { deflateBeachBalls: boolean; deflateBlimps: boolean; maxMirrorBounce: number; curseYou: string; // BEGIN ADDED: Add triggerTime triggerTime: Date; // END ADDED } Now let’s pretend that you want the triggerTime to automatically default to one day from when the user adds the web part. You would change your onInit method as follows:\nprotected onInit(): Promise\u0026lt;void\u0026gt; { // create a new promise return new Promise\u0026lt;void\u0026gt;((resolve, _reject) =\u0026gt; { // set a default if Deflate Beach Balls has not been defined if (this.properties.deflateBeachBalls === undefined) { this.properties.deflateBeachBalls = true; } // set a default if Deflate Blimps has not beed defined if (this.properties.deflateBlimps === undefined) { this.properties.deflateBlimps = true; } // set a default if Mirror Bounce has not beed defined if (this.properties.maxMirrorBounce === undefined) { this.properties.maxMirrorBounce = 3; } // set a default if Curse You name hasn\u0026#39;t been defined if (this.properties.curseYou === undefined) { this.properties.curseYou = strings.DefaultCurseYouName; } // BEGIN ADDED: set a default Trigger Date if (this.properties.triggerTime === undefined) { // Get the current date const defaultTrigger: Date = new Date(); // Add one day // I know, I know, I could use momentjs, but this is // the cheesy way to do it without extra libraries defaultTrigger.setDate(defaultTrigger.getDate() + 1); // Set the default date this.properties.triggerTime = defaultTrigger; } // END ADDED // resolve the promise resolve(undefined); }); } When the user adds your web part, the default triggerTime will automatically calculate tomorrow’s date.\nNOTE: you’ll notice all my code above tests that the property is not undefined before setting the value. It handles cases where there is a default value configured in the manifest.json. It is not necessary, but it doesn’t hurt to be extra careful, right?\nUsing current user information So far, we’ve used pretty simple tricks to set default properties to a dynamic value, but what if we wanted to do something a bit more difficult? What if we wanted to use (gasp!) Promises?! (Insert ominous music here)\nLet us pretend that — for whatever reason — we wanted the web part`s default property to use the name of the user who inserted the web part.\nFor this, we will use the awesome PnP/PnPjs libraries.\nFirst, start by installing the library to your project by using the instructions from the PnP/PnPjs getting started page:\nnpm install @pnp/common @pnp/sp @pnp/logging @pnp/odata NOTE:\nYOU: \u0026ldquo;Hey, everything I have seen — including the PnP documentation — says that I need to add --save in my npm install command. You did not do that! Did you forget it?\u0026rdquo;\nME: No, the --save parameter is no longer required with npm install (see the documentation). It does not hurt if you have it, but it does not do anything anymore … assuming, of course, that you have a current version of npm.\nThen add PnP libraries to your imports at the top of your web part code:\nimport { sp } from \u0026#34;@pnp/sp\u0026#34;; import { CurrentUser } from \u0026#39;@pnp/sp/src/siteusers\u0026#39;; Then change your onInit as follows:\nprotected onInit(): Promise\u0026lt;void\u0026gt; { // create a new promise return new Promise\u0026lt;void\u0026gt;((resolve, _reject) =\u0026gt; { // set a default if Deflate Beach Balls has not been defined if (this.properties.deflateBeachBalls === undefined) { this.properties.deflateBeachBalls = true; } // set a default if Deflate Blimps has not beed defined if (this.properties.deflateBlimps === undefined) { this.properties.deflateBlimps = true; } //MOVED: moved the code to set the default Curse You name to the end of this function // Set a default Trigger Date if (this.properties.triggerTime === undefined) { // Get the current date const defaultTrigger: Date = new Date(); // Add one day defaultTrigger.setDate(defaultTrigger.getDate() + 1); // Set the default date this.properties.triggerTime = defaultTrigger; } // set a default if Mirror Bounce has not beed defined if (this.properties.maxMirrorBounce === undefined) { this.properties.maxMirrorBounce = 3; } // BEGIN CHANGED: If there is no one to curse, get the current user if (this.properties.curseYou === undefined) { // No default value, get the current user\u0026#39;s name sp.web.currentUser .select(\u0026#34;Title\u0026#34;) // don\u0026#39;t retrieve everytyhing, we just want the display name .get() .then((r: CurrentUser) =\u0026gt; { // set a default if Curse You name hasn\u0026#39;t been defined // I always set a default value in case I can\u0026#39;t get the current user\u0026#39;s name let curseYouUser: string = strings.DefaultCurseYouName; // If we got user properties if (r !== undefined) { console.log(\u0026#34;Yes to current user\u0026#34;, r[\u0026#34;Title\u0026#34;]); curseYouUser = r[\u0026#34;Title\u0026#34;]; } this.properties.curseYou = curseYouUser; // resolve the promise when done resolve(undefined); }); } else { // Resolve the promise resolve(undefined); } // END CHANGED }); } You could also use the same approach to retrieve data from a SharePoint list, or from an external API.\nBonus benefits There is an added benefit to set default values in the onInit method: if you are debugging and testing your code, and want to make changes to the default values, you can just change the code in your onInit and your changes will be reflected next time you add the web part to a page.\nIf you changed your default values in your manifest.json instead, you would need to stop debugging, run gulp bundle, restart debugging, remove the web part, refresh the page, re-add the web part.\nFor a lazy person like me, it is much easier to change the onInit method. Just keep in mind that there are valid scenarios (like when you need to offer multiple versions of your web part) where it is better to use the manifest.json preconfiguredEntries.\nAlso, it doesn’t need to be a one-size-fits-all scenario: you can combine some entries in the manifest.json with some code in your onInit. That is why my code above always verifies that the value is undefined before I attempt to apply default values.\nJust keep in mind the onInit gets called often. You want the code to be as fast and optimized as possible. For example, make sure the value you want to set as default is really empty before you call an API to get a default value.\nConclusion SPFx allows you to pre-configure default values for your web part custom properties that get applied when a user first adds the web part to a page.\nWhen you want to dynamically set default values, you can override the onInit method to apply any logic you need.\nIn this article, I used a completely nonsense web part to demonstrate the concepts, but you can apply the same principles in your own (hopefully, less nonsense) web parts.\nI hope this helps?\nFor more information Pre-configure web parts (Microsoft) Configure custom properties (Microsoft) Localize web parts (Microsoft) Define multiple pre-configured entries (Microsoft) Get Current User information using PnP Library in SPFx from Shantha Kumar Thambidurai. ","permalink":"http://localhost:1313/posts/dynamic-default-properties-in-spfx-web-parts/","tags":null,"title":"Dynamic default properties in SPFx web parts"},{"categories":["SPFx"],"contents":"Introduction Ihate acronyms.\nShould have thought of that before getting into IT for a living!\nOne of the most annoying acronyms, to me, is CORS. It is annoying because it shows up in an error message when you’re trying to make an HTTP request to a URL external to SharePoint.\nIt may be hard to diagnose if you don’t handle your HTTP request rejections, or if you don’t have your developer tools enabled in your browser, but when you do, you’ll get an error message that looks like this:\nworkbench.html:1 Access to fetch at \u0026amp;#039;https://somecoolexternalapi.com/api\u0026amp;#039; from origin \u0026amp;#039;https://localhost:4321\u0026amp;#039; has been blocked by CORS policy: Response to preflight request doesn\u0026amp;#039;t pass access control check: It does not have HTTP ok status. This article will explain what CORS is, and how to avoid issues with CORS when making HTTP requests to an external resource.\nWhat is CORS? NOTE: I’m over-simplifying the explanation and definition of CORS. If you want the real definition, go look at Wikipedia. Just don’t scream at me for being slightly inaccurate, ok? 🙂\nCORS stands for Cross-origin resource sharing. It is a way to control how stuff from one web sites (like images, CSS, scripts, and even APIs) is shared with other web sites.\nWhen it isn’t busy ruining your day, CORS can be useful because it allows you to prevent people from pointing to your web site to steal resources from it (while causing extra traffic). Or worse.\nIt usually works by looking at the domain where the request originates from (e.g.: mytenant.sharepoint.com) and comparing against the domain where the resource sites (e.g.: mycoolapi.com). If the two domains aren’t the same, it is a cross-domain request or — in CORS terms — a cross-origin request.\nWhile you can do some CORS validation on the server-side (that’s another blog), it is usually enforced by your browser. In fact, the CORS standards request that any requests that potentially change data (like an API call) should be pre-validated by your browser before even requesting the resource. That pre-verification is called preflight.\nIt goes a little something like this:\nCLIENT-SIDE COMPONENT: “Hey browser, please call this API from https://somecoolapi.com\nBROWSER: “Sure thing. Lemme ask.”. “Hmm, somecoolapi.com is a different domain than mytenant.sharepoint.com, where we are now. I should check first”; calls somecoolapi.com.\nWEBSITE: “New domain, who dis?”\nBROWSER: “Hey, someone from origin: mytenant.sharepoint.com would like to get access to your API. You can find out all about it in my OPTIONS HTTP headers.”\nWEBSITE: “Sure, I don’t see any reasons why you shouldn’t be allowed. Here, let me give you some Access-Control-Allow-Origin headers to confirm I’m ok with it. Just make sure you only GET stuff, no POST or DELETEs, ok?”.\nWEBSITE: “Awesome!”; Turns to user, “Good news! somecoolapi.com said they’ll do it!”.\nWEBSITE: Makes request. Gets results. Returns results to user.\nThey lived happily ever after.\nThe End.\nCome to think of it, that’s exactly how I handle phone calls; If call display is blocked, or it is a number I don’t know, I let it go to voicemail. If it is my wife, I answer. She then asks me to buy more Nespresso coffee on the way home. I usually accept the request, because standing between my wife and coffee is like standing between a mother bear and her cub: dangerous.\nSo, CORS may be annoying, but it is useful.\nThe problem is that when you make requests to another domain in a SPFx web part using SPHttpClient, you’re making a request from mytenant.sharepoint.com. It usually triggers a CORS error.\nTo make things worse, when you search for the error, you usually get tons of results on how to change the server settings to prevent the issue. Nothing on how to solve it in your client-side web part.\nHow to solve CORS issues with SPHttpClient SPHttpClient, included in strong\u0026gt;@microsoft/sp-http\u0026lt;/strong, make it easy to make HTTP requests using the current web part’s context.\nTo access it from your component or service, you need to get the web part’s WebPartContext — I usually pass it into my component’s props, like this:\nimport { WebPartContext } from \u0026amp;quot;@microsoft/sp-webpart-base\u0026amp;quot;; export interface IMyCustomComponent { context: WebPartContext; } Once you have the WebPartContext you can make the Http request using SPHttpClient, usually something like this:\nimport { SPHttpClient, SPHttpClientResponse} from \u0026amp;#039;@microsoft/sp-http\u0026amp;#039;; … /* When ready to make request */ return this.props.context.spHttpClient.get(yourApiUrl, SPHttpClient.configuration.v1) .then((apiResponse: SPHttpClientResponse) =\u0026amp;gt; apiResponse.json() .then(…) /* Handle the results */ …which is usually when you get the CORS issue.\nTo avoid the CORS issue, you need to make sure that your request meets the following requirements:\nNo custom HTTP headers such as ‘application/xml’ or ‘application/json’ Request method has to be GET, HEAD, or POST. If method is POST, content type should be ‘application/x-www-form-urlencoded’, ‘multipart/form-data’, or ‘text/plain’ However, SPHttpClient tries to be nice and sets a custom OPTIONS HTTP header for you by default.\nIn order to override the OPTIONS header in your SPHttpClient request, just pass a new/clean IHttpClientOptions parameter, as follows:\nimport { SPHttpClient, SPHttpClientResponse, ISPHttpClientOptions } from \u0026amp;#039;@microsoft/sp-http\u0026amp;#039;; … /* When ready to make request */ const myOptions: ISPHttpClientOptions = { headers: new Headers(), method: \u0026amp;quot;GET\u0026amp;quot;, mode: \u0026amp;quot;cors\u0026amp;quot; }; return this.props.context.spHttpClient.get(yourApiUrl, SPHttpClient.configuration.v1, myOptions) .then((apiResponse: SPHttpClientResponse) =\u0026amp;gt; apiResponse.json() .then(…) /* Handle the results */ And that should be it.\nConclusion CORS can be scary, it can be annoying, but it is a good thing.\nYou can avoid CORS issues when using SPHttpClient in your SPFx component by passing a ISPHttpClientOptions that doesn’t set custom options.\nI only covered how to make GET requests in the code above. You can use a similar approach for HEAD and POST requests.\nThis approach won’t always work (for example, if the API you’re calling requires custom HTTP headers), but it should solve most other CORS issues.\nAnd if you have any more questions, post a comment, e-mail, or text. Don’t call 🙂\n","permalink":"http://localhost:1313/posts/getting-around-cors-issues-in-spfx-with-sphttpclient/","tags":null,"title":"Getting around CORS issues in SPFx with SPHttpClient"},{"categories":["SPFx"],"contents":"Introduction If you write SPFx web parts or extensions using React, you may have had to assign more than one or more CSS classes to the same element. To do so, you simply list all the CSS class names inside a string, separated by spaces; Like this:\npublic render(): React.ReactElement\u0026lt;IDemoProps\u0026gt; { return ( \u0026lt;div className={\u0026#34;myClass mySelectedClass myEnabledClass\u0026#34;}\u0026gt; ... \u0026lt;/div\u0026gt;); } However, if you want to dynamically assign CSS classes, the string gets a bit more complicated.\nFor example, if I wanted to add a CSS class only if the state of the element is selected, and also have a different CSS class for whether the object is enabled or not, you would combine a whole bunch of conditional operators inside your string.\nSomething like this:\npublic render(): React.ReactElement\u0026lt;IDemoProps\u0026gt; { const { selected, enabled } = this.state; return ( \u0026lt;div className={\u0026#34;myClass \u0026#34; + selected ? \u0026#34;mySelectedClass \u0026#34; : undefined + enabled ? \u0026#34;myEnabledClass\u0026#34; : \u0026#34;myDisabledClass\u0026#34;}\u0026gt; ... \u0026lt;/div\u0026gt;); } Note that I had to include a space after myClass and mySelectedClass because, if they get concatenated in a string and I forget to include the space, the className attribute will be:\nmyClassmySelectedClassmyEnabledClass instead of:\nmyClass mySelectedClass myEnabledClass Which is obvious now that I write it, but when it is 3 in the morning and you’re trying to figure out why your CSS class isn’t working properly, it is a small mistake that can be very annoying.\nAnd if your logic gets even more complicated, your CSS class name concatenation can be pretty unruly.\nLuckily, the standards SPFx solution has a built-in helper.\n@uifabric/utilities/lib/css Courtesy of our Office UI Fabric friends, there is a helper function that takes an array of CSS class names and concatenates it for you.\nAnd the best part is: it is already included inside your SPFx solution!\nTo use it, start by importing the CSS utilities:\nimport { css } from \u0026#34;@uifabric/utilities/lib/css\u0026#34;; And replace all that concatenation ugliness with a simple call to css, as follows:\npublic render(): React.ReactElement\u0026lt;IDemoProps\u0026gt; { const { selected, enabled } = this.state; return ( \u0026lt;div className={css(\u0026#34;myClass\u0026#34;, selected \u0026amp;amp;\u0026amp;amp; \u0026#34;mySelectedClass\u0026#34;, enabled ? \u0026#34;myEnabledClass\u0026#34; : \u0026#34;myDisabledClass\u0026#34;)}\u0026gt; ... \u0026lt;/div\u0026gt;); } The class takes care of adding spaces between the classes. For example, the following code:\nclassName={css(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;)} will produce:\nclassName={\u0026#39;a b c\u0026#39;} It also skips the \u0026ldquo;falsey\u0026rdquo; values (according to comments in their code). In other words, you can evaluate class names that result in a null, undefined, or false value and it will skip it.\nFor example the following code:\nclassName={css(\u0026#39;a\u0026#39;, null, undefined, false, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;)} Will produce:\nclassName={\u0026#39;a b c\u0026#39;} You can even pass a dictionary of class names, each with a true/false value, and css will concatenate all the class names that are true, as follows:\nclassName={css(\u0026#39;a\u0026#39;, { b: true, z: false }, \u0026#39;c\u0026#39;)} Produces:\nclassName={\u0026#39;a b c\u0026#39;} \u0026lt;strong\u0026gt;But wait! If you order now, you\u0026#39;ll also get\u0026lt;/strong\u0026gt; the ability to pass serializable objects (objects that have a \u0026lt;strong\u0026gt;toString()\u0026lt;/strong\u0026gt; method) -- at no extra charge! ```TypeScript const myObject = { toString: () =\u0026gt; \u0026#39;b\u0026#39; }; ... className={css(\u0026#39;a\u0026#39;, myObject, \u0026#39;c\u0026#39;)} Will result in:\nclassName={\u0026#39;a b c\u0026#39;} Conclusion As a self-proclaimed World’s Laziest Developer, I tend to avoid extra work at any cost. The css helper function, which is already in your SPFx solution helps avoid writing extra CSS class name concatenation logic by provided something that is versatile, sturdy and — best of all — tested!\nI know that this isn’t an earth-shattering technique or original, but I find myself constantly re-opening old SPFx solutions to remember where that css function is defined. This article may save me some searching in the future… and hopefully, help you as well!\n","permalink":"http://localhost:1313/posts/dynamically-assign-multiple-css-class-names-in-spfx-the-easy-way/","tags":null,"title":"Dynamically Assign Multiple CSS Class Names in SPFx — The Easy Way"},{"categories":["Coding"],"contents":"Introduction Today, I was moving my files to my new Surface Studio 2 (which is an awesome development machine!); All my personal files are synched to OneDrive, except for my Visual Studio and GitHub project files which are — by default — stored in c:\\users[myuseraccount]\\source\\repos.\nSynching your personal files to OneDrive makes it really easy to work on multiple devices or making sure that you have a backup in case your workstation is stolen, lost, self-destroyed, or abducted by aliens.\nMaking sure that your project files are also synched ensures that all those prototypes, proofs of concepts, and other code snippets that you never bothered adding to source control are also safe.\nThis article describes the steps to move your default project location to a folder that can be stored in OneDrive.\nLet’s make one thing clear: synching your project files to OneDrive does not replace using source control; if you have any production code in your project files, please use source control.\nChange the default project directory In Visual Studio 2017, select the Tools menu, then Options. In the Options dialog select the Projects and Solutions category, then Locations. In the Projects location type (or browse to) a folder on your OneDrive where you want your new projects to be created. Click OK. Changing the default GitHub repo location in Visual Studio In Visual Studio, make sure you’re connected to GitHub. From the Team Explorer pane, go to Settings. In the Settings pane, select Global Settings. In the Global Settings pane, type (or browse to) the folder you want to use in the Default Repository Location. Click Update. Conclusion The instructions above will default your new Visual Studio projects and repos in a OneDrive folder; they’ll get synchronized with OneDrive.\nThanks to Daniel Zikmund for the detailed steps on how to set up the folder in Visual Studio. Also, Andrew Grant has a great video showing how to do the above steps.\nI hope this helps!?\nUPDATE: I apologize to Daniel Zikmund, I gave your brother Martin credits. Thanks Martin for letting me know.\n","permalink":"http://localhost:1313/posts/change-default-project-folder-in-visual-studio-2017-to-a-onedrive-folder/","tags":["OneDrive","Visual Studio"],"title":"Change default project folder in Visual Studio 2017 to a OneDrive folder"},{"categories":["SPFx"],"contents":"Introduction A while ago, I wrote an article describing how you can inject a custom CSS stylesheet on SharePoint modern pages using an SPFx application extension. The code sample is now part of the SharePoint SP-Dev-Fx-Extensions repository on GitHub.\nSince the article, I have been getting tons of e-mails asking all sorts of questions about the solution.\nSince SPFx 1.6 was released, I took the opportunity to upgrade the solution to the latest and greatest version of the toolset. You can find the latest code on GitHub, or download the latest SharePoint package.\nIn this post, I’ll (hopefully) answer some questions about how to use it.\nBe smart You should really use the out-of-the-box customizations features before you resort to injecting custom CSS.\nThere are a few reasons why you shouldn’t inject your own CSS:\nMicrosoft can change the HTML layout, element ids, or CSS classes at any time — thus breaking your custom CSS. Your customizations may hide or otherwise disable (or interfere with) new features Microsoft may introduce in the future. Your customizations will be unsupported by Microsoft. Don’t try to open support tickets (unless you’re willing to pay for them, I guess). Although the solution uses SPFx application extensions, the SharePoint/SPFx team will not be able to support your customizations. That being said, there are valid reasons why you may need to inject custom CSS. Vesa and his team had to give careful consideration before accepting my solution as a code sample.\nHere are some sample valid reasons for injecting your own CSS:\nTo meet your corporate branding guidelines (but consider using a custom theme first). To solve unique accessibility requirements (such as importing a custom font to help with cognitive disabilities, such as dyslexia). To solve an showstopping issue (you know, to shut up one of those bosses/clients that say distasteful stuff like: “we’ll only use SharePoint Online/Office 365 **if** Microsoft fixes the ugly look and feel and [insert bad idea here]”. For limited-time customizations (like fixing an issue while you’re waiting for Microsoft to fix it, or making it snow on Christmas Eve). Ok, maybe the last one isn’t such a valid reason.\nSteps to inject your own CSS Download the code and build the solution, or download the pre-built solution. Go to your tenant’s app catalog (usually at https://[yourtenant].sharepoint.com//sites/Apps/AppCatalog/Forms/AllItems.aspx) Drag and drop the sppkg file from step 1 onto the library (or click Upload and select the file). When it prompts you Do you trust react-application-injectcss-client-side-solution? select Deploy (provided, of course, that you trust the solution!). If you want the extension to be available on all sites. check Make this solution available to all sites in the organization before you select Deploy. You may have to check-in the file if it is checked-out. It may take a while for the application extension to show up (I once had to wait overnight for the magical SharePoint elves to deploy the extension). Meanwhile, create your own CSS file to include your customizations. Name it custom.css (don’t worry, I’ll show you how to change that default name later). Upload your custom.css to your root style library (located at https://[yourtenant].sharepoint.com/Style%20Library/Forms/AllItems.aspx). If you have versioning enabled on that library, you may have to check-in the file so that other people can see your custom css. Again, don’t worry, I’ll show you how to use a different location later. Your custom CSS should show up! The most important part of this is that the custom.css is NOT part of the SPFx solution! It is a separate file stored in a publicly-accessible location.\nFrequently Asked Questions It doesn’t work Start by using the default custom.css name, with the default location of https://[yourtenant].sharepoint.com/Style%20Library/Forms/AllItems.aspx. Once it works, we can move/rename the CSS. Use a really obvious CSS to see that the style sheet is getting loaded. Something like: .ms-compositeHeader-topWrapper { margin-top: 5px !Important; background-color: green; }\nif the above CSS works (by adding an ugly green bar at the top of the page), it means that the extension works and is able to load the custom CSS. Verify your CSS.\nUsing your browser’s developer extensions, check to see if you’re getting any kind of HTTP 404 (Not Found) message. If you’re getting a 404, your CSS is named wrong or in the wrong place. It works, but only for me (and other administrators) You probably didn’t check-in and publish your CSS. The CSS doesn’t get packaged in my solution It isn’t supposed to be! By default, the CSS is uploaded in the root style library (which can be found at https://[yourtenant].sharepoint.com/Style%20Library/Forms/AllItems.aspx. Why doesn’t the CSS get packaged in the solution? I wanted to avoid having to re-deploy the solution every time I wanted to change the CSS. I wanted non-developers to be able to use the application extension. How do I change the name of the CSS? Rename your CSS to whatever you want Upload it to your root style library Go to your Tenant Wide Extensions (located at: https://[yourtenant].sharepoint.com/sites/Apps/Lists/TenantWideExtensions/AllItems.aspx Select the InjectCssApplicationCustomizer from the list. Select Edit Item from the ribbon. In the edit form, change the value in Component Properties to use your new CSS name and hit Save. For example, if you renamed your CSS to contoso.css, you’d change the entry to be: { \u0026#34;cssurl\u0026#34;:\u0026#34;/Style%20Library/\u0026lt;strong\u0026gt;contoso\u0026lt;/strong\u0026gt;.css\u0026#34; } How do I place the CSS somewhere else than the root style library? Place your CSS in a publicly accessible library Go to your Tenant Wide Extensions (located at: https://[yourtenant].sharepoint.com/sites/Apps/Lists/TenantWideExtensions/AllItems.aspx Select the InjectCssApplicationCustomizer from the list. Select Edit Item from the ribbon. In the edit form, change the value in Component Properties to use your new CSS name and hit Save. For example, if you created a new style library called InjectCss in the root site, you’d change the entry to be: { \u0026#34;cssurl\u0026#34;:\u0026#34;/\u0026lt;strong\u0026gt;InjectCSS\u0026lt;/strong\u0026gt;/custom.css\u0026#34; } How do I place the CSS in a CDN? I didn’t test it. but in theory, you could follow the instructions above, but change the cssurl value to include the full path to your CDN. How do I do [insert your own customization] by injecting CSS? I’m not a CSS expert, but here’s how I usually do my customizations:\nUsing your browser, surf to a modern page. Launch your browser’s developer toolbar (CTRL-Shift-I for Chrome, F12 for Edge) Use the element selector (CTRL-Shift-C for Chrome, Ctrl-B for Edge) select the element you want to customize. From the Styles pane in the developer tools, select + (New Style Rule) and enter the styles you want to change. Both Chrome and Edge has autocomplete capabilities, so feel free to explore. Don’t worry, it only changes your current page, and does not gets saved if you refresh the page or load a new page. If you find that your styles are getting overwritten as soon as you apply them, try adding an !important instruction at the end of your style. (CSS experts are cringing as they read this). Once your element looks the way you want it, copy the rule to your custom CSS and upload the CSS wherever your placed it in your tenant. Did I forget anything? If there is anything I forgot, please let me know in the comments. I’ll try to answer every question… eventually.\n","permalink":"http://localhost:1313/posts/update-inject-custom-css-on-sharepoint-modern-pages-using-spfx-application-extensions/","tags":["React","SPFx"],"title":"UPDATE: Inject Custom CSS on SharePoint Modern Pages using SPFx Application Extensions"},{"categories":["SPFx"],"contents":"Introduction A week ago, Microsoft officially released the SharePoint Framework Package v1.5, introducing new awesome features like the Developer Preview of Dynamic Data and the ability to create solutions with beta features by adding –plusbeta to the Yeoman command — among other features.\nWhile it isn’t necessary to update your existing SPFx solutions, you may need to do so (let’s say, because you have an existing solution that needs a feature only available in SPFx 1.5, for example).\nUnfortunately, the solution upgrade process between versions of SPFx is often painful.\nThankfully, there is an easy way to do this now!\nThis article explain a (mostly) pain-free to upgrade your SPFx solution. Waldek explains this process in details, but this is a summary of how to do it.\nOffice 365 CLI Office 365 CLI is a cross-platform command-line interface (at least, that’s what I think CLI means… I hate acronyms) that allows you to do a lot of things with your Office 365 subscription, on pretty-much any operating system you want to do. (Find out more about Office 365 CLI).\nThe Office 365 CLI version 1.4.0-beta version introduced a new spfx project upgrade function; It can be used to upgrade an SPFx project.\nIf you don’t have Office 365 CLI version 1.4.0-beta or above, you’ll need to install it first. To do so, run the following command:\nnpm i -g @pnp/office365-cli@next Analyzing your project The spfx project upgrade function does not change your project — you’ll need to do this yourself; it analyzes your project and gives you a report telling you exactly what you need to do.\nSample upgrade report\nTo use it, follow these steps:\nFrom your command-line, change your current directory to the root of your SPFx project.\nType the following command:\no365 spfx project upgrade --output md \u0026gt; report.md Once analysis is completed, open the report.md file that was created in your SPFx project folder.\nUpgrading your project If you really want to all the required changes that the analysis found, you can read the report, but if you’re in a hurry, follow these steps:\nBack-up your project (do I really need to say this?)\nScroll to the (almost) end of the report.md file and look for the Summary section.\nCopy the code block under the Execute script header and paste it into your console.\nThe Summary Execute script section\nNext, find every file in the Modify files section and make the highlighted changes. Pro tip: the report provides a hyperlink to each file that you need to change. Just use CTRL-Click to open the file.\nThe Modify files section\nNote that you may have multiple updates to make to the same file, but the report will list each update as a separate entry. The report also pretends that there is nothing else in the file than what it shows in the report. So, for example, if your .yo-rc.json file looks like this before the upgrade:\n{ \u0026#34;@microsoft/generator-sharepoint\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.4.1\u0026#34;, \u0026#34;libraryName\u0026#34;: \u0026#34;react-calendar-feed\u0026#34;, \u0026#34;libraryId\u0026#34;: \u0026#34;dd42aa00-b07d-48a2-8896-cc2f8c0d3fae\u0026#34;, \u0026#34;environment\u0026#34;: \u0026#34;spo\u0026#34; } } and the upgrade report tells you to update .yo-rc.json as follows:\n{ \u0026#34;@microsoft/generator-sharepoint\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.5.0\u0026#34; } } You’re really supposed to update the .yo-rc.json as follows (change highlighted in bold):\n{ \u0026#34;@microsoft/generator-sharepoint\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.5.0\u0026#34;, \u0026#34;libraryName\u0026#34;: \u0026#34;react-calendar-feed\u0026#34;, \u0026#34;libraryId\u0026#34;: \u0026#34;dd42aa00-b07d-48a2-8896-cc2f8c0d3fae\u0026#34;, \u0026#34;environment\u0026#34;: \u0026#34;spo\u0026#34; } } But the next sections in the report will include more changes to the .yo-rc.json file, which — when you’ve made all the changes — will look like this:\n{ \u0026#34;@microsoft/generator-sharepoint\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.5.0\u0026#34;, \u0026#34;libraryName\u0026#34;: \u0026#34;react-calendar-feed\u0026#34;, \u0026#34;libraryId\u0026#34;: \u0026#34;dd42aa00-b07d-48a2-8896-cc2f8c0d3fae\u0026#34;, \u0026#34;environment\u0026#34;: \u0026#34;spo\u0026#34;, \u0026#34;isCreatingSolution\u0026#34;: true, \u0026#34;packageManager\u0026#34;: \u0026#34;npm\u0026#34;, \u0026#34;componentType\u0026#34;: \u0026#34;webpart\u0026#34; } } Once you’ve made all your changes, test your solution and (hopefully) it will work with SPFx 1.5!\nConclusion You shouldn’t need to upgrade your solution every single time Microsoft releases a new version of SPFx.\nIf you have to upgrade your solution, however, the Office 365 CLI spfx upgrade project command can save you a lot of time.\nFor more information This article is mostly a note to myself on how to upgrade an SPFx project. For the real deal, I encourage you to read Waldek’s detailed article, from where I learned about the spfx project upgrade command. (Thanks Waldek for being awesome!)\nTo learn more about Office 365 CLI, go to https://aka.ms/o365cli\nTo learn more about the cool new features available in SPFx 1.5, go to the Release Notes for SharePoint Framework Package 1.5.\nThe solution I used in this article is my React Calendar Feed sample web part, available on the SharePoint Framework Client-Side Web Part Samples \u0026amp; Tutorial Materials.\n","permalink":"http://localhost:1313/posts/upgrade-your-spfx-solution-to-sharepoint-framework-package-v1-5/","tags":null,"title":"Upgrade your SPFx solution to SharePoint Framework Package v1.5"},{"categories":["SharePoint"],"contents":"Introduction In Part 1 of this article, I walked through the various components that we’ll need to build to create a responsive calendar feed web part that mimics the out-of-the-box SharePoint events web part.\nIn this article, we’ll:\nCreate a web part solution Add a mock service to return test events, and We’ll display a simple list of events The final product will look like this:\nCreating a web part solution If you haven’t done so yet, set up your SharePoint Framework development environment following Microsoft’s awesome instructions.\nWe’ll create a solution called react-calendar-feed-1. In future articles, we’ll take what we built in this article as the foundation for react-calendar-feed-2, and so on until we’re done with the solution, which we’ll call react-calendar-feed. Of course, you can skip all the steps and get the code for the final solution, if you’d like.\nWhen you’re ready to create the solution, use the following steps:\nUsing the command line, create a new project directory md react-calendar-feed-1 Change the current directory to your new project directory cd react-calendar-feed-1 Launch the Yeoman SharePoint Generator: yo @microsoft/sharepoint When prompted for the solution name, accept the default react-calendar-feed-1.\nFor the baseline package select SharePoint Online only (latest).\nWhen asked Where do you want to place the files? accept the default Use the current folder.\nWhen asked if you want to allow the tenant admin the choice of being able to deploy the solution to all sites immediately respond No.\nWhen asked for the type of client-side component to create select WebPart.\nFor Web part name, use CalendarFeedSummary. Later, we’re planning on adding other web parts for searching events (but that’s another blog post).\nFor Web part description, enter Displays events from an external feed.\nWhen asked for a framework select React.\nWhat Yeoman is done creating the project for you, it’ll say Congratulations! Solution react-calendar-feed-1 is created. Run gulp serve to play with it!.\nSince we’re not quite ready to play with the web part yet, let’s launch Visual Studio Code by typing:\ncode . Once Visual Studio Code is launched, we’re ready to code!\nCleaning up the generated web part code If you open the CalendarFeedWebPart.ts file, you’ll notice that there are multiple exports : one for ICalendarFeedSummaryWebPartProps and one for CalendarFeedSummaryWebPart.\nOne practice that I’ve learned by reading the Office UI Fabric code is they keep the component code separate from the Prop and State interfaces in separate files, making each component file simpler and easier to read. This is a practice I tend to follow as well, so let’s create a separate file for the web part’s types:\nIn the src | webparts | calendarFeedSummary folder, create a new file called CalendarFeedSummaryWebPart.types.ts. Back in the CalendarFeedSummaryWebPart.ts, find the export interface ICalendarFeedSummaryWebPartProps block and cut it. Go back to CalendarFeedSummaryWebPart.types.ts and paste the code you just cut. The file should look as follows: View the code on Gist.\nBack in CalendarFeedSummaryWebPart.ts, you’ll want to add an import to the interface we just moved out. At the top of the file, just below the last import line, type the following:\nimport { ICalendarFeedSummaryWebPartProps } from \u0026#39;./CalendarFeedSummaryWebPart.types\u0026#39;; Create the folder structure When the final solution will be completed, our web part will consume calendar feeds from various services. Those services will also be re-usable by other web parts.\nWe’ll start by create a single mock service that will return events in the format that we need. In future posts, we’ll add more types of services.\nIn the src folder, create a new folder called shared. This is where all shared components will reside. In the newly created shared folder, create a new folder called services. This is where all services will go. Even if we’ll only have one type of service. it is a good idea to adopt a consistent folder structure. In the services folder, create a folder called CalendarService. Create an ICalendarEvent interface Our calendar service providers will return a bunch of events that will all have the same properties:\nTitle: the title of the event Start: the start date and time of the event End: the end date and time URL: the URL for the event, if applicable AllDay: a boolean (true or false) value indicating if the event is an all-day event (i.e.: with no start and end time). Category: a classification for the event, if applicable. Description: a short text summary of the event, if available. Location: a physical location for the event, if applicable. Why “if applicable”? Not all event providers are capable of returning all properties for events.\nTo make it easier to work with, we’ll create an ICalendarEvent that will expose all the above properties. Why an interface and not a class? Well, in Typescript, an interface is the easiest way to describe a type of thing without actually saying what the thing does or how it does things.\nIf our events needed to do things, like calculate their own duration (end date minus start date) or something of the sort, we’d need a class to implement the method; our ICalendarEvent interface is really a convenient way to describe that all events have a title, a start date, end date, etc.\nTo create the ICalendarEvent interface:\nIn the src | shared | services | CalendarService folder, create a new file called ICalendarEvent.ts Copy the code below and paste it in the new file you created: View the code on Gist.\nSome may argue that the ICalendarEvent is really a model and it should really reside in a different folder where all models go, but I like the simplicity of the CalendarService folder holding everything it needs to deliver a calendar feed. If I ever wanted to move it out to its own module, I could do it very simply.\nCreate a service interface We’ll first create an interface that all calendar service providers will implement. Again, the interface will describe what the calendar service providers will look like. Later, we’ll create a calendar service provider class that will implement the interface.\nBut for now, let’s create the interface:\nIn the src | shared | services | CalendarService folder, create a new file called ICalendarService.ts. Create another file called index.ts in the CalendarService folder. Paste the following code in each respective file View the code on Gist.\nAs you’ll see, the ICalendarService interface says that all calendar service providers will need to implement a getEvents method that will return a promise of an array of ICalendarEvent. We return a promise because we’ll (usually) be retrieving events from calendar service providers asynchronously, and promises make it easier to do that.\nDon’t worry, we’ll explain this better when we implement our first real calendar service provider.\nYou’ll notice that we create a index.ts in the root of the CalendarService folder and exported both the ICalendarService and the ICalendarEvent interfaces. Why? Just like index.html used to be the default web page for a site, index.ts is the default file for a folder in Typescript. If you don’t specify a file when using an import, it automatically looks for the default file.\nBut why would I create an index.ts file? Isn’t just an extra file that I’ll need to maintain? Yes, but it makes it easier to hide the complexities of the CalendarService to the rest of the application — they just need to know that they need an ICalendarService and an ICalendarEvent interface from the CalendarService folder, without needing to know where (in which specific file) the interfaces are implemented. When we start adding new service providers, or when we move stuff around, we won’t have to change our imports because we’ll always point to the default index.ts for the CalendarService.\nDon’t worry, it’ll make sense very soon.\nCreating the mock service provider Now that we have an ICalendarEvent interface to represent events, and an ICalendarService to represent a service provider, let’s combine the two and return some sample events.\nInstead of created events with hard-coded dates that will become obsolete as time goes by, we’ll create events with dates that are dynamically generated when the web part is displayed. To make our lives easier, we’ll use Moment.js to manipulate dates throughout this project. Moment.js makes it easy to manipulate dates and format them into human-readable formats.\nFrom Visual Studio Code’s Integrated Terminal (CTRL-`) type\nnpm install moment In the src | shared | services folder, create a new folder called MockCalendarService.\nIn the new folder, create a new file called MockCalendarService.ts, then create another file called index.ts.\nCopy and paste the content from the files below into the respective files below.\nexport * from \u0026#39;./MockCalendarService\u0026#39;; import* as moment from \u0026lsquo;moment\u0026rsquo;; import { ICalendarEvent } from \u0026lsquo;../ICalendarEvent\u0026rsquo;; import { ICalendarService } from \u0026lsquo;../ICalendarService\u0026rsquo;;\nconst today: Date = new Date(); const sampleEvents: ICalendarEvent[] = [ { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be tomorrow\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(1, \u0026ldquo;d\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(1, \u0026ldquo;d\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/1/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: \u0026ldquo;Meeting\u0026rdquo;, \u0026ldquo;location\u0026rdquo;: \u0026ldquo;Barrie, ON\u0026rdquo;, \u0026ldquo;description\u0026rdquo;: \u0026ldquo;This is a description\u0026rdquo; }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in one week\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(1, \u0026ldquo;w\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(1, \u0026ldquo;w\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/2/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: \u0026ldquo;Meeting\u0026rdquo;, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will last two days\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(1, \u0026ldquo;w\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(1, \u0026ldquo;w\u0026rdquo;).add(2, \u0026ldquo;d\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/2/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: \u0026ldquo;Meeting\u0026rdquo;, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in two weeks\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(2, \u0026ldquo;w\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(2, \u0026ldquo;w\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/3/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: \u0026ldquo;Meeting\u0026rdquo;, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in one month\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(1, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(1, \u0026ldquo;M\u0026rdquo;).add(2, \u0026ldquo;d\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/4/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: \u0026ldquo;Meeting\u0026rdquo;, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in two months\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(2, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(2, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/5/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: \u0026ldquo;Meeting\u0026rdquo;, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in 1 quarter\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(1, \u0026ldquo;Q\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(1, \u0026ldquo;Q\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/6/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: undefined, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in 4 months\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(4, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(4, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/7/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: undefined, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in 5 months\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(5, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(5, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/8/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: undefined, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in 6 months\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(6, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(6, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/9/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: undefined, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in 9 months\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(9, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(9, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/10/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: undefined, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in 1 year\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(1, \u0026ldquo;y\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(1, \u0026ldquo;y\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/11/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: \u0026ldquo;Partayyyy!\u0026rdquo;, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined }, { \u0026ldquo;title\u0026rdquo;: \u0026ldquo;This event will be in 18 months\u0026rdquo;, \u0026ldquo;start\u0026rdquo;: moment().add(18, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;end\u0026rdquo;: moment().add(18, \u0026ldquo;M\u0026rdquo;).toDate(), \u0026ldquo;url\u0026rdquo;: \u0026ldquo;http://web.archive.org/web/20230917181131/https://www.contoso.com/news-events/events/12/\u0026rdquo;, \u0026ldquo;allDay\u0026rdquo;: true, \u0026ldquo;category\u0026rdquo;: \u0026ldquo;Meeting\u0026rdquo;, \u0026ldquo;location\u0026rdquo;: undefined, \u0026ldquo;description\u0026rdquo;: undefined } ];\nexport class MockCalendarService implements ICalendarService {\npublic getEvents = (): Promise\u0026lt;ICalendarEvent[]\u0026gt; =\u0026gt; {\rreturn new Promise\u0026lt;ICalendarEvent[]\u0026gt;((resolve: any) =\u0026gt; {\rsetTimeout(() =\u0026gt; {\rresolve(sampleEvents);\r}, 1000);\r});\r}\r} ```\nMockExtensionService This provider will NOT be listed in the list of available providers when this solution is packaged with \u0026ndash;ship. Don\u0026rsquo;t freak out, it didn\u0026rsquo;t just disappear. The MockCalendarService creates a series of events that range from tomorrow to 18 months from now. Some are only 1 day long, but some events last a few days.\nThe getEvents method in MockCalendarService simulates the delay of getting the events through an HTTP request and returns the list of pre-generated events. In a later article, we’ll actually get real events, but — for now — this should do to test our rendering.\nRendering events Although our goal is to render calendar events that look exactly like what SharePoint does, we’ll begin by rendering a list of events as bullet points. This is to ensure that our code works, and to allow us to finish this article with something that works before we explore rendering.\nFind the CalendarFeedSummary.tsx file (located under src | webparts | components | calendarFeedSummary ) Above the render function, add a new public function called componentDidMount which calls this._loadEvents() (we’ll create the _loadEvents function shortly). The code should look as follows: public componentDidMount(): void { Below the render function (I like to keep my public functions separate from my private functions), add a private function called _loadEvents(). The code will look as follows: private _loadEvents(): void { You’ll notice that we’re referring to isLoading and events state variables, but we haven’t defined them. Let’s fix that by going to CalendarFeedSummaryProps.ts and adding a new interface called ICalendarFeedSummaryState , as follows: export interface ICalendarFeedSummaryState { And, at the top of the same file, add a reference to ICalendarEvent as follows: import { ICalendarEvent } from \u0026#34;../../../shared/services/CalendarService\u0026#34;; Since the file no longer contain only the CalendarFeedSummaryProps, rename the file from CalendarFeedSummaryProps.ts to CalendarFeedSummary.types.ts. Back in CalendarFeedSummary, find the following line: export default class CalendarFeedSummary extends React.Component\u0026lt;ICalendarFeedSummaryProps, {}\u0026gt; { And replace it with: export default class CalendarFeedSummary extends React.Component\u0026lt;ICalendarFeedSummaryProps, ICalendarFeedSummaryState\u0026gt; { Essentially telling the CalendarFeedSummary component to use the ICalendarFeedSummaryProps interface for its properties, and ICalendarFeedSummaryState interface for its state. Make sure to update the existing reference to ICalendarFeedSummaryProps and to include a reference to ICalendarFeedSummaryState by changing the following import statement at the top of the file: import { ICalendarFeedSummaryProps } from \u0026#39;./ICalendarFeedSummaryProps\u0026#39;; with:\nimport { ICalendarFeedSummaryProps, ICalendarFeedSummaryState } from \u0026#39;./CalendarFeedSummary.types\u0026#39;; Since we no longer use an empty state, we need to initialize it with a constructor. At the top of the CalendarFeedSummary.tsx file, just above the componentDidMount function, add the following code: constructor(props: ICalendarFeedSummaryProps) { In the render method, remove the with a className styles.container and all of its content. You’ll be left with something that looks like this: public render(): React.ReactElement\u0026lt;ICalendarFeedSummaryProps\u0026gt; { ); } Inside the blank div in the render function, add some code that will render the events as a bulleted list, by adding the following code: { this.state.events.map(e=\u0026gt;{ return\n{e.title}\u0026amp;lt/li\u0026gt;; })} The final code should look as follows:\nView the code on Gist.\nWhen you’re ready to test the web part, type:\ngulp serve\nand add the web part we created to the page. The events will render as a list:\nConclusion Although it isn’t very exciting (yet), the web part we created creates a bunch of events, simulates retrieving them from an HTTP request and renders them in a list.\nIn our next article, we’ll render the events so that they look like SharePoint events.\n","permalink":"http://localhost:1313/posts/creating-a-calendar-feed-web-part-part-ii/","tags":["SPFx"],"title":"Creating a calendar feed web part – Part II"},{"categories":["Coding"],"contents":"Introduction Last week, I attended the SharePoint 2018 Conference in Las Vegas. There were a lot of cool announcements and demos. The SharePoint team rocks!\nOne of the cool things that I noticed which has nothing to do with SharePoint was that a lot of presenters who showed code had a really cool command prompt that showed the node module they were in, and their Git branch status in a pretty “boat chart”.\nI had seen this many times before, but never realized how much easier it was to get a sense of what’s going on until I was watching someone else code on a big screen.\nOf course, I set out to find and configure this awesome command-line on my workstation.\nThis article will show you how you too can install and configure this command line interface.\nCmder During Vesa‘s awesome session, I paid close attention to the title of his command line window. It said Cmder.\nI had seen Cmder before; the article Set up your SPFx development environment mentions Cmder in the Optional Tools section.\nBut the version of Cmder I had installed didn’t have the fancy “boat chart” at the top that got my attention.\nAs it turns out, you need to download another custom prompt for Cmder that adds the Powerline (that’s the real name for the “boat chart”) at the top.\nHere is how to install and configure Cmder with the Powerline command prompt:\nInstalling Cmder Go to http://cmder.net/ and download either the Mini pack or the Full pack.\nUnzip the package. Cmder is designed to be portable and to require no administrative privileges to run, so their instructions tell you to not install it in the Program Files folder (where you’ll need administrative privileges). I placed it in C:\\Users\\[myusername]\\AppData\\Local\\cmder.\nOpen a command prompt in Administrative mode from the folder where you copied the Cmder files\nFrom the command-prompt, type:\ncmder /REGISTER ALL\nIf you get an Access Denied error, you probably forgot to run the command in Administrative mode. If you don’t know how to do that, type cmd from your Start menu, and right-click on Command Prompt and select Run as administrator.\nCmder should be installed. You can verify by opening a new File Explorer window and right-clicking on a folder. You should get a Cmder Here option.\nUnfortunately, if you open Cmder with that command line, you don’t get the fancy Powerline.\nLet’s fix that!\nInstalling Cmder Powerline custom prompt The Cmder Powerline custom prompt changes the Cmder prompt to include the following modifications:\nThe folder portion of the prompt is displayed in blue. The user’s home folder is also replaced with a tilde (~). If the current folder is an npm package, the prompt will display the package package name and version number in teal. If the current folder is a Git repository, the prompt will display the branch name with a green colour if the branch is unchanged, or yellow if changes are found. To install the Cmder Powerline custom prompt:\nDownload the AnonymousPro font. You can do so by clicking on each TTF file in GitHub and selecting View Raw. For your convenience, here are the links to the raw files:\nAnonymice Powerline Bold Italic.ttf\nAnonymice Powerline Bold.ttf\nAnonymice Powerline Italic.ttf\nAnonymice Powerline.ttf Once dowloaded each font, install them by double-clicking them and selecting Install on each one of them. Copy all the .lua files from the Cmder Powerline source and place them in the config folder under the Cmder install folder. If you haven’t done so yet, launch a Cmder window by going to the folder where you installed in and double-clicking on Cmder.exe From the Cmder window, open the Settings by hitting Windows-Alt-P. From the Main settings area, select Anonymice Powerline font from the Alternative font (pseudographics, CJK, etc.) drop-down. In the Unicode ranges combo box, type E0A0-E0B0 and select Apply. Select Save settings to save your settings and return to the command prompt in Cmder. That’s all you need to do.\nCmder with Visual Studio Code If you want Cmder to show up in Visual Studio Code, follow these steps:\nLaunch Visual Studio Code.\nFrom the File menu, select Preferences | Settings or use Ctrl-, (Control and comma). This will open your settings editor.\nIn the right-pane of the settings editor (the one that’s actually editable), insert the following JSON, just before the last } , making sure to replace the path to Cmder with the path where you installed it.\n\u0026#34;terminal.external.windowsExec\u0026#34;: \u0026#34;C:\\\\Users\\\\[myusername]\\\\AppData\\\\Local\\\\cmder\\\\Cmder.exe\u0026#34;,\r\u0026#34;terminal.integrated.shell.windows\u0026#34;: \u0026#34;cmd.exe\u0026#34;,\r\u0026#34;terminal.integrated.shellArgs.windows\u0026#34; : [\r\u0026#34;/K\u0026#34;,\r\u0026#34;C:\\\\Users\\\\[myusername]\\\\AppData\\\\Local\\\\cmder\\\\vendor\\\\init.bat\u0026#34;\r], That’s all!\nConclusion I hope that you’ll find Cmder and the custom Cmder Powerline command-prompt useful in your SPFx development endeavors.\nI know I did!\nFor More Information Cmder.net lists more information about Cmder, including the super-powerful shortcut keys.\nAmr Eldib is the brilliant mind behind the Cmder Powerline command-prompt.\nSahil Malik has detailed instructions (and a video!) to to integrate with Cmder Visual Studio Code.\nUpdate In the previous revision of this article, I had forgotten to include the steps to copy the .lua files to the config folder. It works much better when you include all the steps, it turns out 🙂\n","permalink":"http://localhost:1313/posts/changing-your-command-prompt-to-display-node-module-and-git-information-like-the-sharepoint-conference-presenters/","tags":["Command prompt"],"title":"Changing your command prompt to display node module and Git information like the SharePoint Conference presenters"},{"categories":["SharePoint"],"contents":"Introduction One of the premises of SPFx is that, with it, third-party developers have the same set of tools that the SharePoint team has. So, if you like the look of an out-of-the-box web part you can, in theory, reproduce the same look and feel yourself.\nA friend of mine needed to display a list of upcoming events, but the events are coming from a WordPress site that uses the WP Fullcalendar widget. They also really liked the look of events in SharePoint.\nSo, I thought: why not try re-creating the out-of-the-box SharePoint events web part, but instead of reading events from a SharePoint list (or group calendar), it would read from WordPress?\nSince I was taking the challenge, I decided to also try to do these extra features:\nRead events from multiple event providers, including RSS, iCal, and WordPress. Support additional event providers without having to re-design the entire web part Make the web part responsive, just like the SharePoint events web part, with a narrow view and a wide view. Support “Add to my calendar” Make it possible to add more web parts, for example, the Event Search web part, reusing as many of the components as possible. This article will explain the various components of this web part. Because I tend to ramble on and on, I’ll then explain how to write every component of the web part in separate articles so that you can read as much (or as little) as you want.\nAnd if you really don’t want to read the articles, you can always get the code. I won’t be offended if you do.\nConfiguration If you download the web part and run\ngulp serve\nyou’ll see the web part in your web part catalog.\nNote: when I designed this web part, I created an SVG icon for it. At the time of this writing, there was an issue with using custom base64-encoded SVG icons. If your icon doesn’t look like the one in the picture above, don’t worry.\nWhen you add the web part, you’ll be prompted to configure it:\nSelecting the Configure button (or selecting Edit web part in the web part’s “toolbox”) will launch the web part’s property pane.\nIn the property pane, the Feed type drop-down lists all the service providers that the web part can find.\nThe idea is that if we add more feed types, they’ll automatically show up here. Let me know in the comments if you have an idea for a feed type you think we should add, or if you’d like to add one yourself just submit a pull request.\nIf you’re running the web part in a development environment, it’ll offer you a Mock option, which will add bogus events for testing purposes. In production, this option will not appear.\nThe Feed URL input box will prompt you to enter a URL for the feed you wish to display. It validates the URL format (but doesn’t yet check the URL for results).\nBecause the WordPress feed URL that I was using supports a from and to date value in the URL, I added the ability to automatically insert today’s date and an end date (see below). All you have to do is to add a {s} where you want the start date and {e} where you want the end date.\nThe Date range drop-down allows you to select anything from Next week to Next year.\nUnlike the out-of-the-box SharePoint events search, I didn’t add a All events option because there was no way (that I know of) in React to find the maximum possible date. I could have passed a null value around, but I didn’t want to do that. If there are enough requests for it, I’ll figure out a way to do All events later.\nThe only event provider that I know of which actually supports specifying a start and end date is WordPress. When a provider doesn’t support filtering at the source, I just filter them out once I have received the events.\nIn the Advanced section, you can specify the Maximum number of events per page for the narrow view (the normal view just fits in as many events as it can on every page).\nThe default is 4 (that’s what SharePoint events does), but you can put as many as you want on every page. You can also put 0 if you don’t want pagination for the narrow view.\nWhen I was testing this web part, I kept on getting all sorts of CORS issues on some of the feeds I was using. So I added a Use proxy option, which — you guessed it — routes your requests through a proxy.\nFinally, the web part can use the user’s local storage to cache events it retrieves so that the web part doesn’t fetch every. single. time. you. resize. the. page.\nYou can set the cache duration from 0 to 1440 minutes (1 day) in 15 minute increments. Be careful, though, because it’ll always cache a user’s results from the time they last retrieved the events. So, if you set it to cache for a day, it’ll wait an entire day before reloading events again no matter the time of the day. You should probably set it to half-a-day, just to be safe.\nIf you don’t want to cache, you can set the cache duration to 0 and it’ll refresh from the source every time. If your feed is slow, the web part will take forever to load every time.\nThe Apply button is just to make sure that the web part won’t try to load the feed as you type the URL.\nAssuming you configured the web part (and that my code works well), you’ll get to see your events in a pretty calendar view soon enough.\nThe narrow view When you put the web part in a single-column, or when the web part is less than 480 pixels wide, the web part renders a list view of events.\nThe list will render all the events retrieved and paginate the results according to the page size option you configured.\nThe dates are rendered to look like a page-a-day calendar.\nIf the event spans over multiple days, the date box will render differently:\nThe pagination component renders a Previous and Next button, and helps manage how many pages to render, which page to render, etc. Unfortunately, Office UI Fabric doesn’t offer a pagination control so I had to write my own.\nOf course, if I wasn’t so lazy, I would have created a full pagination control with page numbers, and all, but the SharePoint events web part doesn’t show the page numbers so I didn’t do it. If there is enough demand for it, I’ll make the component more generic and add the page numbers.\nThe Normal view (or carousel view) When you view the web part on a full page (or when it is wider than 480 pixels), the web part switches to a carousel view.\nThe carousel view is responsive and renders between 1 and 4 events per page.\nLike the SharePoint events web part, there is a next and previous arrow when you mouse over the calendar, with dots at the bottom to indicate what page you’re on.\nFinally, the Add to my calendar button creates a dynamic ICS file, allowing you to import the event to most calendars on most devices.\nConclusion In upcoming articles, I’ll show how to build this, component by component.\nI hope that you’ll enjoy it.\n","permalink":"http://localhost:1313/posts/creating-a-calendar-feed-web-part/","tags":["SPFx"],"title":"Creating a calendar feed web part – Part I"},{"categories":["SharePoint"],"contents":"Why would you want to inject CSS? Since Microsoft introduced Modern Pages to Office 365 and SharePoint, it is really easy to create beautiful sites and pages without requiring any design experience.\nIf you need to customize the look and feel of modern pages, you can use custom tenant branding, custom site designs, and modern site themes without incurring the wrath of the SharePoint gods.\nIf you want to go even further, you can use SharePoint Framework Extensions and page placeholders to customize well-known areas of modern pages. Right now, those well-known locations are limited to the top and bottom of the page, but I suspect that in a few weeks, we’ll find out that there are more placeholder locations coming.\nBut what happens when your company has a very strict branding guideline that requires very specific changes to every page? When your customization needs go beyond what’s supported in themes? When you need to tweak outside of those well-known locations?\nOr, what if you’re building a student portal on Office 365 and you need to inject a custom font in a page that is specifically designed to help users with dyslexia?\nThat’s when I would use a custom CSS.\nHere be dragons Before you go nuts and start customizing SharePoint pages with crazy CSS customizations, we need to set one thing straight:\nWith SharePoint, you should always color within the lines. Don’t do anything that isn’t supported, ever. If you do, and you run into issues, you’re on your own.\nWith SharePoint, you should always color within the lines\nRemember that Microsoft is constantly adding new features to SharePoint. The customizations you make with injecting custom CSS may stop working if the structure of pages change.\nWhat’s worse, you could make changes to a page that prevents new features from appearing on your tenant because you’re inadvertently hiding elements that are needed for new features.\nWith custom CSS (and a CSS zen master), you can pretty much do anything you want. The question you should ask yourself is not whether you can do it, but whether it is the right thing to do.\nEnough warnings! How do I inject custom CSS? It is very easy. In fact, I’m probably spending more time explaining how to do it than it took me to write the code for this. If you don’t care about how it works, feel free to download the source and install it.\nUsing SharePoint Framework Extensions, you can write code that you can attach to any Site, Web, or Lists. You can control the scope by how you register your extensions in your SharePoint tenant.\nWith an extension, you can insert tags in the HTML Head element.\nI know what you’re thinking: we can just insert a STYLE block at in the HEAD element and insert your own CSS. Sure, but what happens when you need to change your CSS? Re-build and re-deploy your extension? Nah!\nInstead, how about inserting a LINK tag and point to a custom CSS that’s located in a shared location? That way, you can modify the custom CSS in one place.\nYou can even have more than one custom CSS and use your extension properties to specify the URL to your custom CSS. In fact, you can add more than one extension on a site to combine multiple custom CSS together to suit your needs.\nBuilding your custom CSS injection extension You too can design a beautiful SharePoint site that looks like this:\nI’m really a better designer than this. I just wanted a screen shot that smacks you in the face with a bright red bar and a custom round site icon. It hurts my eyes.\nStart by creating your own custom CSS (something better than I did, please). For example, the above look was achieved with the following CSS:\n.ms-compositeHeader { background-color: red; } .ms-siteLogoContainerOuter { border-radius: 50%; border-width: 3px; } .ms-siteLogo-actual { border-radius: 50%; }\nSave your custom CSS to a shared location on your SharePoint tenant. For example, you could save it in the Styles Library of your root site collection. You could also add it to your own Office 365 CDN. Make note of the URL to your CSS for later. For example, if you saved your custom CSS as contoso.css in the Styles Library of your tenant contoso.sharepoint.com, your CSS URL will be:\nhttps://contoso.sharepoint.com/Style%20Library/contoso.css\nwhich can be simplified to:\n/Style%20Library/custom.css\nCreate an SPFx extension following the instructions provided in the Build your first SharePoint Framework Extension (Hello World part 1) article. (Hey, why improve what’s already perfect?). Change the props interface that was created for your ApplicationCustomizer class and replace the description property to cssurl. For example, my ApplicationCustomer class is called InjectCssApplicationCustomizer so my props interface is going to be called IInjectCssApplicationCustomizerProperties. Like this: export interface IInjectCssApplicationCustomizerProperties { cssurl: string; } Change your onInit method to insert a LINK element pointing to your cssurl property. @override public onInit(): Promise\u0026lt;void\u0026gt; { Log.info(LOG_SOURCE, `Initialized ${strings.Title}`); const cssUrl: string = this.properties.cssurl; if (cssUrl) { // inject the style sheet const head: any = document.getElementsByTagName(\u0026#34;head\u0026#34;)[0] || document.documentElement; let customStyle: HTMLLinkElement = document.createElement(\u0026#34;link\u0026#34;); customStyle.href = cssUrl; customStyle.rel = \u0026#34;stylesheet\u0026#34;; customStyle.type = \u0026#34;text/css\u0026#34;; head.insertAdjacentElement(\u0026#34;beforeEnd\u0026#34;, customStyle); } return Promise.resolve(); } In your serve.json located in the config folder, change the pageUrl to connect to a page on your tenant. Also change the cssurl property to pass the URL to the custom CSS you created in steps 1-2, as follows: { \u0026#34;$schema\u0026#34;: \u0026#34;https://dev.office.com/json-schemas/core-build/serve.schema.json\u0026#34;, \u0026#34;port\u0026#34;: 4321, \u0026#34;https\u0026#34;: true, \u0026#34;serveConfigurations\u0026#34;: { \u0026#34;default\u0026#34;: { \u0026#34;pageUrl\u0026#34;: \u0026#34;https://contoso.sharepoint.com/SitePages/Home.aspx\u0026#34;, \u0026#34;customActions\u0026#34;: { \u0026#34;fcea9230-7f22-45b7-815c-081a49474611\u0026#34;: { \u0026#34;location\u0026#34;: \u0026#34;ClientSideExtension.ApplicationCustomizer\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;cssurl\u0026#34;: \u0026#34;/Style%20Library/custom.css\u0026#34; } } } }, \u0026#34;injectCss\u0026#34;: { \u0026#34;pageUrl\u0026#34;: \u0026#34;https://contoso.sharepoint.com/SitePages/Home.aspx\u0026#34;, \u0026#34;customActions\u0026#34;: { \u0026#34;fcea9230-7f22-45b7-815c-081a49474611\u0026#34;: { \u0026#34;location\u0026#34;: \u0026#34;ClientSideExtension.ApplicationCustomizer\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;cssurl\u0026#34;: \u0026#34;/Style%20Library/custom.css\u0026#34; } } } } } } Test that your extension works by running gulp serve. When prompted to allow debug scripts, select Load debug scripts. You can now tweak your custom CSS to suit your needs, continuing to hit refresh until you’re happy with the results.\nDeploying to your production tenant When ready to deploy, you need to bundle your solution, upload it to the app catalog, and enable the extension on every site you want to customize.\nTo make things easy, you can add an elements.xml file in your SharePoint folder and pre-configure your custom CSS URL. Here’s how:\nIn your solution’s sharepoint/assets folder, create a new file called elements.xml. If you don’t have a sharepoint folder or assets sub-folder, create them.\nPaste the code below in your elements**.xml**:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; ```\rMake sure to replace the custom action Title, ClientSideComponentId to match your own extension. You can find those values in your InjectCssApplicationCustomizer.manifest.json, under id and alias. Change the ClientSideComponentProperties to point to your CSS URL. Pay attention to URL encode the values (e.g.: a space becomes %20). Run gulp bundle –ship to bundle your solution/ Run gulp package-solution –ship Drag and drop the .sppkg file that was created in your sharepoint/solution folder to your tenant’s app catalog. If you selected to automatically deploy to all site collections when building the extension, you’re done. If not, you’ll need to go to every site and add the extension by using the Site Contents and Add an App links.\nConclusion You can easily inject custom CSS in every modern page of your SharePoint tenant by using an SPFx extension, but be careful. With great CSS power comes great SharePoint responsibility.\nYou can get the code for this extension at https://github.com/hugoabernier/react-application-injectcss\nI’d love to see what you’re doing with your custom CSS. Let me know in the comments what you have done, and — if you’re interested — share the CSS.\nI hope this helps?\n","permalink":"http://localhost:1313/posts/inject-custom-css-on-sharepoint-modern-pages-using-spfx-extensions/","tags":["SPFx"],"title":"Inject Custom CSS on SharePoint Modern Pages using SPFx Extensions"},{"categories":["SPFx"],"contents":"Value proposition As an independent consultant, I get to work with a lot of organizations in both public and private sectors. Most deal with various levels of security classification.\nGovernance is always a hot topic with SharePoint. Most understand the importance of governance; some shrug it off as a “we’ll deal with it when it becomes a problem” — which is never a good idea, as far as I’m concerned.\nBut what if we could make applying governance in SharePoint a lot easier? So easy, in fact, that it would be more painful to deal with it when it becomes a problem.\nThat’s what I hope to do with this series of blog articles: demonstrate easy ways to introduce some level of governance using new enabling technologies — like SPFx web parts, extensions, and site scripts.\nMy goal is not to duplicate the work of Microsoft and others; I may use a very simple approach in this first blog to keep the example easy to understand, but I fully intend on leveraging out-of-the-box Office 365 features like Data Loss Prevention (DLP) features.\nI hope you’ll stick with me for the journey!\nInformation security classification Information security classification or information classification is a step in the process of managing information. There are people who are way smarter about this topic, and there is a whole ISO 27001 standard on the topic, so I’ll avoid a detailed explanation.\n…But I’ll definitely throw in a gratuitous graphic. I guess my time McKinsey \u0026amp; Company rubbed off on me.\nManaging classified information typically consists of 4 steps:\nAsset inventory: finding out what kind of information your organization has, and who is responsible for it. Information classification: identifying how sensitive the information is. How bad would it be if this information was leaked, it’s integrity compromised, etc. There is no one way to classify information — it depends on your organization size, industry, country, etc. The most frequently use examples are: Confidential: top confidentiality level Restricted: medium confidentiality level Internal use: lowest level of confidentiality Public: everyone can see the information Information labelling: you kinda need to tell your employees how the information is classified so that they can handle it properly. Information handling: where you define rules and processes around how to handle the information. This article will focus on the information handling part of the process.\nMicrosoft’s information classification Microsoft internally classifies their information as follows:\nHigh Business Impact (HBI): Authentication / authorization credentials (i.e., usernames and passwords, private cryptography keys, PIN’s, and hardware or software tokens), and highly sensitive personally identifiable information (PII) including government-provided credentials (i.e. passport, social security, or driver’s license numbers), financial data such as credit card information, credit reports, or personal income statements, and medical information such as records and biometric identifiers. Moderate Business Impact (MBI): Includes all personally identifiable information (PII) that is not classified as HBI such as: Information that can be used to contact an individual such as name, address, e-mail address, fax number, phone number, IP address, etc.; Information regarding an individual’s race, ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health, sexual orientation, commission or alleged commission of offenses and court proceedings. Low Business Impact (LBI): Includes all other information that does not fall into the HBI or MBI categories. A while ago, Microsoft also released on GitHub some cool solution to apply their classification on SharePoint sites. They also have a great case study that shows how they approached classification on their own content.\nSo, since I want to keep things simple, I’ll use HBI, MBI, and LBI classification labels in my example. You can use your own classification if you want.\nUsing SPFx extensions to add a header If you read my equally long post on creating SPFx extensions, you’ll know that you can use SPFx extensions to do cool things on every page of a site. To keep this example really simple, I’ll create a header that reads the site’s property bag and displays a very simple Office Fabric UI Message Bar indicating the site’s classification. It isn’t going to be particularly pretty, but we can improve on looks later.\nThe bar will say “This site is classified as [LBI|MBI|HBI]. Learn more about the proper handling procedures.”, but you can make it say whatever is appropriate for you.\nHere is what the HBI header will look like:\nThe MBI header:\nAnd the LBI header:\nIn the next article, we’ll start writing the code.\n","permalink":"http://localhost:1313/posts/displaying-site-information-security-classification-on-every-page-using-a-custom-spfx-extensions/","tags":null,"title":"Displaying site information security classification on every page using a custom SPFx extensions — Part I"},{"categories":["SPFx"],"contents":"In part 1 of this article, I introduced the concept for an SPFx extension that adds a header to every page, showing the classification information for a site.\nWe’ll actually do the coding in this article!\nCreating the SPFx extension solution Using the command line, create a new project directory md classification-extension Change the current directory to your new project directory cd classification-extension Launch the Yeoman SharePoint Generator: yo @Microsoft/sharepoint When prompted for the solution name, accept the default classification-extension. For the baseline package select SharePoint Online only (latest). When asked Where do you want to place the files? accept the default Use the current folder. When asked if you want to allow the tenant admin the choice of being able to deploy the solution to all sites immediately respond Yes (unless you really want to deploy it to every single site manually). When asked for the type of client-side component to create select Extension. Select Application Customizer when asked about Which type of client-side extension to create. Almost there. For Application Customizer name, use ClassificationExtension. Keep this name to less than 40 characters always. For Application Customizer description, enter Displays the site’s information security classification. What the miracle that is Yeoman creating the project for you. It’ll take a few minutes. Eventually, it’ll say Congratulations! Solution classification-extension is created. Run gulp serve to play with it!. We’re not quite ready, yet. Adding a static header Now that the solution is created, we’ll quickly add a header to text that our extension is working. We’ll add the dynamic code later.\nLaunch Visual Studio Code and open the new project you created. From the command line, type: code . We could add code to directly manipulate the DOM and insert elements, but I prefer keeping my components in separate .TSX files. It keeps everything simple (because every component is responsible for only one thing), which makes my brain happy. It also keeps everything modular. From your project’s file explorer pane, navigate to src | extensions | classificationExtension Right-click and select New Folder.\nType components as the folder name. On the newly created folder, right-click and select New File. Name the new file ClassificationHeader.types.ts. This file will contain all the types that the Footer component (to be created soon) will use. In the ClassificationHeader.types.ts file, paste the following (placeholder) code: View the code on Gist.\n7. Now right-click the components folder and select New File. Name your new file ClassificationHeader.tsx.\n8. Paste the following code in your ClassificationHeader.tsx.\nView the code on Gist.\n9. Finally, find the ClassificationExtensionApplicationCustomizer.ts file that was created by Yeoman and replace its content with the following code:\nView the code on Gist.\nWhat the code does:\nClassificationExtensionApplicationCustomizer.ts: looks if there is a placeholder available called “Top”. If there is, it calls the ClassificationHeader.tsx component to render. You are never supposed to assume that a placeholder is there, so check every time. ClassificationHeader.tsx: renders a static/hard-coded Office UI Fabric MessageBar that says the site is MBI, and provides a fake link. ClassificationHeader.types.ts: defines a property and state interface for the ClassificationHeader component. Right now, both are empty but we’ll add some fields in future versions of this code. Testing that the extension works Unlike SPFx web parts, you can’t text your extensions in the SPFx Workbench. I hope that it’ll be fixed in future versions of the workbench, but until then you need to test it on a real page on your Office 365 tenant.\nHere is how to test your extension:\nIn Visual Studio Code, find serve.json (located in the config folder). Find an entry that looks like https://contoso.sharepoint.com/sites/mySite/SitePages/myPage.aspx and replace it to the url to a test page on your Office 365 tenant. For example: https://yourtenant.sharepoint.com/SitePages/Test-extension.aspx. There should be two instances to replace.\nFrom the Terminal pane (hit CTRL-`) type:\ngulp serve After a few moments, your favorite browser should launch and you should get a scary warning:\nSelect Load debug scripts and the page should load with our fancy message bar at the top.\nI would consider that a success! Except, of course, that the extension is hard-coded to say that the site is classified as MBI.\nBut first, we need to create some test sites and classify them.\nCreating test sites In your Office 365 tenant, create three new sites. You can use the Communication or Team site template, as long as you use a modern template.\nThe three sites will be:\nTestLBI TestMBI TestHBI You can use any naming convention you’d like, just make note of the urls for each site because you’ll need them in the next step.\nWe’ll set the property bags on each of the three testing sites, but — unfortunately — it’ll have to be in the next article.\n","permalink":"http://localhost:1313/posts/displaying-site-information-security-classification-on-every-page-using-a-custom-spfx-extensions-part-ii/","tags":null,"title":"Displaying site information security classification on every page using a custom SPFx extensions — Part II"},{"categories":["SPFx"],"contents":"In part 1 of this article, I introduced the concept for an SPFx extension that adds a header to every page, showing the classification information for a site. In part 2, we created an SPFx extension that adds a header that displays a static message with the security classification of a site.\nYes, static. As in hard-coded. I try to write these articles for people who don’t have as much experience with developing SPFx extensions, so I included the step-by-step instructions.\nIn this article, we’ll discuss how we use property bags to store the security classification.\nWhat are property bags anyway? Property bags is a term used when describing a serialized list of properties. It isn’t unique to SharePoint — I remember using them in the good old C days, but SharePoint has been using them for a long time. Remember this screen from SharePoint Designer?\nProperty bags are a convenient way to store a whole bunch of properties of things. In SharePoint, a property bag can be applied to the File, Folder, List or Web-level in SharePoint. When set at the Web level, it can be for a Site Collection or Site — at least that’s what MSDN said about SharePoint 2013.\nThe great thing about property bags in SharePoint is that they are attributes of their parent, which means they are protected the same way their parents are.\nIn theory, you could use a custom SharePoint list, add it to every site, manage the permissions, and add one row per property you want to store about each site, but that would be painful.\nYou could also store an XML or JSON file in every site that does the same, but then you’d have to write the code to create and store the file, protect it, and read it.\n…or you could use the out-of-the-box mechanism to store metadata about a site, and let SharePoint create it and protect it. Also, you could use the countless ways to access the property bags (SharePoint designer, PowerShell, CSOM, PnP JS, Office 365 CLI, etc.).\nSo, for our Classification extension, we’ll store and read from the site’s property bag. To pay a homage to Microsoft’s own solution to Implement a SharePoint site classification solution, we’ll use sc_BusinessImpact for the property name. You could name it anything you want, but you probably want to keep it somewhat unique.\nHere is what the property bag looks like in SharePoint Designer 2013:\nStoring custom properties in site property bags In the previous article, I asked you to create test sites for LBI, MBI, and HBI tests. Now we’ll store the values LBI, MBI, and HBI in the sc_BusinessImpact property in each respective site’s property bags.\nThere are a few ways to do this, but since this is just for testing purposes, I’ll offer two ways to cheat.\nSetting a custom property using SharePoint Design 2013 Yes, SharePoint Designer 2013 is still around. and it works with Office 365! What’s more, you can use it to easily set custom property bag values using it!\nUsing SharePoint Designer 2013, go to File | Open SharePoint Site and type the URL to your LBI site you created in the previous article in the Site name field. Once connected, select Site Options from the toolbar. On the Parameters tab in the Site Options dialog, you’ll see the list of properties in the property bag. Don’t mess with them.\nSelect Add… to add a new property. In the Add Name and Value dialog box, type sc_BusinessImpact in the Name field, and LBI in the Value field. Select OK.\nBack on the Site Options dialog, you should see the new property you created. Select OK to dismiss the Site Options dialog. Repeat steps 1-6 with your MBI and HBI site, making sure to use MBI and HBI, respectively, in the Value field for step 5. Storing custom properties using the Chrome SharePoint Editor Extension If you haven’t installed it yet, the Chrome SharePoint Editor Extension is a wonderful Chrome Extension that makes it easy to manage property bags. This is how to use it.\nUsing Chrome, browse to your LBI site. Hit F12 or CTRL-SHIFT-I to open the Developer Tools. Find the SharePoint tab (should be one of the last ones, after Audit). From the Chrome SharePoint Editor navigation, select Web properties. In the New Property Name field, type sc_BusinessImpact In the New Property Value field, type LBI Select Add Property to submit your changes. You should see a toast notification at the bottom right of the screen indicating it worked. Repeat steps 1-8 with your MBI and HBI site. What to do if you get errors setting the property bag values It is possible that you run into an issue where SharePoint actively refuses to set the property bag. To resolve this issue, you need to temporarily set DenyAddAndCustomizePages to 0 on each site. To do so:\nLaunch the SharePoint Online Management Shell.\nFrom the command-line, type:\nConnect-SPOService When prompted for it, enter the URL to your admin site (e.g.: https://mytenant-admin.sharepoint.com) and hit Enter.\nYou’ll most likely be prompted to log-in. Enter your credentials.\nOnce connected, type the following, making sure to enter the URL to your LBI site:\nSet-SPOSite https://yourtenant.sharepoint.com/sites/testlbi -DenyAddAndCustomizePage 0 Repeat the previous step with your MBI and HBI site URLs, then try again one of the two methods to set your site property bags.\nIf you wish to do so, you can re-run the above commands setting DenyAddAndCustomizePages to 1 after you’re done setting your property bag values. Thanks to Asish Padhy for the inspiration to set DenyAddAndCustomizePages.\nYou may think “Bah, I can just go to the SharePoint Admin site, and go to the settings, and enable this”, but as My SharePoint Log pointed out, you’ll have to wait up to 24 hours for this to take effect.\nPart III Conclusion There are plenty of other methods to set property bag values, but the ones I listed above seemed the easiest.\nI didn’t spend too much time on how to set up the values because, in a real-world scenario, you shouldn’t be setting the security classification property bag value by hand. It should be automatically configured when the site is created.\nThat’s something we’ll get to that much later. For now, we’ll focus on changing our hard-coded message bar and make it display the actual site classification.\nIn the next part of this article, we’ll finally return to code and retrieve the site classification from the property bags and display the appropriate message.\n","permalink":"http://localhost:1313/posts/displaying-site-information-security-classification-on-every-page-using-a-custom-spfx-extensions-part-iii/","tags":null,"title":"Displaying site information security classification on every page using a custom SPFx extensions — Part III"},{"categories":["SPFx"],"contents":"In part 1 of this article, I introduced the concept for an SPFx extension that adds a header to every page, showing the classification information for a site.\nIn part 2, we created an SPFx extension that adds a header that displays a static message with the security classification of a site.\nIn part 3, we learned more about property bags and learned a few ways to set the sc_BusinessImpact property (a property we made up) of our test sites to LBI, MBI, and HBI.\nIn this part, we will finally get to add code to our extension that reads the property bag of the current site and displays the appropriate site classification label.\nReading the classification from the site’s property bag You can get the property bag of a site using a simple REST call to https://yourtenant.sharepoint.com/sites/yoursite/_api/web/allProperties but it is even easier to use the SP PnP JS library make queries like these.\nAdding the SP PnP JS library to your project Open the Visual Studio Code solution you created in part 2 and perform the following steps:\nOpen the terminal pane (CTRL-`).\nFrom the terminal pane, type:\nnpm i sp-pnp-js --save We’ll need to update the ExtensionContext in the IClassificationHeaderProps interface. It will allow the ClassificationHeader component to access the context used to make PnP calls. We’ll also add a couple variables to the IClassificationHeaderState interface: one to keep the classification we’ll retrieve from the property bag, and one to keep track if we’re still loading the page.\nThe code also defines the classification property bag name (sc_BusinessImpact) and the default classification (“LBI”) for when it doesn’t find a classification for a site. Feel free to change either of those values to what makes sense for your needs.\nSimply copy and paste the following code to ClassificationHeader.types.ts:\nView the code on Gist.\nNow we need to pass the ExtensionContext to the ClassificationHeader component. Open the ClassificationExtensionApplicationCustomizer.ts file and paste the following code (line 53 is the only line that was updated): View the code on Gist.\nNow we just need to make the ClassificationHeader component query the property bag when component mounts, save the classification in the state variable and change the render code to display the classification. Just copy the code below to ClassificationHeader.tsx: View the code on Gist.\nThat should be it, let’s try it!\nFrom the Terminal pane in Visual Studio Code, type:\ngulp serve It should launch the browser to the page you had set up in part 2, in serve.json. If prompted to run debug scripts, accept.\nAssuming that the default page is not one of your LBI, MBI, or HBI test pages, you should get the default value classification (e.g.: LBI).\nChange the first part of the browser’s URL to point to your HBI page (change the part before ?debugManifestsFile=…), and it should tell you that the site is classified HBI.\nRepeat step 4 with your LBI and MBI sites and make sure that you get the right messages.\nIf everything went well, your sites displayed the right classification, but the message bar didn’t change from the default yellow warning. Let’s change that.\nChanging the message bar type based on the site classification Change the render method of the ClassificationHeader.tsx to display a message bar type “warning” for MBI, and “severeWarning” for HBI, and “info” for everything else. The render method should look like this: View the code on Gist.\nTry the LBI, MBI, and HBI test pages again just like you did before, except this time, you should get the following:\nMBI Test Site\nHBI Test Site\nHelp! The extension stops loading when I changed pages and it stopped prompting me if I want to load the debug scripts You most likely forgot to include the part after ?debugManifestsFile=… in the URL**.** Try to launch the extension again (gulp serve) and copy the part of the URL with the ? to your test pages.\n(I know because I did this a few times)\nHow to debug the extension In theory, the extension should work and load at least the default LBI message. But what if you want to debug the extension?\nHere is a simple trick:\nLaunch your extension by using gulp serve as you did above.\nCopy the everything in the URL from the ?. It should look like something like this:\n?debugManifestsFile=https%3A%2F%2Flocalhost%3A4321%2Ftemp%2Fmanifests.js\u0026amp;loadSPFX=true\u0026amp;customActions=%7B%224017f67b-81c7-5631-b0e5-57bd266bc5c1%22%3A%7B%22location%22%3A%22ClientSideExtension.ApplicationCustomizer%22%2C%22properties%22%3A%7B%22testMessage%22%3A%22Test%20message%22%7D%7D%7D\nIn your Visual Studio Code project, find launch.json under the .vscode folder.\nIf you don’t have such a file, you probably need to install the Chrome Debugger Extension for Visual Studio Code. Just go to https://aka.ms/spfx-debugger-extensions and follow the instructions to install it.\nFind the configuration entry that starts with “name”: “Hosted Workbench” and paste the ugly URL you got in step 2 at the end of the URL marked “url”. This will add the instructions to load the extension in debug mode.\nFrom the Terminal pane, type:\ngulp serve --nobrowser This will start the local web server but won’t launch the browser.\nSet a few breakpoints where you want to debug the code by using F9. For example, the render method of the ClassificationHeader component.\nFrom the Debug menu in Visual Studio Code, select Start Debugging and it should launch Chrome to the page you specified in launch.json, prompt you to login, then prompt you to run Debug scripts. Accept and you should be able to debug through the code.\nThis should be all for today. Next part of this article will clean up some of the code, add localized strings, and prepare the code for production and deploy it!.\n","permalink":"http://localhost:1313/posts/displaying-site-information-security-classification-on-every-page-using-a-custom-spfx-extensions-part-iv/","tags":null,"title":"Displaying site information security classification on every page using a custom SPFx extensions — Part IV"},{"categories":["SPFx"],"contents":"In part 1 of this article, I introduced the concept for an SPFx extension that adds a header to every page, showing the classification information for a site.\nIn part 2, we created an SPFx extension that adds a header that displays a static message with the security classification of a site.\nIn part 3, we learned more about property bags and learned a few ways to set the sc_BusinessImpact property (a property we made up) of our test sites to LBI, MBI, and HBI.\nIn part 4, we wrote the extension that reads from a site’s property bags and displays the classification in the header.\nIn this part, we will clean up a few things, package and deploy the extension.\nPreparing to deploy to production The extension we wrote in parts 1-4 of this article works, but it isn’t really production ready.\nFirst, we’ll want to change the code to only display the extension if a web can find a site’s information security classification in its property bag. That way, if you chose to deploy the extension to production, you won’t have to worry about affecting sites that do not have a security classification (although, it is recommended that every site has a classification, even if it is LBI by default).\nSecond, we’ll change the hard-coded hyperlink to point to a page on your tenant that provides handling instructions for each security classification.\nThen we’ll remove all those hard-coded strings and replace them with localized strings.\nLet’s get started!\nConditionally display the extension So far, our code assumes that every site has a security classification — which is the right thing to do if you want to be compliant.\nHowever, there are cases where you may want to deploy this extension in production and not display a security classification until you’ve actually applied a classification to a site.\nTo do this, we’ll change our code a little bit.\nIn ClassificationHeader.types.ts, we’ll change the default classification to be undefined. So, we’re changing this line:\nexport const DefaultClassification: string = \u0026#34;LBI\u0026#34;; to this line:\nexport const DefaultClassification: string = undefined; Now let’s change the render method in ClassificationHeader.tsx to handle an undefined value and skip rendering if there is no security classification. Change this code:\nvar barType: MessageBarType; switch (businessImpact) { case \u0026#34;MBI\u0026#34;: barType = MessageBarType.warning; break; case \u0026#34;HBI\u0026#34;: barType = MessageBarType.severeWarning; break; default: barType = MessageBarType.info; } to this code:\n// change this switch statement to suit your security classification var barType: MessageBarType; switch (businessImpact) { case \u0026#34;MBI\u0026#34;: barType = MessageBarType.warning; break; case \u0026#34;HBI\u0026#34;: barType = MessageBarType.severeWarning; break; case \u0026#34;LBI\u0026#34;: barType = MessageBarType.info; break; default: barType = undefined; } // if no security classification, do not display a header if (barType === undefined) { return null; } When you’re done, the code should look like this:\nView the code on Gist.\nTest your extension again, making sure to try with an LBI, MBI, and HBI site, as well as any other site that hasn’t been classified yet (i.e.: that doesn’t have a security classification property bag value defined yet).\nLinking to handling procedures Since the first part of this article, I have been using a fake URL instead of an actual link to handling instructions. Let’s set a default URL to display proper handling procedures.\nStart by creating a page on your SharePoint site that explains to your users how they should properly handle information based on their security classification. You can create one page, or (ideally) create a separate set of URLs for each classification.\nIn ClassificationHeader.types.ts, we’ll add a new constant to store the URL to the new handling procedures page you created. If you created more than one, feel free to add more than one constant. If you don’t want to use a hyperlink, just set it as undefined. Add this line of code, with the URL of your choice:\nexport const DefaultHandlingUrl: string = \u0026#34;/SitePages/Handling-instructions.aspx\u0026#34;; Remember that your URLs should be absolute (e.g.: https://yourtenant.sharepoint.com/sitepages/handling-instructions.aspx) or at least relative to the root (e.g.: /sitepages/handling-instructions.aspx), because your links will get rendered on every page in the site.\nNow let’s change the render method in ClassificationHeader.tsx to use the handling URL in the hyperlink. Change this code:\npublic render(): React.ReactElement { // get the business impact from the state let { businessImpact } = this.state; // change this switch statement to suit your security classification var barType: MessageBarType; switch (businessImpact) { case \u0026#34;MBI\u0026#34;: barType = MessageBarType.warning; break; case \u0026#34;HBI\u0026#34;: barType = MessageBarType.severeWarning; break; case \u0026#34;LBI\u0026#34;: barType = MessageBarType.info; break; default: barType = undefined; } // if no security classification, do not display a header if (barType === undefined) { return null; } return ( This site is classified as {this.state.businessImpact}. Learn more about the proper handling procedures. ); } to this code (note that you’ll need to add an import for DefaultHandlingUrl at the top (not shown here):\npublic render(): React.ReactElement { // get the business impact from the state let { businessImpact } = this.state; // ge the default handling URL let handlingUrl: string = DefaultHandlingUrl; // change this switch statement to suit your security classification var barType: MessageBarType; switch (businessImpact) { case \u0026#34;MBI\u0026#34;: // if you\u0026#39;d like to display a different URL per classification, override the handlingUrl variable here // handlingUrl = \u0026#34;/SitePages/Handling-instructions-MBI.aspx\u0026#34; barType = MessageBarType.warning; break; case \u0026#34;HBI\u0026#34;: barType = MessageBarType.severeWarning; break; case \u0026#34;LBI\u0026#34;: barType = MessageBarType.info; break; default: barType = undefined; } // if no security classification, do not display a header if (barType === undefined) { return null; } return ( This site is classified as {this.state.businessImpact}. {handlingUrl \u0026amp;\u0026amp; handlingUrl !== undefined ? Learn more about the proper handling procedures. : null } ); } When you’re done, the code should look like this:\nView the code on Gist.\nLocalizing resources There are a few places in our code where we display some text that is hard-coded in the code.\nBeing of French-Canadian origins, I am especially sensitive to the aspect of localization; you shouldn’t hard-code text, dates, numbers, currencies, and images in code if you can avoid it. Not only because it makes it easier to support easily support another language, but also because it makes it easy to maintain the text in your solution without wading through code.\nFlashback: I remember working on a project where the geniuses in the marketing department changed the name of the product about 17 times while we were building it. Every time, the team would have to scour through the code to change the references to the product name. Once they learned the wonders of localization and string resources, they could change all references to the product name in a few seconds (they still gave the marketing department a hard time, though) 🙂\nYou only need to localize the code where something that is displayed could potentially change in a different locale. It’s not just a different language, dates, numbers and currencies are displayed differently depending on where you live, even if you speak English. You don’t need to worry about debugging code (e.g.: when you write to the console) unless you want people who speak in a different language to debug your code too.\nLuckily, our code has only a few strings literals to worry about, and they’re all in the ClassificationHeader.tsx.\nYou don’t have to localize your code. But you should. So follow these instructions if you want to be a better SPFx developer:\nIn the myStrings.d.ts file, located in the loc folder (source | extensions | classificationExtension | loc), add the following two lines to the\nIClassificationExtensionApplicationCustomizerStrings interface:\n\u0026#34;ClassifactionMessage\u0026#34;: \u0026#34;This site is classified as {0}. \u0026#34;, \u0026#34;HandlingMessage\u0026#34;: \u0026#34;Learn more about the proper handling procedures.\u0026#34; In the en-us.js file, add two more lines below the “Title” line, making sure to add a comma at the end of the line that already exists:\nClassifactionMessage: string; HandlingMessage: string; Now go to the ClassificationHeader.tsx file and add a reference to your localized strings at the top of the file, below all the other import statements:\nimport * as strings from \u0026#34;ClassificationExtensionApplicationCustomizerStrings\u0026#34;; Finally, replace the code in the render method to use the localized strings. Note that we’re replacing the placeholder in the localization string with the classification label. We could have simply concatenated the values, but every language has a different syntax structure, and doing it this way makes it easier to deal with different language syntax.\nreturn ( {strings.ClassifactionMessage.replace(\u0026#34;{0}\u0026#34;,this.state.businessImpact)} {handlingUrl \u0026amp;\u0026amp; handlingUrl !== undefined ? {strings.HandlingMessage} : null } ); You code should look like this:\nView the code on Gist.\nOptional: using configuration properties The eagle-eyed reader may have noticed two things:\nThere is a testMessage property that is defined in the ClassificationExtensionApplicationCustomizer.ts that we never use.\nThe ClassificationPropertyBag, DefaultClassification, and\nDefaultHandlingUrl are all hard-coded. If you ever need to change any of the configuration items, you’d have to change the code, re-build, and re-deploy.\nThankfully, the SPFx team did a great job and designed SPFx extensions to support configuration properties. I don’t know if that’s what they’re actually called, but that’s what I call them 🙂\nThe testMessage is a sample configuration property that is created for us when we use the Yeoman generator. We can replace this property to anything that suits us. In our case, the ClassificationPropertyBag, DefaultClassification, and DefaultHandlingUrl.\nTo do this, let’s follow these steps:\nOpen ClassificationExtensionApplicationCustomizer.ts and replace the IClassificationExtensionApplicationCustomizerProperties interface code so that it looks like this:\nexport interface IClassificationExtensionApplicationCustomizerProperties { ClassificationPropertyBag: string; DefaultClassification: string; DefaultHandlingUrl: string; } In the ClassificationHeader.types.ts file, add the same properties to the IClassificationHeaderProps interface by replacing the code to this:\nexport interface IClassificationHeaderProps { context: ExtensionContext; ClassificationPropertyBag: string; DefaultClassification: string; DefaultHandlingUrl: string; } While you’re in there, make sure to remove the other definitions of ClassificationPropertyBag, DefaultClassification, and DefaultHandlingUrl.\nNow back in ClassificationExtensionApplicationCustomizer.ts pass the properties to the ClassificationHeader props by replacing this code:\nconst elem: React.ReactElement = React.createElement(ClassificationHeader, { context: this.context }); to this:\nconst elem: React.ReactElement = React.createElement(ClassificationHeader, { context: this.context, ClassificationPropertyBag: this.properties.ClassificationPropertyBag, DefaultClassification: this.properties.DefaultClassification, DefaultHandlingUrl: this.properties.DefaultHandlingUrl }); To prevent any issues from not having any configuration information, let’s add some code at the top of the onInit method:\nif (!this.properties.ClassificationPropertyBag) { const e: Error = new Error(\u0026#34;Missing required configuration parameters\u0026#34;); Log.error(LOG_SOURCE, e); return Promise.reject(e); } Finally, find any references to ClassificationPropertyBag, DefaultClassification, or DefaultHandlingUrl in ClassificationHeader.tsx and replace them to this.props.[property]. For example, replace ClassificationPropertyBag to this.props.ClassificationPropertyBag.\nWhen you’re done, the code should look like this:\nView the code on Gist.\nThis will allow you to pass configuration properties to the extension without having to change code.\nTo test this:\nFind serve.json in the config folder.\nReplace the “properties” attribute to pass the configuration we need, from this:\n\u0026#34;properties\u0026#34;: { \u0026#34;testMessage\u0026#34;: \u0026#34;Test message\u0026#34; } to this:\n\u0026#34;properties\u0026#34;: { \u0026#34;ClassificationPropertyBag\u0026#34;: \u0026#34;sc_x005f_BusinessImpact\u0026#34;, \u0026#34;DefaultClassification\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;DefaultHandlingUrl\u0026#34;:\u0026#34;/SitePages/Handling-instructions.aspx\u0026#34; } Launch the extension by using gulp serve and test that the extension still works.\nNote: if you’re planning on debugging the extension, don’t forget that the URL has now changed with these new properties. Follow the instructions earlier to copy the URL to the launch.json file.\nDeploying to production Assuming that everything works, we’re only a few steps away from deploying to production:\nWhen you deploy the solution that includes the extension, SharePoint looks for the default configuration in the elementx.xml and uses whatever it found. Since we changed the default properties, let’s go change the elements.xml file (you can find it in the sharepoint folder) to the following:\n\u0026lt;Elements xmlns=\u0026#34;http://schemas.microsoft.com/sharepoint/\u0026#34;\u0026gt; \u0026lt;CustomAction Title=\u0026#34;ClassificationExtension\u0026#34; Location=\u0026#34;ClientSideExtension.ApplicationCustomizer\u0026#34; ClientSideComponentId=\u0026#34;4017f67b-80c7-4631-b0e5-57bd266bc5c1\u0026#34; ClientSideComponentProperties=\u0026#34;{\u0026#34;ClassificationPropertyBag\u0026#34;:\u0026#34;sc_x005f_BusinessImpact\u0026#34;,\u0026#34;DefaultClassification\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;DefaultHandlingUrl\u0026#34;:\u0026#34;/SitePages/Handling-instructions.aspx\u0026#34;}\u0026#34;\u0026gt; \u0026lt;/CustomAction\u0026gt; \u0026lt;/Elements\u0026gt; From the Terminal pane type:\ngulp bundle --ship Followed by:\ngulp package-solution --ship Navigate to your tenant’s App Catalog (e.g.: https://yourtenant.sharepoint.com/sites/apps) site and navigate to the Apps for SharePoint library.\nFind the folder where the package was created by going to Visual Studio Code and finding the sharepoint | solution folder, right-clicking and selecting Reveal in explorer.\nDrag and drop the classification-extension.sppkg solution package to the Apps for SharePoint library.\nYou should be able to go visit your classified sites and see the extension at work. If it doesn’t work, you may have elected to not automatically deploy the solution to every site when you built the extension. If that’s the case, you’ll need to add the extension to the sites by using Add an App.\nConclusion It took 5 parts to describe how to build the extension, but we successfully created an extension that reads a site’s security classification from its property bag and displays the site’s classification in a label.\nIn our article, we manually set the classification by modifying the property bag, but in the real world, we’ll want to use an approach that automatically classifies sites when they are created.\nThe code for this application (including any modifications I may have made to it since publishing this article) can be found at: https://github.com/hugoabernier/react-application-classification.\nIf you’re interested in seeing how we might approach automatically classification, let me know in the comments and maybe I’ll create another (series of) article(s).\nI hope this helps!?\n","permalink":"http://localhost:1313/posts/displaying-site-information-security-classification-on-every-page-using-a-custom-spfx-extensions-part-v/","tags":null,"title":"Displaying site information security classification on every page using a custom SPFx extensions — Part V"},{"categories":["SPFx"],"contents":"An awesome part of SPFx is the ability to create SharePoint Framework Extensions. At the time of this writing, you can write three types of SPFx extensions:\nApplication customizers: to add scripts to pages and access HTML to predefined (well-known) HTML elements. At the moment, there are only a few page placeholders (like headers and footers), but I’m sure the hard-working SPFx team will announce new ones soon enough. For example, you can add your own customized copyright and privacy notices at the bottom of every modern page. Field customizers: to change the way fields are rendered within a list. For example, you could render your own sparkline chart on every row in a list view. Command sets: to add commands to list view toolbars. For example, you could add a button to perform an action on a selected list item. This articles doesn’t try to explain how to create extensions — there are many great examples on the SharePoint Framework Extensions Samples \u0026amp; Tutorial Materials GitHub repo, and the Overview of SharePoint Framework Extensions tutorial is a pretty place to start if you haven’t played with extensions.\nIn this article, I’ll share a PowerShell script I use to deploy to many sites at once.\nBut first, a few things you need to know:\nTo deploy an extension, you need to first deploy the solution (.sppkg) containing the extension, then add a custom user action to your site, web, or list. In other words, tell the site, web, or list to use the extension that you deployed in the solution. There are no user interfaces to add custom user actions. When you add a custom user action, you can pass configuration properties to your extension. It is possible to add a custom user action to the same site, web, or list more than once (because you could pass different configuration properties every for every instance). You can also specify a JSON file in your solution that will automatically deploy and add the custom user action, but you can’t customize the configuration properties. When you have a SharePoint tenant with lots and lots of sites, and you need to provide different configuration properties for each site, it can become painful to deploy an extension everywhere.\nSure, the solution deployment step is easy, just make sure that your solution-package.json has \u0026quot;skipFeatureDeployment\u0026quot;: true, and SharePoint will kindly offer to automatically deploy your solution to every site for you.\nBut to add an extension as a custom user action and provide configuration properties, you need to call a command or use some scripts:\nYou can use Vardhaman Deshpande’s SPFx-extensions-cli (or command-line interface). You can use CSOM You can use the Pnp PowerShell cmdlets You can use cli-microsoft365 (spo customaction add) When I need to do just one site, I’ll often use the SPFx-extensions-cli, but when I need to do a whole bunch of sites, I like to use the PnP PowerShell cmdlets and PowerShell.\nThe idea came from the RegionsFooterProvisionCustomizer.ps1 script on Paolo Pialorsi’s awesome Regions Footer Application Customizer example, which goes like this:\n$credentials = Get-Credential Connect-PnPOnline \u0026#34;https://.sharepoint.com/sites/\u0026#34; -Credentials $credentials $context = Get-PnPContext $web = Get-PnPWeb $context.Load($web) Execute-PnPQuery $ca = $web.UserCustomActions.Add() $ca.ClientSideComponentId = \u0026#34;67fd1d01-84e8-4fbf-85bd-4b80768c6080\u0026#34; $ca.ClientSideComponentProperties = \u0026#34;{\u0026#34;\u0026#34;SourceTermSetName\u0026#34;\u0026#34;:\u0026#34;\u0026#34;Regions\u0026#34;\u0026#34;}\u0026#34; $ca.Location = \u0026#34;ClientSideExtension.ApplicationCustomizer\u0026#34; $ca.Name = \u0026#34;RegionsFooterCustomAction\u0026#34; $ca.Title = \u0026#34;RegionsFooterCustomizer\u0026#34; $ca.Description = \u0026#34;Custom action for Regions Footer Application Customizer\u0026#34; $ca.Update() $context.Load($web.UserCustomActions) Execute-PnPQuery Now Paolo’s script will only work for his extension, but you can easily go in and change the ClientSideComponentId, ClientSideComponentProperties, Name, Title and Description and make it your own. And if you mistakenly re-run the script for the same site twice, the extension will appear twice.\nBut I wanted to repeat this for each site on one of my tenant’s bazillion sites, and provide different configuration properties — if necessary. I also wanted to be able to re-run the script as many times as I wanted. Finally, I wanted the customer to be able to simply provide a CSV with a list of sites where they wanted the extensions applied.\nSo I made tweaked Paolo’s code to read the list of sites from aCSV file and apply the extension to each site. I borrowed a lot of this script from another example on the SharePoint Framework Extensions Samples \u0026amp; Tutorial Materials GitHub repo, but I can’t find it anymore, so I can’t tell who I should give the credit to. Let me know in the comments if you know who deserves the credits. I’m lazy, but I’m not a thief 🙂\nFirst, make sure that you install the PnP PowerShell cmdlets on your workstation.\nThen create a new PowerShell file and copy this code into it:\n$credentials = Get-Credential # Import the list of sites where we want to apply $sitesToProcess = import-csv \u0026#34;sites.csv\u0026#34; # details of custom action/SPFx extension [guid]$spfxExtId = \u0026#34;[extension id goes here]\u0026#34; [string]$spfxExtName = \u0026#34;[extension name goes here]\u0026#34; [string]$spfxExtTitle = \u0026#34;[extension title goes here]\u0026#34; [string]$spfxExtGroup = \u0026#34;[extension group goes here]\u0026#34; [string]$spfxExtDescription = \u0026#34;[extension description goes here]\u0026#34; [string]$spfxExtLocation = \u0026#34;ClientSideExtension.ApplicationCustomizer\u0026#34; [string]$spfxExtension_Properties = \u0026#34;[properties JSON goes here]\u0026#34; function Add-CustomActionForSPFxExt ([string]$url, $clientContext) { Write-Output \u0026#34;-- About to add custom action to: $url\u0026#34; $rootWeb = $clientContext.Web $clientContext.ExecuteQuery() $customActions = $rootWeb.UserCustomActions $clientContext.Load($customActions) $clientContext.ExecuteQuery() $custAction = $customActions.Add() $custAction.Name = $spfxExtName $custAction.Title = $spfxExtTitle $custAction.Description = $spfxExtDescription $custAction.Location = $spfxExtLocation $custAction.ClientSideComponentId = $spfxExtId $custAction.ClientSideComponentProperties = $spfxExtension_Properties $custAction.Update() $clientContext.ExecuteQuery() Write-Output \u0026#34;-- Successfully added extension\u0026#34; Write-Output \u0026#34;Processed: $url\u0026#34; } function Remove-CustomActionForSPFxExt ([string]$extensionName, [string]$url, $clientContext) { Write-Output \u0026#34;-- About to remove custom action with name \u0026#39;$($extensionName)\u0026#39; from: $url\u0026#34; $actionsToRemove = Get-PnPCustomAction -Web $clientContext.Web | Where-Object {$_.Location -eq $spfxExtLocation -and $_.Name -eq $extensionName } Write-Output \u0026#34;-- Found $($actionsToRemove.Count) extensions with name $extensionName on this web.\u0026#34; foreach ($action in $actionsToRemove) { Remove-PnPCustomAction -Identity $action.Id Write-Output \u0026#34;-- Successfully removed extension $extensionName from web $url.\u0026#34; } Write-Output \u0026#34;Processed: $url\u0026#34; } # -- end functions -- foreach ($site in $sitesToProcess) { $ctx = $null $url = $site.Url try { Connect-PnPOnline -Url $url -Credentials $credentials Write-Output \u0026#34;\u0026#34; Write-Output \u0026#34;Authenticated to: $url\u0026#34; $ctx = Get-PnPContext } catch { Write-Error \u0026#34;Failed to authenticate to $url\u0026#34; Write-Error $_.Exception } # Make sure have a context before continuing if ($ctx) { # Find out if the extension is already added $existingActions = Get-PnPCustomAction -Web $ctx.Web | Where-Object {$_.Location -eq $spfxExtLocation -and $_.Name -eq $spfxExtName } # Count how many existing extensions we found $count = $($existingActions.Count) # Don\u0026#39;t re-install extension if it is already there if ($count -ge 1) { #This assumes that you don\u0026#39;t want to duplicate extensions. If you do, feel free to change the logic below if ($count -eq 1) { Write-Output \u0026#34;Extension is already applied\u0026#34; } else { Write-Warning \u0026#34;Extension is duplicated!\u0026#34; } } else { # Add the extension Add-CustomActionForSPFxExt $url $ctx Write-Output \u0026#34;-- Successfully added extension $spfxExtName to web $url.\u0026#34; } #Add-CustomActionForSPFxExt $url $ctx #Remove-CustomActionForSPFxExt $spfxExtName $site $ctx #Get-PnPCustomAction -Web $ctx.Web | Where-Object {$_.Location -eq \u0026#34;ClientSideExtension.ApplicationCustomizer\u0026#34; } } } Making sure to replace all the [sections in bold] with your own information. I get the name and id from the extension’s manifest.json file.\nThen, create a CSV file containing all the sites you want to get the extension. It should look like this:\nUrl\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/About\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/Calendars\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/Learning\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/FAQs\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/Learning\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/News\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/InformationTechnology\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/MarketingAndCommunications\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/Security\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/EnvironmentalSustainability\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/HealthAndSafety\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/Fundraising\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/Glossary\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/Parking\rhttps://yourtenantgoeshere.sharepoint.com/sites/Employee/purchasing Using your own urls, and saving it as sites.csv in the same folder as the PowerShell script.\nThen you can run the script and it’ll connect to every site and apply the extension and provide the configuration properties, but only if the extension hasn’t already been installed.\nYou could also tweak the script and the CSV to pass different configuration properties for each site, but I’ll reserve it for another post.\nLeave me a comment if you’d like me to post it.\nI hope it helps!\n","permalink":"http://localhost:1313/posts/automatically-deploy-spfx-extension-to-multiple-sites-using-powershell/","tags":["PowerShell"],"title":"Automatically deploy SPFx extension to multiple sites using PowerShell"},{"categories":["SPFx"],"contents":"As the World’s Laziest Developer, I don’t like to invent anything new if I can find something that already exists (and meets my needs).\nThis article is a great example of that mentality. I’m really standing on the shoulder of giants and combining a few links and re-using someone else’s code (with credit, of course) to document what my approach to versioning SPFx packages is, with the hope that it helps someone else.\nThe problem with change logs There are a few ways to communicate changes when working on a project: you can use your commit log diffs, GitHub Releases, use your own log, or any other standard out there.\nThe problem with commit log diffs is that, while comprehensive, they are an automated log of changes that include every-single-change. Log diffs are great for documenting code changes, but if you have a team of developers merging multiple commits every day between versions, they aren’t great at summarizing the noteworthy differences.\nGitHub Releases solves a part of this problem by making it easy to manually (or automatically) creating release notes with git tags. (f you haven’t looked into GitHub Releases, it is awesome — take a look!.\nHowever, GitHub Releases is still not very user-friendly (or manager-friendly).\nYou can always write your own change log format, but why not adopt a format and structure that you can use consistently across projects \u0026amp; teams?\nCHANGELOG.md This is where CHANGELOGs come in. According to Olivier Lacan at KeepAChangeLog.com, a changelog is…\n“a file which contains a curated, chronologically ordered list of notable changes for each version of a project.”\nChangelogs use the markdown syntax to make it easy to maintain. They follow a few principles (again, credit to KeepAChangeLog.com):\nThey are for humans not machines: they should be easy to read and quickly make sense of relevant changes. There should be an entry on every single version: Latest version comes first: List versions in reverse-chronological order, makes it easier to see what matters. Release date of each version is displayed: use a consistent ISO standard date format (e.g.: 2018-04-16). Versions should be linkable: becomes handy when you have a giant changelog. Just wrap your version number with [] (e.g.: [0.0.1]). Changes should be grouped by type of change: group you changes into Added, Changed, Deprecated, Removed, Fixed, and Security. Only include the groups of change types you have (no need to have a Deprecated section if you don’t have any deprecated-type changes). Mention whether you follow Semantic Versioning: You should, by the way. How to use CHANGELOG.md in your SPFx project Add a new file in your project — wherever you put your README.md) and call it CHANGELOG.md.\n(Sure, you can name your changelog whatever you want, but the whole point of a changelog is to make it easy to find the changes on any projects, consistently. Just name it CHANGELOG.md. Trust me.) Paste this template in the new file you created: All notable changes to this project will be documented in this file. The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/) and this project adheres to [Semantic Versioning](http://semver.org/spec/v2.0.0.html). ## [Unreleased] ### Added - (List new added features) ### Changed - (List changes to existing functionality) ### Deprecated - (List soon-to-be removed features) ### Removed - (List features removed in this version) ### Fixed - (List bugs fixed in this version) ### Security - (List vulnerabilities that were fixed in this version) As you work, keep a log of your changes in the Unreleased section, making sure to put the changes under their respective change types. If you want, you can even link to commits, but I don’t. When you change your solution version, create a new section version entry below the Unreleased section. For example, for version 0.0.1 created April 16, 2018, insert the following text below the unreleased version: ## [0.0.1] - 2018-04-16 Remember that not everyone is an American-born, native English speaker. Use the ISO Standard format for dates. The French-Canadian in me thanks you.\nCopy all the changes from Unreleased to your new version section, making sure to remove any empty change type sections. For example, if you don’t have any deprecated changes, remove the ### Deprecated section. This is what the final version of your CHANGELOG.md would look like: All notable changes to this project will be documented in this file. The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/) and this project adheres to [Semantic Versioning](http://semver.org/spec/v2.0.0.html). ## [Unreleased] ## [0.0.1] - 2018-04-16 ### Added - (List new added features) ### Changed - (List changes to existing functionality) ### Removed - (List features removed in this version) ### Fixed - (List bugs fixed in this version) ### Security - (List vulnerabilities that were fixed in this version) Copy back the section templates to the Unreleased section and continue steps 3-7 with every new version. Semantic versioning I have worked with Microsoft technologies as long as I can remember, so it is ingrained in me that every version number should consist of 4 parts: Major, Minor, Build, Revision. For example, 1.0.0.0.\nWhen you package an SPFx solution, the solution version always starts with version 1.0.0.0, and you can’t make it lower than that. (Well, you can, but SharePoint will ignore it and it will become version 1.0.0.0).\nImagine my horror when, one day, I was trying to change the version number of a solution and searched for 1.0.0 and found that the NodeJS package also has its own version, stored in a file called package.json. What’s worse, it didn’t even have 4 parts!\nThe heresy!\nAfter my initial indignation, I decided to research this and found that the versioning schema is called Semantic Versioning (or sem-ver for short). It consists of three mandatory parts: Major, Minor, Patch, plus an optional label for pre-release and build metadata. For example, you could have a version 1.0.0-rc for a release candidate version.\nHmmm, makes it easier to keep track of versions. And it is more human-readable, which is always good.\nTo keep things even more confusing, each web part can have its own version number. While there are valid reasons why you would want to keep the package version, the solution version and the web part versions separate, it quickly becomes impossible to keep track of versions.\nTo keep things clean, it makes sense to keep version numbers in sync.\nnpm version Luckily, makes it easy to update your package.json version by simply calling:\nnpm version \u0026lt;major|minor|patch\u0026gt; Where you specify to increase either the major, minor, or patch version.\nFor example, if you start with a package.json version 0.0.3 and want to increase the major version, you’d call:\nnpm version major Which would produce v1.0.0.\nIf only there was a way to make it this easy to synchronize the package.json version to the package-solution.json version.\nIf only someone way smarter than I had thought of this…\nSync npm version with package-solution.json It turns out there is such a person: Stefan Bauer!\nIn his blog post, he shares a way to add a Gulp function that automatically syncs the package.json version with the package-solution.json.\n(Thanks Stefan for being awesome!)\nTo add this Gulp function, do the following steps:\nIn your SPFx project, open gulpfile.js\nBefore build.initialize(gulp); add my slightly modified version of Stefan‘s code. If it works, credit goes to Stefan. If it fails, it was my changes.\nlet syncVersionsSubtask = build.subTask(\u0026#39;version-sync\u0026#39;, function (gulp, buildOptions, done) { this.log(\u0026#39;Synching versions\u0026#39;); // import gulp utilits to write error messages const gutil = require(\u0026#39;gulp-util\u0026#39;); // import file system utilities form nodeJS const fs = require(\u0026#39;fs\u0026#39;); // read package.json var pkgConfig = require(\u0026#39;./package.json\u0026#39;); // read configuration of web part solution file var pkgSolution = require(\u0026#39;./config/package-solution.json\u0026#39;); // log old version this.log(\u0026#39;package-solution.json version:\\t\u0026#39; + pkgSolution.solution.version); // Generate new MS compliant version number var newVersionNumber = pkgConfig.version.split(\u0026#39;-\u0026#39;)[0] + \u0026#39;.0\u0026#39;; if (pkgSolution.solution.version !== newVersionNumber) { // assign newly generated version number to web part version pkgSolution.solution.version = newVersionNumber; // log new version this.log(\u0026#39;New package-solution.json version:\\t\u0026#39; + pkgSolution.solution.version); // write changed package-solution file fs.writeFile(\u0026#39;./config/package-solution.json\u0026#39;, JSON.stringify(pkgSolution, null, 4)); } else { this.log(\u0026#39;package-solution.json version is up-to-date\u0026#39;); } done(); }); let syncVersionTask = build.task(\u0026#39;version-sync\u0026#39;, syncVersionsSubtask); build.rig.addPreBuildTask(syncVersionTask); Save your file\nThe final gulpfile.js should look like this:\n\u0026#39;use strict\u0026#39;; const gulp = require(\u0026#39;gulp\u0026#39;); const build = require(\u0026#39;@microsoft/sp-build-web\u0026#39;); build.addSuppression(`Warning - [sass] The local CSS class \u0026#39;ms-Grid\u0026#39; is not camelCase and will not be type-safe.`); //BEGIN: Added code for version-sync let syncVersionsSubtask = build.subTask(\u0026#39;version-sync\u0026#39;, function (gulp, buildOptions, done) { this.log(\u0026#39;Synching versions\u0026#39;); // import gulp utilits to write error messages const gutil = require(\u0026#39;gulp-util\u0026#39;); // import file system utilities form nodeJS const fs = require(\u0026#39;fs\u0026#39;); // read package.json var pkgConfig = require(\u0026#39;./package.json\u0026#39;); // read configuration of web part solution file var pkgSolution = require(\u0026#39;./config/package-solution.json\u0026#39;); // log old version this.log(\u0026#39;package-solution.json version:\\t\u0026#39; + pkgSolution.solution.version); // Generate new MS compliant version number var newVersionNumber = pkgConfig.version.split(\u0026#39;-\u0026#39;)[0] + \u0026#39;.0\u0026#39;; if (pkgSolution.solution.version !== newVersionNumber) { // assign newly generated version number to web part version pkgSolution.solution.version = newVersionNumber; // log new version this.log(\u0026#39;New package-solution.json version:\\t\u0026#39; + pkgSolution.solution.version); // write changed package-solution file fs.writeFile(\u0026#39;./config/package-solution.json\u0026#39;, JSON.stringify(pkgSolution, null, 4)); } else { this.log(\u0026#39;package-solution.json version is up-to-date\u0026#39;); } done(); }); let syncVersionTask = build.task(\u0026#39;version-sync\u0026#39;, syncVersionsSubtask); build.rig.addPreBuildTask(syncVersionTask); //END: Added code for version-sync build.initialize(gulp); Next time you build your package, the Gulp task version-sync will grab the package.json version (which you updated using npm version, right?) and will update package-solution.json, adding an extra zero at the end of the version number to Microsoftify the version.\nWhen you get the version number, go update your CHANGELOG.md file by moving the changes from [unreleased] to a new section with the new version number you just created.\nSync package-solution.json version with webpart.manifest.json version So far, we have done the following:\nCreated a CHANGELOG.md of unreleased changes Maintained version number using npm version Synchronized package.json versions with package-solution.json versions Updated your CHANGELOG.md to describe the changes you made But there is still a little annoying thing: the web part versions (stored in webpart.manifest.json, where webpart is the name of your web part) can be different than the package.json and package-solution.json.\nTurns out that it is pretty easy to fix:\nIn your SPFx solution, open webpart.manifest.json where webpart is the name of your web part. For example, HelloWorldWebPart.manifest.json for HelloWorldWebPart. Find the “version” line and replace whatever version you have in there for “*”, making it: \u0026#34;version\u0026#34;: \u0026#34;*\u0026#34;, Doing so will cause the version of the webpart.manifest.json to match the package-solution.json version.\n(Turns out that the latest version of SPFx documents this by adding the following comment on the line above “version”: “*”.\n// The \u0026#34;*\u0026#34; signifies that the version should be taken from the package.json \u0026#34;version\u0026#34;: \u0026#34;*\u0026#34;, How cool is that?!\nConclusion By using CHANGELOG.md to keep track of changes between versions, and using semantic versioning for your versions, you can make it pretty easy to document your changes across versions.\nBy using npm version, you can easily maintain the semantic version of your package.json.\nBy using Stefan’s cool version-sync Gulp command, you can easily sync your package.json version and your package-solution.json.\nBy using “version”: “*”, you can synchronize your package-solution.json and your webpart.manifest.json versions.\nFinally, by not reinventing the wheel and by leveraging the hard-work of other people, you can do it all with very little effort!\nI hope this helps you?!\n","permalink":"http://localhost:1313/posts/spfx-semantic-versioning-and-changelog-md/","tags":null,"title":"SPFx, Semantic versioning, and CHANGELOG.md"},{"categories":["SharePoint"],"contents":"This is an easy one, but I keep Googling it.\nWhen you create an SPFx web part, the default Property Pane automatically submits changes to the web part. There is no “Apply” button.\nDefault property pane — no Apply button\nBut sometimes you don’t want changes to the property pane fields to automatically apply.\nAll you have to do is to add this method in your web part class (just before\ngetPropertyPaneConfiguration is where I like to place it):\nprotected get disableReactivePropertyChanges(): boolean { return true; } When you refresh the web part, your property pane will sport a fancy Apply button!\nProperty pane with an Apply button\nProperty changes in the property pane will only get applied when users hit Apply.\nThat’s it!\n","permalink":"http://localhost:1313/posts/creating-spfx-web-part-property-panes-with-an-apply-button/","tags":["SPFx"],"title":"Creating SPFx web part property panes with an Apply button"},{"categories":["SharePoint"],"contents":"Hub sites? Unless you’re a SharePoint geek like me, you may not have been eagerly waiting for this new feature announced at Ignite 2017 in Orlando. Hub sites are a special site template that allows you to logically group team sites and communication sites under another site, with a shared navigation, theme, and logo.\nHub sites will also aggregate news and activities from any sites associated to it, and you can search within a scope of a hub site and it’s associated sites.\nThe picture Microsoft used in their announcement explains it best:\nThe Problem The typical corporate intranet is often nothing more than a re-hash of the company’s corporate organization structure, blindly copied to a web site accessible to employees. If that intranet is done using SharePoint or Office 365, it’ll consist of a bunch of site collections with some sub-sites.\n(By the way, I completely disagree with using the org chart for your intranet structure, but I’ll save it for another blog post).\nWhat happens when your company restructures for (insert official reason here)? Let’s say that you had a whole bunch of Divisions, each with their own site (or site collection) and they completely change the divisions every quarter (like the CEO of a former client of mine liked to do).\nWhat happens when the IT, Finance, and HR team are no longer in the same groups?\nYou end up having to either:\na) Move sites around, break a lot of people’s favorite shortcuts and links; or\nb) Leave everything the way it is and give up hope\nOr, you could create a structure that doesn’t need to change with the org-chart-of-the-week by using a flat structure. Since the new modern sites in Office 365, it is a lot easier to create groups, team sites and communication sites in a rather “flat” structure (every site is created in their own site collection, located under https://_yourtenant_.sharepoint.com/sites/ or https://yourtenant.sharepoint.com/teams/).\nSo, now you end up with a flat site structure that doesn’t need to change when your information architecture changes again, but there is no easy way to navigate through this flat structure.\nYou can hack together some sort of global navigation with custom code and/or scripts, but every time someone wants to add a new site, you need to change the code.\nThe Solution SharePoint Hub Sites allows you to continue creating a flat structure and logically group sites together in a semi-hierarchical fashion.\nThere are caveats:\nAs of this writing, you can only have up to 50 hub sites on your tenant. You can add sites to hub sites, but you can’t add hub sites to hub sites. And don’t get me started about hub sites under hub sites under hub sites. You need to be a SharePoint admin to create hub sites, but you can control who can add sites to what hub sites. You’ll need to do some PowerShell. Demonstration We are going to create an Employee Matters hub, which will be the go-to place for employees to find resources related to being an employee of [XYZ Corp].\nIt will contain the following sites:\nBenefits Jobs Training Before you start Download and install the latest SharePoint Online Management Shell.\nCreate “Sub” Communication Sites From your Office 365 environment, create a Communication site by going to the **waffle\n**| SharePoint | Create site.\nFrom the Create site panel, select Communication site. It also works with Team sites. Choose the Topic layout and name the site Benefits. Give it a description if you’d like. Select Finish.\nRepeat steps 1-3 above with Jobs and Training (or anything else you’d like to do), making sure to remember the URL of every site you create (you’ll need to go back to the sites you just created later). Create a (future) hub site Repeat steps 1-3 above again, but this time call the site Employee Matters. This will be the site that will be converted to a hub site. Make note of the site’s URL.\nRegister the hub site Start the SharePoint Online Management Shell.\nFrom the PowerShell command prompt, type:\nConnect-SPOService -URL https://-admin.sharepoint.com where is your own SharePoint tenant. Note that we’re connecting to the Admin site, not the regular .sharepoint.com site.\nOnce connected (you’ll be prompted to login, probably), type:\nRegister-SPOHubSite -site https://.sharepoint.com/sites/employeematters …making sure to use the URL of the Employee Matters you created earlier. Note that this time, we are not using the -admin.sharepoint.com domain, just the regular .sharepoint.com domain.\nIf all goes well, you’ll get something like this:\nID : 2be153d3-0fe8-4fb8-8fa0-b41dfdd8bd3f Title : Employee Matters SiteId : 2be153d3-0fe8-4fb8-8fa0-b41dfdd8bd3f SiteUrl : https://.sharepoint.com/sites/EmployeeMatters LogoUrl : Description : Permissions : Memorize the GUIDs. Just kidding! You can pretty much ignore the response — as long as it didn’t start spewing red text, you’re doing fine.\nAt this point, if you got an error saying Register-SPOHubSite is not a valid command, you probably haven’t installed the latest version of the SharePoint Online Management Shell.\nIf it gives you an error saying that hub sites aren’t yet supported, go have a big nap and try again tomorrow.\nYou can go visit your newly created hub site. It should look like this:\nIt doesn’t look much different than any other communication site, but it has an extra navigation bit at the top:\nIf your site hasn’t updated yet, wait a little bit. Some of the changes take up to 2 hours, but every time I have done this, it was instant.\nOptional: Set your hub site icon and description You don’t have to do this, but it is generally a good idea to label your sites and give them a custom icon. To do so:\nUpload an icon of your choice to a library of your choice (for this demo, I created a document library called Site Assets in the Employee Matters site). Make note of the URL to the icon. The icon should be 64×64 pixels.\nFrom the SharePoint Online Management Shell thingy, enter the following:\nSet-SPOHubSite -Identity https://.sharepoint.com/sites/employeematters -LogoUrl https://.sharepoint.com/sites/employeematters/site%20assets/employeemattersicon.png -Description \u0026#34;Find resources for employees\u0026#34; Making sure to replace the LogoUrl for the URL to the icon you want (and making sure that you put whatever description you want for the site hub).\nYour site hub will eventually get updated. Go take a look.\nBy the way, there is a user interface to change the site hub logo, but there isn’t one to change the description. You can get to it by following these steps:\nUsing your browser, go to your site hub. From the site hub home page, select the settings gear and select Hub site settings\nFrom the Edit hub site settings pane that appears, you can change the icon or the site hub title. Not the description.\nSelect Save and your changes will (eventually) be reflected. Associate “sub” sites to hub site using your browser Go to the Benefits site you created what seems like a million years ago. From the settings gear icon, select **Site information\n** From Edit site information pane that appears, select the Employee Matters hub site from the Hub site association, then select Save.\nNote thaNote that, in real life, only users who have been granted the rights to join a site will be able to do this — but that’s another blog post. Also, note that changing the hub site will change the site theme to match the hub site and add its navigation (as is clearly indicated on the Edit site information pane). You should notice that your Benefits site will now have the Employee Matters navigation added at the top. That means it worked.\nAssociate “sub” site to hub site using PowerShell From the SharePoint Online Management Shell, enter the following:\nAdd-SPOHubSiteAssociation -Site https://.sharepoint.com/sites/Jobs -HubSite https://.sharepoint.com/sites/EmployeeMatters It will associate the Jobs site to the Employee Matters hub. Note that the -Site parameter is the site you want to add to the hub site, while the -HubSite parameter is the hub site.\nUse either the PowerShell method or the browser method to add the Training site to the hub site.\nAdd links to the hub site navigation The sites associated to your hub site now sport the new fancy hub site navigation, showing Employee Matters, but you’ll notice that the navigation did not get updated to show the newly associated sites.\nTo fix this:\nGo to your hub site’s home page. You can do so by clicking on Employee Matters from any of your associated sites. From the hub navigation (top left corner of the hub site, where it says Employee Matters) select Edit. From the navigation editing pane that appears, select the + button to add a new link.\nIn the Add a link pop-up that appears, enter the URL to the Jobs site in the Address field, and type in Jobs for the Display name, then select OK. Repeat until you have added Jobs, Benefits, and Training then hit Save. Your hub navigation will contain links to each associated site.\nNews, activities and search results from the hub home will include results from all associated sites, provided that the current user has permissions to each site. It takes a while before the results appear, but they will!\nConclusion Hub sites are going to be a great addition to SharePoint in Office 365. They aren’t going to solve every navigation issues, but they are certainly a step in the right direction.\nThere is still a lot to cover with theming and security, but that’s probably enough for today.\n","permalink":"http://localhost:1313/posts/getting-to-know-sharepoint-hub-sites/","tags":null,"title":"Getting to know SharePoint Hub sites"},{"categories":["SharePoint"],"contents":"The Problem I was trying to write a little app to programmatically download files from a SharePoint instance on Office 365 to a local folder on my hard-drive/network file share — something I’ve probably done a thousand times — using this code:\n/* * This code assumes you already have filled the following variables * earlier in the code * Code has been simplified for */ var webUrl = \u0026#34;https://yourtenantgoeshere.sharepoint.com/site/yoursitename\u0026#34;; var username = \u0026#34;yourusernamegoeshere@yourtenantgoeshere.com\u0026#34;; var password = \u0026#34;pleasedonteverwriteyourpasswordincode\u0026#34;; var listTitle = \u0026#34;yourdocumentlibrarytitle\u0026#34;; var destinationFolder = @\u0026#34;C:temp\u0026#34;; var securePassword = new SecureString(); //Convert string to secure string foreach (char c in password) { securePassword.AppendChar(c); } securePassword.MakeReadOnly(); using (var context = new ClientContext(webUrl)) { // Connect using credentials -- use the approach that suits you context.Credentials = new SharePointOnlineCredentials(userName, securePassword); // Get a reference to the SharePoint site var web = context.Web; // Get a reference to the document library var list = context.Web.Lists.GetByTitle(listTitle); // Get the list of files you want to export. I\u0026#39;m using a query // to find all files where the \u0026#34;Status\u0026#34; column is marked as \u0026#34;Approved\u0026#34; var camlQuery = new CamlQuery { ViewXml = @\u0026#34; Approved 1000 \u0026#34; }; // Retrieve the items matching the query var items = list.GetItems(camlQuery); // Make sure to load the File in the context otherwise you won\u0026#39;t go far context.Load(items, items2 =\u0026gt; items2.IncludeWithDefaultProperties (item =\u0026gt; item.DisplayName, item =\u0026gt; item.File)); // Execute the query and actually populate the results context.ExecuteQuery(); // Iterate through every file returned and save them foreach (var item in items) { // THIS IS THE LINE THAT CAUSES ISSUES!!!!!!!! using (FileInformation fileInfo = Microsoft.SharePoint.Client.File.OpenBinaryDirect(context, item.File.ServerRelativeUrl)) { // Combine destination folder with filename -- don\u0026#39;t concatenate // it\u0026#39;s just wrong! var filePath = Path.Combine(destinationFolder, item.File.Name); // Erase existing files, cause that\u0026#39;s how I roll if (System.IO.File.Exists(filePath)) { System.IO.File.Delete(filePath); } // Create the file using (var fileStream = System.IO.File.Create(filePath)) { fileInfo.Stream.CopyTo(fileStream); } } } } The “usings” at the top of the file were:\nusing System; using System.Collections.Generic; using System.Security; using Microsoft.SharePoint.Client; using System.IO; And every time I ran the code, I’d get a really annoying error on the OpenBinaryDirect method:\nthis property cannot be set after writing has started.\nIf I wasn’t already bald, I would be after searching everywhere how to solve it.\nThe Solution As it turns out, when I created my console application, I followed these steps:\nLaunch Visual Studio File | New Project… | Console Application and saved the project On the newly created project, added Microsoft.SharePoint.Client references by right-clicking on the project’s References and selecting Manage Nuget Packages and selecting the first nuget reference that had Microsoft.SharePoint.Client that looked semi-official — you know, the one that says “by Microsoft” Wrote the code and quickly ran into the aforementioned error.\nAs it turns out, I needed to use the Nuget package that said Microsoft.SharePointOnline.CSOM (also by Microsoft).\nI removed the Microsoft.SharePoint.Client Nuget package and added Microsoft.SharePointOnline.CSOM instead. It automatically included the right Microsoft.SharePoint.Client and Microsoft.SharePoint.Client.RunTime dependencies it needed.\nAfter recompiling, it worked perfectly.\nThe way it should have done several hours ago.\nAfter a lot of cursing, mostly directed at myself, I decided to write this down as a #NoteToSelf. Next time I run into this issue, at least I’ll find a blog entry describing the solution.\nMy own.\n","permalink":"http://localhost:1313/posts/saving-files-from-a-sharepoint-document-library-to-a-local-folder-using-csom/","tags":["CSOM"],"title":"Saving files from a SharePoint document library to a local folder using CSOM"},{"categories":["Surface"],"contents":"","permalink":"http://localhost:1313/posts/getting-windows-10-build-10122-to-install-on-a-surface-pro-3/","tags":null,"title":"Getting Windows 10 Build 10122 to install on a Surface Pro 3"},{"categories":["SharePoint"],"contents":"You may never need this tip, but I recently ran into an issue where my article page’s Edit Page button stopped working in SharePoint 2013 (probably something I messed up with the master page… I’ll fix it later). I Googled and Binged everywhere, but couldn’t find how to switch an article page to edit mode.\nAll you need to do is append your page URL with the following parameters:\n?DisplayMode=Design\u0026amp;ControlMode=Edit\nSo if your page is:\nhttp://mysharepointserver/pages/tdamnededitbutton.aspx You would write:\nhttp://mysharepointserver/pages/tdamnededitbutton.aspx?DisplayMode=Design\u0026amp;ControlMode=Edit\nI hope it saves someone else from having to search.\nDid anyone have any problems with the Edit button not working? Share below!\n","permalink":"http://localhost:1313/posts/view-an-article-page-in-edit-mode-using-query-string-parameters/","tags":null,"title":"View an Article Page in Edit Mode using Query String Parameters"},{"categories":["Microsoft 365"],"contents":"In Office 365, you can upload profile pictures for each user’s contact card. The contact card will appear in Outlook, SharePoint, Lync, Word, Excel, PowerPoint… well, in any Office product that displays contact cards 🙂\nSample Contact Card in Outlook 2013\nWhile this isn’t a new concept to Office 2013, and this feature is available in On Premise installations, these articles focus on Office 365.\nThere are two ways to achieve this:\nVia the web-based graphical user interface; or Using PowerShell You’ll find all sorts of confusing information online regarding the dimensions, file size and format restrictions. I found that either of the two methods described in this article will work with almost any file sizes and dimensions.\nThere are, however, some best practices.\nChoose Square Photos Choose a square image as the source (i.e.: same width and height), otherwise the picture will be cropped when you upload and you may end up with portions of people’s faces being cropped out.\nExample of a great picture, wrong shape… (Photo Credit: rubenshito)\nWill be automatically cropped to:\nAuto-cropped result.\nGo for the Max Lync 2010 supported the ability to view contact photos which were stored as part of the thumbnailPhoto attribute in Active Directory, meaning that pictures could only be 48×48 pixels.\nHowever, Lync 2013 can now store photos in user’s Exchange 2013 mailbox, meaning that it supports images of up to 648×648 pixels.\nWhen you upload a photo to Exchange 2013, it automatically creates 3 versions of the photo:\nSizeUsed By48×48Active Directory thumbnailPhoto attribute96×96Outlook 2013 Web App\nOutlook 2013\nLync Web App\nLync 2013\nSharePoint648×648Lync 2013\nLync Web App\rIf you only upload a smaller image (e.g.: 48×48), it’ll be scaled to 96×96 and 648×648, resulting in photos that look fuzzy. However, if you upload photos that are already 648×648. The system will automatically generate 48×48 and 96×96 thumbnails for you.\nOriginalAuto-Scaled (Photo Credit: rubenshito)\nNote that if you upload a photo to the thumbnailPhoto in Active Directory, the photo will not be updated in Exchange. If you are lazy like me, you probably want to update photos only once.\nMy recommendation (and Microsoft’s) is to use 648×648 pixels, 24-bit JPG images.\n","permalink":"http://localhost:1313/posts/uploading-high-resolution-user-profile-pictures-in-office-365/","tags":null,"title":"Uploading High Resolution User Profile Pictures in Office 365"},{"categories":["Microsoft 365"],"contents":"Although you can use the web-based GUI to update profile pictures on Office 365, sometimes you need to upload many pictures at once.\nThis is where PowerShell comes in handy. Here are the instructions to upload high resolution user profile pictures to Office 365 using PowerShell commands:\nLaunch the PowerShell console using Run as Administrator\nIn the PowerShell console, provide your Office 365 credentials by typing the following command and hitting Enter:\n```powershell\r$Creds = Get-Credential\r```\rYou’ll be prompted to enter your credentials. Go ahead, I’ll wait.\nCreate a PowerShell remote session to Office 365/Exchange by entering the following command and hitting Enter:\n```powershell\r$RemoteSession = New-PSSession -ConfigurationName Microsoft.Exchange\r-ConnectionUri https://outlook.office365.com/powershell-liveid/?proxymethod=rps -Credential $Creds -Authentication Basic\r-AllowRedirection\r```\rInitialize the remote session by entering:\nImport-PSSession $RemoteSession\nDoing so will import all the required Cmdlets to manage Exchange – this is why you don’t need to install any Exchange PowerShell modules or anything like that.\nIf you get an error at this time telling you something about script execution not being enabled (or something like that, I never read the actual error message). Enter the following command to enable remotely signed commands:\n```powershell\rSet-ExecutionPolicy RemoteSigned\r```\rThe above command is only required if you got an error. Some articles may say that you need to set the execution policy to Unrestricted, but – being paranoid – I prefer to limit the policy to remote signed commands. If you got an error while trying to set the execution policy, it is most likely because you forgot to **Run as Administrator** as indicated in step 1 above. Tsk tsk, pay attention! Once you set the execution policy without an error, try **step 5** again.\rOnce the session has been imported, you’ll have new Cmdlets available. The most important one being Set-UserPhoto. But before you need to call Set-UserPhoto, you need to load the photo you want to use. To do so, call:\n```powershell\r$photo = \u0026quot;pathofyourphoto.jpg\u0026quot;\r```\rMaking sure to replace **pathofyourphoto** with the file name for the picture you wish to upload\rNow you can set the user’s photo by using the following command:\n```powershell\rSet-UserPhoto -Identity \u0026quot;testuser@xyz.com\u0026quot; -PictureData ([System.IO.File]::ReadAllBytes($photo)) -Confirm:$false\r```\rMaking sure to replace **\u0026lt;testuser@xyz.com\u0026gt;** with the user id of the profile you wish to change.\rRepeat steps 8-9 until all your pictures have been uploaded. One of these days, I’ll write a script to iterate through all the pictures. Let me know in comments below if you need that script.\nWhen done, call\n```powershell\rRemove-PSSession $RemoteSession\r```\rFor your convenience, here is the whole PowerShell script:\n$Creds = Get-Credential $RemoteSession = New-PSSession -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/?proxymethod=rps -Credential $Creds -Authentication Basic –AllowRedirection Import-PSSession $RemoteSession $photo = “pathofyourphoto.jpg” Set-UserPhoto -Identity “testuser@xyz.com” -PictureData ([System.IO.File]::ReadAllBytes($photo)) -Confirm:$false Remove-PSSession $RemoteSession If you used the PowerShell script above, you’ll be able to upload 648×648 pixel photos without any issues for you and other users. If you didn’t use this script, but you get the following error:\nThe remote server returned an error: (413) Request Entity Too Large …it is most likely because you connected to your remote PowerShell session without setting the proxy method. Compare the two PowerShell commands:\nWorks Only with Photos 10Kb or Below$RemoteSession = New-PSSession -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/ -Credential $Creds -Authentication Basic –AllowRedirectionCopyWorks with Photos Greater than 10Kb$RemoteSession = New-PSSession -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/?proxymethod=rps -Credential $Creds -Authentication Basic –AllowRedirectionCopy\rI hope the information above helped?\nFor more information Set-UserPhoto CmdLet\nhttp://technet.microsoft.com/en-us/library/jj218694.aspx\nConfiguring the use of high-resolution photos in Microsoft Lync Server 2013\nhttps://technet.microsoft.com/en-us/library/jj688150.aspx\n","permalink":"http://localhost:1313/posts/uploading-high-resolution-user-profile-pictures-to-office-365-using-powershell/","tags":["PowerShell"],"title":"Uploading High Resolution User Profile Pictures to Office 365 Using PowerShell"},{"categories":["Microsoft 365"],"contents":"In my previous article, I discuss best practices on how to choose high resolution photos to use in user profile pictures for Office 365.\nYou can upload user profile pictures using the Office 365 Admin Center. It may be obvious to everyone else, but I didn’t know this was possible until a very astute coop student showed me this feature (after I spent an afternoon telling him the only way to do this was to use PowerShell). So, to save you the embarrassment, here is the web-based method:\nFrom the Office 365 Admin Center (https://portal.office.com) go to Admin then Exchange. In the Exchange Admin Center click on your profile picture and select Another User…. from the drop-down menu that appears.\nThe system will pop-up a window listing users in your Office 365 subscription. Search for the user you wish to change and click OK.\nThe system will pop-up the user’s profile, indicating that you are working on behalf of the user you selected. Scroll all the way to the bottom and select Edit Information…\nAnother pop-up window (seriously, disable your pop-up blockers if you haven’t done so already) will the editable user profile page, starting with the Photo section. Click on Change\nClick on Browse… and select the picture you wish to use.\nClick Save to dismiss the window. Close all the pop-ups. Repeat for all user profiles pictures you wish to upload. If you have Lync open, you should see the results almost immediately.\nThe profile picture will also be automatically synched with SharePoint user profiles (at least, that has been my experience… please feel free to comment below if you’ve had different results).\nWhile it may be handy to do a few pictures, if you have to update hundreds of user profile pictures, you may want to use the PowerShell method.\n","permalink":"http://localhost:1313/posts/uploading-user-profile-pictures-using-the-web-based-gui/","tags":null,"title":"Uploading User Profile Pictures using the Web-Based GUI"},{"categories":["SketchFlow"],"contents":"Introduction Microsoft Expression Blend makes it easy launch animations. It is easy to launch animations with a few clicks… But sometimes, you need to launch animations from within your code – for example, to launch an animation after performing calculations. This article will show you how to play an animation from within your code.\nBackground If you’re doing a SketchFlow application, you can right-click the control you want to launch the animation, select Play SketchFlow Animation, and select the animation you want to trigger.\nIf you’re not doing a SketchFlow application, you can drag a ControlStoryboardAnimation from the Assets pane unto the control you want to trigger the animation.\nFrom the Properties pane, you can then select what Storyboard you want to launch, and what event (EventName) you want to launch the animation:\nBut when you want to use code to launch an animation, you need to take a few more steps. Here’s how:\nFirst: create your animation (d’uh!)\nRemember the name you gave the animation. If you can’t remember it, open your XAML and look for a Storyboard element. The name of the animation can be found in the x:Key tag.\n\u0026lt;UserControl.Resources\u0026gt;\n…\n\u0026lt;/UserControl.Resources\u0026gt;\nNow crack open the code-behind page. We’ll write some code!\nMake sure that you have System.Windows.Media.Animation in your using section. If not, add it by adding the following line:\nusing System.Windows.Media.Animation;\nIn the event handler where you want to launch your animation, declare an object of type Storyboard and load it from the page’s resources, using the animation name as the key, as follows:\nStoryboard myAnimationStoryboard = this.Resources[“myAnimation”] as Storyboard;\nAfter you verified that the object you retrieved isn’t null, you can start the animation by calling the Storyboard’s Begin method.\nmyAnimationStoryboard.Begin();\nThat’s really all there is to it. I personally like to declare the Storyboard as a member variable and assign it in the constructor, then I use the Storyboard object anywhere I need it.\nOnce you’ve developed XAML applications, you’ll think this article is silly, but until you do, I hope that it’ll save you some searching!\nMore Information Learn more about the Storyboard class, including how to control a storyboard at http://msdn.microsoft.com/library/system.windows.media.animation.storyboard.aspx\nLearn about How to Control a Storyboard After It Starts at http://msdn.microsoft.com/library/ms741997.aspx\n","permalink":"http://localhost:1313/posts/play-sketchflowwpf-animation-programmatically/","tags":["WPF"],"title":"Play SketchFlow/WPF Animation Programmatically"},{"categories":["InfoPath"],"contents":"A new feature in SharePoint 2010 is that you can customize the form that is displayed when you create a new list item by using InfoPath. That means that you can leverage the extensive capabilities of InfoPath without having to write a single line of code – and that’s a good thing, if you’re as lazy as I am and want to avoid resorting to custom code.\nTo do it, you simply go to the list you want to customize, click on Customize Form, and edit the InfoPath form that was thoughtfully created for you. Once you’ve published the form, you’ve got a custom form for your list. SharePoint will automatically create a read-only version of your form for displaying items. Easy!\nBut what if you want to have a different form when creating new items, one for editing items, and one for viewing items? In this post, I’ll show you how to create a different InfoPath view for New, Edit, and Display forms, as pictured below:\nHere are the steps:\nGo to the list you want to customize (or create a new list). For this example, I’ll be customizing an Issues List.\nSelect the List ribbon and, from the Customize List group, click on Customize Form.\nSharePoint will open InfoPath and load the default form. You can customize it just like you would any other InfoPath form. Just make sure you stick to browser compatible settings, because the form will be loaded using InfoPath Forms Services.\nFor this sample, I’ll add a title to every form and change the colours of each form (so that we can prove that it works). Let’s treat this form as the New Item form:\nWe’ll create two more views (one for Edit, and one for Display). To make things less confusing, let’s rename the view. We do this by changing the view’s properties using the following steps: switch to the Page Design ribbon, and select Properties from the Views group.\nIn the View Properties dialog, change the View name to New item, then click OK. This step is optional, but it’ll make things less confusing later – trust me.\nBack on the New item view, select the entire content of the form and copy to the clipboard. We’ll paste the form’s content in a new view.\nFrom the Page Design gallery, click on New View from the Views group.\nName the new view Edit view.\nIn the newly created view, select all content and replace it with the content you copied from the previous view. Make your changes to the Edit view – in my case, I changed the title of the form to Edit Issue and changed the colour.\nRepeat steps 7 to 10, but this time name the newly create view Display view\nI’ll change the title and colour of the Display view\nSharePoint will automatically display the Display view in read-only mode. Since I’m a control freak, I prefer to create my own read-only view by going to every control, and converting them to Calculated value fields by right-clicking each control, select Change Control and picking Calculated value.\nThe final Display Issue view look like this:\nYou can add as many views as you want using the same approach, and use rules to select the appropriate view. For example, you may want to display a different view based on a user’s role. If you do, you probably don’t want users to be able to switch between views. To do so, go to the View Properties for each view, and de-select the Show on the View menu when filling out this form option.\nSo far, all we did was setting up the different views for New, Edit, and Display. The next few steps will configure which view to use when displaying, editing, and creating a new item. Let’s start with the Display form; go to the File menu, then select Info and Advanced form options.\nIn the Form Options dialog, select the Web Browser category. In the Display View area, select the view you want to appear when displaying an item (in our sample, it is called Display view).\nUnfortunately, to set the Edit and New views, we don’t have an easy option. We can, however, use Form Rules to change the view when the form is loaded. If the IDfield is blank, we’ll assume that the user is creating a New item. If the ID field is not blank, the user is Editing the item. To do this, switch to the Data ribbon, and click on Form Load in the Rules group.\nInfoPath will open the Rules pane (on the right side of the form). Click on New then Action.\nName the rule Switch to New View. Then click on default condition (None – Rule runs when form is loaded) to create a new condition.\nFrom the Condition dialog, change myFields to Select a field or group… then pick ID from the dialog that pops-up. Click OK to return to the Condition dialog.\nChange is equal to to is blank then click OK.\nBack at the Rules pane, find Run these actions and select Add then Switch views.\nFrom the Rules Details dialog, select New item from the View field and click OK.\nYou may be tempted to switch the view to Edit Item when the IDis not blank, but – if you think about it – this condition would occur both when viewing an item and editing an item. It would make SharePoint switch to the Edit item view when you try to display an item, even if you did set up the Display view option step 17. Don’t do it!\nAll you need to do now is publish the form! To do so, select the File menu, Info then Quick Publish.\nWait until InfoPath does its thing. You’ll get a message indicating that publishing was successful.\nClick on Open the SharePoint list in the browser to test your new forms. Here are the final results:\nWhat gets displayed with creating a new item:\nWhen displaying an item:\nWhen editing an item:\nThat’s it! Of course, in real life, you’d probably want to customize each form a bit more than just changing the title and colour.\nHope this helps!\n","permalink":"http://localhost:1313/posts/customizing-new-edit-and-display-list-forms-using-infopath/","tags":["SharePoint"],"title":"Customizing New, Edit, and Display List Forms using InfoPath"}]